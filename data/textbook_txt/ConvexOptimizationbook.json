{"Filename": "ConvexOptimizationbook", "Pages": [{"Page_number": 1, "text": "convex optimization\n\n "}, {"Page_number": 2, "text": " "}, {"Page_number": 3, "text": "convex optimization\n\nstephen boyd\n\ndepartment of electrical engineering\nstanford university\n\nlieven vandenberghe\n\nelectrical engineering department\nuniversity of california, los angeles\n\n "}, {"Page_number": 4, "text": "cambridge university press\ncambridge, new york, melbourne, madrid, cape town, singapore, s\u02dcao paolo, delhi\n\ncambridge university press\nthe edinburgh building, cambridge, cb2 8ru, uk\n\npublished in the united states of america by cambridge university press, new york\n\nhttp://www.cambridge.org\ninformation on this title: www.cambridge.org/9780521833783\n\nc(cid:13) cambridge university press 2004\nthis publication is in copyright. subject to statutory exception\nand to the provisions of relevant collective licensing agreements,\nno reproduction of any part may take place without\nthe written permission of cambridge university press.\n\nfirst published 2004\nseventh printing with corrections 2009\n\nprinted in the united kingdom at the university press, cambridge\n\na catalogue record for this publication is available from the british library\n\nlibrary of congress cataloguing-in-publication data\n\nboyd, stephen p.\nconvex optimization / stephen boyd & lieven vandenberghe\n\np. cm.\n\nincludes bibliographical references and index.\nisbn 0 521 83378 7\n1. mathematical optimization. 2. convex functions. i. vandenberghe, lieven. ii. title.\n\nqa402.5.b69 2004\n519.6\u2013dc22\n\n2003063284\n\nisbn 978-0-521-83378-3 hardback\n\ncambridge university press has no responsiblity for the persistency or accuracy of urls\nfor external or third-party internet websites referred to in this publication, and does not\nguarantee that any content on such websites is, or will remain, accurate or appropriate.\n\n "}, {"Page_number": 5, "text": "for\n\nanna, nicholas, and nora\n\ndani\u00a8el and margriet\n\n "}, {"Page_number": 6, "text": " "}, {"Page_number": 7, "text": "contents\n\npreface\n\nxi\n\n1 introduction\n\n1\n1\n1.1 mathematical optimization . . . . . . . . . . . . . . . . . . . . . . . .\n4\n1.2 least-squares and linear programming . . . . . . . . . . . . . . . . . .\n7\n1.3 convex optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . .\n9\n1.4 nonlinear optimization . . . . . . . . . . . . . . . . . . . . . . . . . .\n1.5 outline . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 11\n1.6 notation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 14\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 16\n\ni theory\n\n19\n\n2 convex sets\n\n21\n2.1 affine and convex sets . . . . . . . . . . . . . . . . . . . . . . . . . . . 21\n2.2 some important examples . . . . . . . . . . . . . . . . . . . . . . . . . 27\n2.3 operations that preserve convexity . . . . . . . . . . . . . . . . . . . . 35\n2.4 generalized inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . 43\n2.5 separating and supporting hyperplanes . . . . . . . . . . . . . . . . . . 46\n2.6 dual cones and generalized inequalities . . . . . . . . . . . . . . . . . . 51\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60\n\n3 convex functions\n\n67\n. . . . . . . . . . . . . . . . . . . . . . 67\n3.1 basic properties and examples\n3.2 operations that preserve convexity . . . . . . . . . . . . . . . . . . . . 79\n3.3 the conjugate function . . . . . . . . . . . . . . . . . . . . . . . . . . 90\n3.4 quasiconvex functions . . . . . . . . . . . . . . . . . . . . . . . . . . . 95\n. . . . . . . . . . . . . . . . . . 104\n3.5 log-concave and log-convex functions\n. . . . . . . . . . . . 108\n3.6 convexity with respect to generalized inequalities\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 112\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 113\n\n "}, {"Page_number": 8, "text": "viii\n\ncontents\n\n4 convex optimization problems\n\n127\n. . . . . . . . . . . . . . . . . . . . . . . . . . 127\n4.1 optimization problems\n4.2 convex optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 136\n4.3 linear optimization problems . . . . . . . . . . . . . . . . . . . . . . . 146\n4.4 quadratic optimization problems . . . . . . . . . . . . . . . . . . . . . 152\n4.5 geometric programming . . . . . . . . . . . . . . . . . . . . . . . . . . 160\n4.6 generalized inequality constraints . . . . . . . . . . . . . . . . . . . . . 167\n4.7 vector optimization . . . . . . . . . . . . . . . . . . . . . . . . . . . . 174\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 189\n\n5 duality\n\n215\n5.1 the lagrange dual function . . . . . . . . . . . . . . . . . . . . . . . . 215\n5.2 the lagrange dual problem . . . . . . . . . . . . . . . . . . . . . . . . 223\n5.3 geometric interpretation . . . . . . . . . . . . . . . . . . . . . . . . . 232\n5.4 saddle-point interpretation . . . . . . . . . . . . . . . . . . . . . . . . 237\n5.5 optimality conditions . . . . . . . . . . . . . . . . . . . . . . . . . . . 241\n. . . . . . . . . . . . . . . . . . . 249\n5.6 perturbation and sensitivity analysis\n5.7 examples . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 253\n. . . . . . . . . . . . . . . . . . . . . . . . . 258\n5.8 theorems of alternatives\n5.9 generalized inequalities . . . . . . . . . . . . . . . . . . . . . . . . . . 264\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 272\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 273\n\nii applications\n\n289\n\n6 approximation and fitting\n\n291\n6.1 norm approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . . 291\n. . . . . . . . . . . . . . . . . . . . . . . . . . . 302\n6.2 least-norm problems\n6.3 regularized approximation . . . . . . . . . . . . . . . . . . . . . . . . 305\n6.4 robust approximation . . . . . . . . . . . . . . . . . . . . . . . . . . . 318\n6.5 function fitting and interpolation . . . . . . . . . . . . . . . . . . . . . 324\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 343\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 344\n\n7 statistical estimation\n\n351\n7.1 parametric distribution estimation . . . . . . . . . . . . . . . . . . . . 351\n7.2 nonparametric distribution estimation . . . . . . . . . . . . . . . . . . 359\n7.3 optimal detector design and hypothesis testing . . . . . . . . . . . . . 364\n. . . . . . . . . . . . . . . . . . . . . 374\n7.4 chebyshev and chernoff bounds\n7.5 experiment design . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 384\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 392\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 393\n\n "}, {"Page_number": 9, "text": "contents\n\nix\n\n8 geometric problems\n\n397\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . 397\n8.1 projection on a set\n8.2 distance between sets . . . . . . . . . . . . . . . . . . . . . . . . . . . 402\n8.3 euclidean distance and angle problems . . . . . . . . . . . . . . . . . . 405\n. . . . . . . . . . . . . . . . . . . . . . . . 410\n8.4 extremal volume ellipsoids\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 416\n8.5 centering\n8.6 classification . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 422\n8.7 placement and location . . . . . . . . . . . . . . . . . . . . . . . . . . 432\n8.8 floor planning . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 438\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 446\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 447\n\niii algorithms\n\n455\n\n9 unconstrained minimization\n\n457\n. . . . . . . . . . . . . . . . . . 457\n9.1 unconstrained minimization problems\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . 463\n9.2 descent methods\n9.3 gradient descent method . . . . . . . . . . . . . . . . . . . . . . . . . 466\n9.4 steepest descent method . . . . . . . . . . . . . . . . . . . . . . . . . 475\n9.5 newton\u2019s method . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 484\n9.6 self-concordance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 496\nimplementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 508\n9.7\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 513\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 514\n\n10 equality constrained minimization\n\n521\n. . . . . . . . . . . . . . . 521\n10.1 equality constrained minimization problems\n10.2 newton\u2019s method with equality constraints . . . . . . . . . . . . . . . . 525\n10.3 infeasible start newton method . . . . . . . . . . . . . . . . . . . . . . 531\n10.4 implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 542\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 556\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 557\n\n11 interior-point methods\n\n561\n. . . . . . . . . . . . . . 561\n11.1 inequality constrained minimization problems\n11.2 logarithmic barrier function and central path . . . . . . . . . . . . . . 562\n11.3 the barrier method . . . . . . . . . . . . . . . . . . . . . . . . . . . . 568\n11.4 feasibility and phase i methods . . . . . . . . . . . . . . . . . . . . . . 579\n11.5 complexity analysis via self-concordance . . . . . . . . . . . . . . . . . 585\n. . . . . . . . . . . . . . . . . . 596\n11.6 problems with generalized inequalities\n11.7 primal-dual interior-point methods . . . . . . . . . . . . . . . . . . . . 609\n11.8 implementation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 615\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 621\nexercises . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 623\n\n "}, {"Page_number": 10, "text": "x\n\nappendices\n\ncontents\n\n631\n\na mathematical background\n\n633\na.1 norms . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 633\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 637\na.2 analysis\n. . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 639\na.3 functions\na.4 derivatives . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 640\na.5 linear algebra . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 645\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 652\n\nb problems involving two quadratic functions\n\n653\nb.1 single constraint quadratic optimization . . . . . . . . . . . . . . . . . 653\nb.2 the s-procedure . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 655\nb.3 the field of values of two symmetric matrices . . . . . . . . . . . . . . 656\nb.4 proofs of the strong duality results . . . . . . . . . . . . . . . . . . . . 657\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 659\n\nc numerical linear algebra background\n\n661\nc.1 matrix structure and algorithm complexity . . . . . . . . . . . . . . . . 661\nc.2 solving linear equations with factored matrices . . . . . . . . . . . . . . 664\nc.3 lu, cholesky, and ldlt factorization . . . . . . . . . . . . . . . . . . 668\nc.4 block elimination and schur complements . . . . . . . . . . . . . . . . 672\nc.5 solving underdetermined linear equations . . . . . . . . . . . . . . . . . 681\nbibliography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 684\n\nreferences\n\nnotation\n\nindex\n\n685\n\n697\n\n701\n\n "}, {"Page_number": 11, "text": "preface\n\nthis book is about convex optimization, a special class of mathematical optimiza-\ntion problems, which includes least-squares and linear programming problems. it\nis well known that least-squares and linear programming problems have a fairly\ncomplete theory, arise in a variety of applications, and can be solved numerically\nvery efficiently. the basic point of this book is that the same can be said for the\nlarger class of convex optimization problems.\n\nwhile the mathematics of convex optimization has been studied for about a\ncentury, several related recent developments have stimulated new interest in the\ntopic. the first is the recognition that interior-point methods, developed in the\n1980s to solve linear programming problems, can be used to solve convex optimiza-\ntion problems as well. these new methods allow us to solve certain new classes\nof convex optimization problems, such as semidefinite programs and second-order\ncone programs, almost as easily as linear programs.\n\nthe second development is the discovery that convex optimization problems\n(beyond least-squares and linear programs) are more prevalent in practice than\nwas previously thought. since 1990 many applications have been discovered in\nareas such as automatic control systems, estimation and signal processing, com-\nmunications and networks, electronic circuit design, data analysis and modeling,\nstatistics, and finance. convex optimization has also found wide application in com-\nbinatorial optimization and global optimization, where it is used to find bounds on\nthe optimal value, as well as approximate solutions. we believe that many other\napplications of convex optimization are still waiting to be discovered.\n\nthere are great advantages to recognizing or formulating a problem as a convex\noptimization problem. the most basic advantage is that the problem can then be\nsolved, very reliably and efficiently, using interior-point methods or other special\nmethods for convex optimization. these solution methods are reliable enough to be\nembedded in a computer-aided design or analysis tool, or even a real-time reactive\nor automatic control system. there are also theoretical or conceptual advantages\nof formulating a problem as a convex optimization problem. the associated dual\nproblem, for example, often has an interesting interpretation in terms of the original\nproblem, and sometimes leads to an efficient or distributed method for solving it.\n\nwe think that convex optimization is an important enough topic that everyone\nwho uses computational mathematics should know at least a little bit about it.\nin our opinion, convex optimization is a natural next topic after advanced linear\nalgebra (topics like least-squares, singular values), and linear programming.\n\n "}, {"Page_number": 12, "text": "xii\n\npreface\n\ngoal of this book\n\nfor many general purpose optimization methods, the typical approach is to just\ntry out the method on the problem to be solved. the full benefits of convex\noptimization, in contrast, only come when the problem is known ahead of time to\nbe convex. of course, many optimization problems are not convex, and it can be\ndifficult to recognize the ones that are, or to reformulate a problem so that it is\nconvex.\n\nour main goal is to help the reader develop a working knowledge of\nconvex optimization, i.e., to develop the skills and background needed\nto recognize, formulate, and solve convex optimization problems.\n\ndeveloping a working knowledge of convex optimization can be mathematically\ndemanding, especially for the reader interested primarily in applications. in our\nexperience (mostly with graduate students in electrical engineering and computer\nscience), the investment often pays off well, and sometimes very well.\n\nthere are several books on linear programming, and general nonlinear pro-\ngramming, that focus on problem formulation, modeling, and applications. several\nother books cover the theory of convex optimization, or interior-point methods and\ntheir complexity analysis. this book is meant to be something in between, a book\non general convex optimization that focuses on problem formulation and modeling.\nwe should also mention what this book is not. it is not a text primarily about\nconvex analysis, or the mathematics of convex optimization; several existing texts\ncover these topics well. nor is the book a survey of algorithms for convex optimiza-\ntion. instead we have chosen just a few good algorithms, and describe only simple,\nstylized versions of them (which, however, do work well in practice). we make no\nattempt to cover the most recent state of the art in interior-point (or other) meth-\nods for solving convex problems. our coverage of numerical implementation issues\nis also highly simplified, but we feel that it is adequate for the potential user to\ndevelop working implementations, and we do cover, in some detail, techniques for\nexploiting structure to improve the efficiency of the methods. we also do not cover,\nin more than a simplified way, the complexity theory of the algorithms we describe.\nwe do, however, give an introduction to the important ideas of self-concordance\nand complexity analysis for interior-point methods.\n\naudience\n\nthis book is meant for the researcher, scientist, or engineer who uses mathemat-\nical optimization, or more generally, computational mathematics. this includes,\nnaturally, those working directly in optimization and operations research, and also\nmany others who use optimization, in fields like computer science, economics, fi-\nnance, statistics, data mining, and many fields of science and engineering. our\nprimary focus is on the latter group, the potential users of convex optimization,\nand not the (less numerous) experts in the field of convex optimization.\n\nthe only background required of the reader is a good knowledge of advanced\ncalculus and linear algebra. if the reader has seen basic mathematical analysis (e.g.,\nnorms, convergence, elementary topology), and basic probability theory, he or she\nshould be able to follow every argument and discussion in the book. we hope that\n\n "}, {"Page_number": 13, "text": "preface\n\nxiii\n\nreaders who have not seen analysis and probability, however, can still get all of the\nessential ideas and important points. prior exposure to numerical computing or\noptimization is not needed, since we develop all of the needed material from these\nareas in the text or appendices.\n\nusing this book in courses\n\nwe hope that this book will be useful as the primary or alternate textbook for\nseveral types of courses. since 1995 we have been using drafts of this book for\ngraduate courses on linear, nonlinear, and convex optimization (with engineering\napplications) at stanford and ucla. we are able to cover most of the material,\nthough not in detail, in a one quarter graduate course. a one semester course allows\nfor a more leisurely pace, more applications, more detailed treatment of theory,\nand perhaps a short student project. a two quarter sequence allows an expanded\ntreatment of the more basic topics such as linear and quadratic programming (which\nare very useful for the applications oriented student), or a more substantial student\nproject.\n\nthis book can also be used as a reference or alternate text for a more traditional\ncourse on linear and nonlinear optimization, or a course on control systems (or\nother applications area), that includes some coverage of convex optimization. as\nthe secondary text in a more theoretically oriented course on convex optimization,\nit can be used as a source of simple practical examples.\n\nacknowledgments\n\nwe have been developing the material for this book for almost a decade. over the\nyears we have benefited from feedback and suggestions from many people, including\nour own graduate students, students in our courses, and our colleagues at stanford,\nucla, and elsewhere. unfortunately, space limitations and shoddy record keeping\ndo not allow us to name everyone who has contributed. however, we wish to\nparticularly thank a. aggarwal, v. balakrishnan, a. bernard, b. bray, r. cottle,\na. d\u2019aspremont, j. dahl, j. dattorro, d. donoho, j. doyle, l. el ghaoui, p. glynn,\nm. grant, a. hansson, t. hastie, a. lewis, m. lobo, z.-q. luo, m. mesbahi, w.\nnaylor, p. parrilo, i. pressman, r. tibshirani, b. van roy, l. xiao, and y. ye.\nj. jalden and a. d\u2019aspremont contributed the time-frequency analysis example\nin \u00a76.5.4, and the consumer preference bounding example in \u00a76.5.5, respectively.\np. parrilo suggested exercises 4.4 and 4.56. newer printings benefited greatly from\nigal sason\u2019s meticulous reading of the book.\n\nwe want to single out two others for special acknowledgment. arkadi ne-\nmirovski incited our original interest in convex optimization, and encouraged us\nto write this book. we also want to thank kishan baheti for playing a critical\nrole in the development of this book. in 1994 he encouraged us to apply for a na-\ntional science foundation combined research and curriculum development grant,\non convex optimization with engineering applications, and this book is a direct (if\ndelayed) consequence.\n\nstephen boyd\nlieven vandenberghe\n\nstanford, california\nlos angeles, california\n\n "}, {"Page_number": 14, "text": " "}, {"Page_number": 15, "text": "chapter 1\n\nintroduction\n\nin this introduction we give an overview of mathematical optimization, focusing on\nthe special role of convex optimization. the concepts introduced informally here\nwill be covered in later chapters, with more care and technical detail.\n\n1.1 mathematical optimization\n\na mathematical optimization problem, or just optimization problem, has the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 bi,\n\ni = 1, . . . , m.\n\n(1.1)\n\nhere the vector x = (x1, . . . , xn) is the optimization variable of the problem, the\nfunction f0 : rn \u2192 r is the objective function, the functions fi\n: rn \u2192 r,\ni = 1, . . . , m, are the (inequality) constraint functions, and the constants b1, . . . , bm\nare the limits, or bounds, for the constraints. a vector x\u22c6 is called optimal, or a\nsolution of the problem (1.1), if it has the smallest objective value among all vectors\nthat satisfy the constraints: for any z with f1(z) \u2264 b1, . . . , fm(z) \u2264 bm, we have\nf0(z) \u2265 f0(x\u22c6).\nwe generally consider families or classes of optimization problems, characterized\nby particular forms of the objective and constraint functions. as an important\nexample, the optimization problem (1.1) is called a linear program if the objective\nand constraint functions f0, . . . , fm are linear, i.e., satisfy\n\nfi(\u03b1x + \u03b2y) = \u03b1fi(x) + \u03b2fi(y)\n\n(1.2)\nfor all x, y \u2208 rn and all \u03b1, \u03b2 \u2208 r. if the optimization problem is not linear, it is\ncalled a nonlinear program.\nthis book is about a class of optimization problems called convex optimiza-\ntion problems. a convex optimization problem is one in which the objective and\nconstraint functions are convex, which means they satisfy the inequality\n\nfi(\u03b1x + \u03b2y) \u2264 \u03b1fi(x) + \u03b2fi(y)\n\n(1.3)\n\n "}, {"Page_number": 16, "text": "2\n\n1 introduction\n\nfor all x, y \u2208 rn and all \u03b1, \u03b2 \u2208 r with \u03b1 + \u03b2 = 1, \u03b1 \u2265 0, \u03b2 \u2265 0. comparing (1.3)\nand (1.2), we see that convexity is more general than linearity: inequality replaces\nthe more restrictive equality, and the inequality must hold only for certain values\nof \u03b1 and \u03b2. since any linear program is therefore a convex optimization problem,\nwe can consider convex optimization to be a generalization of linear programming.\n\n1.1.1 applications\n\nthe optimization problem (1.1) is an abstraction of the problem of making the best\npossible choice of a vector in rn from a set of candidate choices. the variable x\nrepresents the choice made; the constraints fi(x) \u2264 bi represent firm requirements\nor specifications that limit the possible choices, and the objective value f0(x) rep-\nresents the cost of choosing x. (we can also think of \u2212f0(x) as representing the\nvalue, or utility, of choosing x.) a solution of the optimization problem (1.1) corre-\nsponds to a choice that has minimum cost (or maximum utility), among all choices\nthat meet the firm requirements.\n\nin portfolio optimization, for example, we seek the best way to invest some\ncapital in a set of n assets. the variable xi represents the investment in the ith\nasset, so the vector x \u2208 rn describes the overall portfolio allocation across the set of\nassets. the constraints might represent a limit on the budget (i.e., a limit on the\ntotal amount to be invested), the requirement that investments are nonnegative\n(assuming short positions are not allowed), and a minimum acceptable value of\nexpected return for the whole portfolio. the objective or cost function might be\na measure of the overall risk or variance of the portfolio return.\nin this case,\nthe optimization problem (1.1) corresponds to choosing a portfolio allocation that\nminimizes risk, among all possible allocations that meet the firm requirements.\n\nanother example is device sizing in electronic design, which is the task of choos-\ning the width and length of each device in an electronic circuit. here the variables\nrepresent the widths and lengths of the devices. the constraints represent a va-\nriety of engineering requirements, such as limits on the device sizes imposed by\nthe manufacturing process, timing requirements that ensure that the circuit can\noperate reliably at a specified speed, and a limit on the total area of the circuit. a\ncommon objective in a device sizing problem is the total power consumed by the\ncircuit. the optimization problem (1.1) is to find the device sizes that satisfy the\ndesign requirements (on manufacturability, timing, and area) and are most power\nefficient.\n\nin data fitting, the task is to find a model, from a family of potential models,\nthat best fits some observed data and prior information. here the variables are the\nparameters in the model, and the constraints can represent prior information or\nrequired limits on the parameters (such as nonnegativity). the objective function\nmight be a measure of misfit or prediction error between the observed data and\nthe values predicted by the model, or a statistical measure of the unlikeliness or\nimplausibility of the parameter values. the optimization problem (1.1) is to find\nthe model parameter values that are consistent with the prior information, and give\nthe smallest misfit or prediction error with the observed data (or, in a statistical\n\n "}, {"Page_number": 17, "text": "1.1 mathematical optimization\n\n3\n\nframework, are most likely).\n\nan amazing variety of practical problems involving decision making (or system\ndesign, analysis, and operation) can be cast in the form of a mathematical opti-\nmization problem, or some variation such as a multicriterion optimization problem.\nindeed, mathematical optimization has become an important tool in many areas.\nit is widely used in engineering, in electronic design automation, automatic con-\ntrol systems, and optimal design problems arising in civil, chemical, mechanical,\nand aerospace engineering. optimization is used for problems arising in network\ndesign and operation, finance, supply chain management, scheduling, and many\nother areas. the list of applications is still steadily expanding.\n\nfor most of these applications, mathematical optimization is used as an aid to\na human decision maker, system designer, or system operator, who supervises the\nprocess, checks the results, and modifies the problem (or the solution approach)\nwhen necessary. this human decision maker also carries out any actions suggested\nby the optimization problem, e.g., buying or selling assets to achieve the optimal\nportfolio.\n\na relatively recent phenomenon opens the possibility of many other applications\nfor mathematical optimization. with the proliferation of computers embedded in\nproducts, we have seen a rapid growth in embedded optimization.\nin these em-\nbedded applications, optimization is used to automatically make real-time choices,\nand even carry out the associated actions, with no (or little) human intervention or\noversight. in some application areas, this blending of traditional automatic control\nsystems and embedded optimization is well under way; in others, it is just start-\ning. embedded real-time optimization raises some new challenges:\nin particular,\nit requires solution methods that are extremely reliable, and solve problems in a\npredictable amount of time (and memory).\n\n1.1.2 solving optimization problems\n\na solution method for a class of optimization problems is an algorithm that com-\nputes a solution of the problem (to some given accuracy), given a particular problem\nfrom the class, i.e., an instance of the problem. since the late 1940s, a large effort\nhas gone into developing algorithms for solving various classes of optimization prob-\nlems, analyzing their properties, and developing good software implementations.\nthe effectiveness of these algorithms, i.e., our ability to solve the optimization prob-\nlem (1.1), varies considerably, and depends on factors such as the particular forms\nof the objective and constraint functions, how many variables and constraints there\nare, and special structure, such as sparsity. (a problem is sparse if each constraint\nfunction depends on only a small number of the variables).\n\neven when the objective and constraint functions are smooth (for example,\npolynomials) the general optimization problem (1.1) is surprisingly difficult to solve.\napproaches to the general problem therefore involve some kind of compromise, such\nas very long computation time, or the possibility of not finding the solution. some\nof these methods are discussed in \u00a71.4.\nthere are, however, some important exceptions to the general rule that most\noptimization problems are difficult to solve. for a few problem classes we have\n\n "}, {"Page_number": 18, "text": "4\n\n1 introduction\n\neffective algorithms that can reliably solve even large problems, with hundreds or\nthousands of variables and constraints. two important and well known examples,\ndescribed in \u00a71.2 below (and in detail in chapter 4), are least-squares problems and\nlinear programs. it is less well known that convex optimization is another exception\nto the rule: like least-squares or linear programming, there are very effective\nalgorithms that can reliably and efficiently solve even large convex problems.\n\n1.2 least-squares and linear programming\n\nin this section we describe two very widely known and used special subclasses of\nconvex optimization: least-squares and linear programming. (a complete technical\ntreatment of these problems will be given in chapter 4.)\n\n1.2.1 least-squares problems\n\na least-squares problem is an optimization problem with no constraints (i.e., m =\n0) and an objective which is a sum of squares of terms of the form at\n\ni x \u2212 bi:\n\nminimize\n\nf0(x) = kax \u2212 bk2\n\ni=1(at\n\ni x \u2212 bi)2.\n\n(1.4)\n\nhere a \u2208 rk\u00d7n (with k \u2265 n), at\noptimization variable.\n\ni are the rows of a, and the vector x \u2208 rn is the\n\n2 =pk\n\nsolving least-squares problems\n\nthe solution of a least-squares problem (1.4) can be reduced to solving a set of\nlinear equations,\n\n(at a)x = at b,\n\nso we have the analytical solution x = (at a)\u22121at b. for least-squares problems\nwe have good algorithms (and software implementations) for solving the problem to\nhigh accuracy, with very high reliability. the least-squares problem can be solved\nin a time approximately proportional to n2k, with a known constant. a current\ndesktop computer can solve a least-squares problem with hundreds of variables, and\nthousands of terms, in a few seconds; more powerful computers, of course, can solve\nlarger problems, or the same size problems, faster. (moreover, these solution times\nwill decrease exponentially in the future, according to moore\u2019s law.) algorithms\nand software for solving least-squares problems are reliable enough for embedded\noptimization.\n\nin many cases we can solve even larger least-squares problems, by exploiting\nsome special structure in the coefficient matrix a. suppose, for example, that the\nmatrix a is sparse, which means that it has far fewer than kn nonzero entries. by\nexploiting sparsity, we can usually solve the least-squares problem much faster than\norder n2k. a current desktop computer can solve a sparse least-squares problem\n\n "}, {"Page_number": 19, "text": "1.2 least-squares and linear programming\n\n5\n\nwith tens of thousands of variables, and hundreds of thousands of terms, in around\na minute (although this depends on the particular sparsity pattern).\n\nfor extremely large problems (say, with millions of variables), or for problems\nwith exacting real-time computing requirements, solving a least-squares problem\ncan be a challenge. but in the vast majority of cases, we can say that existing\nmethods are very effective, and extremely reliable. indeed, we can say that solving\nleast-squares problems (that are not on the boundary of what is currently achiev-\nable) is a (mature) technology, that can be reliably used by many people who do\nnot know, and do not need to know, the details.\n\nusing least-squares\n\nthe least-squares problem is the basis for regression analysis, optimal control, and\nmany parameter estimation and data fitting methods. it has a number of statistical\ninterpretations, e.g., as maximum likelihood estimation of a vector x, given linear\nmeasurements corrupted by gaussian measurement errors.\n\nrecognizing an optimization problem as a least-squares problem is straightfor-\nward; we only need to verify that the objective is a quadratic function (and then\ntest whether the associated quadratic form is positive semidefinite). while the\nbasic least-squares problem has a simple fixed form, several standard techniques\nare used to increase its flexibility in applications.\n\nin weighted least-squares, the weighted least-squares cost\n\nkxi=1\n\nwi(at\n\ni x \u2212 bi)2,\n\nwhere w1, . . . , wk are positive, is minimized.\n(this problem is readily cast and\nsolved as a standard least-squares problem.) here the weights wi are chosen to\nreflect differing levels of concern about the sizes of the terms at\ni x \u2212 bi, or simply\nto influence the solution.\nin a statistical setting, weighted least-squares arises\nin estimation of a vector x, given linear measurements corrupted by errors with\nunequal variances.\n\nanother technique in least-squares is regularization, in which extra terms are\nadded to the cost function. in the simplest case, a positive multiple of the sum of\nsquares of the variables is added to the cost function:\n\nkxi=1\n\n(at\ni x \u2212 bi)2 + \u03c1\n\nx2\ni ,\n\nnxi=1\n\nwhere \u03c1 > 0. (this problem too can be formulated as a standard least-squares\nproblem.) the extra terms penalize large values of x, and result in a sensible\nsolution in cases when minimizing the first sum only does not. the parameter \u03c1 is\nchosen by the user to give the right trade-off between making the original objective\ni not too big. regularization\ncomes up in statistical estimation when the vector x to be estimated is given a prior\ndistribution.\n\ni x\u2212 bi)2 small, while keepingpn\n\nfunctionpk\n\ni=1(at\n\ni=1 x2\n\nweighted least-squares and regularization are covered in chapter 6; their sta-\n\ntistical interpretations are given in chapter 7.\n\n "}, {"Page_number": 20, "text": "6\n\n1 introduction\n\n1.2.2 linear programming\n\nanother important class of optimization problems is linear programming, in which\nthe objective and all constraint functions are linear:\n\nminimize\nsubject to at\n\nct x\ni x \u2264 bi,\n\ni = 1, . . . , m.\n\n(1.5)\n\nhere the vectors c, a1, . . . , am \u2208 rn and scalars b1, . . . , bm \u2208 r are problem pa-\nrameters that specify the objective and constraint functions.\n\nsolving linear programs\n\nthere is no simple analytical formula for the solution of a linear program (as there\nis for a least-squares problem), but there are a variety of very effective methods for\nsolving them, including dantzig\u2019s simplex method, and the more recent interior-\npoint methods described later in this book. while we cannot give the exact number\nof arithmetic operations required to solve a linear program (as we can for least-\nsquares), we can establish rigorous bounds on the number of operations required\nto solve a linear program, to a given accuracy, using an interior-point method. the\ncomplexity in practice is order n2m (assuming m \u2265 n) but with a constant that is\nless well characterized than for least-squares. these algorithms are quite reliable,\nalthough perhaps not quite as reliable as methods for least-squares. we can easily\nsolve problems with hundreds of variables and thousands of constraints on a small\ndesktop computer, in a matter of seconds. if the problem is sparse, or has some\nother exploitable structure, we can often solve problems with tens or hundreds of\nthousands of variables and constraints.\n\nas with least-squares problems, it is still a challenge to solve extremely large\nlinear programs, or to solve linear programs with exacting real-time computing re-\nquirements. but, like least-squares, we can say that solving (most) linear programs\nis a mature technology. linear programming solvers can be (and are) embedded in\nmany tools and applications.\n\nusing linear programming\n\nsome applications lead directly to linear programs in the form (1.5), or one of\nseveral other standard forms. in many other cases the original optimization prob-\nlem does not have a standard linear program form, but can be transformed to an\nequivalent linear program (and then, of course, solved) using techniques covered in\ndetail in chapter 4.\n\nas a simple example, consider the chebyshev approximation problem:\n\nminimize maxi=1,...,k |at\n\ni x \u2212 bi|.\n\n(1.6)\n\nhere x \u2208 rn is the variable, and a1, . . . , ak \u2208 rn, b1, . . . , bk \u2208 r are parameters\nthat specify the problem instance. note the resemblance to the least-squares prob-\nlem (1.4). for both problems, the objective is a measure of the size of the terms\nat\ni x \u2212 bi. in least-squares, we use the sum of squares of the terms as objective,\nwhereas in chebyshev approximation, we use the maximum of the absolute values.\n\n "}, {"Page_number": 21, "text": "1.3 convex optimization\n\n7\n\none other important distinction is that the objective function in the chebyshev\napproximation problem (1.6) is not differentiable; the objective in the least-squares\nproblem (1.4) is quadratic, and therefore differentiable.\n\nthe chebyshev approximation problem (1.6) can be solved by solving the linear\n\nprogram\n\nt\n\nminimize\nsubject to at\ni x \u2212 t \u2264 bi,\n\u2212at\ni x \u2212 t \u2264 \u2212bi,\nwith variables x \u2208 rn and t \u2208 r.\n(the details will be given in chapter 6.)\nsince linear programs are readily solved, the chebyshev approximation problem is\ntherefore readily solved.\n\ni = 1, . . . , k,\n\ni = 1, . . . , k\n\n(1.7)\n\nanyone with a working knowledge of linear programming would recognize the\nchebyshev approximation problem (1.6) as one that can be reduced to a linear\nprogram. for those without this background, though, it might not be obvious that\nthe chebyshev approximation problem (1.6), with its nondifferentiable objective,\ncan be formulated and solved as a linear program.\n\nwhile recognizing problems that can be reduced to linear programs is more\ninvolved than recognizing a least-squares problem, it is a skill that is readily ac-\nquired, since only a few standard tricks are used. the task can even be partially\nautomated; some software systems for specifying and solving optimization prob-\nlems can automatically recognize (some) problems that can be reformulated as\nlinear programs.\n\n1.3 convex optimization\n\na convex optimization problem is one of the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 bi,\n\ni = 1, . . . , m,\n\n(1.8)\n\nwhere the functions f0, . . . , fm : rn \u2192 r are convex, i.e., satisfy\n\nfi(\u03b1x + \u03b2y) \u2264 \u03b1fi(x) + \u03b2fi(y)\n\nfor all x, y \u2208 rn and all \u03b1, \u03b2 \u2208 r with \u03b1 + \u03b2 = 1, \u03b1 \u2265 0, \u03b2 \u2265 0. the least-squares\nproblem (1.4) and linear programming problem (1.5) are both special cases of the\ngeneral convex optimization problem (1.8).\n\n1.3.1 solving convex optimization problems\n\nthere is in general no analytical formula for the solution of convex optimization\nproblems, but (as with linear programming problems) there are very effective meth-\nods for solving them. interior-point methods work very well in practice, and in some\ncases can be proved to solve the problem to a specified accuracy with a number of\n\n "}, {"Page_number": 22, "text": "8\n\n1 introduction\n\noperations that does not exceed a polynomial of the problem dimensions. (this is\ncovered in chapter 11.)\n\nwe will see that interior-point methods can solve the problem (1.8) in a num-\nber of steps or iterations that is almost always in the range between 10 and 100.\nignoring any structure in the problem (such as sparsity), each step requires on the\norder of\n\nmax{n3, n2m, f}\n\noperations, where f is the cost of evaluating the first and second derivatives of the\nobjective and constraint functions f0, . . . , fm.\n\nlike methods for solving linear programs, these interior-point methods are quite\nreliable. we can easily solve problems with hundreds of variables and thousands\nof constraints on a current desktop computer, in at most a few tens of seconds. by\nexploiting problem structure (such as sparsity), we can solve far larger problems,\nwith many thousands of variables and constraints.\n\nwe cannot yet claim that solving general convex optimization problems is a\nmature technology, like solving least-squares or linear programming problems. re-\nsearch on interior-point methods for general nonlinear convex optimization is still\na very active research area, and no consensus has emerged yet as to what the best\nmethod or methods are. but it is reasonable to expect that solving general con-\nvex optimization problems will become a technology within a few years. and for\nsome subclasses of convex optimization problems, for example second-order cone\nprogramming or geometric programming (studied in detail in chapter 4), it is fair\nto say that interior-point methods are approaching a technology.\n\n1.3.2 using convex optimization\n\nusing convex optimization is, at least conceptually, very much like using least-\nsquares or linear programming. if we can formulate a problem as a convex opti-\nmization problem, then we can solve it efficiently, just as we can solve a least-squares\nproblem efficiently. with only a bit of exaggeration, we can say that, if you formu-\nlate a practical problem as a convex optimization problem, then you have solved\nthe original problem.\n\nthere are also some important differences. recognizing a least-squares problem\nis straightforward, but recognizing a convex function can be difficult. in addition,\nthere are many more tricks for transforming convex problems than for transforming\nlinear programs. recognizing convex optimization problems, or those that can\nbe transformed to convex optimization problems, can therefore be challenging.\nthe main goal of this book is to give the reader the background needed to do\nthis. once the skill of recognizing or formulating convex optimization problems is\ndeveloped, you will find that surprisingly many problems can be solved via convex\noptimization.\n\nthe challenge, and art, in using convex optimization is in recognizing and for-\nmulating the problem. once this formulation is done, solving the problem is, like\nleast-squares or linear programming, (almost) technology.\n\n "}, {"Page_number": 23, "text": "1.4 nonlinear optimization\n\n9\n\n1.4 nonlinear optimization\n\nnonlinear optimization (or nonlinear programming) is the term used to describe\nan optimization problem when the objective or constraint functions are not linear,\nbut not known to be convex. sadly, there are no effective methods for solving\nthe general nonlinear programming problem (1.1). even simple looking problems\nwith as few as ten variables can be extremely challenging, while problems with a\nfew hundreds of variables can be intractable. methods for the general nonlinear\nprogramming problem therefore take several different approaches, each of which\ninvolves some compromise.\n\n1.4.1 local optimization\n\nin local optimization, the compromise is to give up seeking the optimal x, which\nminimizes the objective over all feasible points. instead we seek a point that is\nonly locally optimal, which means that it minimizes the objective function among\nfeasible points that are near it, but is not guaranteed to have a lower objective\nvalue than all other feasible points. a large fraction of the research on general\nnonlinear programming has focused on methods for local optimization, which as a\nconsequence are well developed.\n\nlocal optimization methods can be fast, can handle large-scale problems, and\nare widely applicable, since they only require differentiability of the objective and\nconstraint functions. as a result, local optimization methods are widely used in\napplications where there is value in finding a good point, if not the very best. in\nan engineering design application, for example, local optimization can be used to\nimprove the performance of a design originally obtained by manual, or other, design\nmethods.\n\nthere are several disadvantages of local optimization methods, beyond (possi-\nbly) not finding the true, globally optimal solution. the methods require an initial\nguess for the optimization variable. this initial guess or starting point is critical,\nand can greatly affect the objective value of the local solution obtained. little\ninformation is provided about how far from (globally) optimal the local solution\nis. local optimization methods are often sensitive to algorithm parameter values,\nwhich may need to be adjusted for a particular problem, or family of problems.\n\nusing a local optimization method is trickier than solving a least-squares prob-\nlem, linear program, or convex optimization problem. it involves experimenting\nwith the choice of algorithm, adjusting algorithm parameters, and finding a good\nenough initial guess (when one instance is to be solved) or a method for producing\na good enough initial guess (when a family of problems is to be solved). roughly\nspeaking, local optimization methods are more art than technology. local opti-\nmization is a well developed art, and often very effective, but it is nevertheless an\nart. in contrast, there is little art involved in solving a least-squares problem or\na linear program (except, of course, those on the boundary of what is currently\npossible).\n\nan interesting comparison can be made between local optimization methods for\nnonlinear programming, and convex optimization. since differentiability of the ob-\n\n "}, {"Page_number": 24, "text": "10\n\n1 introduction\n\njective and constraint functions is the only requirement for most local optimization\nmethods, formulating a practical problem as a nonlinear optimization problem is\nrelatively straightforward. the art in local optimization is in solving the problem\n(in the weakened sense of finding a locally optimal point), once it is formulated.\nin convex optimization these are reversed: the art and challenge is in problem\nformulation; once a problem is formulated as a convex optimization problem, it is\nrelatively straightforward to solve it.\n\n1.4.2 global optimization\n\nin global optimization, the true global solution of the optimization problem (1.1)\nis found; the compromise is efficiency. the worst-case complexity of global opti-\nmization methods grows exponentially with the problem sizes n and m; the hope\nis that in practice, for the particular problem instances encountered, the method is\nfar faster. while this favorable situation does occur, it is not typical. even small\nproblems, with a few tens of variables, can take a very long time (e.g., hours or\ndays) to solve.\n\nglobal optimization is used for problems with a small number of variables, where\ncomputing time is not critical, and the value of finding the true global solution is\nvery high. one example from engineering design is worst-case analysis or verifica-\ntion of a high value or safety-critical system. here the variables represent uncertain\nparameters, that can vary during manufacturing, or with the environment or op-\nerating condition. the objective function is a utility function, i.e., one for which\nsmaller values are worse than larger values, and the constraints represent prior\nknowledge about the possible parameter values. the optimization problem (1.1) is\nthe problem of finding the worst-case values of the parameters. if the worst-case\nvalue is acceptable, we can certify the system as safe or reliable (with respect to\nthe parameter variations).\n\na local optimization method can rapidly find a set of parameter values that\nis bad, but not guaranteed to be the absolute worst possible. if a local optimiza-\ntion method finds parameter values that yield unacceptable performance, it has\nsucceeded in determining that the system is not reliable. but a local optimization\nmethod cannot certify the system as reliable; it can only fail to find bad parameter\nvalues. a global optimization method, in contrast, will find the absolute worst val-\nues of the parameters, and if the associated performance is acceptable, can certify\nthe system as safe. the cost is computation time, which can be very large, even\nfor a relatively small number of parameters. but it may be worth it in cases where\nthe value of certifying the performance is high, or the cost of being wrong about\nthe reliability or safety is high.\n\n1.4.3 role of convex optimization in nonconvex problems\n\nin this book we focus primarily on convex optimization problems, and applications\nthat can be reduced to convex optimization problems. but convex optimization\nalso plays an important role in problems that are not convex.\n\n "}, {"Page_number": 25, "text": "1.5 outline\n\n11\n\ninitialization for local optimization\n\none obvious use is to combine convex optimization with a local optimization\nmethod. starting with a nonconvex problem, we first find an approximate, but\nconvex, formulation of the problem. by solving this approximate problem, which\ncan be done easily and without an initial guess, we obtain the exact solution to the\napproximate convex problem. this point is then used as the starting point for a\nlocal optimization method, applied to the original nonconvex problem.\n\nconvex heuristics for nonconvex optimization\n\nconvex optimization is the basis for several heuristics for solving nonconvex prob-\nlems. one interesting example we will see is the problem of finding a sparse vector\nx (i.e., one with few nonzero entries) that satisfies some constraints. while this is\na difficult combinatorial problem, there are some simple heuristics, based on con-\nvex optimization, that often find fairly sparse solutions. (these are described in\nchapter 6.)\n\nanother broad example is given by randomized algorithms, in which an ap-\nproximate solution to a nonconvex problem is found by drawing some number of\ncandidates from a probability distribution, and taking the best one found as the\napproximate solution. now suppose the family of distributions from which we will\ndraw the candidates is parametrized, e.g., by its mean and covariance. we can then\npose the question, which of these distributions gives us the smallest expected value\nof the objective? it turns out that this problem is sometimes a convex problem,\nand therefore efficiently solved. (see, e.g., exercise 11.23.)\n\nbounds for global optimization\n\nmany methods for global optimization require a cheaply computable lower bound\non the optimal value of the nonconvex problem. two standard methods for doing\nthis are based on convex optimization. in relaxation, each nonconvex constraint\nis replaced with a looser, but convex, constraint.\nin lagrangian relaxation, the\nlagrangian dual problem (described in chapter 5) is solved. this problem is convex,\nand provides a lower bound on the optimal value of the nonconvex problem.\n\n1.5 outline\n\nthe book is divided into three main parts, titled theory, applications, and algo-\nrithms.\n\n1.5.1 part i: theory\n\nin part i, theory, we cover basic definitions, concepts, and results from convex\nanalysis and convex optimization. we make no attempt to be encyclopedic, and\nskew our selection of topics toward those that we think are useful in recognizing\n\n "}, {"Page_number": 26, "text": "12\n\n1 introduction\n\nand formulating convex optimization problems. this is classical material, almost\nall of which can be found in other texts on convex analysis and optimization. we\nmake no attempt to give the most general form of the results; for that the reader\ncan refer to any of the standard texts on convex analysis.\n\nchapters 2 and 3 cover convex sets and convex functions, respectively. we\ngive some common examples of convex sets and functions, as well as a number of\nconvex calculus rules, i.e., operations on sets and functions that preserve convexity.\ncombining the basic examples with the convex calculus rules allows us to form\n(or perhaps more importantly, recognize) some fairly complicated convex sets and\nfunctions.\n\nin chapter 4, convex optimization problems, we give a careful treatment of op-\ntimization problems, and describe a number of transformations that can be used to\nreformulate problems. we also introduce some common subclasses of convex opti-\nmization, such as linear programming and geometric programming, and the more\nrecently developed second-order cone programming and semidefinite programming.\nchapter 5 covers lagrangian duality, which plays a central role in convex opti-\nmization. here we give the classical karush-kuhn-tucker conditions for optimality,\nand a local and global sensitivity analysis for convex optimization problems.\n\n1.5.2 part ii: applications\n\nin part ii, applications, we describe a variety of applications of convex optimization,\nin areas like probability and statistics, computational geometry, and data fitting.\nwe have described these applications in a way that is accessible, we hope, to a broad\naudience. to keep each application short, we consider only simple cases, sometimes\nadding comments about possible extensions. we are sure that our treatment of\nsome of the applications will cause experts to cringe, and we apologize to them\nin advance. but our goal is to convey the flavor of the application, quickly and\nto a broad audience, and not to give an elegant, theoretically sound, or complete\ntreatment. our own backgrounds are in electrical engineering, in areas like control\nsystems, signal processing, and circuit analysis and design. although we include\nthese topics in the courses we teach (using this book as the main text), only a few\nof these applications are broadly enough accessible to be included here.\n\nthe aim of part ii is to show the reader, by example, how convex optimization\n\ncan be applied in practice.\n\n1.5.3 part iii: algorithms\n\nin part iii, algorithms, we describe numerical methods for solving convex opti-\nmization problems, focusing on newton\u2019s algorithm and interior-point methods.\npart iii is organized as three chapters, which cover unconstrained optimization,\nequality constrained optimization, and inequality constrained optimization, respec-\ntively. these chapters follow a natural hierarchy, in which solving a problem is\nreduced to solving a sequence of simpler problems. quadratic optimization prob-\nlems (including, e.g., least-squares) form the base of the hierarchy; they can be\n\n "}, {"Page_number": 27, "text": "1.5 outline\n\n13\n\nsolved exactly by solving a set of linear equations. newton\u2019s method, developed in\nchapters 9 and 10, is the next level in the hierarchy. in newton\u2019s method, solving\nan unconstrained or equality constrained problem is reduced to solving a sequence\nof quadratic problems. in chapter 11, we describe interior-point methods, which\nform the top level of the hierarchy. these methods solve an inequality constrained\nproblem by solving a sequence of unconstrained, or equality constrained, problems.\noverall we cover just a handful of algorithms, and omit entire classes of good\nmethods, such as quasi-newton, conjugate-gradient, bundle, and cutting-plane al-\ngorithms. for the methods we do describe, we give simplified variants, and not the\nlatest, most sophisticated versions. our choice of algorithms was guided by several\ncriteria. we chose algorithms that are simple (to describe and implement), but\nalso reliable and robust, and effective and fast enough for most problems.\n\nmany users of convex optimization end up using (but not developing) standard\nsoftware, such as a linear or semidefinite programming solver. for these users, the\nmaterial in part iii is meant to convey the basic flavor of the methods, and give\nsome ideas of their basic attributes. for those few who will end up developing new\nalgorithms, we think that part iii serves as a good introduction.\n\n1.5.4 appendices\n\nthere are three appendices. the first lists some basic facts from mathematics that\nwe use, and serves the secondary purpose of setting out our notation. the second\nappendix covers a fairly particular topic, optimization problems with quadratic\nobjective and one quadratic constraint. these are nonconvex problems that never-\ntheless can be effectively solved, and we use the results in several of the applications\ndescribed in part ii.\n\nthe final appendix gives a brief introduction to numerical linear algebra, con-\ncentrating on methods that can exploit problem structure, such as sparsity, to gain\nefficiency. we do not cover a number of important topics, including roundoff analy-\nsis, or give any details of the methods used to carry out the required factorizations.\nthese topics are covered by a number of excellent texts.\n\n1.5.5 comments on examples\n\nin many places in the text (but particularly in parts ii and iii, which cover ap-\nplications and algorithms, respectively) we illustrate ideas using specific examples.\nin some cases, the examples are chosen (or designed) specifically to illustrate our\npoint; in other cases, the examples are chosen to be \u2018typical\u2019. this means that the\nexamples were chosen as samples from some obvious or simple probability distri-\nbution. the dangers of drawing conclusions about algorithm performance from a\nfew tens or hundreds of randomly generated examples are well known, so we will\nnot repeat them here. these examples are meant only to give a rough idea of al-\ngorithm performance, or a rough idea of how the computational effort varies with\nproblem dimensions, and not as accurate predictors of algorithm performance. in\nparticular, your results may vary from ours.\n\n "}, {"Page_number": 28, "text": "14\n\n1 introduction\n\n1.5.6 comments on exercises\n\neach chapter concludes with a set of exercises. some involve working out the de-\ntails of an argument or claim made in the text. others focus on determining, or\nestablishing, convexity of some given sets, functions, or problems; or more gener-\nally, convex optimization problem formulation. some chapters include numerical\nexercises, which require some (but not much) programming in an appropriate high\nlevel language. the difficulty level of the exercises is mixed, and varies without\nwarning from quite straightforward to rather tricky.\n\n1.6 notation\n\nour notation is more or less standard, with a few exceptions. in this section we\ndescribe our basic notation; a more complete list appears on page 697.\n\nwe use r to denote the set of real numbers, r+ to denote the set of nonnegative\nreal numbers, and r++ to denote the set of positive real numbers. the set of real\nn-vectors is denoted rn, and the set of real m \u00d7 n matrices is denoted rm\u00d7n. we\ndelimit vectors and matrices with square brackets, with the components separated\nby space. we use parentheses to construct column vectors from comma separated\nlists. for example, if a, b, c \u2208 r, we have\n\n(a, b, c) =\uf8ee\uf8f0\n\na\nb\n\nc \uf8f9\uf8fb = [ a b\n\nc ]t ,\n\nwhich is an element of r3. the symbol 1 denotes a vector all of whose components\nare one (with dimension determined from context). the notation xi can refer to\nthe ith component of the vector x, or to the ith element of a set or sequence of\nvectors x1, x2, . . .. the context, or the text, makes it clear which is meant.\n\nwe use sk to denote the set of symmetric k \u00d7 k matrices, sk\n\n+ to denote the\nset of symmetric positive semidefinite k \u00d7 k matrices, and sk\n++ to denote the set\nof symmetric positive definite k \u00d7 k matrices. the curled inequality symbol (cid:23)\n(and its strict form \u227b) is used to denote generalized inequality: between vectors,\nit represents componentwise inequality; between symmetric matrices, it represents\nmatrix inequality. with a subscript, the symbol (cid:22)k (or \u227ak) denotes generalized\ninequality with respect to the cone k (explained in \u00a72.4.1).\nour notation for describing functions deviates a bit from standard notation,\nbut we hope it will cause no confusion. we use the notation f : rp \u2192 rq to mean\nthat f is an rq-valued function on some subset of rp, specifically, its domain,\nwhich we denote dom f . we can think of our use of the notation f : rp \u2192 rq as\na declaration of the function type, as in a computer language: f : rp \u2192 rq means\nthat the function f takes as argument a real p-vector, and returns a real q-vector.\nthe set dom f , the domain of the function f , specifies the subset of rp of points\nx for which f (x) is defined. as an example, we describe the logarithm function\nas log : r \u2192 r, with dom log = r++. the notation log : r \u2192 r means that\n\n "}, {"Page_number": 29, "text": "1.6 notation\n\n15\n\nthe logarithm function accepts and returns a real number; dom log = r++ means\nthat the logarithm is defined only for positive numbers.\n\nwe use rn as a generic finite-dimensional vector space. we will encounter\nseveral other finite-dimensional vector spaces, e.g., the space of polynomials of a\nvariable with a given maximum degree, or the space sk of symmetric k\u00d7k matrices.\nby identifying a basis for a vector space, we can always identify it with rn (where\nn is its dimension), and therefore the generic results, stated for the vector space\nrn, can be applied. we usually leave it to the reader to translate general results\nor statements to other vector spaces. for example, any linear function f : rn \u2192 r\ncan be represented in the form f (x) = ct x, where c \u2208 rn. the corresponding\nstatement for the vector space sk can be found by choosing a basis and translating.\nthis results in the statement: any linear function f : sk \u2192 r can be represented\nin the form f (x) = tr(cx), where c \u2208 sk.\n\n "}, {"Page_number": 30, "text": "16\n\n1 introduction\n\nbibliography\n\nleast-squares is a very old subject; see, for example, the treatise written (in latin) by\ngauss in the 1820s, and recently translated by stewart [gau95]. more recent work in-\ncludes the books by lawson and hanson [lh95] and bj\u00a8orck [bj\u00a8o96]. references on linear\nprogramming can be found in chapter 4.\n\nthere are many good texts on local methods for nonlinear programming, including gill,\nmurray, and wright [gmw81], nocedal and wright [nw99], luenberger [lue84], and\nbertsekas [ber99].\n\nglobal optimization is covered in the books by horst and pardalos [hp94], pinter [pin95],\nand tuy [tuy98]. using convex optimization to find bounds for nonconvex problems is\nan active research topic, and addressed in the books above on global optimization, the\nbook by ben-tal and nemirovski [btn01, \u00a74.3], and the survey by nesterov, wolkowicz,\nand ye [nwy00]. some notable papers on this subject are goemans and williamson\n[gw95], nesterov [nes00, nes98], ye [ye99], and parrilo [par03]. randomized methods\nare discussed in motwani and raghavan [mr95].\n\nconvex analysis, the mathematics of convex sets, functions, and optimization problems, is\na well developed subfield of mathematics. basic references include the books by rockafel-\nlar [roc70], hiriart-urruty and lemar\u00b4echal [hul93, hul01], borwein and lewis [bl00],\nand bertsekas, nedi\u00b4c, and ozdaglar [ber03]. more references on convex analysis can be\nfound in chapters 2\u20135.\n\nnesterov and nemirovski [nn94] were the first to point out that interior-point methods\ncan solve many convex optimization problems; see also the references in chapter 11. the\nbook by ben-tal and nemirovski [btn01] covers modern convex optimization, interior-\npoint methods, and applications.\n\nsolution methods for convex optimization that we do not cover in this book include\nsubgradient methods [sho85], bundle methods [hul93], cutting-plane methods [kel60,\nem75, gly96], and the ellipsoid method [sho91, bgt81].\n\nthe idea that convex optimization problems are tractable is not new. it has long been rec-\nognized that the theory of convex optimization is far more straightforward (and complete)\nthan the theory of general nonlinear optimization. in this context rockafellar stated, in\nhis 1993 siam review survey paper [roc93],\n\nin fact the great watershed in optimization isn\u2019t between linearity and nonlin-\nearity, but convexity and nonconvexity.\n\nthe first formal argument that convex optimization problems are easier to solve than\ngeneral nonlinear optimization problems was made by nemirovski and yudin, in their\n1983 book problem complexity and method efficiency in optimization [ny83]. they\nshowed that the information-based complexity of convex optimization problems is far\nlower than that of general nonlinear optimization problems. a more recent book on this\ntopic is vavasis [vav91].\n\nthe low (theoretical) complexity of interior-point methods is integral to modern research\nin this area. much of the research focuses on proving that an interior-point (or other)\nmethod can solve some class of convex optimization problems with a number of operations\nthat grows no faster than a polynomial of the problem dimensions and log(1/\u01eb), where\n\u01eb > 0 is the required accuracy. (we will see some simple results like these in chapter 11.)\nthe first comprehensive work on this topic is the book by nesterov and nemirovski\n[nn94]. other books include ben-tal and nemirovski [btn01, lecture 5] and renegar\n[ren01]. the polynomial-time complexity of interior-point methods for various convex\noptimization problems is in marked contrast to the situation for a number of nonconvex\noptimization problems, for which all known algorithms require, in the worst case, a number\nof operations that is exponential in the problem dimensions.\n\n "}, {"Page_number": 31, "text": "bibliography\n\n17\n\nconvex optimization has been used in many applications areas, too numerous to cite\nhere. convex analysis is central in economics and finance, where it is the basis of many\nresults. for example the separating hyperplane theorem, together with a no-arbitrage\nassumption, is used to deduce the existence of prices and risk-neutral probabilities (see,\ne.g., luenberger [lue95, lue98] and ross [ros99]). convex optimization, especially our\nability to solve semidefinite programs, has recently received particular attention in au-\ntomatic control theory. applications of convex optimization in control theory can be\nfound in the books by boyd and barratt [bb91], boyd, el ghaoui, feron, and balakrish-\nnan [befb94], dahleh and diaz-bobillo [ddb95], el ghaoui and niculescu [en00], and\ndullerud and paganini [dp00]. a good example of embedded (convex) optimization is\nmodel predictive control, an automatic control technique that requires the solution of a\n(convex) quadratic program at each step. model predictive control is now widely used in\nthe chemical process control industry; see morari and zafirou [mz89]. another applica-\ntions area where convex optimization (and especially, geometric programming) has a long\nhistory is electronic circuit design. research papers on this topic include fishburn and\ndunlop [fd85], sapatnekar, rao, vaidya, and kang [srvk93], and hershenson, boyd,\nand lee [hbl01]. luo [luo03] gives a survey of applications in signal processing and\ncommunications. more references on applications of convex optimization can be found in\nchapters 4 and 6\u20138.\n\nhigh quality implementations of recent interior-point methods for convex optimization\nproblems are available in the loqo [van97] and mosek [mos02] software packages,\nand the codes listed in chapter 11. software systems for specifying optimization prob-\nlems include ampl [fgk99] and gams [bkmr98]. both provide some support for\nrecognizing problems that can be transformed to linear programs.\n\n "}, {"Page_number": 32, "text": " "}, {"Page_number": 33, "text": "part i\n\ntheory\n\n "}, {"Page_number": 34, "text": " "}, {"Page_number": 35, "text": "chapter 2\n\nconvex sets\n\n2.1 affine and convex sets\n\n2.1.1 lines and line segments\n\nsuppose x1 6= x2 are two points in rn. points of the form\n\ny = \u03b8x1 + (1 \u2212 \u03b8)x2,\n\nwhere \u03b8 \u2208 r, form the line passing through x1 and x2. the parameter value \u03b8 = 0\ncorresponds to y = x2, and the parameter value \u03b8 = 1 corresponds to y = x1.\nvalues of the parameter \u03b8 between 0 and 1 correspond to the (closed) line segment\nbetween x1 and x2.\n\nexpressing y in the form\n\ny = x2 + \u03b8(x1 \u2212 x2)\n\ngives another interpretation: y is the sum of the base point x2 (corresponding\nto \u03b8 = 0) and the direction x1 \u2212 x2 (which points from x2 to x1) scaled by the\nparameter \u03b8. thus, \u03b8 gives the fraction of the way from x2 to x1 where y lies. as\n\u03b8 increases from 0 to 1, the point y moves from x2 to x1; for \u03b8 > 1, the point y lies\non the line beyond x1. this is illustrated in figure 2.1.\n\n2.1.2 affine sets\n\na set c \u2286 rn is affine if the line through any two distinct points in c lies in c,\ni.e., if for any x1, x2 \u2208 c and \u03b8 \u2208 r, we have \u03b8x1 + (1\u2212 \u03b8)x2 \u2208 c. in other words,\nc contains the linear combination of any two points in c, provided the coefficients\nin the linear combination sum to one.\n\nthis idea can be generalized to more than two points. we refer to a point\nof the form \u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk, where \u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1, as an affine combination\nof the points x1, . . . , xk. using induction from the definition of affine set (i.e.,\nthat it contains every affine combination of two points in it), it can be shown that\n\n "}, {"Page_number": 36, "text": "22\n\n2 convex sets\n\n\u03b8 = 1.2\n\nx1\n\n\u03b8 = 1\n\n\u03b8 = 0.6\n\nx2\n\n\u03b8 = 0\n\u03b8 = \u22120.2\n\nfigure 2.1 the line passing through x1 and x2 is described parametrically\nby \u03b8x1 + (1\u2212 \u03b8)x2, where \u03b8 varies over r. the line segment between x1 and\nx2, which corresponds to \u03b8 between 0 and 1, is shown darker.\n\nan affine set contains every affine combination of its points: if c is an affine set,\nx1, . . . , xk \u2208 c, and \u03b81 +\u00b7\u00b7\u00b7 + \u03b8k = 1, then the point \u03b81x1 +\u00b7\u00b7\u00b7 + \u03b8kxk also belongs\nto c.\n\nif c is an affine set and x0 \u2208 c, then the set\n\nv = c \u2212 x0 = {x \u2212 x0 | x \u2208 c}\n\nis a subspace, i.e., closed under sums and scalar multiplication. to see this, suppose\nv1, v2 \u2208 v and \u03b1, \u03b2 \u2208 r. then we have v1 + x0 \u2208 c and v2 + x0 \u2208 c, and so\n\n\u03b1v1 + \u03b2v2 + x0 = \u03b1(v1 + x0) + \u03b2(v2 + x0) + (1 \u2212 \u03b1 \u2212 \u03b2)x0 \u2208 c,\n\nsince c is affine, and \u03b1 + \u03b2 + (1 \u2212 \u03b1 \u2212 \u03b2) = 1. we conclude that \u03b1v1 + \u03b2v2 \u2208 v ,\nsince \u03b1v1 + \u03b2v2 + x0 \u2208 c.\n\nthus, the affine set c can be expressed as\n\nc = v + x0 = {v + x0 | v \u2208 v },\n\ni.e., as a subspace plus an offset. the subspace v associated with the affine set c\ndoes not depend on the choice of x0, so x0 can be chosen as any point in c. we\ndefine the dimension of an affine set c as the dimension of the subspace v = c\u2212x0,\nwhere x0 is any element of c.\n\nexample 2.1 solution set of linear equations. the solution set of a system of linear\nequations, c = {x | ax = b}, where a \u2208 rm\u00d7n and b \u2208 rm, is an affine set. to\nshow this, suppose x1, x2 \u2208 c, i.e., ax1 = b, ax2 = b. then for any \u03b8, we have\n\na(\u03b8x1 + (1 \u2212 \u03b8)x2) = \u03b8ax1 + (1 \u2212 \u03b8)ax2\n\n= \u03b8b + (1 \u2212 \u03b8)b\n= b,\n\nwhich shows that the affine combination \u03b8x1 + (1 \u2212 \u03b8)x2 is also in c. the subspace\nassociated with the affine set c is the nullspace of a.\n\nwe also have a converse: every affine set can be expressed as the solution set of a\nsystem of linear equations.\n\n "}, {"Page_number": 37, "text": "2.1 affine and convex sets\n\n23\n\nthe set of all affine combinations of points in some set c \u2286 rn is called the\n\naffine hull of c, and denoted aff c:\n\naff c = {\u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk | x1, . . . , xk \u2208 c, \u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1}.\n\nthe affine hull is the smallest affine set that contains c, in the following sense: if\ns is any affine set with c \u2286 s, then aff c \u2286 s.\n\n2.1.3 affine dimension and relative interior\n\nwe define the affine dimension of a set c as the dimension of its affine hull. affine\ndimension is useful in the context of convex analysis and optimization, but is not\nalways consistent with other definitions of dimension. as an example consider the\n2 = 1}. its affine hull is all of r2, so its\nunit circle in r2, i.e., {x \u2208 r2 | x2\naffine dimension is two. by most definitions of dimension, however, the unit circle\nin r2 has dimension one.\n\n1 + x2\n\nif the affine dimension of a set c \u2286 rn is less than n, then the set lies in\nthe affine set aff c 6= rn. we define the relative interior of the set c, denoted\nrelint c, as its interior relative to aff c:\n\nrelint c = {x \u2208 c | b(x, r) \u2229 aff c \u2286 c for some r > 0},\n\nwhere b(x, r) = {y | ky \u2212 xk \u2264 r}, the ball of radius r and center x in the norm\nk \u00b7 k. (here k \u00b7 k is any norm; all norms define the same relative interior.) we can\nthen define the relative boundary of a set c as cl c \\ relint c, where cl c is the\nclosure of c.\n\nexample 2.2 consider a square in the (x1, x2)-plane in r3, defined as\n\nc = {x \u2208 r3 | \u2212 1 \u2264 x1 \u2264 1, \u22121 \u2264 x2 \u2264 1, x3 = 0}.\n\nits affine hull is the (x1, x2)-plane, i.e., aff c = {x \u2208 r3 | x3 = 0}. the interior of c\nis empty, but the relative interior is\n\nrelint c = {x \u2208 r3 | \u2212 1 < x1 < 1, \u22121 < x2 < 1, x3 = 0}.\n\nits boundary (in r3) is itself; its relative boundary is the wire-frame outline,\n\n{x \u2208 r3 | max{|x1|,|x2|} = 1, x3 = 0}.\n\n2.1.4 convex sets\n\na set c is convex if the line segment between any two points in c lies in c, i.e.,\nif for any x1, x2 \u2208 c and any \u03b8 with 0 \u2264 \u03b8 \u2264 1, we have\n\n\u03b8x1 + (1 \u2212 \u03b8)x2 \u2208 c.\n\n "}, {"Page_number": 38, "text": "24\n\n2 convex sets\n\nfigure 2.2 some simple convex and nonconvex sets. left. the hexagon,\nwhich includes its boundary (shown darker), is convex. middle. the kidney\nshaped set is not convex, since the line segment between the two points in\nthe set shown as dots is not contained in the set. right. the square contains\nsome boundary points but not others, and is not convex.\n\nfigure 2.3 the convex hulls of two sets in r2. left. the convex hull of a\nset of fifteen points (shown as dots) is the pentagon (shown shaded). right.\nthe convex hull of the kidney shaped set in figure 2.2 is the shaded set.\n\nroughly speaking, a set is convex if every point in the set can be seen by every other\npoint, along an unobstructed straight path between them, where unobstructed\nmeans lying in the set. every affine set is also convex, since it contains the entire\nline between any two distinct points in it, and therefore also the line segment\nbetween the points. figure 2.2 illustrates some simple convex and nonconvex sets\nin r2.\n\nwe call a point of the form \u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk, where \u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1 and\n\u03b8i \u2265 0, i = 1, . . . , k, a convex combination of the points x1, . . . , xk. as with affine\nsets, it can be shown that a set is convex if and only if it contains every convex\ncombination of its points. a convex combination of points can be thought of as a\nmixture or weighted average of the points, with \u03b8i the fraction of xi in the mixture.\n\nthe convex hull of a set c, denoted conv c, is the set of all convex combinations\n\nof points in c:\n\nconv c = {\u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk | xi \u2208 c, \u03b8i \u2265 0, i = 1, . . . , k, \u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1}.\nas the name suggests, the convex hull conv c is always convex. it is the smallest\nconvex set that contains c: if b is any convex set that contains c, then conv c \u2286\nb. figure 2.3 illustrates the definition of convex hull.\nthe idea of a convex combination can be generalized to include infinite sums, in-\ntegrals, and, in the most general form, probability distributions. suppose \u03b81, \u03b82, . . .\n\n "}, {"Page_number": 39, "text": "2.1 affine and convex sets\n\n25\n\nsatisfy\n\n\u221exi=1\nand x1, x2, . . . \u2208 c, where c \u2286 rn is convex. then\n\ni = 1, 2, . . . ,\n\n\u03b8i \u2265 0,\n\n\u03b8i = 1,\n\n\u221exi=1\n\n\u03b8ixi \u2208 c,\n\nif the series converges. more generally, suppose p : rn \u2192 r satisfies p(x) \u2265 0 for\nall x \u2208 c andrc p(x) dx = 1, where c \u2286 rn is convex. then\n\nzc\n\np(x)x dx \u2208 c,\n\nif the integral exists.\n\nin the most general form, suppose c \u2286 rn is convex and x is a random vector\nwith x \u2208 c with probability one. then e x \u2208 c. indeed, this form includes all\nthe others as special cases. for example, suppose the random variable x only takes\non the two values x1 and x2, with prob(x = x1) = \u03b8 and prob(x = x2) = 1 \u2212 \u03b8,\nwhere 0 \u2264 \u03b8 \u2264 1. then e x = \u03b8x1 + (1 \u2212 \u03b8)x2, and we are back to a simple convex\ncombination of two points.\n\n2.1.5 cones\n\na set c is called a cone, or nonnegative homogeneous, if for every x \u2208 c and \u03b8 \u2265 0\nwe have \u03b8x \u2208 c. a set c is a convex cone if it is convex and a cone, which means\nthat for any x1, x2 \u2208 c and \u03b81, \u03b82 \u2265 0, we have\n\u03b81x1 + \u03b82x2 \u2208 c.\n\npoints of this form can be described geometrically as forming the two-dimensional\npie slice with apex 0 and edges passing through x1 and x2. (see figure 2.4.)\n\na point of the form \u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk with \u03b81, . . . , \u03b8k \u2265 0 is called a conic\nif xi are in a\ncombination (or a nonnegative linear combination) of x1, . . . , xk.\nconvex cone c, then every conic combination of xi is in c. conversely, a set c is\na convex cone if and only if it contains all conic combinations of its elements. like\nconvex (or affine) combinations, the idea of conic combination can be generalized\nto infinite sums and integrals.\n\nthe conic hull of a set c is the set of all conic combinations of points in c, i.e.,\n\n{\u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk | xi \u2208 c, \u03b8i \u2265 0, i = 1, . . . , k},\n\nwhich is also the smallest convex cone that contains c (see figure 2.5).\n\n "}, {"Page_number": 40, "text": "26\n\n2 convex sets\n\nx1\n\nx2\n\n0\n\nfigure 2.4 the pie slice shows all points of the form \u03b81x1 + \u03b82x2, where\n\u03b81, \u03b82 \u2265 0. the apex of the slice (which corresponds to \u03b81 = \u03b82 = 0) is at\n0; its edges (which correspond to \u03b81 = 0 or \u03b82 = 0) pass through the points\nx1 and x2.\n\nfigure 2.5 the conic hulls (shown shaded) of the two sets of figure 2.3.\n\n0\n\n0\n\n "}, {"Page_number": 41, "text": "2.2 some important examples\n\n27\n\n2.2 some important examples\n\nin this section we describe some important examples of convex sets which we will\nencounter throughout the rest of the book. we start with some simple examples.\n\n\u2022 the empty set \u2205, any single point (i.e., singleton) {x0}, and the whole space\n\nrn are affine (hence, convex) subsets of rn.\n\n\u2022 any line is affine. if it passes through zero, it is a subspace, hence also a\n\nconvex cone.\n\n\u2022 a line segment is convex, but not affine (unless it reduces to a point).\n\u2022 a ray, which has the form {x0 + \u03b8v | \u03b8 \u2265 0}, where v 6= 0, is convex, but not\n\naffine. it is a convex cone if its base x0 is 0.\n\n\u2022 any subspace is affine, and a convex cone (hence convex).\n\n2.2.1 hyperplanes and halfspaces\n\na hyperplane is a set of the form\n\n{x | at x = b},\n\nwhere a \u2208 rn, a 6= 0, and b \u2208 r. analytically it is the solution set of a nontrivial\nlinear equation among the components of x (and hence an affine set). geometri-\ncally, the hyperplane {x | at x = b} can be interpreted as the set of points with a\nconstant inner product to a given vector a, or as a hyperplane with normal vector\na; the constant b \u2208 r determines the offset of the hyperplane from the origin. this\ngeometric interpretation can be understood by expressing the hyperplane in the\nform\n\nwhere x0 is any point in the hyperplane (i.e., any point that satisfies at x0 = b).\nthis representation can in turn be expressed as\n\n{x | at (x \u2212 x0) = 0},\n\n{x | at (x \u2212 x0) = 0} = x0 + a\u22a5,\n\nwhere a\u22a5 denotes the orthogonal complement of a, i.e., the set of all vectors or-\nthogonal to it:\n\na\u22a5 = {v | at v = 0}.\n\nthis shows that the hyperplane consists of an offset x0, plus all vectors orthog-\nonal to the (normal) vector a. these geometric interpretations are illustrated in\nfigure 2.6.\n\na hyperplane divides rn into two halfspaces. a (closed) halfspace is a set of\n\nthe form\n\n(2.1)\nwhere a 6= 0, i.e., the solution set of one (nontrivial) linear inequality. halfspaces\nare convex, but not affine. this is illustrated in figure 2.7.\n\n{x | at x \u2264 b},\n\n "}, {"Page_number": 42, "text": "28\n\n2 convex sets\n\na\n\nx0\n\nx\n\nat x = b\n\nfigure 2.6 hyperplane in r2, with normal vector a and a point x0 in the\nhyperplane. for any point x in the hyperplane, x \u2212 x0 (shown as the darker\narrow) is orthogonal to a.\n\na\n\nx0\n\nat x \u2265 b\n\nat x \u2264 b\n\nfigure 2.7 a hyperplane defined by at x = b in r2 determines two halfspaces.\nthe halfspace determined by at x \u2265 b (not shaded) is the halfspace extending\nin the direction a. the halfspace determined by at x \u2264 b (which is shown\nshaded) extends in the direction \u2212a. the vector a is the outward normal of\nthis halfspace.\n\n "}, {"Page_number": 43, "text": "2.2 some important examples\n\n29\n\nx1\n\nx0\n\na\n\nx2\n\nfigure 2.8 the shaded set is the halfspace determined by at (x \u2212 x0) \u2264 0.\nthe vector x1\u2212x0 makes an acute angle with a, so x1 is not in the halfspace.\nthe vector x2 \u2212 x0 makes an obtuse angle with a, and so is in the halfspace.\n\nthe halfspace (2.1) can also be expressed as\n\n{x | at (x \u2212 x0) \u2264 0},\n\n(2.2)\n\nwhere x0 is any point on the associated hyperplane, i.e., satisfies at x0 = b. the\nrepresentation (2.2) suggests a simple geometric interpretation: the halfspace con-\nsists of x0 plus any vector that makes an obtuse (or right) angle with the (outward\nnormal) vector a. this is illustrated in figure 2.8.\n\nthe boundary of the halfspace (2.1) is the hyperplane {x | at x = b}. the set\n{x | at x < b}, which is the interior of the halfspace {x | at x \u2264 b}, is called an\nopen halfspace.\n\n2.2.2 euclidean balls and ellipsoids\n\na (euclidean) ball (or just ball) in rn has the form\n\nb(xc, r) = {x | kx \u2212 xck2 \u2264 r} = {x | (x \u2212 xc)t (x \u2212 xc) \u2264 r2},\n\nwhere r > 0, and k \u00b7 k2 denotes the euclidean norm, i.e., kuk2 = (ut u)1/2. the\nvector xc is the center of the ball and the scalar r is its radius; b(xc, r) consists\nof all points within a distance r of the center xc. another common representation\nfor the euclidean ball is\n\nb(xc, r) = {xc + ru | kuk2 \u2264 1}.\n\n "}, {"Page_number": 44, "text": "30\n\n2 convex sets\n\nxc\n\nfigure 2.9 an ellipsoid in r2, shown shaded. the center xc is shown as a\ndot, and the two semi-axes are shown as line segments.\n\na euclidean ball is a convex set:\n\n0 \u2264 \u03b8 \u2264 1, then\n\nif kx1 \u2212 xck2 \u2264 r, kx2 \u2212 xck2 \u2264 r, and\n\nk\u03b8x1 + (1 \u2212 \u03b8)x2 \u2212 xck2 = k\u03b8(x1 \u2212 xc) + (1 \u2212 \u03b8)(x2 \u2212 xc)k2\n\u2264 \u03b8kx1 \u2212 xck2 + (1 \u2212 \u03b8)kx2 \u2212 xck2\n\u2264 r.\n\n(here we use the homogeneity property and triangle inequality for k\u00b7k2; see \u00a7a.1.2.)\n\na related family of convex sets is the ellipsoids, which have the form\n\ne = {x | (x \u2212 xc)t p \u22121(x \u2212 xc) \u2264 1},\n\n(2.3)\nwhere p = p t \u227b 0, i.e., p is symmetric and positive definite. the vector xc \u2208 rn\nis the center of the ellipsoid. the matrix p determines how far the ellipsoid extends\nin every direction from xc; the lengths of the semi-axes of e are given by \u221a\u03bbi, where\n\n\u03bbi are the eigenvalues of p . a ball is an ellipsoid with p = r2i. figure 2.9 shows\nan ellipsoid in r2.\n\nanother common representation of an ellipsoid is\ne = {xc + au | kuk2 \u2264 1},\n\n(2.4)\n\nwhere a is square and nonsingular. in this representation we can assume without\nloss of generality that a is symmetric and positive definite. by taking a = p 1/2,\nthis representation gives the ellipsoid defined in (2.3). when the matrix a in (2.4)\nis symmetric positive semidefinite but singular, the set in (2.4) is called a degenerate\nellipsoid ; its affine dimension is equal to the rank of a. degenerate ellipsoids are\nalso convex.\n\n2.2.3 norm balls and norm cones\n\nsuppose k\u00b7k is any norm on rn (see \u00a7a.1.2). from the general properties of norms it\ncan be shown that a norm ball of radius r and center xc, given by {x | kx\u2212xck \u2264 r},\nis convex. the norm cone associated with the norm k \u00b7 k is the set\n\nc = {(x, t) | kxk \u2264 t} \u2286 rn+1.\n\n "}, {"Page_number": 45, "text": "2.2 some important examples\n\n31\n\n1\n\n0.5\n\nt\n\n0\n1\n\n0\n\nx2\n\n0\n\n\u22121\n\n\u22121\n\nx1\n\n1\n\nfigure 2.10 boundary of second-order cone in r3, {(x1, x2, t) | (x2\nt}.\n\n1+x2\n\n2)1/2 \u2264\n\nit is (as the name suggests) a convex cone.\n\nexample 2.3 the second-order cone is the norm cone for the euclidean norm, i.e.,\n\nc = {(x, t) \u2208 rn+1 | kxk2 \u2264 t}\n\nt (cid:21)t(cid:20) i\n(cid:20) x\n\n0 \u22121 (cid:21)(cid:20) x\n\n0\n\nt (cid:21) \u2264 0, t \u2265 0) .\n\nt (cid:21) (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n= ((cid:20) x\n\nthe second-order cone is also known by several other names. it is called the quadratic\ncone, since it is defined by a quadratic inequality. it is also called the lorentz cone\nor ice-cream cone. figure 2.10 shows the second-order cone in r3.\n\n2.2.4 polyhedra\n\na polyhedron is defined as the solution set of a finite number of linear equalities\nand inequalities:\n\np = {x | at\n\nj x \u2264 bj, j = 1, . . . , m, ct\n\nj x = dj, j = 1, . . . , p}.\n\n(2.5)\n\na polyhedron is thus the intersection of a finite number of halfspaces and hyper-\nplanes. affine sets (e.g., subspaces, hyperplanes, lines), rays, line segments, and\nhalfspaces are all polyhedra.\nit is easily shown that polyhedra are convex sets.\na bounded polyhedron is sometimes called a polytope, but some authors use the\nopposite convention (i.e., polytope for any set of the form (2.5), and polyhedron\n\n "}, {"Page_number": 46, "text": "32\n\n2 convex sets\n\na1\n\na2\n\na5\n\np\n\na3\n\na4\n\nfigure 2.11 the polyhedron p (shown shaded) is the intersection of five\nhalfspaces, with outward normal vectors a1, . . . . , a5.\n\nwhen it is bounded). figure 2.11 shows an example of a polyhedron defined as the\nintersection of five halfspaces.\n\nit will be convenient to use the compact notation\n\np = {x | ax (cid:22) b, cx = d}\n\n(2.6)\n\nfor (2.5), where\n\na =\uf8ee\uf8ef\uf8f0\n\nat\n1\n...\nat\nm\n\n\uf8f9\uf8fa\uf8fb ,\n\nc =\uf8ee\uf8ef\uf8f0\n\nct\n1\n...\nct\np\n\n\uf8f9\uf8fa\uf8fb ,\n\nand the symbol (cid:22) denotes vector inequality or componentwise inequality in rm:\nu (cid:22) v means ui \u2264 vi for i = 1, . . . , m.\n\nexample 2.4 the nonnegative orthant is the set of points with nonnegative compo-\nnents, i.e.,\n\nrn\n+ = {x \u2208 rn | xi \u2265 0, i = 1, . . . , n} = {x \u2208 rn | x (cid:23) 0}.\n\n(here r+ denotes the set of nonnegative numbers: r+ = {x \u2208 r | x \u2265 0}.) the\nnonnegative orthant is a polyhedron and a cone (and therefore called a polyhedral\ncone).\n\nsimplexes\n\nsimplexes are another important family of polyhedra. suppose the k + 1 points\nv0, . . . , vk \u2208 rn are affinely independent, which means v1 \u2212 v0, . . . , vk \u2212 v0 are\nlinearly independent. the simplex determined by them is given by\n\nc = conv{v0, . . . , vk} = {\u03b80v0 + \u00b7\u00b7\u00b7 + \u03b8kvk | \u03b8 (cid:23) 0, 1t \u03b8 = 1},\n\n(2.7)\n\n "}, {"Page_number": 47, "text": "2.2 some important examples\n\n33\n\nwhere 1 denotes the vector with all entries one. the affine dimension of this simplex\nis k, so it is sometimes referred to as a k-dimensional simplex in rn.\n\nexample 2.5 some common simplexes. a 1-dimensional simplex is a line segment;\na 2-dimensional simplex is a triangle (including its interior); and a 3-dimensional\nsimplex is a tetrahedron.\n\nthe unit simplex is the n-dimensional simplex determined by the zero vector and the\nunit vectors, i.e., 0, e1, . . . , en \u2208 rn. it can be expressed as the set of vectors that\nsatisfy\n\nx (cid:23) 0,\n\n1t x \u2264 1.\n\nthe probability simplex is the (n \u2212 1)-dimensional simplex determined by the unit\nvectors e1, . . . , en \u2208 rn. it is the set of vectors that satisfy\n\nx (cid:23) 0,\n\n1t x = 1.\n\nvectors in the probability simplex correspond to probability distributions on a set\nwith n elements, with xi interpreted as the probability of the ith element.\n\nto describe the simplex (2.7) as a polyhedron, i.e., in the form (2.6), we proceed\nas follows. by definition, x \u2208 c if and only if x = \u03b80v0 + \u03b81v1 +\u00b7\u00b7\u00b7 + \u03b8kvk for some\n\u03b8 (cid:23) 0 with 1t \u03b8 = 1. equivalently, if we define y = (\u03b81, . . . , \u03b8k) and\n\nb =(cid:2) v1 \u2212 v0\n\n\u00b7\u00b7\u00b7\n\nvk \u2212 v0 (cid:3) \u2208 rn\u00d7k,\n\nwe can say that x \u2208 c if and only if\n\nx = v0 + by\n\n(2.8)\n\nfor some y (cid:23) 0 with 1t y \u2264 1. now we note that affine independence of the\npoints v0, . . . , vk implies that the matrix b has rank k. therefore there exists a\nnonsingular matrix a = (a1, a2) \u2208 rn\u00d7n such that\na2 (cid:21) b =(cid:20) i\n0 (cid:21) .\n\nab =(cid:20) a1\n\nmultiplying (2.8) on the left with a, we obtain\n\na1x = a1v0 + y,\n\na2x = a2v0.\n\nfrom this we see that x \u2208 c if and only if a2x = a2v0, and the vector y =\na1x \u2212 a1v0 satisfies y (cid:23) 0 and 1t y \u2264 1. in other words we have x \u2208 c if and only\nif\n\na2x = a2v0,\n\na1x (cid:23) a1v0,\n\n1t a1x \u2264 1 + 1t a1v0,\n\nwhich is a set of linear equalities and inequalities in x, and so describes a polyhe-\ndron.\n\n "}, {"Page_number": 48, "text": "34\n\n2 convex sets\n\nconvex hull description of polyhedra\nthe convex hull of the finite set {v1, . . . , vk} is\n\nconv{v1, . . . , vk} = {\u03b81v1 + \u00b7\u00b7\u00b7 + \u03b8kvk | \u03b8 (cid:23) 0, 1t \u03b8 = 1}.\n\nthis set is a polyhedron, and bounded, but (except in special cases, e.g., a simplex)\nit is not simple to express it in the form (2.5), i.e., by a set of linear equalities and\ninequalities.\n\na generalization of this convex hull description is\n\n{\u03b81v1 + \u00b7\u00b7\u00b7 + \u03b8kvk | \u03b81 + \u00b7\u00b7\u00b7 + \u03b8m = 1, \u03b8i \u2265 0, i = 1, . . . , k},\n\n(2.9)\n\nwhere m \u2264 k. here we consider nonnegative linear combinations of vi, but only\nthe first m coefficients are required to sum to one. alternatively, we can inter-\npret (2.9) as the convex hull of the points v1, . . . , vm, plus the conic hull of the\npoints vm+1, . . . , vk. the set (2.9) defines a polyhedron, and conversely, every\npolyhedron can be represented in this form (although we will not show this).\n\nthe question of how a polyhedron is represented is subtle, and has very im-\nportant practical consequences. as a simple example consider the unit ball in the\n\u2113\u221e-norm in rn,\n\nc = {x | |xi| \u2264 1, i = 1, . . . , n}.\n\nthe set c can be described in the form (2.5) with 2n linear inequalities \u00b1et\ni x \u2264 1,\nwhere ei is the ith unit vector. to describe it in the convex hull form (2.9) requires\nat least 2n points:\n\nc = conv{v1, . . . , v2n},\n\nwhere v1, . . . , v2n are the 2n vectors all of whose components are 1 or \u22121. thus\nthe size of the two descriptions differs greatly, for large n.\n\n2.2.5 the positive semidefinite cone\n\nwe use the notation sn to denote the set of symmetric n \u00d7 n matrices,\n\nsn = {x \u2208 rn\u00d7n | x = x t},\n\nwhich is a vector space with dimension n(n + 1)/2. we use the notation sn\ndenote the set of symmetric positive semidefinite matrices:\n\n+ to\n\nand the notation sn\n\n++ to denote the set of symmetric positive definite matrices:\n\nsn\n+ = {x \u2208 sn | x (cid:23) 0},\n\n++ = {x \u2208 sn | x \u227b 0}.\nsn\n\n(this notation is meant to be analogous to r+, which denotes the nonnegative\nreals, and r++, which denotes the positive reals.)\n\n "}, {"Page_number": 49, "text": "2.3 operations that preserve convexity\n\n35\n\n1\n\n0.5\n\nz\n\n0\n1\n\n0\n\ny\n\n\u22121\n\n0\n\n0.5\n\nx\n\n1\n\nfigure 2.12 boundary of positive semidefinite cone in s2.\n\nthe set sn\n\n+ is a convex cone: if \u03b81, \u03b82 \u2265 0 and a, b \u2208 sn\n\n+, then \u03b81a+\u03b82b \u2208 sn\n+.\nthis can be seen directly from the definition of positive semidefiniteness: for any\nx \u2208 rn, we have\n\nxt (\u03b81a + \u03b82b)x = \u03b81xt ax + \u03b82xt bx \u2265 0,\n\nif a (cid:23) 0, b (cid:23) 0 and \u03b81, \u03b82 \u2265 0.\n\nexample 2.6 positive semidefinite cone in s2. we have\n\nx =(cid:20) x y\n\nz (cid:21) \u2208 s2\n\ny\n\n+ \u21d0\u21d2 x \u2265 0,\n\nz \u2265 0,\n\nxz \u2265 y2.\n\nthe boundary of this cone is shown in figure 2.12, plotted in r3 as (x, y, z).\n\n2.3 operations that preserve convexity\n\nin this section we describe some operations that preserve convexity of sets, or\nallow us to construct convex sets from others. these operations, together with the\nsimple examples described in \u00a72.2, form a calculus of convex sets that is useful for\ndetermining or establishing convexity of sets.\n\n "}, {"Page_number": 50, "text": "36\n\n2.3.1 intersection\n\n2 convex sets\n\nconvexity is preserved under intersection: if s1 and s2 are convex, then s1 \u2229 s2 is\nconvex. this property extends to the intersection of an infinite number of sets: if\n\ns\u03b1 is convex for every \u03b1 \u2208 a, thent\u03b1\u2208a s\u03b1 is convex. (subspaces, affine sets, and\n\nconvex cones are also closed under arbitrary intersections.) as a simple example,\na polyhedron is the intersection of halfspaces and hyperplanes (which are convex),\nand therefore is convex.\n\nexample 2.7 the positive semidefinite cone sn\n\n+ can be expressed as\n\n{x \u2208 sn | zt xz \u2265 0}.\n\n\\z6=0\n\nfor each z 6= 0, zt xz is a (not identically zero) linear function of x, so the sets\n\n{x \u2208 sn | zt xz \u2265 0}\n\nare, in fact, halfspaces in sn. thus the positive semidefinite cone is the intersection\nof an infinite number of halfspaces, and so is convex.\n\nexample 2.8 we consider the set\n\ns = {x \u2208 rm | |p(t)| \u2264 1 for |t| \u2264 \u03c0/3},\n\n(2.10)\n\nk=1 xk cos kt. the set s can be expressed as the intersection of an\n\nwhere p(t) =pm\ninfinite number of slabs: s =t|t|\u2264\u03c0/3 st, where\n\nst = {x | \u2212 1 \u2264 (cos t, . . . , cos mt)t x \u2264 1},\n\nand so is convex. the definition and the set are illustrated in figures 2.13 and 2.14,\nfor m = 2.\n\nin the examples above we establish convexity of a set by expressing it as a\n(possibly infinite) intersection of halfspaces. we will see in \u00a72.5.1 that a converse\nholds: every closed convex set s is a (usually infinite) intersection of halfspaces.\nin fact, a closed convex set s is the intersection of all halfspaces that contain it:\n\ns =\\ {h | h halfspace, s \u2286 h}.\n\n2.3.2 affine functions\n\nrecall that a function f : rn \u2192 rm is affine if it is a sum of a linear function and\na constant, i.e., if it has the form f (x) = ax + b, where a \u2208 rm\u00d7n and b \u2208 rm.\nsuppose s \u2286 rn is convex and f : rn \u2192 rm is an affine function. then the image\nof s under f ,\n\nf (s) = {f (x) | x \u2208 s},\n\n "}, {"Page_number": 51, "text": "2.3 operations that preserve convexity\n\n37\n\n1\n\n0\n\u22121\n\n)\nt\n(\np\n\n0\n\n\u03c0/3\n\nt\n\n2\u03c0/3\n\n\u03c0\n\nfigure 2.13 three trigonometric polynomials associated with points in the\nset s defined in (2.10), for m = 2. the trigonometric polynomial plotted\nwith dashed line type is the average of the other two.\n\n2\n\n1\n\n2\nx\n\n0\n\n\u22121\n\n\u22122\n\u22122\n\ns\n\n\u22121\n\n0\nx1\n\n1\n\n2\n\nfigure 2.14 the set s defined in (2.10), for m = 2, is shown as the white\narea in the middle of the plot. the set is the intersection of an infinite\nnumber of slabs (20 of which are shown), hence convex.\n\n "}, {"Page_number": 52, "text": "38\n\n2 convex sets\n\nis convex. similarly, if f : rk \u2192 rn is an affine function, the inverse image of s\nunder f ,\n\nf \u22121(s) = {x | f (x) \u2208 s},\n\nis convex.\n\ntwo simple examples are scaling and translation. if s \u2286 rn is convex, \u03b1 \u2208 r,\n\nand a \u2208 rn, then the sets \u03b1s and s + a are convex, where\n\n\u03b1s = {\u03b1x | x \u2208 s},\n\ns + a = {x + a | x \u2208 s}.\n\nthe projection of a convex set onto some of its coordinates is convex:\nrm \u00d7 rn is convex, then\n\nt = {x1 \u2208 rm | (x1, x2) \u2208 s for some x2 \u2208 rn}\n\nif s \u2286\n\nis convex.\n\nthe sum of two sets is defined as\n\ns1 + s2 = {x + y | x \u2208 s1, y \u2208 s2}.\n\nif s1 and s2 are convex, then s1 + s2 is convex. to see this, if s1 and s2 are\nconvex, then so is the direct or cartesian product\n\ns1 \u00d7 s2 = {(x1, x2) | x1 \u2208 s1, x2 \u2208 s2}.\n\nthe image of this set under the linear function f (x1, x2) = x1 + x2 is the sum\ns1 + s2.\n\nwe can also consider the partial sum of s1, s2 \u2208 rn \u00d7 rm, defined as\n\ns = {(x, y1 + y2) | (x, y1) \u2208 s1, (x, y2) \u2208 s2},\n\nwhere x \u2208 rn and yi \u2208 rm. for m = 0, the partial sum gives the intersection of\ns1 and s2; for n = 0, it is set addition. partial sums of convex sets are convex (see\nexercise 2.16).\n\nexample 2.9 polyhedron. the polyhedron {x | ax (cid:22) b, cx = d} can be expressed as\nthe inverse image of the cartesian product of the nonnegative orthant and the origin\nunder the affine function f (x) = (b \u2212 ax, d \u2212 cx):\n\n{x | ax (cid:22) b, cx = d} = {x | f (x) \u2208 rm\n\n+ \u00d7 {0}}.\n\nexample 2.10 solution set of linear matrix inequality. the condition\n\n(2.11)\nwhere b, ai \u2208 sm, is called a linear matrix inequality (lmi) in x (note the similarity\nto an ordinary linear inequality,\n\na(x) = x1a1 + \u00b7\u00b7\u00b7 + xnan (cid:22) b,\n\nat x = x1a1 + \u00b7\u00b7\u00b7 + xnan \u2264 b,\n\nwith b, ai \u2208 r.)\nthe solution set of a linear matrix inequality, {x | a(x) (cid:22) b}, is convex. indeed,\nit is the inverse image of the positive semidefinite cone under the affine function\nf : rn \u2192 sm given by f (x) = b \u2212 a(x).\n\n "}, {"Page_number": 53, "text": "2.3 operations that preserve convexity\n\n39\n\nexample 2.11 hyperbolic cone. the set\n\n{x | xt p x \u2264 (ct x)2, ct x \u2265 0}\n\nwhere p \u2208 sn\ncone,\n\n+ and c \u2208 rn, is convex, since it is the inverse image of the second-order\n\nunder the affine function f (x) = (p 1/2x, ct x).\n\n{(z, t) | zt z \u2264 t2, t \u2265 0},\n\nexample 2.12 ellipsoid. the ellipsoid\n\ne = {x | (x \u2212 xc)t p \u22121(x \u2212 xc) \u2264 1},\n\nwhere p \u2208 sn\n++, is the image of the unit euclidean ball {u | kuk2 \u2264 1} under the\naffine mapping f (u) = p 1/2u + xc. (it is also the inverse image of the unit ball under\nthe affine mapping g(x) = p \u22121/2(x \u2212 xc).)\n\n2.3.3 linear-fractional and perspective functions\n\nin this section we explore a class of functions, called linear-fractional, that is more\ngeneral than affine but still preserves convexity.\n\nthe perspective function\nwe define the perspective function p : rn+1 \u2192 rn, with domain dom p = rn \u00d7\nr++, as p (z, t) = z/t. (here r++ denotes the set of positive numbers: r++ =\n{x \u2208 r | x > 0}.) the perspective function scales or normalizes vectors so the last\ncomponent is one, and then drops the last component.\n\nremark 2.1 we can interpret the perspective function as the action of a pin-hole\ncamera. a pin-hole camera (in r3) consists of an opaque horizontal plane x3 = 0,\nwith a single pin-hole at the origin, through which light can pass, and a horizontal\nimage plane x3 = \u22121. an object at x, above the camera (i.e., with x3 > 0), forms\nan image at the point \u2212(x1/x3, x2/x3, 1) on the image plane. dropping the last\ncomponent of the image point (since it is always \u22121), the image of a point at x\nappears at y = \u2212(x1/x3, x2/x3) = \u2212p (x) on the image plane. this is illustrated in\nfigure 2.15.\n\nif c \u2286 dom p is convex, then its image\n\np (c) = {p (x) | x \u2208 c}\n\nis convex. this result is certainly intuitive: a convex object, viewed through a\npin-hole camera, yields a convex image. to establish this fact we show that line\nsegments are mapped to line segments under the perspective function. (this too\n\n "}, {"Page_number": 54, "text": "40\n\n2 convex sets\n\nx3 = 0\n\nx3 = \u22121\n\nfigure 2.15 pin-hole camera interpretation of perspective function. the\ndark horizontal line represents the plane x3 = 0 in r3, which is opaque,\nexcept for a pin-hole at the origin. objects or light sources above the plane\nappear on the image plane x3 = \u22121, which is shown as the lighter horizontal\nline. the mapping of the position of a source to the position of its image is\nrelated to the perspective function.\n\nmakes sense: a line segment, viewed through a pin-hole camera, yields a line seg-\nment image.) suppose that x = (\u02dcx, xn+1), y = (\u02dcy, yn+1) \u2208 rn+1 with xn+1 > 0,\nyn+1 > 0. then for 0 \u2264 \u03b8 \u2264 1,\n\np (\u03b8x + (1 \u2212 \u03b8)y) =\n\n\u03b8\u02dcx + (1 \u2212 \u03b8)\u02dcy\n\n\u03b8xn+1 + (1 \u2212 \u03b8)yn+1\n\n= \u00b5p (x) + (1 \u2212 \u00b5)p (y),\n\nwhere\n\n\u00b5 =\n\n\u03b8xn+1\n\n\u03b8xn+1 + (1 \u2212 \u03b8)yn+1 \u2208 [0, 1].\n\nthis correspondence between \u03b8 and \u00b5 is monotonic: as \u03b8 varies between 0 and 1\n(which sweeps out the line segment [x, y]), \u00b5 varies between 0 and 1 (which sweeps\nout the line segment [p (x), p (y)]). this shows that p ([x, y]) = [p (x), p (y)].\n\nnow suppose c is convex with c \u2286 dom p (i.e., xn+1 > 0 for all x \u2208 c), and\nx, y \u2208 c. to establish convexity of p (c) we need to show that the line segment\n[p (x), p (y)] is in p (c). but this line segment is the image of the line segment\n[x, y] under p , and so lies in p (c).\n\nthe inverse image of a convex set under the perspective function is also convex:\n\nif c \u2286 rn is convex, then\n\np \u22121(c) = {(x, t) \u2208 rn+1 | x/t \u2208 c, t > 0}\n\nis convex. to show this, suppose (x, t) \u2208 p \u22121(c), (y, s) \u2208 p \u22121(c), and 0 \u2264 \u03b8 \u2264 1.\nwe need to show that\n\ni.e., that\n\n\u03b8(x, t) + (1 \u2212 \u03b8)(y, s) \u2208 p \u22121(c),\n\n\u03b8x + (1 \u2212 \u03b8)y\n\u03b8t + (1 \u2212 \u03b8)s \u2208 c\n\n "}, {"Page_number": 55, "text": "2.3 operations that preserve convexity\n\n41\n\n(\u03b8t + (1 \u2212 \u03b8)s > 0 is obvious). this follows from\n\nwhere\n\n\u03b8x + (1 \u2212 \u03b8)y\n\u03b8t + (1 \u2212 \u03b8)s\n\n= \u00b5(x/t) + (1 \u2212 \u00b5)(y/s),\n\n\u00b5 =\n\n\u03b8t\n\n\u03b8t + (1 \u2212 \u03b8)s \u2208 [0, 1].\n\nlinear-fractional functions\n\na linear-fractional function is formed by composing the perspective function with\nan affine function. suppose g : rn \u2192 rm+1 is affine, i.e.,\nd (cid:21) ,\nct (cid:21) x +(cid:20) b\n\ng(x) =(cid:20) a\n\n(2.12)\n\nwhere a \u2208 rm\u00d7n, b \u2208 rm, c \u2208 rn, and d \u2208 r. the function f : rn \u2192 rm given\nby f = p \u25e6 g, i.e.,\n\nf (x) = (ax + b)/(ct x + d),\n\ndom f = {x | ct x + d > 0},\n\n(2.13)\n\nis called a linear-fractional (or projective) function. if c = 0 and d > 0, the domain\nof f is rn, and f is an affine function. so we can think of affine and linear functions\nas special cases of linear-fractional functions.\n\nremark 2.2 projective interpretation. it is often convenient to represent a linear-\nfractional function as a matrix\n\nq =(cid:20) a b\n\nd (cid:21) \u2208 r(m+1)\u00d7(n+1)\n\nct\n\n(2.14)\n\nthat acts on (multiplies) points of form (x, 1), which yields (ax + b, ct x + d). this\nresult is then scaled or normalized so that its last component is one, which yields\n(f (x), 1).\nthis representation can be interpreted geometrically by associating rn with a set\nof rays in rn+1 as follows. with each point z in rn we associate the (open) ray\np(z) = {t(z, 1) | t > 0} in rn+1. the last component of this ray takes on positive\nvalues. conversely any ray in rn+1, with base at the origin and last component\nwhich takes on positive values, can be written as p(v) = {t(v, 1) | t \u2265 0} for some\nv \u2208 rn. this (projective) correspondence p between rn and the halfspace of rays\nwith positive last component is one-to-one and onto.\n\nthe linear-fractional function (2.13) can be expressed as\n\nf (x) = p \u22121(qp(x)).\n\nthus, we start with x \u2208 dom f , i.e., ct x + d > 0. we then form the ray p(x) in\nrn+1. the linear transformation with matrix q acts on this ray to produce another\nray qp(x). since x \u2208 dom f , the last component of this ray assumes positive values.\nfinally we take the inverse projective transformation to recover f (x).\n\n "}, {"Page_number": 56, "text": "42\n\n2 convex sets\n\n1\n\n2\nx\n\n0\n\n\u22121\n\u22121\n\nc\n\n0\nx1\n\n1\n\n2\nx\n\n0\n\nf (c)\n\n1\n\n\u22121\n\u22121\n\n0\nx1\n\n1\n\nfigure 2.16 left. a set c \u2286 r2. the dashed line shows the boundary of\nthe domain of the linear-fractional function f (x) = x/(x1 + x2 + 1) with\ndom f = {(x1, x2) | x1 + x2 + 1 > 0}. right. image of c under f . the\ndashed line shows the boundary of the domain of f \u22121.\n\nlike the perspective function, linear-fractional functions preserve convexity. if\nc is convex and lies in the domain of f (i.e., ct x + d > 0 for x \u2208 c), then its\nimage f (c) is convex. this follows immediately from results above: the image of c\nunder the affine mapping (2.12) is convex, and the image of the resulting set under\nthe perspective function p , which yields f (c), is convex. similarly, if c \u2286 rm is\nconvex, then the inverse image f \u22121(c) is convex.\n\nexample 2.13 conditional probabilities. suppose u and v are random variables\nthat take on values in {1, . . . , n} and {1, . . . , m}, respectively, and let pij denote\nprob(u = i, v = j). then the conditional probability fij = prob(u = i|v = j) is\ngiven by\n\nthus f is obtained by a linear-fractional mapping from p.\n\nfij =\n\n.\n\nk=1 pkj\n\npijpn\n\nit follows that if c is a convex set of joint probabilities for (u, v), then the associated\nset of conditional probabilities of u given v is also convex.\n\nfigure 2.16 shows a set c \u2286 r2, and its image under the linear-fractional\n\nfunction\n\nf (x) =\n\n1\n\nx1 + x2 + 1\n\nx,\n\ndom f = {(x1, x2) | x1 + x2 + 1 > 0}.\n\n "}, {"Page_number": 57, "text": "2.4 generalized inequalities\n\n43\n\n2.4 generalized inequalities\n\n2.4.1 proper cones and generalized inequalities\n\na cone k \u2286 rn is called a proper cone if it satisfies the following:\n\n\u2022 k is convex.\n\u2022 k is closed.\n\u2022 k is solid, which means it has nonempty interior.\n\u2022 k is pointed, which means that it contains no line (or equivalently, x \u2208\n\nk, \u2212 x \u2208 k =\u21d2 x = 0).\n\na proper cone k can be used to define a generalized inequality, which is a partial\nordering on rn that has many of the properties of the standard ordering on r.\nwe associate with the proper cone k the partial ordering on rn defined by\n\nx (cid:22)k y \u21d0\u21d2 y \u2212 x \u2208 k.\n\nwe also write x (cid:23)k y for y (cid:22)k x. similarly, we define an associated strict partial\nordering by\n\nx \u227ak y \u21d0\u21d2 y \u2212 x \u2208 int k,\n\nand write x \u227bk y for y \u227ak x.\n(to distinguish the generalized inequality (cid:22)k\nfrom the strict generalized inequality, we sometimes refer to (cid:22)k as the nonstrict\ngeneralized inequality.)\nwhen k = r+, the partial ordering (cid:22)k is the usual ordering \u2264 on r, and\nthe strict partial ordering \u227ak is the same as the usual strict ordering < on r.\nso generalized inequalities include as a special case ordinary (nonstrict and strict)\ninequality in r.\n\nexample 2.14 nonnegative orthant and componentwise inequality. the nonnegative\northant k = rn\n+ is a proper cone. the associated generalized inequality (cid:22)k corre-\nsponds to componentwise inequality between vectors: x (cid:22)k y means that xi \u2264 yi,\ni = 1, . . . , n. the associated strict inequality corresponds to componentwise strict\ninequality: x \u227ak y means that xi < yi, i = 1, . . . , n.\nthe nonstrict and strict partial orderings associated with the nonnegative orthant\narise so frequently that we drop the subscript rn\n+; it is understood when the symbol\n(cid:22) or \u227a appears between vectors.\n\nexample 2.15 positive semidefinite cone and matrix inequality. the positive semidef-\n+ is a proper cone in sn. the associated generalized inequality (cid:22)k is the\ninite cone sn\nusual matrix inequality: x (cid:22)k y means y \u2212 x is positive semidefinite. the inte-\nrior of sn\n+ (in sn) consists of the positive definite matrices, so the strict generalized\ninequality also agrees with the usual strict inequality between symmetric matrices:\nx \u227ak y means y \u2212 x is positive definite.\nhere, too, the partial ordering arises so frequently that we drop the subscript: for\nsymmetric matrices we write simply x (cid:22) y or x \u227a y . it is understood that the\ngeneralized inequalities are with respect to the positive semidefinite cone.\n\n "}, {"Page_number": 58, "text": "44\n\n2 convex sets\n\nexample 2.16 cone of polynomials nonnegative on [0, 1]. let k be defined as\n\nk = {c \u2208 rn | c1 + c2t + \u00b7\u00b7\u00b7 + cntn\u22121 \u2265 0 for t \u2208 [0, 1]},\n\n(2.15)\n\ni.e., k is the cone of (coefficients of) polynomials of degree n\u22121 that are nonnegative\non the interval [0, 1]. it can be shown that k is a proper cone; its interior is the set\nof coefficients of polynomials that are positive on the interval [0, 1].\ntwo vectors c, d \u2208 rn satisfy c (cid:22)k d if and only if\n\nc1 + c2t + \u00b7\u00b7\u00b7 + cntn\u22121 \u2264 d1 + d2t + \u00b7\u00b7\u00b7 + dntn\u22121\n\nfor all t \u2208 [0, 1].\n\nproperties of generalized inequalities\n\na generalized inequality (cid:22)k satisfies many properties, such as\n\n\u2022 (cid:22)k is preserved under addition: if x (cid:22)k y and u (cid:22)k v, then x + u (cid:22)k y + v.\n\u2022 (cid:22)k is transitive: if x (cid:22)k y and y (cid:22)k z then x (cid:22)k z.\n\u2022 (cid:22)k is preserved under nonnegative scaling:\n\nif x (cid:22)k y and \u03b1 \u2265 0 then\n\n\u03b1x (cid:22)k \u03b1y.\n\n\u2022 (cid:22)k is reflexive: x (cid:22)k x.\n\u2022 (cid:22)k is antisymmetric: if x (cid:22)k y and y (cid:22)k x, then x = y.\n\u2022 (cid:22)k is preserved under limits: if xi (cid:22)k yi for i = 1, 2, . . ., xi \u2192 x and yi \u2192 y\n\nas i \u2192 \u221e, then x (cid:22)k y.\n\nthe corresponding strict generalized inequality \u227ak satisfies, for example,\n\n\u2022 if x \u227ak y then x (cid:22)k y.\n\u2022 if x \u227ak y and u (cid:22)k v then x + u \u227ak y + v.\n\u2022 if x \u227ak y and \u03b1 > 0 then \u03b1x \u227ak \u03b1y.\n\u2022 x 6\u227ak x.\n\u2022 if x \u227ak y, then for u and v small enough, x + u \u227ak y + v.\n\nthese properties are inherited from the definitions of (cid:22)k and \u227ak, and the prop-\nerties of proper cones; see exercise 2.30.\n\n "}, {"Page_number": 59, "text": "2.4 generalized inequalities\n\n45\n\n2.4.2 minimum and minimal elements\n\nthe notation of generalized inequality (i.e., (cid:22)k, \u227ak) is meant to suggest the\nanalogy to ordinary inequality on r (i.e., \u2264, <). while many properties of ordinary\ninequality do hold for generalized inequalities, some important ones do not. the\nmost obvious difference is that \u2264 on r is a linear ordering: any two points are\ncomparable, meaning either x \u2264 y or y \u2264 x. this property does not hold for\nother generalized inequalities. one implication is that concepts like minimum and\nmaximum are more complicated in the context of generalized inequalities. we\nbriefly discuss this in this section.\n\nwe say that x \u2208 s is the minimum element of s (with respect to the general-\nized inequality (cid:22)k) if for every y \u2208 s we have x (cid:22)k y. we define the maximum\nelement of a set s, with respect to a generalized inequality, in a similar way. if a\nset has a minimum (maximum) element, then it is unique. a related concept is\nminimal element. we say that x \u2208 s is a minimal element of s (with respect to\nthe generalized inequality (cid:22)k) if y \u2208 s, y (cid:22)k x only if y = x. we define maxi-\nmal element in a similar way. a set can have many different minimal (maximal)\nelements.\n\nwe can describe minimum and minimal elements using simple set notation. a\n\npoint x \u2208 s is the minimum element of s if and only if\n\ns \u2286 x + k.\n\nhere x + k denotes all the points that are comparable to x and greater than or\nequal to x (according to (cid:22)k). a point x \u2208 s is a minimal element if and only if\n\n(x \u2212 k) \u2229 s = {x}.\n\nhere x \u2212 k denotes all the points that are comparable to x and less than or equal\nto x (according to (cid:22)k); the only point in common with s is x.\nfor k = r+, which induces the usual ordering on r, the concepts of minimal\nand minimum are the same, and agree with the usual definition of the minimum\nelement of a set.\n\nexample 2.17 consider the cone r2\n+, which induces componentwise inequality in\nr2. here we can give some simple geometric descriptions of minimal and minimum\nelements. the inequality x (cid:22) y means y is above and to the right of x. to say that\nx \u2208 s is the minimum element of a set s means that all other points of s lie above\nand to the right. to say that x is a minimal element of a set s means that no other\npoint of s lies to the left and below x. this is illustrated in figure 2.17.\n\nexample 2.18 minimum and minimal elements of a set of symmetric matrices. we\nassociate with each a \u2208 sn\n\n++ an ellipsoid centered at the origin, given by\n\nea = {x | xt a\u22121x \u2264 1}.\n\nwe have a (cid:22) b if and only if ea \u2286 eb.\nlet v1, . . . , vk \u2208 rn be given and define\n++ | vt\n\ns = {p \u2208 sn\n\ni p \u22121vi \u2264 1, i = 1, . . . , k},\n\n "}, {"Page_number": 60, "text": "46\n\n2 convex sets\n\ns1\n\nx1\n\ns2\n\nx2\n\nfigure 2.17 left. the set s1 has a minimum element x1 with respect to\ncomponentwise inequality in r2. the set x1 + k is shaded lightly; x1 is\nthe minimum element of s1 since s1 \u2286 x1 + k. right. the point x2 is a\nminimal point of s2. the set x2 \u2212 k is shown lightly shaded. the point x2\nis minimal because x2 \u2212 k and s2 intersect only at x2.\n\nwhich corresponds to the set of ellipsoids that contain the points v1, . . . , vk. the\nset s does not have a minimum element: for any ellipsoid that contains the points\nv1, . . . , vk we can find another one that contains the points, and is not comparable\nto it. an ellipsoid is minimal if it contains the points, but no smaller ellipsoid does.\nfigure 2.18 shows an example in r2 with k = 2.\n\n2.5 separating and supporting hyperplanes\n\n2.5.1 separating hyperplane theorem\n\nin this section we describe an idea that will be important later: the use of hyper-\nplanes or affine functions to separate convex sets that do not intersect. the basic\nresult is the separating hyperplane theorem: suppose c and d are two convex sets\nthat do not intersect, i.e., c \u2229 d = \u2205. then there exist a 6= 0 and b such that\nat x \u2264 b for all x \u2208 c and at x \u2265 b for all x \u2208 d. in other words, the affine function\nat x \u2212 b is nonpositive on c and nonnegative on d. the hyperplane {x | at x = b}\nis called a separating hyperplane for the sets c and d, or is said to separate the\nsets c and d. this is illustrated in figure 2.19.\n\nproof of separating hyperplane theorem\n\nhere we consider a special case, and leave the extension of the proof to the gen-\neral case as an exercise (exercise 2.22). we assume that the (euclidean) distance\nbetween c and d, defined as\n\ndist(c, d) = inf{ku \u2212 vk2 | u \u2208 c, v \u2208 d},\n\n "}, {"Page_number": 61, "text": "2.5 separating and supporting hyperplanes\n\n47\n\ne2\n\ne3\n\ne1\n\nfigure 2.18 three ellipsoids in r2, centered at the origin (shown as the\nlower dot), that contain the points shown as the upper dots. the ellipsoid\ne1 is not minimal, since there exist ellipsoids that contain the points, and\nare smaller (e.g., e3). e3 is not minimal for the same reason. the ellipsoid\ne2 is minimal, since no other ellipsoid (centered at the origin) contains the\npoints and is contained in e2.\n\nat x \u2265 b\n\nat x \u2264 b\n\nd\n\na\n\nc\n\nfigure 2.19 the hyperplane {x | at x = b} separates the disjoint convex sets\nc and d. the affine function at x \u2212 b is nonpositive on c and nonnegative\non d.\n\n "}, {"Page_number": 62, "text": "48\n\n2 convex sets\n\na\n\nd\n\nd\n\nc\n\nc\n\nfigure 2.20 construction of a separating hyperplane between two convex\nsets. the points c \u2208 c and d \u2208 d are the pair of points in the two sets that\nare closest to each other. the separating hyperplane is orthogonal to, and\nbisects, the line segment between c and d.\n\nis positive, and that there exist points c \u2208 c and d \u2208 d that achieve the minimum\ndistance, i.e., kc \u2212 dk2 = dist(c, d). (these conditions are satisfied, for example,\nwhen c and d are closed and one set is bounded.)\n\ndefine\n\nwe will show that the affine function\n\na = d \u2212 c,\n\nb = kdk2\n\n2 \u2212 kck2\n2\n\n2\n\n.\n\nf (x) = at x \u2212 b = (d \u2212 c)t (x \u2212 (1/2)(d + c))\n\nis nonpositive on c and nonnegative on d, i.e., that the hyperplane {x | at x = b}\nseparates c and d. this hyperplane is perpendicular to the line segment between\nc and d, and passes through its midpoint, as shown in figure 2.20.\n\nwe first show that f is nonnegative on d. the proof that f is nonpositive on\nc is similar (or follows by swapping c and d and considering \u2212f ). suppose there\nwere a point u \u2208 d for which\n\nf (u) = (d \u2212 c)t (u \u2212 (1/2)(d + c)) < 0.\n\n(2.16)\n\nwe can express f (u) as\n\nf (u) = (d \u2212 c)t (u \u2212 d + (1/2)(d \u2212 c)) = (d \u2212 c)t (u \u2212 d) + (1/2)kd \u2212 ck2\n2.\n\nwe see that (2.16) implies (d \u2212 c)t (u \u2212 d) < 0. now we observe that\n\nd\ndtkd + t(u \u2212 d) \u2212 ck2\n\n= 2(d \u2212 c)t (u \u2212 d) < 0,\n\n2(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\nso for some small t > 0, with t \u2264 1, we have\n\nkd + t(u \u2212 d) \u2212 ck2 < kd \u2212 ck2,\n\n "}, {"Page_number": 63, "text": "2.5 separating and supporting hyperplanes\n\n49\n\ni.e., the point d + t(u \u2212 d) is closer to c than d is. since d is convex and contains\nd and u, we have d + t(u\u2212 d) \u2208 d. but this is impossible, since d is assumed to be\nthe point in d that is closest to c.\n\nexample 2.19 separation of an affine and a convex set. suppose c is convex and\nd is affine, i.e., d = {f u + g | u \u2208 rm}, where f \u2208 rn\u00d7m. suppose c and d are\ndisjoint, so by the separating hyperplane theorem there are a 6= 0 and b such that\nat x \u2264 b for all x \u2208 c and at x \u2265 b for all x \u2208 d.\nnow at x \u2265 b for all x \u2208 d means at f u \u2265 b \u2212 at g for all u \u2208 rm. but a linear\nfunction is bounded below on rm only when it is zero, so we conclude at f = 0 (and\nhence, b \u2264 at g).\nthus we conclude that there exists a 6= 0 such that f t a = 0 and at x \u2264 at g for all\nx \u2208 c.\n\nstrict separation\n\nthe separating hyperplane we constructed above satisfies the stronger condition\nthat at x < b for all x \u2208 c and at x > b for all x \u2208 d. this is called strict\nseparation of the sets c and d. simple examples show that in general, disjoint\nconvex sets need not be strictly separable by a hyperplane (even when the sets are\nclosed; see exercise 2.23). in many special cases, however, strict separation can be\nestablished.\n\nexample 2.20 strict separation of a point and a closed convex set. let c be a closed\nconvex set and x0 6\u2208 c. then there exists a hyperplane that strictly separates x0\nfrom c.\n\nto see this, note that the two sets c and b(x0, \u01eb) do not intersect for some \u01eb > 0.\nby the separating hyperplane theorem, there exist a 6= 0 and b such that at x \u2264 b for\nx \u2208 c and at x \u2265 b for x \u2208 b(x0, \u01eb).\nusing b(x0, \u01eb) = {x0 + u | kuk2 \u2264 \u01eb}, the second condition can be expressed as\n\nat (x0 + u) \u2265 b for all kuk2 \u2264 \u01eb.\n\nthe u that minimizes the lefthand side is u = \u2212\u01eba/kak2; using this value we have\n\ntherefore the affine function\n\nat x0 \u2212 \u01ebkak2 \u2265 b.\n\nf (x) = at x \u2212 b \u2212 \u01ebkak2/2\n\nis negative on c and positive at x0.\n\nas an immediate consequence we can establish a fact that we already mentioned\nabove: a closed convex set is the intersection of all halfspaces that contain it. indeed,\nlet c be closed and convex, and let s be the intersection of all halfspaces containing\nc. obviously x \u2208 c \u21d2 x \u2208 s. to show the converse, suppose there exists x \u2208 s,\nx 6\u2208 c. by the strict separation result there exists a hyperplane that strictly separates\nx from c, i.e., there is a halfspace containing c but not x. in other words, x 6\u2208 s.\n\n "}, {"Page_number": 64, "text": "50\n\n2 convex sets\n\nconverse separating hyperplane theorems\n\nthe converse of the separating hyperplane theorem (i.e., existence of a separating\nhyperplane implies that c and d do not intersect) is not true, unless one imposes\nadditional constraints on c or d, even beyond convexity. as a simple counterex-\nample, consider c = d = {0} \u2286 r. here the hyperplane x = 0 separates c and\nd.\nby adding conditions on c and d various converse separation theorems can be\nderived. as a very simple example, suppose c and d are convex sets, with c open,\nand there exists an affine function f that is nonpositive on c and nonnegative on\nd. then c and d are disjoint. (to see this we first note that f must be negative\non c; for if f were zero at a point of c then f would take on positive values near\nthe point, which is a contradiction. but then c and d must be disjoint since f\nis negative on c and nonnegative on d.) putting this converse together with the\nseparating hyperplane theorem, we have the following result: any two convex sets\nc and d, at least one of which is open, are disjoint if and only if there exists a\nseparating hyperplane.\n\nexample 2.21 theorem of alternatives for strict linear inequalities. we derive the\nnecessary and sufficient conditions for solvability of a system of strict linear inequal-\nities\n\nthese inequalities are infeasible if and only if the (convex) sets\n\nax \u227a b.\n\n(2.17)\n\nc = {b \u2212 ax | x \u2208 rn},\n\nd = rm\n\n++ = {y \u2208 rm | y \u227b 0}\n\ndo not intersect. the set d is open; c is an affine set. hence by the result above, c\nand d are disjoint if and only if there exists a separating hyperplane, i.e., a nonzero\n\u03bb \u2208 rm and \u00b5 \u2208 r such that \u03bbt y \u2264 \u00b5 on c and \u03bbt y \u2265 \u00b5 on d.\neach of these conditions can be simplified. the first means \u03bbt (b \u2212 ax) \u2264 \u00b5 for all x.\nthis implies (as in example 2.19) that at \u03bb = 0 and \u03bbt b \u2264 \u00b5. the second inequality\nmeans \u03bbt y \u2265 \u00b5 for all y \u227b 0. this implies \u00b5 \u2264 0 and \u03bb (cid:23) 0, \u03bb 6= 0.\nputting it all together, we find that the set of strict inequalities (2.17) is infeasible if\nand only if there exists \u03bb \u2208 rm such that\n\n\u03bb 6= 0,\n\n(2.18)\nthis is also a system of linear inequalities and linear equations in the variable \u03bb \u2208 rm.\nwe say that (2.17) and (2.18) form a pair of alternatives: for any data a and b, exactly\none of them is solvable.\n\n\u03bb (cid:23) 0,\n\n\u03bbt b \u2264 0.\n\nat \u03bb = 0,\n\n2.5.2 supporting hyperplanes\n\nsuppose c \u2286 rn, and x0 is a point in its boundary bd c, i.e.,\n\nx0 \u2208 bd c = cl c \\ int c.\n\nif a 6= 0 satisfies at x \u2264 at x0 for all x \u2208 c, then the hyperplane {x | at x = at x0}\nis called a supporting hyperplane to c at the point x0. this is equivalent to saying\n\n "}, {"Page_number": 65, "text": "2.6 dual cones and generalized inequalities\n\n51\n\na\n\nx0\n\nc\n\nfigure 2.21 the hyperplane {x | at x = at x0} supports c at x0.\n\nthat the point x0 and the set c are separated by the hyperplane {x | at x = at x0}.\nthe geometric interpretation is that the hyperplane {x | at x = at x0} is tangent\nto c at x0, and the halfspace {x | at x \u2264 at x0} contains c. this is illustrated in\nfigure 2.21.\na basic result, called the supporting hyperplane theorem, states that for any\nnonempty convex set c, and any x0 \u2208 bd c, there exists a supporting hyperplane to\nc at x0. the supporting hyperplane theorem is readily proved from the separating\nhyperplane theorem. we distinguish two cases. if the interior of c is nonempty,\nthe result follows immediately by applying the separating hyperplane theorem to\nthe sets {x0} and int c. if the interior of c is empty, then c must lie in an affine\nset of dimension less than n, and any hyperplane containing that affine set contains\nc and x0, and is a (trivial) supporting hyperplane.\n\nthere is also a partial converse of the supporting hyperplane theorem: if a set\nis closed, has nonempty interior, and has a supporting hyperplane at every point\nin its boundary, then it is convex. (see exercise 2.27.)\n\n2.6 dual cones and generalized inequalities\n\n2.6.1 dual cones\n\nlet k be a cone. the set\n\nk \u2217 = {y | xt y \u2265 0 for all x \u2208 k}\n\n(2.19)\n\nis called the dual cone of k. as the name suggests, k \u2217 is a cone, and is always\nconvex, even when the original cone k is not (see exercise 2.31).\n\ngeometrically, y \u2208 k \u2217 if and only if \u2212y is the normal of a hyperplane that\n\nsupports k at the origin. this is illustrated in figure 2.22.\n\nexample 2.22 subspace. the dual cone of a subspace v \u2286 rn (which is a cone) is\nits orthogonal complement v \u22a5 = {y | yt v = 0 for all v \u2208 v }.\n\n "}, {"Page_number": 66, "text": "52\n\n2 convex sets\n\ny\n\nk\n\nz\n\nk\n\nfigure 2.22 left. the halfspace with inward normal y contains the cone k,\nso y \u2208 k \u2217. right. the halfspace with inward normal z does not contain k,\nso z 6\u2208 k \u2217.\n\nexample 2.23 nonnegative orthant. the cone rn\n\n+ is its own dual:\n\nyt x \u2265 0 for all x (cid:23) 0 \u21d0\u21d2 y (cid:23) 0.\n\nwe call such a cone self-dual.\n\nexample 2.24 positive semidefinite cone. on the set of symmetric n \u00d7 n matrices\ni,j=1 xijyij (see \u00a7a.1.1). the\npositive semidefinite cone sn\n\nsn, we use the standard inner product tr(xy ) =pn\n\n+ is self-dual, i.e., for x, y \u2208 sn,\ntr(xy ) \u2265 0 for all x (cid:23) 0 \u21d0\u21d2 y (cid:23) 0.\n\nwe will establish this fact.\nsuppose y 6\u2208 sn\n\n+. then there exists q \u2208 rn with\n\nqt y q = tr(qqt y ) < 0.\n\n+)\u2217.\n\nhence the positive semidefinite matrix x = qqt satisfies tr(xy ) < 0; it follows that\ny 6\u2208 (sn\nnow suppose x, y \u2208 sn\n\n+. we can express x in terms of its eigenvalue decomposition\n\ni , where (the eigenvalues) \u03bbi \u2265 0, i = 1, . . . , n. then we have\n\ni=1 \u03bbiqiqt\n\nas x =pn\n\ntr(y x) = tr y\n\n\u03bbiqiqt\n\ni! =\n\nnxi=1\n\nnxi=1\n\n\u03bbiqt\n\ni y qi \u2265 0.\n\nthis shows that y \u2208 (sn\n\n+)\u2217.\n\nexample 2.25 dual of a norm cone. let k \u00b7 k be a norm on rn. the dual of the\nassociated cone k = {(x, t) \u2208 rn+1 | kxk \u2264 t} is the cone defined by the dual norm,\ni.e.,\n\nk \u2217 = {(u, v) \u2208 rn+1 | kuk\u2217 \u2264 v},\n\n "}, {"Page_number": 67, "text": "2.6 dual cones and generalized inequalities\n\n53\n\nwhere the dual norm is given by kuk\u2217 = sup{ut x | kxk \u2264 1} (see (a.1.6)).\nto prove the result we have to show that\n\nxt u + tv \u2265 0 whenever kxk \u2264 t \u21d0\u21d2 kuk\u2217 \u2264 v.\n\n(2.20)\n\nlet us start by showing that the righthand condition on (u, v) implies the lefthand\ncondition. suppose kuk\u2217 \u2264 v, and kxk \u2264 t for some t > 0. (if t = 0, x must be zero,\nso obviously ut x + vt \u2265 0.) applying the definition of the dual norm, and the fact\nthat k\u2212x/tk \u2264 1, we have\n\nut (\u2212x/t) \u2264 kuk\u2217 \u2264 v,\n\nand therefore ut x + vt \u2265 0.\nnext we show that the lefthand condition in (2.20) implies the righthand condition\nin (2.20). suppose kuk\u2217 > v, i.e., that the righthand condition does not hold. then\nby the definition of the dual norm, there exists an x with kxk \u2264 1 and xt u > v.\ntaking t = 1, we have\n\nut (\u2212x) + v < 0,\nwhich contradicts the lefthand condition in (2.20).\n\ndual cones satisfy several properties, such as:\n\u2022 k \u2217 is closed and convex.\n\u2022 k1 \u2286 k2 implies k \u2217\n2 \u2286 k \u2217\n1 .\n\u2022 if k has nonempty interior, then k \u2217 is pointed.\n\u2022 if the closure of k is pointed then k \u2217 has nonempty interior.\n\u2022 k \u2217\u2217 is the closure of the convex hull of k. (hence if k is convex and closed,\n\nk \u2217\u2217 = k.)\n\n(see exercise 2.31.) these properties show that if k is a proper cone, then so is its\ndual k \u2217, and moreover, that k \u2217\u2217 = k.\n\n2.6.2 dual generalized inequalities\n\nnow suppose that the convex cone k is proper, so it induces a generalized inequality\n(cid:22)k. then its dual cone k \u2217 is also proper, and therefore induces a generalized\ninequality. we refer to the generalized inequality (cid:22)k \u2217 as the dual of the generalized\ninequality (cid:22)k.\nsome important properties relating a generalized inequality and its dual are:\n\u2022 x (cid:22)k y if and only if \u03bbt x \u2264 \u03bbt y for all \u03bb (cid:23)k \u2217 0.\n\u2022 x \u227ak y if and only if \u03bbt x < \u03bbt y for all \u03bb (cid:23)k \u2217 0, \u03bb 6= 0.\nsince k = k \u2217\u2217, the dual generalized inequality associated with (cid:22)k \u2217 is (cid:22)k, so\nthese properties hold if the generalized inequality and its dual are swapped. as a\nspecific example, we have \u03bb (cid:22)k \u2217 \u00b5 if and only if \u03bbt x \u2264 \u00b5t x for all x (cid:23)k 0.\n\n "}, {"Page_number": 68, "text": "54\n\n2 convex sets\n\nexample 2.26 theorem of alternatives for linear strict generalized inequalities. sup-\npose k \u2286 rm is a proper cone. consider the strict generalized inequality\n\nax \u227ak b,\n\n(2.21)\n\nwhere x \u2208 rn.\nwe will derive a theorem of alternatives for this inequality. suppose it is infeasible,\ni.e., the affine set {b \u2212 ax | x \u2208 rn} does not intersect the open convex set int k.\nthen there is a separating hyperplane, i.e., a nonzero \u03bb \u2208 rm and \u00b5 \u2208 r such that\n\u03bbt (b \u2212 ax) \u2264 \u00b5 for all x, and \u03bbt y \u2265 \u00b5 for all y \u2208 int k. the first condition implies\nat \u03bb = 0 and \u03bbt b \u2264 \u00b5. the second condition implies \u03bbt y \u2265 \u00b5 for all y \u2208 k, which\ncan only happen if \u03bb \u2208 k \u2217 and \u00b5 \u2264 0.\nputting it all together we find that if (2.21) is infeasible, then there exists \u03bb such that\n\n\u03bb 6= 0,\n\n\u03bb (cid:23)k \u2217 0,\n\nat \u03bb = 0,\n\n\u03bbt b \u2264 0.\n\n(2.22)\n\nnow we show the converse: if (2.22) holds, then the inequality system (2.21) cannot\nbe feasible. suppose that both inequality systems hold. then we have \u03bbt (b \u2212 ax) >\n0, since \u03bb 6= 0, \u03bb (cid:23)k \u2217 0, and b \u2212 ax \u227bk 0. but using at \u03bb = 0 we find that\n\u03bbt (b \u2212 ax) = \u03bbt b \u2264 0, which is a contradiction.\nthus, the inequality systems (2.21) and (2.22) are alternatives: for any data a, b,\nexactly one of them is feasible. (this generalizes the alternatives (2.17), (2.18) for\nthe special case k = rm\n\n+ .)\n\n2.6.3 minimum and minimal elements via dual inequalities\n\nwe can use dual generalized inequalities to characterize minimum and minimal\nelements of a (possibly nonconvex) set s \u2286 rm with respect to the generalized\ninequality induced by a proper cone k.\n\ndual characterization of minimum element\n\nwe first consider a characterization of the minimum element: x is the minimum\nelement of s, with respect to the generalized inequality (cid:22)k, if and only if for all\n\u03bb \u227bk \u2217 0, x is the unique minimizer of \u03bbt z over z \u2208 s. geometrically, this means\nthat for any \u03bb \u227bk \u2217 0, the hyperplane\n\n{z | \u03bbt (z \u2212 x) = 0}\n\nis a strict supporting hyperplane to s at x. (by strict supporting hyperplane, we\nmean that the hyperplane intersects s only at the point x.) note that convexity\nof the set s is not required. this is illustrated in figure 2.23.\n\nto show this result, suppose x is the minimum element of s, i.e., x (cid:22)k z for\nall z \u2208 s, and let \u03bb \u227bk \u2217 0. let z \u2208 s, z 6= x. since x is the minimum element of\ns, we have z \u2212 x (cid:23)k 0. from \u03bb \u227bk \u2217 0 and z \u2212 x (cid:23)k 0, z \u2212 x 6= 0, we conclude\n\u03bbt (z \u2212 x) > 0. since z is an arbitrary element of s, not equal to x, this shows\nthat x is the unique minimizer of \u03bbt z over z \u2208 s. conversely, suppose that for all\n\u03bb \u227bk \u2217 0, x is the unique minimizer of \u03bbt z over z \u2208 s, but x is not the minimum\n\n "}, {"Page_number": 69, "text": "2.6 dual cones and generalized inequalities\n\n55\n\ns\n\nx\n\nfigure 2.23 dual characterization of minimum element. the point x is the\nminimum element of the set s with respect to r2\n+. this is equivalent to:\nfor every \u03bb \u227b 0, the hyperplane {z | \u03bbt (z \u2212 x) = 0} strictly supports s at\nx, i.e., contains s on one side, and touches it only at x.\n\nelement of s. then there exists z \u2208 s with z 6(cid:23)k x. since z \u2212 x 6(cid:23)k 0, there exists\n\u02dc\u03bb (cid:23)k \u2217 0 with \u02dc\u03bbt (z\u2212 x) < 0. hence \u03bbt (z\u2212 x) < 0 for \u03bb \u227bk \u2217 0 in the neighborhood\nof \u02dc\u03bb. this contradicts the assumption that x is the unique minimizer of \u03bbt z over\ns.\n\ndual characterization of minimal elements\n\nwe now turn to a similar characterization of minimal elements. here there is a gap\nbetween the necessary and sufficient conditions. if \u03bb \u227bk \u2217 0 and x minimizes \u03bbt z\nover z \u2208 s, then x is minimal. this is illustrated in figure 2.24.\nto show this, suppose that \u03bb \u227bk \u2217 0, and x minimizes \u03bbt z over s, but x is not\nminimal, i.e., there exists a z \u2208 s, z 6= x, and z (cid:22)k x. then \u03bbt (x \u2212 z) > 0, which\ncontradicts our assumption that x is the minimizer of \u03bbt z over s.\nthe converse is in general false: a point x can be minimal in s, but not a\nminimizer of \u03bbt z over z \u2208 s, for any \u03bb, as shown in figure 2.25. this figure\nsuggests that convexity plays an important role in the converse, which is correct.\nprovided the set s is convex, we can say that for any minimal element x there\nexists a nonzero \u03bb (cid:23)k \u2217 0 such that x minimizes \u03bbt z over z \u2208 s.\nto show this, suppose x is minimal, which means that ((x \u2212 k) \\ {x})\u2229 s = \u2205.\napplying the separating hyperplane theorem to the convex sets (x \u2212 k) \\ {x} and\ns, we conclude that there is a \u03bb 6= 0 and \u00b5 such that \u03bbt (x \u2212 y) \u2264 \u00b5 for all y \u2208 k,\nand \u03bbt z \u2265 \u00b5 for all z \u2208 s. from the first inequality we conclude \u03bb (cid:23)k \u2217 0. since\nx \u2208 s and x \u2208 x \u2212 k, we have \u03bbt x = \u00b5, so the second inequality implies that \u00b5\nis the minimum value of \u03bbt z over s. therefore, x is a minimizer of \u03bbt z over s,\nwhere \u03bb 6= 0, \u03bb (cid:23)k \u2217 0.\nthis converse theorem cannot be strengthened to \u03bb \u227bk \u2217 0. examples show\nthat a point x can be a minimal point of a convex set s, but not a minimizer of\n\n "}, {"Page_number": 70, "text": "56\n\n2 convex sets\n\n\u03bb1\n\nx1\n\ns\n\nx2\n\n\u03bb2\n\nfigure 2.24 a set s \u2286 r2. its set of minimal points, with respect to r2\n+, is\nshown as the darker section of its (lower, left) boundary. the minimizer of\n\u03bbt\n1 z over s is x1, and is minimal since \u03bb1 \u227b 0. the minimizer of \u03bbt\n2 z over\ns is x2, which is another minimal point of s, since \u03bb2 \u227b 0.\n\ns\n\nx\n\nfigure 2.25 the point x is a minimal element of s \u2286 r2 with respect to\nr2\n+. however there exists no \u03bb for which x minimizes \u03bbt z over z \u2208 s.\n\n "}, {"Page_number": 71, "text": "2.6 dual cones and generalized inequalities\n\n57\n\nx1\n\ns1\n\ns2\n\nx2\n\nfigure 2.26 left. the point x1 \u2208 s1 is minimal, but is not a minimizer of\n\u03bbt z over s1 for any \u03bb \u227b 0. (it does, however, minimize \u03bbt z over z \u2208 s1 for\n\u03bb = (1, 0).) right. the point x2 \u2208 s2 is not minimal, but it does minimize\n\u03bbt z over z \u2208 s2 for \u03bb = (0, 1) (cid:23) 0.\n\n\u03bbt z over z \u2208 s for any \u03bb \u227bk \u2217 0. (see figure 2.26, left.) nor is it true that any\nminimizer of \u03bbt z over z \u2208 s, with \u03bb (cid:23)k \u2217 0, is minimal (see figure 2.26, right.)\n\nexample 2.27 pareto optimal production frontier. we consider a product which\nrequires n resources (such as labor, electricity, natural gas, water) to manufacture.\nthe product can be manufactured or produced in many ways. with each production\nmethod, we associate a resource vector x \u2208 rn, where xi denotes the amount of\nresource i consumed by the method to manufacture the product. we assume that xi \u2265\n0 (i.e., resources are consumed by the production methods) and that the resources\nare valuable (so using less of any resource is preferred).\nthe production set p \u2286 rn is defined as the set of all resource vectors x that\ncorrespond to some production method.\n\nproduction methods with resource vectors that are minimal elements of p , with\nrespect to componentwise inequality, are called pareto optimal or efficient. the set\nof minimal elements of p is called the efficient production frontier.\n\nwe can give a simple interpretation of pareto optimality. we say that one production\nmethod, with resource vector x, is better than another, with resource vector y, if\nxi \u2264 yi for all i, and for some i, xi < yi. in other words, one production method\nis better than another if it uses no more of each resource than another method, and\nfor at least one resource, actually uses less. this corresponds to x (cid:22) y, x 6= y. then\nwe can say: a production method is pareto optimal or efficient if there is no better\nproduction method.\n\nwe can find pareto optimal production methods (i.e., minimal resource vectors) by\nminimizing\n\n\u03bbt x = \u03bb1x1 + \u00b7\u00b7\u00b7 + \u03bbnxn\n\nover the set p of production vectors, using any \u03bb that satisfies \u03bb \u227b 0.\nhere the vector \u03bb has a simple interpretation: \u03bbi is the price of resource i. by\nminimizing \u03bbt x over p we are finding the overall cheapest production method (for\nthe resource prices \u03bbi). as long as the prices are positive, the resulting production\nmethod is guaranteed to be efficient.\n\nthese ideas are illustrated in figure 2.27.\n\n "}, {"Page_number": 72, "text": "58\n\n2 convex sets\n\nfuel\n\nx1\n\np\n\nx2\n\nx5\n\nx4\n\n\u03bb\n\nx3\n\nlabor\n\nfigure 2.27 the production set p , for a product that requires labor and\nfuel to produce, is shown shaded. the two dark curves show the efficient\nproduction frontier. the points x1, x2 and x3 are efficient. the points x4\nand x5 are not (since in particular, x2 corresponds to a production method\nthat uses no more fuel, and less labor). the point x1 is also the minimum\ncost production method for the price vector \u03bb (which is positive). the point\nx2 is efficient, but cannot be found by minimizing the total cost \u03bbt x for any\nprice vector \u03bb (cid:23) 0.\n\n "}, {"Page_number": 73, "text": "bibliography\n\nbibliography\n\n59\n\nminkowski is generally credited with the first systematic study of convex sets, and the\nintroduction of fundamental concepts such as supporting hyperplanes and the supporting\nhyperplane theorem, the minkowski distance function (exercise 3.34), extreme points of\na convex set, and many others.\n\nsome well known early surveys are bonnesen and fenchel [bf48], eggleston [egg58], klee\n[kle63], and valentine [val64]. more recent books devoted to the geometry of convex sets\ninclude lay [lay82] and webster [web94]. klee [kle71], fenchel [fen83], tikhomorov\n[tik90], and berger [ber90] give very readable overviews of the history of convexity and\nits applications throughout mathematics.\n\nlinear inequalities and polyhedral sets are studied extensively in connection with the lin-\near programming problem, for which we give references at the end of chapter 4. some\nlandmark publications in the history of linear inequalities and linear programming are\nmotzkin [mot33], von neumann and morgenstern [vnm53], kantorovich [kan60], koop-\nmans [koo51], and dantzig [dan63]. dantzig [dan63, chapter 2] includes an historical\nsurvey of linear inequalities, up to around 1963.\n\ngeneralized inequalities were introduced in nonlinear optimization during the 1960s (see\nluenberger [lue69, \u00a78.2] and isii [isi64]), and are used extensively in cone programming\n(see the references in chapter 4). bellman and fan [bf63] is an early paper on sets of\ngeneralized linear inequalities (with respect to the positive semidefinite cone).\n\nfor extensions and a proof of the separating hyperplane theorem we refer the reader\nto rockafellar [roc70, part iii], and hiriart-urruty and lemar\u00b4echal [hul93, volume\n1, \u00a7iii4]. dantzig [dan63, page 21] attributes the term theorem of the alternative to\nvon neumann and morgenstern [vnm53, page 138]. for more references on theorems of\nalternatives, see chapter 5.\n\nthe terminology of example 2.27 (including pareto optimality, efficient production, and\nthe price interpretation of \u03bb) is discussed in detail by luenberger [lue95].\n\nconvex geometry plays a prominent role in the classical theory of moments (krein and\nnudelman [kn77], karlin and studden [ks66]). a famous example is the duality between\nthe cone of nonnegative polynomials and the cone of power moments; see exercise 2.37.\n\n "}, {"Page_number": 74, "text": "60\n\n2 convex sets\n\nexercises\n\ndefinition of convexity\n\n2.1 let c \u2286 rn be a convex set, with x1, . . . , xk \u2208 c, and let \u03b81, . . . , \u03b8k \u2208 r satisfy \u03b8i \u2265 0,\n\u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1. show that \u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk \u2208 c. (the definition of convexity is that\nthis holds for k = 2; you must show it for arbitrary k.) hint. use induction on k.\n\n2.2 show that a set is convex if and only if its intersection with any line is convex. show that\n\na set is affine if and only if its intersection with any line is affine.\n\n2.3 midpoint convexity. a set c is midpoint convex if whenever two points a, b are in c, the\naverage or midpoint (a + b)/2 is in c. obviously a convex set is midpoint convex. it can\nbe proved that under mild conditions midpoint convexity implies convexity. as a simple\ncase, prove that if c is closed and midpoint convex, then c is convex.\n\n2.4 show that the convex hull of a set s is the intersection of all convex sets that contain s.\n(the same method can be used to show that the conic, or affine, or linear hull of a set s\nis the intersection of all conic sets, or affine sets, or subspaces that contain s.)\n\nexamples\n\n2.5 what is the distance between two parallel hyperplanes {x \u2208 rn | at x = b1} and {x \u2208\n\nrn | at x = b2}?\n\n2.6 when does one halfspace contain another? give conditions under which\n\n{x | at x \u2264 b} \u2286 {x | \u02dcat x \u2264 \u02dcb}\n\n(where a 6= 0, \u02dca 6= 0). also find the conditions under which the two halfspaces are equal.\n2.7 voronoi description of halfspace. let a and b be distinct points in rn. show that the set\nof all points that are closer (in euclidean norm) to a than b, i.e., {x | kx\u2212ak2 \u2264 kx\u2212bk2},\nis a halfspace. describe it explicitly as an inequality of the form ct x \u2264 d. draw a picture.\n2.8 which of the following sets s are polyhedra? if possible, express s in the form s =\n{x | ax (cid:22) b, f x = g}.\n(a) s = {y1a1 + y2a2 | \u2212 1 \u2264 y1 \u2264 1, \u2212 1 \u2264 y2 \u2264 1}, where a1, a2 \u2208 rn.\ni=1 xia2\n\ni = b2}, where\n\na1, . . . , an \u2208 r and b1, b2 \u2208 r.\n\n(b) s = {x \u2208 rn | x (cid:23) 0, 1t x = 1, pn\n(d) s = {x \u2208 rn | x (cid:23) 0, xt y \u2264 1 for all y with pn\n\n(c) s = {x \u2208 rn | x (cid:23) 0, xt y \u2264 1 for all y with kyk2 = 1}.\n\ni=1 xiai = b1, pn\n\ni=1 |yi| = 1}.\n\n2.9 voronoi sets and polyhedral decomposition. let x0, . . . , xk \u2208 rn. consider the set of\n\npoints that are closer (in euclidean norm) to x0 than the other xi, i.e.,\nv = {x \u2208 rn | kx \u2212 x0k2 \u2264 kx \u2212 xik2, i = 1, . . . , k}.\n\nv is called the voronoi region around x0 with respect to x1, . . . , xk .\n\n(a) show that v is a polyhedron. express v in the form v = {x | ax (cid:22) b}.\n(b) conversely, given a polyhedron p with nonempty interior, show how to find x0, . . . , xk\n\nso that the polyhedron is the voronoi region of x0 with respect to x1, . . . , xk .\n\n(c) we can also consider the sets\n\nvk = {x \u2208 rn | kx \u2212 xkk2 \u2264 kx \u2212 xik2, i 6= k}.\n\nthe set vk consists of points in rn for which the closest point in the set {x0, . . . , xk}\nis xk.\n\n "}, {"Page_number": 75, "text": "exercises\n\n61\n\nintersect at most along a boundary.\n\nthe sets v0, . . . , vk give a polyhedral decomposition of rn. more precisely, the sets\nk=0 vk = rn, and int vi \u2229 int vj = \u2205 for i 6= j, i.e., vi and vj\ni=1 pi = rn, and int pi \u2229\nint pj = \u2205 for i 6= j. can this polyhedral decomposition of rn be described as\nthe voronoi regions generated by an appropriate set of points?\n\nvk are polyhedra,sk\nsuppose that p1, . . . , pm are polyhedra such that sm\n\n2.10 solution set of a quadratic inequality. let c \u2286 rn be the solution set of a quadratic\n\ninequality,\n\nc = {x \u2208 rn | xt ax + bt x + c \u2264 0},\n\nwith a \u2208 sn, b \u2208 rn, and c \u2208 r.\n(a) show that c is convex if a (cid:23) 0.\n(b) show that the intersection of c and the hyperplane defined by gt x + h = 0 (where\n\ng 6= 0) is convex if a + \u03bbggt (cid:23) 0 for some \u03bb \u2208 r.\n\nare the converses of these statements true?\n\n2.11 hyperbolic sets. show that the hyperbolic set {x \u2208 r2\n\ngeneralization, show that {x \u2208 rn\n0 \u2264 \u03b8 \u2264 1, then a\u03b8b1\u2212\u03b8 \u2264 \u03b8a + (1 \u2212 \u03b8)b; see \u00a73.1.9.\n\n+ | qn\n\n2.12 which of the following sets are convex?\n\ni=1 xi \u2265 1} is convex. hint.\n\n+ | x1x2 \u2265 1} is convex. as a\nif a, b \u2265 0 and\n\n(a) a slab, i.e., a set of the form {x \u2208 rn | \u03b1 \u2264 at x \u2264 \u03b2}.\n(b) a rectangle, i.e., a set of the form {x \u2208 rn | \u03b1i \u2264 xi \u2264 \u03b2i, i = 1, . . . , n}. a rectangle\n(c) a wedge, i.e., {x \u2208 rn | at\n(d) the set of points closer to a given point than a given set, i.e.,\n\nis sometimes called a hyperrectangle when n > 2.\n\n1 x \u2264 b1, at\n\n2 x \u2264 b2}.\n\n{x | kx \u2212 x0k2 \u2264 kx \u2212 yk2 for all y \u2208 s}\n\nwhere s \u2286 rn.\n\n(e) the set of points closer to one set than another, i.e.,\n\nwhere s, t \u2286 rn, and\n\n{x | dist(x, s) \u2264 dist(x, t )},\n\ndist(x, s) = inf{kx \u2212 zk2 | z \u2208 s}.\n\nconvex.\n\n(f) [hul93, volume 1, page 93] the set {x | x + s2 \u2286 s1}, where s1, s2 \u2286 rn with s1\n(g) the set of points whose distance to a does not exceed a fixed fraction \u03b8 of the\ndistance to b, i.e., the set {x | kx \u2212 ak2 \u2264 \u03b8kx \u2212 bk2}. you can assume a 6= b and\n0 \u2264 \u03b8 \u2264 1.\n\n2.13 conic hull of outer products. consider the set of rank-k outer products, defined as\n\n{xx t | x \u2208 rn\u00d7k, rank x = k}. describe its conic hull in simple terms.\n2.14 expanded and restricted sets. let s \u2286 rn, and let k \u00b7 k be a norm on rn.\n\n(a) for a \u2265 0 we define sa as {x | dist(x, s) \u2264 a}, where dist(x, s) = inf y\u2208s kx \u2212 yk.\nwe refer to sa as s expanded or extended by a. show that if s is convex, then sa\nis convex.\n\n(b) for a \u2265 0 we define s\u2212a = {x | b(x, a) \u2286 s}, where b(x, a) is the ball (in the norm\nk \u00b7 k), centered at x, with radius a. we refer to s\u2212a as s shrunk or restricted by a,\nsince s\u2212a consists of all points that are at least a distance a from rn\\s. show that\nif s is convex, then s\u2212a is convex.\n\n "}, {"Page_number": 76, "text": "62\n\n2 convex sets\n\n2.15 some sets of probability distributions. let x be a real-valued random variable with\nprob(x = ai) = pi, i = 1, . . . , n, where a1 < a2 < \u00b7\u00b7\u00b7 < an. of course p \u2208 rn lies\nin the standard probability simplex p = {p | 1t p = 1, p (cid:23) 0}. which of the following\nconditions are convex in p? (that is, for which of the following conditions is the set of\np \u2208 p that satisfy the condition convex?)\n(a) \u03b1 \u2264 e f (x) \u2264 \u03b2, where e f (x) is the expected value of f (x), i.e., e f (x) =\n\ni=1 pif (ai). (the function f : r \u2192 r is given.)\n\npn\n\n(b) prob(x > \u03b1) \u2264 \u03b2.\n(c) e|x3| \u2264 \u03b1 e|x|.\n(d) e x2 \u2264 \u03b1.\n(e) e x2 \u2265 \u03b1.\n(f) var(x) \u2264 \u03b1, where var(x) = e(x \u2212 e x)2 is the variance of x.\n(g) var(x) \u2265 \u03b1.\n(h) quartile(x) \u2265 \u03b1, where quartile(x) = inf{\u03b2 | prob(x \u2264 \u03b2) \u2265 0.25}.\n(i) quartile(x) \u2264 \u03b1.\n\noperations that preserve convexity\n\n2.16 show that if s1 and s2 are convex sets in rm\u00d7n, then so is their partial sum\ns = {(x, y1 + y2) | x \u2208 rm, y1, y2 \u2208 rn, (x, y1) \u2208 s1, (x, y2) \u2208 s2}.\n\n2.17 image of polyhedral sets under perspective function. in this problem we study the image\nof hyperplanes, halfspaces, and polyhedra under the perspective function p (x, t) = x/t,\nwith dom p = rn \u00d7 r++. for each of the following sets c, give a simple description of\n\np (c) = {v/t | (v, t) \u2208 c, t > 0}.\n\n(a) the polyhedron c = conv{(v1, t1), . . . , (vk , tk )} where vi \u2208 rn and ti > 0.\n(b) the hyperplane c = {(v, t) | f t v + gt = h} (with f and g not both zero).\n(c) the halfspace c = {(v, t) | f t v + gt \u2264 h} (with f and g not both zero).\n(d) the polyhedron c = {(v, t) | f v + gt (cid:22) h}.\n\n2.18 invertible linear-fractional functions. let f : rn \u2192 rn be the linear-fractional function\n\nf (x) = (ax + b)/(ct x + d),\n\ndom f = {x | ct x + d > 0}.\n\nsuppose the matrix\n\nq =(cid:20) a b\nd (cid:21)\n\nct\n\nis nonsingular. show that f is invertible and that f \u22121 is a linear-fractional mapping.\ngive an explicit expression for f \u22121 and its domain in terms of a, b, c, and d. hint. it\nmay be easier to express f \u22121 in terms of q.\n\n2.19 linear-fractional functions and convex sets. let f : rm \u2192 rn be the linear-fractional\n\nfunction\n\ndom f = {x | ct x + d > 0}.\nin this problem we study the inverse image of a convex set c under f , i.e.,\n\nf (x) = (ax + b)/(ct x + d),\n\nf \u22121(c) = {x \u2208 dom f | f (x) \u2208 c}.\n\nfor each of the following sets c \u2286 rn, give a simple description of f \u22121(c).\n\n "}, {"Page_number": 77, "text": "exercises\n\n63\n\n(a) the halfspace c = {y | gt y \u2264 h} (with g 6= 0).\n(b) the polyhedron c = {y | gy (cid:22) h}.\n(c) the ellipsoid {y | yt p \u22121y \u2264 1} (where p \u2208 sn\n(d) the solution set of a linear matrix inequality, c = {y | y1a1 + \u00b7\u00b7\u00b7 + ynan (cid:22) b},\n\n++).\n\nwhere a1, . . . , an, b \u2208 sp.\n\nseparation theorems and supporting hyperplanes\n\n2.20 strictly positive solution of linear equations. suppose a \u2208 rm\u00d7n, b \u2208 rm, with b \u2208 r(a).\n\nshow that there exists an x satisfying\n\nx \u227b 0,\n\nax = b\n\nif and only if there exists no \u03bb with\nat \u03bb (cid:23) 0,\n\nat \u03bb 6= 0,\n\nbt \u03bb \u2264 0.\n\nhint. first prove the following fact from linear algebra: ct x = d for all x satisfying\nax = b if and only if there is a vector \u03bb such that c = at \u03bb, d = bt \u03bb.\n\n2.21 the set of separating hyperplanes. suppose that c and d are disjoint subsets of rn.\nconsider the set of (a, b) \u2208 rn+1 for which at x \u2264 b for all x \u2208 c, and at x \u2265 b for all\nx \u2208 d. show that this set is a convex cone (which is the singleton {0} if there is no\nhyperplane that separates c and d).\n\n2.22 finish the proof of the separating hyperplane theorem in \u00a72.5.1: show that a separating\nhyperplane exists for two disjoint convex sets c and d. you can use the result proved\nin \u00a72.5.1, i.e., that a separating hyperplane exists when there exist points in the two sets\nwhose distance is equal to the distance between the two sets.\nhint. if c and d are disjoint convex sets, then the set {x \u2212 y | x \u2208 c, y \u2208 d} is convex\nand does not contain the origin.\n\n2.23 give an example of two closed convex sets that are disjoint but cannot be strictly sepa-\n\nrated.\n\n2.24 supporting hyperplanes.\n\n(a) express the closed convex set {x \u2208 r2\n+ | x1x2 \u2265 1} as an intersection of halfspaces.\n(b) let c = {x \u2208 rn | kxk\u221e \u2264 1}, the \u2113\u221e-norm unit ball in rn, and let \u02c6x be a point\n\nin the boundary of c. identify the supporting hyperplanes of c at \u02c6x explicitly.\n\n2.25 inner and outer polyhedral approximations. let c \u2286 rn be a closed convex set, and\ni (x\u2212xi) = 0\ni (x \u2212 xi) \u2264 0}. consider the\n\nsuppose that x1, . . . , xk are on the boundary of c. suppose that for each i, at\ndefines a supporting hyperplane for c at xi, i.e., c \u2286 {x | at\ntwo polyhedra\n\npinner = conv{x1, . . . , xk},\n\npouter = {x | at\n\ni (x \u2212 xi) \u2264 0, i = 1, . . . , k}.\n\nshow that pinner \u2286 c \u2286 pouter. draw a picture illustrating this.\n\n2.26 support function. the support function of a set c \u2286 rn is defined as\n\nsc (y) = sup{yt x | x \u2208 c}.\n\n(we allow sc (y) to take on the value +\u221e.) suppose that c and d are closed convex sets\nin rn. show that c = d if and only if their support functions are equal.\n\n2.27 converse supporting hyperplane theorem. suppose the set c is closed, has nonempty\ninterior, and has a supporting hyperplane at every point in its boundary. show that c is\nconvex.\n\n "}, {"Page_number": 78, "text": "64\n\n2 convex sets\n\nconvex cones and generalized inequalities\n\n2.28 positive semidefinite cone for n = 1, 2, 3. give an explicit description of the positive\n+, in terms of the matrix coefficients and ordinary inequalities, for\n\nsemidefinite cone sn\nn = 1, 2, 3. to describe a general element of sn, for n = 1, 2, 3, use the notation\n\nx1,\n\n(cid:20) x1\n\nx2\n\nx2\n\nx3 (cid:21) ,\n\n\" x1\n\nx2\nx3\n\nx2\nx4\nx5\n\nx3\nx5\n\nx6 # .\n\n2.29 cones in r2. suppose k \u2286 r2 is a closed convex cone.\n\n(a) give a simple description of k in terms of the polar coordinates of its elements\n\n(b) give a simple description of k \u2217, and draw a plot illustrating the relation between\n\n(x = r(cos \u03c6, sin \u03c6) with r \u2265 0).\nk and k \u2217.\n\n(c) when is k pointed?\n\n(d) when is k proper (hence, defines a generalized inequality)? draw a plot illustrating\n\nwhat x (cid:22)k y means when k is proper.\n\n2.30 properties of generalized inequalities. prove the properties of (nonstrict and strict) gen-\n\neralized inequalities listed in \u00a72.4.1.\n\n2.31 properties of dual cones. let k \u2217 be the dual cone of a convex cone k, as defined in (2.19).\n\nprove the following.\n\n(a) k \u2217 is indeed a convex cone.\n2 \u2286 k \u2217\n(b) k1 \u2286 k2 implies k \u2217\n1 .\n(c) k \u2217 is closed.\n(d) the interior of k \u2217 is given by int k \u2217 = {y | yt x > 0 for all x \u2208 cl k}.\n(e) if k has nonempty interior then k \u2217 is pointed.\n(f) k \u2217\u2217 is the closure of k. (hence if k is closed, k \u2217\u2217 = k.)\n(g) if the closure of k is pointed then k \u2217 has nonempty interior.\n\n2.32 find the dual cone of {ax | x (cid:23) 0}, where a \u2208 rm\u00d7n.\n2.33 the monotone nonnegative cone. we define the monotone nonnegative cone as\n\nkm+ = {x \u2208 rn | x1 \u2265 x2 \u2265 \u00b7\u00b7\u00b7 \u2265 xn \u2265 0}.\n\ni.e., all nonnegative vectors with components sorted in nonincreasing order.\n\n(a) show that km+ is a proper cone.\n(b) find the dual cone k \u2217\n\nm+. hint. use the identity\n\nnxi=1\n\nxiyi = (x1 \u2212 x2)y1 + (x2 \u2212 x3)(y1 + y2) + (x3 \u2212 x4)(y1 + y2 + y3) + \u00b7\u00b7\u00b7\n\n+ (xn\u22121 \u2212 xn)(y1 + \u00b7\u00b7\u00b7 + yn\u22121) + xn(y1 + \u00b7\u00b7\u00b7 + yn).\n2.34 the lexicographic cone and ordering. the lexicographic cone is defined as\n\nklex = {0} \u222a {x \u2208 rn | x1 = \u00b7\u00b7\u00b7 = xk = 0, xk+1 > 0, for some k, 0 \u2264 k < n},\n\ni.e., all vectors whose first nonzero coefficient (if any) is positive.\n\n(a) verify that klex is a cone, but not a proper cone.\n\n "}, {"Page_number": 79, "text": "exercises\n\n65\n\n(b) we define the lexicographic ordering on rn as follows: x \u2264lex y if and only if\ny \u2212 x \u2208 klex. (since klex is not a proper cone, the lexicographic ordering is not a\ngeneralized inequality.) show that the lexicographic ordering is a linear ordering:\nfor any x, y \u2208 rn, either x \u2264lex y or y \u2264lex x. therefore any set of vectors can be\nsorted with respect to the lexicographic cone, which yields the familiar sorting used\nin dictionaries.\n\n(c) find k \u2217\n\nlex.\n\nverify that the set of copositive matrices is a proper cone. find its dual cone.\n\n2.35 copositive matrices. a matrix x \u2208 sn is called copositive if zt xz \u2265 0 for all z (cid:23) 0.\n2.36 euclidean distance matrices. let x1, . . . , xn \u2208 rk. the matrix d \u2208 sn defined by dij =\nkxi \u2212 xjk2\n2 is called a euclidean distance matrix. it satisfies some obvious properties such\nas dij = dji, dii = 0, dij \u2265 0, and (from the triangle inequality) d1/2\nij + d1/2\njk .\nwe now pose the question: when is a matrix d \u2208 sn a euclidean distance matrix (for\nsome points in rk, for some k)? a famous result answers this question: d \u2208 sn is a\neuclidean distance matrix if and only if dii = 0 and xt dx \u2264 0 for all x with 1t x = 0.\n(see \u00a78.3.3.)\nshow that the set of euclidean distance matrices is a convex cone.\n\nik \u2264 d1/2\n\n2.37 nonnegative polynomials and hankel lmis. let kpol be the set of (coefficients of) non-\n\nnegative polynomials of degree 2k on r:\n\nkpol = {x \u2208 r2k+1 | x1 + x2t + x3t2 + \u00b7\u00b7\u00b7 + x2k+1t2k \u2265 0 for all t \u2208 r}.\n\n(a) show that kpol is a proper cone.\n\n(b) a basic result states that a polynomial of degree 2k is nonnegative on r if and only\nif it can be expressed as the sum of squares of two polynomials of degree k or less.\nin other words, x \u2208 kpol if and only if the polynomial\n\np(t) = x1 + x2t + x3t2 + \u00b7\u00b7\u00b7 + x2k+1t2k\n\ncan be expressed as\n\np(t) = r(t)2 + s(t)2,\n\nwhere r and s are polynomials of degree k.\nuse this result to show that\n\nkpol =(x \u2208 r2k+1 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n\nxi = xm+n=i+1\n\nymn for some y \u2208 sk+1\n\n+ ) .\n\nin other words, p(t) = x1 + x2t + x3t2 + \u00b7\u00b7\u00b7 + x2k+1t2k is nonnegative if and only if\nthere exists a matrix y \u2208 sk+1\n\nsuch that\n\n+\n\nx1 = y11\nx2 = y12 + y21\nx3 = y13 + y22 + y31\n\n...\n\nx2k+1 = yk+1,k+1.\n\n(c) show that k \u2217\n\npol = khan where\n\nkhan = {z \u2208 r2k+1 | h(z) (cid:23) 0}\n\n "}, {"Page_number": 80, "text": "66\n\nand\n\nh(z) =\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\nz1\nz2\nz3\n...\nzk\nzk+1\n\nz2\nz3\nz4\n...\nzk+1\nzk+2\n\nz3\nz4\nz5\n...\nzk+2\nzk+3\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n. . .\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\nzk\nzk+1\nzk+2\n...\n\nz2k\u22121\n\nz2k\n\nzk+1\nzk+2\nzk+4\n...\nz2k\nz2k+1\n\n2 convex sets\n\n.\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n(this is the hankel matrix with coefficients z1, . . . , z2k+1.)\n\n(d) let kmom be the conic hull of the set of all vectors of the form (1, t, t2, . . . , t2k),\n\nwhere t \u2208 r. show that y \u2208 kmom if and only if y1 \u2265 0 and\n\ny = y1(1, e u, e u2, . . . , e u2k)\n\nfor some random variable u. in other words, the elements of kmom are nonnegative\nmultiples of the moment vectors of all possible distributions on r. show that kpol =\nk \u2217\n\nmom.\n\n(e) combining the results of (c) and (d), conclude that khan = cl kmom.\n\nas an example illustrating the relation between kmom and khan, take k = 2 and\nz = (1, 0, 0, 0, 1). show that z \u2208 khan, z 6\u2208 kmom. find an explicit sequence of\npoints in kmom which converge to z.\n\n2.38 [roc70, pages 15, 61] convex cones constructed from sets.\n\n(a) the barrier cone of a set c is defined as the set of all vectors y such that yt x is\nbounded above over x \u2208 c. in other words, a nonzero vector y is in the barrier cone\nif and only if it is the normal vector of a halfspace {x | yt x \u2264 \u03b1} that contains c.\nverify that the barrier cone is a convex cone (with no assumptions on c).\n\n(b) the recession cone (also called asymptotic cone) of a set c is defined as the set of\nall vectors y such that for each x \u2208 c, x \u2212 ty \u2208 c for all t \u2265 0. show that the\nrecession cone of a convex set is a convex cone. show that if c is nonempty, closed,\nand convex, then the recession cone of c is the dual of the barrier cone.\n\n(c) the normal cone of a set c at a boundary point x0 is the set of all vectors y such\nthat yt (x \u2212 x0) \u2264 0 for all x \u2208 c (i.e., the set of vectors that define a supporting\nhyperplane to c at x0). show that the normal cone is a convex cone (with no\nassumptions on c). give a simple description of the normal cone of a polyhedron\n{x | ax (cid:22) b} at a point in its boundary.\n\n2.39 separation of cones. let k and \u02dck be two convex cones whose interiors are nonempty and\n\ndisjoint. show that there is a nonzero y such that y \u2208 k \u2217, \u2212y \u2208 \u02dck \u2217.\n\n "}, {"Page_number": 81, "text": "chapter 3\n\nconvex functions\n\n3.1 basic properties and examples\n\n3.1.1 definition\n\na function f : rn \u2192 r is convex if dom f is a convex set and if for all x,\ny \u2208 dom f , and \u03b8 with 0 \u2264 \u03b8 \u2264 1, we have\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u2264 \u03b8f (x) + (1 \u2212 \u03b8)f (y).\n\n(3.1)\n\ngeometrically, this inequality means that the line segment between (x, f (x)) and\n(y, f (y)), which is the chord from x to y, lies above the graph of f (figure 3.1).\na function f is strictly convex if strict inequality holds in (3.1) whenever x 6= y\nand 0 < \u03b8 < 1. we say f is concave if \u2212f is convex, and strictly concave if \u2212f is\nstrictly convex.\nfor an affine function we always have equality in (3.1), so all affine (and therefore\nalso linear) functions are both convex and concave. conversely, any function that\nis convex and concave is affine.\n\na function is convex if and only if it is convex when restricted to any line that\nintersects its domain. in other words f is convex if and only if for all x \u2208 dom f and\n\n(x, f (x))\n\n(y, f (y))\n\nfigure 3.1 graph of a convex function. the chord (i.e., line segment) be-\ntween any two points on the graph lies above the graph.\n\n "}, {"Page_number": 82, "text": "68\n\n3 convex functions\n\nall v, the function g(t) = f (x + tv) is convex (on its domain, {t | x + tv \u2208 dom f}).\nthis property is very useful, since it allows us to check whether a function is convex\nby restricting it to a line.\n\nthe analysis of convex functions is a well developed field, which we will not\npursue in any depth. one simple result, for example, is that a convex function is\ncontinuous on the relative interior of its domain; it can have discontinuities only\non its relative boundary.\n\n3.1.2 extended-value extensions\n\nit is often convenient to extend a convex function to all of rn by defining its value\nto be \u221e outside its domain. if f is convex we define its extended-value extension\n\u02dcf : rn \u2192 r \u222a {\u221e} by\n\n\u02dcf (x) =(cid:26) f (x) x \u2208 dom f\n\n\u221e x 6\u2208 dom f.\n\nthe extension \u02dcf is defined on all rn, and takes values in r\u222a{\u221e}. we can recover\nthe domain of the original function f from the extension \u02dcf as dom f = {x | \u02dcf (x) <\n\u221e}.\nthe extension can simplify notation, since we do not need to explicitly describe\nthe domain, or add the qualifier \u2018for all x \u2208 dom f \u2019 every time we refer to f (x).\nconsider, for example, the basic defining inequality (3.1). in terms of the extension\n\u02dcf , we can express it as: for 0 < \u03b8 < 1,\n\n\u02dcf (\u03b8x + (1 \u2212 \u03b8)y) \u2264 \u03b8 \u02dcf (x) + (1 \u2212 \u03b8) \u02dcf (y)\n\nfor any x and y. (for \u03b8 = 0 or \u03b8 = 1 the inequality always holds.) of course here we\nmust interpret the inequality using extended arithmetic and ordering. for x and y\nboth in dom f , this inequality coincides with (3.1); if either is outside dom f , then\nthe righthand side is \u221e, and the inequality therefore holds. as another example\nof this notational device, suppose f1 and f2 are two convex functions on rn. the\npointwise sum f = f1 + f2 is the function with domain dom f = dom f1 \u2229 dom f2,\nwith f (x) = f1(x) + f2(x) for any x \u2208 dom f . using extended-value extensions we\ncan simply say that for any x, \u02dcf (x) = \u02dcf1(x) + \u02dcf2(x). in this equation the domain\nof f has been automatically defined as dom f = dom f1 \u2229 dom f2, since \u02dcf (x) = \u221e\nwhenever x 6\u2208 dom f1 or x 6\u2208 dom f2. in this example we are relying on extended\narithmetic to automatically define the domain.\nin this book we will use the same symbol to denote a convex function and its\nextension, whenever there is no harm from the ambiguity. this is the same as\nassuming that all convex functions are implicitly extended, i.e., are defined as \u221e\noutside their domains.\n\nexample 3.1 indicator function of a convex set. let c \u2286 rn be a convex set, and\nconsider the (convex) function ic with domain c and ic (x) = 0 for all x \u2208 c. in\nother words, the function is identically zero on the set c. its extended-value extension\n\n "}, {"Page_number": 83, "text": "3.1 basic properties and examples\n\n69\n\nf (y)\n\nf (x) + \u2207f (x)t (y \u2212 x)\n\n(x, f (x))\n\nfigure 3.2 if f is convex and differentiable, then f (x)+\u2207f (x)t (y\u2212x) \u2264 f (y)\nfor all x, y \u2208 dom f .\n\nis given by\n\n\u02dcic (x) =(cid:26) 0\n\nx \u2208 c\n\u221e x 6\u2208 c.\n\nthe convex function \u02dcic is called the indicator function of the set c.\nwe can play several notational tricks with the indicator function \u02dcic . for example\nthe problem of minimizing a function f (defined on all of rn, say) on the set c is the\nsame as minimizing the function f + \u02dcic over all of rn. indeed, the function f + \u02dcic\nis (by our convention) f restricted to the set c.\n\nin a similar way we can extend a concave function by defining it to be \u2212\u221e\n\noutside its domain.\n\n3.1.3 first-order conditions\n\nsuppose f is differentiable (i.e., its gradient \u2207f exists at each point in dom f ,\nwhich is open). then f is convex if and only if dom f is convex and\n\nf (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x)\n\n(3.2)\n\nholds for all x, y \u2208 dom f . this inequality is illustrated in figure 3.2.\nthe affine function of y given by f (x)+\u2207f (x)t (y\u2212x) is, of course, the first-order\ntaylor approximation of f near x. the inequality (3.2) states that for a convex\nfunction, the first-order taylor approximation is in fact a global underestimator of\nthe function. conversely, if the first-order taylor approximation of a function is\nalways a global underestimator of the function, then the function is convex.\n\nthe inequality (3.2) shows that from local information about a convex function\n(i.e., its value and derivative at a point) we can derive global information (i.e., a\nglobal underestimator of it). this is perhaps the most important property of convex\nfunctions, and explains some of the remarkable properties of convex functions and\nconvex optimization problems. as one simple example, the inequality (3.2) shows\nthat if \u2207f (x) = 0, then for all y \u2208 dom f , f (y) \u2265 f (x), i.e., x is a global minimizer\nof the function f .\n\n "}, {"Page_number": 84, "text": "70\n\n3 convex functions\n\nstrict convexity can also be characterized by a first-order condition: f is strictly\n\nconvex if and only if dom f is convex and for x, y \u2208 dom f , x 6= y, we have\n\nf (y) > f (x) + \u2207f (x)t (y \u2212 x).\n\n(3.3)\n\nfor concave functions we have the corresponding characterization: f is concave\n\nif and only if dom f is convex and\n\nf (y) \u2264 f (x) + \u2207f (x)t (y \u2212 x)\n\nfor all x, y \u2208 dom f .\nproof of first-order convexity condition\n\nto prove (3.2), we first consider the case n = 1: we show that a differentiable\nfunction f : r \u2192 r is convex if and only if\n\nf (y) \u2265 f (x) + f \u2032(x)(y \u2212 x)\n\n(3.4)\n\nfor all x and y in dom f .\n\nassume first that f is convex and x, y \u2208 dom f . since dom f is convex (i.e.,\nan interval), we conclude that for all 0 < t \u2264 1, x + t(y \u2212 x) \u2208 dom f , and by\nconvexity of f ,\n\nif we divide both sides by t, we obtain\n\nf (x + t(y \u2212 x)) \u2264 (1 \u2212 t)f (x) + tf (y).\n\nf (y) \u2265 f (x) +\n\nf (x + t(y \u2212 x)) \u2212 f (x)\n\nt\n\n,\n\nand taking the limit as t \u2192 0 yields (3.4).\nto show sufficiency, assume the function satisfies (3.4) for all x and y in dom f\n(which is an interval). choose any x 6= y, and 0 \u2264 \u03b8 \u2264 1, and let z = \u03b8x + (1\u2212 \u03b8)y.\napplying (3.4) twice yields\n\nf (x) \u2265 f (z) + f \u2032(z)(x \u2212 z),\n\nf (y) \u2265 f (z) + f \u2032(z)(y \u2212 z).\n\nmultiplying the first inequality by \u03b8, the second by 1 \u2212 \u03b8, and adding them yields\n\n\u03b8f (x) + (1 \u2212 \u03b8)f (y) \u2265 f (z),\n\nwhich proves that f is convex.\n\nnow we can prove the general case, with f : rn \u2192 r. let x, y \u2208 rn and\nconsider f restricted to the line passing through them, i.e., the function defined by\ng(t) = f (ty + (1 \u2212 t)x), so g\u2032(t) = \u2207f (ty + (1 \u2212 t)x)t (y \u2212 x).\nwe have g(1) \u2265 g(0) + g\u2032(0), which means\n\nfirst assume f is convex, which implies g is convex, so by the argument above\n\nf (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x).\n\nnow assume that this inequality holds for any x and y, so if ty + (1 \u2212 t)x \u2208 dom f\nand \u02dcty + (1 \u2212 \u02dct)x \u2208 dom f , we have\n\nf (ty + (1 \u2212 t)x) \u2265 f (\u02dcty + (1 \u2212 \u02dct)x) + \u2207f (\u02dcty + (1 \u2212 \u02dct)x)t (y \u2212 x)(t \u2212 \u02dct),\ni.e., g(t) \u2265 g(\u02dct) + g\u2032(\u02dct)(t \u2212 \u02dct). we have seen that this implies that g is convex.\n\n "}, {"Page_number": 85, "text": "3.1 basic properties and examples\n\n71\n\n3.1.4 second-order conditions\n\nwe now assume that f is twice differentiable, that is, its hessian or second deriva-\ntive \u22072f exists at each point in dom f , which is open. then f is convex if and\nonly if dom f is convex and its hessian is positive semidefinite: for all x \u2208 dom f ,\n\n\u22072f (x) (cid:23) 0.\n\nfor a function on r, this reduces to the simple condition f \u2032\u2032(x) \u2265 0 (and dom f\nconvex, i.e., an interval), which means that the derivative is nondecreasing. the\ncondition \u22072f (x) (cid:23) 0 can be interpreted geometrically as the requirement that the\ngraph of the function have positive (upward) curvature at x. we leave the proof\nof the second-order condition as an exercise (exercise 3.8).\n\nsimilarly, f is concave if and only if dom f is convex and \u22072f (x) (cid:22) 0 for\nall x \u2208 dom f . strict convexity can be partially characterized by second-order\nif \u22072f (x) \u227b 0 for all x \u2208 dom f , then f is strictly convex. the\nconditions.\nfor example, the function f : r \u2192 r given by\nconverse, however, is not true:\nf (x) = x4 is strictly convex but has zero second derivative at x = 0.\n\nexample 3.2 quadratic functions. consider the quadratic function f : rn \u2192 r, with\ndom f = rn, given by\n\nf (x) = (1/2)xt p x + qt x + r,\n\nwith p \u2208 sn, q \u2208 rn, and r \u2208 r. since \u22072f (x) = p for all x, f is convex if and only\nif p (cid:23) 0 (and concave if and only if p (cid:22) 0).\nfor quadratic functions, strict convexity is easily characterized: f is strictly convex\nif and only if p \u227b 0 (and strictly concave if and only if p \u227a 0).\n\nremark 3.1 the separate requirement that dom f be convex cannot be dropped from\nthe first- or second-order characterizations of convexity and concavity. for example,\nthe function f (x) = 1/x2, with dom f = {x \u2208 r | x 6= 0}, satisfies f \u2032\u2032(x) > 0 for all\nx \u2208 dom f , but is not a convex function.\n\n3.1.5 examples\n\nwe have already mentioned that all linear and affine functions are convex (and\nconcave), and have described the convex and concave quadratic functions. in this\nsection we give a few more examples of convex and concave functions. we start\nwith some functions on r, with variable x.\n\n\u2022 exponential. eax is convex on r, for any a \u2208 r.\n\u2022 powers. xa is convex on r++ when a \u2265 1 or a \u2264 0, and concave for 0 \u2264 a \u2264 1.\n\u2022 powers of absolute value. |x|p, for p \u2265 1, is convex on r.\n\u2022 logarithm. log x is concave on r++.\n\n "}, {"Page_number": 86, "text": "72\n\n3 convex functions\n\n)\ny\n,\n\nx\n(\nf\n\n2\n\n1\n\n0\n2\n\n2\n\n1\n\ny\n\n0\n\nx\n\n0\n\n\u22122\n\nfigure 3.3 graph of f (x, y) = x2/y.\n\n\u2022 negative entropy. x log x (either on r++, or on r+, defined as 0 for x = 0)\n\nis convex.\n\nconvexity or concavity of these examples can be shown by verifying the ba-\nsic inequality (3.1), or by checking that the second derivative is nonnegative or\nnonpositive. for example, with f (x) = x log x we have\n\nf \u2032(x) = log x + 1,\n\nf \u2032\u2032(x) = 1/x,\n\nso that f \u2032\u2032(x) > 0 for x > 0. this shows that the negative entropy function is\n(strictly) convex.\n\nwe now give a few interesting examples of functions on rn.\n\u2022 norms. every norm on rn is convex.\n\u2022 max function. f (x) = max{x1, . . . , xn} is convex on rn.\n\u2022 quadratic-over-linear function. the function f (x, y) = x2/y, with\n\ndom f = r \u00d7 r++ = {(x, y) \u2208 r2 | y > 0},\n\nis convex (figure 3.3).\n\n\u2022 log-sum-exp. the function f (x) = log (ex1 + \u00b7\u00b7\u00b7 + exn) is convex on rn.\nthis function can be interpreted as a differentiable (in fact, analytic) approx-\nimation of the max function, since\n\nmax{x1, . . . , xn} \u2264 f (x) \u2264 max{x1, . . . , xn} + log n\n\nfor all x. (the second inequality is tight when all components of x are equal.)\nfigure 3.4 shows f for n = 2.\n\n "}, {"Page_number": 87, "text": "3.1 basic properties and examples\n\n73\n\n4\n\n2\n\n0\n\n)\ny\n,\n\nx\n(\nf\n\n\u22122\n\n2\n\n0\n\ny\n\n\u22122\n\n2\n\n0\n\n\u22122\n\nx\n\nfigure 3.4 graph of f (x, y) = log(ex + ey).\n\n\u2022 geometric mean. the geometric mean f (x) = (qn\n\ndom f = rn\n\n++.\n\ni=1 xi)1/n is concave on\n\n\u2022 log-determinant. the function f (x) = log det x is concave on dom f =\n\nsn\n\n++.\n\nconvexity (or concavity) of these examples can be verified in several ways,\nsuch as directly verifying the inequality (3.1), verifying that the hessian is positive\nsemidefinite, or restricting the function to an arbitrary line and verifying convexity\nof the resulting function of one variable.\n\nnorms.\n\nif f : rn \u2192 r is a norm, and 0 \u2264 \u03b8 \u2264 1, then\nf (\u03b8x + (1 \u2212 \u03b8)y) \u2264 f (\u03b8x) + f ((1 \u2212 \u03b8)y) = \u03b8f (x) + (1 \u2212 \u03b8)f (y).\n\nthe inequality follows from the triangle inequality, and the equality follows from\nhomogeneity of a norm.\n\nmax function. the function f (x) = maxi xi satisfies, for 0 \u2264 \u03b8 \u2264 1,\n\nf (\u03b8x + (1 \u2212 \u03b8)y) = max\n\u2264 \u03b8 max\n= \u03b8f (x) + (1 \u2212 \u03b8)f (y).\n\n(\u03b8xi + (1 \u2212 \u03b8)yi)\nxi + (1 \u2212 \u03b8) max\n\ni\n\ni\n\ni\n\nyi\n\nquadratic-over-linear function. to show that the quadratic-over-linear function\nf (x, y) = x2/y is convex, we note that (for y > 0),\n\n\u22072f (x, y) =\n\n2\n\ny3(cid:20) y2 \u2212xy\n\nx2 (cid:21) =\n\n\u2212xy\n\n2\n\ny3(cid:20) y\n\n\u2212x (cid:21)(cid:20) y\n\n\u2212x (cid:21)t\n\n(cid:23) 0.\n\n "}, {"Page_number": 88, "text": "74\n\n3 convex functions\n\nlog-sum-exp. the hessian of the log-sum-exp function is\n\nwhere z = (ex1 , . . . , exn ). to verify that \u22072f (x) (cid:23) 0 we must show that for all v,\nvt\u22072f (x)v \u2265 0, i.e.,\n\n\u22072f (x) =\n\n1\n\n(1t z)2(cid:0)(1t z) diag(z) \u2212 zzt(cid:1) ,\ni zi! \u2212  nxi=1\n\nzi!  nxi=1\n\nv2\n\n1\n\n(1t z)2\uf8eb\uf8ed  nxi=1\n\nvizi!2\uf8f6\uf8f8 \u2265 0.\n\nbut this follows from the cauchy-schwarz inequality (at a)(bt b) \u2265 (at b)2 applied\nto the vectors with components ai = vi\u221azi, bi = \u221azi.\n\nvt\u22072f (x)v =\n\n(qn\n\ngeometric mean.\n\nin a similar way we can show that the geometric mean f (x) =\n\ni=1 xi)1/n is concave on dom f = rn\n\n++. its hessian \u22072f (x) is given by\n\ni=1 xi)1/n\nn2x2\nk\n\n,\n\n\u22022f (x)\n\u2202xk\u2202xl\n\n=\n\n(qn\n\ni=1 xi)1/n\nn2xkxl\n\nfor k 6= l,\n\n\u22022f (x)\n\n\u2202x2\nk\n\n= \u2212(n \u2212 1)\nand can be expressed as\n\n(qn\n\u22072f (x) = \u2212qn\nvt\u22072f (x)v = \u2212qn\n\n1, . . . , 1/x2\nwhere qi = 1/xi. we must show that \u22072f (x) (cid:22) 0, i.e., that\n\ni\n\ni=1 x1/n\nn2\n\ni=1 x1/n\nn2\n\ni\n\n(cid:0)n diag(1/x2\n\uf8eb\uf8edn\nnxi=1\n\nv2\ni /x2\n\ni \u2212  nxi=1\n\nn) \u2212 qqt(cid:1)\nvi/xi!2\uf8f6\uf8f8 \u2264 0\n\nfor all v. again this follows from the cauchy-schwarz inequality (at a)(bt b) \u2265\n(at b)2, applied to the vectors a = 1 and bi = vi/xi.\n\nlog-determinant. for the function f (x) = log det x, we can verify concavity by\nconsidering an arbitrary line, given by x = z + tv , where z, v \u2208 sn. we define\ng(t) = f (z + tv ), and restrict g to the interval of values of t for which z + tv \u227b 0.\nwithout loss of generality, we can assume that t = 0 is inside this interval, i.e.,\nz \u227b 0. we have\n\ng(t) = log det(z + tv )\n\n= log det(z 1/2(i + tz \u22121/2v z \u22121/2)z 1/2)\n\n=\n\nlog(1 + t\u03bbi) + log det z\n\nwhere \u03bb1, . . . , \u03bbn are the eigenvalues of z \u22121/2v z \u22121/2. therefore we have\n\ng\u2032(t) =\n\n\u03bbi\n\n1 + t\u03bbi\n\n,\n\ng\u2032\u2032(t) = \u2212\n\n\u03bb2\ni\n\n(1 + t\u03bbi)2 .\n\nnxi=1\n\nsince g\u2032\u2032(t) \u2264 0, we conclude that f is concave.\n\nnxi=1\nnxi=1\n\n "}, {"Page_number": 89, "text": "3.1 basic properties and examples\n\n75\n\n3.1.6 sublevel sets\n\nthe \u03b1-sublevel set of a function f : rn \u2192 r is defined as\nc\u03b1 = {x \u2208 dom f | f (x) \u2264 \u03b1}.\n\nsublevel sets of a convex function are convex, for any value of \u03b1. the proof is\nif x, y \u2208 c\u03b1, then f (x) \u2264 \u03b1 and\nimmediate from the definition of convexity:\nf (y) \u2264 \u03b1, and so f (\u03b8x + (1\u2212 \u03b8)y) \u2264 \u03b1 for 0 \u2264 \u03b8 \u2264 1, and hence \u03b8x + (1\u2212 \u03b8)y \u2208 c\u03b1.\nthe converse is not true: a function can have all its sublevel sets convex, but\nnot be a convex function. for example, f (x) = \u2212ex is not convex on r (indeed, it\nis strictly concave) but all its sublevel sets are convex.\nif f is concave, then its \u03b1-superlevel set, given by {x \u2208 dom f | f (x) \u2265 \u03b1}, is a\nconvex set. the sublevel set property is often a good way to establish convexity of\na set, by expressing it as a sublevel set of a convex function, or as the superlevel\nset of a concave function.\n\nexample 3.3 the geometric and arithmetic means of x \u2208 rn\n\n+ are, respectively,\n\ng(x) =  nyi=1\n\nxi!1/n\n\n,\n\na(x) =\n\n1\nn\n\nxi,\n\nnxi=1\n\n(where we take 01/n = 0 in our definition of g). the arithmetic-geometric mean\ninequality states that g(x) \u2264 a(x).\nsuppose 0 \u2264 \u03b1 \u2264 1, and consider the set\n\n{x \u2208 rn\n\n+ | g(x) \u2265 \u03b1a(x)},\n\ni.e., the set of vectors with geometric mean at least as large as a factor \u03b1 times the\narithmetic mean. this set is convex, since it is the 0-superlevel set of the function\ng(x) \u2212 \u03b1a(x), which is concave. in fact, the set is positively homogeneous, so it is a\nconvex cone.\n\n3.1.7 epigraph\n\nthe graph of a function f : rn \u2192 r is defined as\n\nwhich is a subset of rn+1. the epigraph of a function f : rn \u2192 r is defined as\n\n{(x, f (x)) | x \u2208 dom f},\n\nepi f = {(x, t) | x \u2208 dom f, f (x) \u2264 t},\n\nwhich is a subset of rn+1. (\u2018epi\u2019 means \u2018above\u2019 so epigraph means \u2018above the\ngraph\u2019.) the definition is illustrated in figure 3.5.\n\nthe link between convex sets and convex functions is via the epigraph: a\nfunction is convex if and only if its epigraph is a convex set. a function is concave\nif and only if its hypograph, defined as\n\nis a convex set.\n\nhypo f = {(x, t) | t \u2264 f (x)},\n\n "}, {"Page_number": 90, "text": "76\n\n3 convex functions\n\nepi f\n\nf\n\nfigure 3.5 epigraph of a function f , shown shaded. the lower boundary,\nshown darker, is the graph of f .\n\nexample 3.4 matrix fractional function. the function f : rn \u00d7 sn \u2192 r, defined as\n\nf (x, y ) = xt y \u22121x\n\n++. (this generalizes the quadratic-over-linear function\n\nis convex on dom f = rn\u00d7sn\nf (x, y) = x2/y, with dom f = r \u00d7 r++.)\none easy way to establish convexity of f is via its epigraph:\nepi f = {(x, y, t) | y \u227b 0, xt y \u22121x \u2264 t}\n\n= (cid:26)(x, y, t) (cid:12)(cid:12)(cid:12)(cid:12)(cid:20) y\n\nxt\n\nx\n\nt (cid:21) (cid:23) 0, y \u227b 0(cid:27) ,\n\nusing the schur complement condition for positive semidefiniteness of a block matrix\n(see \u00a7a.5.5). the last condition is a linear matrix inequality in (x, y, t), and therefore\nepi f is convex.\n\nfor the special case n = 1, the matrix fractional function reduces to the quadratic-\nover-linear function x2/y, and the associated lmi representation is\n\n(cid:20) y\n\nx\n\nx\n\nt (cid:21) (cid:23) 0,\n\ny > 0\n\n(the graph of which is shown in figure 3.3).\n\nmany results for convex functions can be proved (or interpreted) geometrically\nusing epigraphs, and applying results for convex sets. as an example, consider the\nfirst-order condition for convexity:\n\nf (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x),\n\nwhere f is convex and x, y \u2208 dom f . we can interpret this basic inequality\ngeometrically in terms of epi f . if (y, t) \u2208 epi f , then\n\nt \u2265 f (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x).\n\n "}, {"Page_number": 91, "text": "3.1 basic properties and examples\n\n77\n\nepi f\n\n(x, f (x))\n\n(\u2207f (x),\u22121)\n\nfigure 3.6 for a differentiable convex function f , the vector (\u2207f (x), \u22121)\ndefines a supporting hyperplane to the epigraph of f at x.\n\nwe can express this as:\n\n(y, t) \u2208 epi f =\u21d2 (cid:20) \u2207f (x)\n\n\u22121\n\n(cid:21)t(cid:18)(cid:20) y\n\nt (cid:21) \u2212(cid:20)\n\nx\n\nf (x) (cid:21)(cid:19) \u2264 0.\n\nthis means that the hyperplane defined by (\u2207f (x),\u22121) supports epi f at the\nboundary point (x, f (x)); see figure 3.6.\n\n3.1.8 jensen\u2019s inequality and extensions\n\nthe basic inequality (3.1), i.e.,\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u2264 \u03b8f (x) + (1 \u2212 \u03b8)f (y),\n\nis sometimes called jensen\u2019s inequality. it is easily extended to convex combinations\nof more than two points: if f is convex, x1, . . . , xk \u2208 dom f , and \u03b81, . . . , \u03b8k \u2265 0\nwith \u03b81 + \u00b7\u00b7\u00b7 + \u03b8k = 1, then\n\nf (\u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8kxk) \u2264 \u03b81f (x1) + \u00b7\u00b7\u00b7 + \u03b8kf (xk).\n\nas in the case of convex sets, the inequality extends to infinite sums, integrals, and\n\nexpected values. for example, if p(x) \u2265 0 on s \u2286 dom f ,rs p(x) dx = 1, then\n\nf(cid:18)zs\n\np(x)x dx(cid:19) \u2264zs\n\nf (x)p(x) dx,\n\nprovided the integrals exist. in the most general case we can take any probability\nmeasure with support in dom f . if x is a random variable such that x \u2208 dom f\nwith probability one, and f is convex, then we have\n\nf (e x) \u2264 e f (x),\n\n(3.5)\n\nprovided the expectations exist. we can recover the basic inequality (3.1) from\nthis general form, by taking the random variable x to have support {x1, x2}, with\n\n "}, {"Page_number": 92, "text": "78\n\n3 convex functions\n\nprob(x = x1) = \u03b8, prob(x = x2) = 1 \u2212 \u03b8. thus the inequality (3.5) characterizes\nconvexity: if f is not convex, there is a random variable x, with x \u2208 dom f with\nprobability one, such that f (e x) > e f (x).\nall of these inequalities are now called jensen\u2019s inequality, even though the\n\ninequality studied by jensen was the very simple one\n\nf(cid:18) x + y\n\n2 (cid:19) \u2264\n\nf (x) + f (y)\n\n2\n\n.\n\nremark 3.2 we can interpret (3.5) as follows. suppose x \u2208 dom f \u2286 rn and z is\nany zero mean random vector in rn. then we have\ne f (x + z) \u2265 f (x).\n\nthus, randomization or dithering (i.e., adding a zero mean random vector to the\nargument) cannot decrease the value of a convex function on average.\n\n3.1.9 inequalities\n\nmany famous inequalities can be derived by applying jensen\u2019s inequality to some\nappropriate convex function. (indeed, convexity and jensen\u2019s inequality can be\nmade the foundation of a theory of inequalities.) as a simple example, consider\nthe arithmetic-geometric mean inequality:\n\n(3.6)\nfor a, b \u2265 0. the function \u2212 log x is convex; jensen\u2019s inequality with \u03b8 = 1/2 yields\n\n\u221aab \u2264 (a + b)/2\n2 (cid:19) \u2264 \u2212 log a \u2212 log b\n\n2\n\n.\n\n\u2212 log(cid:18) a + b\n\ntaking the exponential of both sides yields (3.6).\n\nas a less trivial example we prove h\u00a8older\u2019s inequality: for p > 1, 1/p + 1/q = 1,\n\nand x, y \u2208 rn,\n\nxiyi \u2264  nxi=1\n\n|xi|p!1/p  nxi=1\n\nnxi=1\n\n|yi|q!1/q\n\n.\n\nby convexity of \u2212 log x, and jensen\u2019s inequality with general \u03b8, we obtain the more\ngeneral arithmetic-geometric mean inequality\n\na =\n\na\u03b8b1\u2212\u03b8 \u2264 \u03b8a + (1 \u2212 \u03b8)b,\nvalid for a, b \u2265 0 and 0 \u2264 \u03b8 \u2264 1. applying this with\n|yi|q\n|xi|p\nj=1 |xj|p ,\nj=1 |yj|q ,\npn\npn\n  |xi|p\nj=1 |xj|p!1/p  |yi|q\nj=1 |yj|q!1/q\npn\npn\n\nsumming over i then yields h\u00a8older\u2019s inequality.\n\nyields\n\nb =\n\n\u2264\n\n\u03b8 = 1/p,\n\n|xi|p\nj=1 |xj|p +\nppn\n\n|yi|q\nj=1 |yj|q .\nqpn\n\n "}, {"Page_number": 93, "text": "3.2 operations that preserve convexity\n\n79\n\n3.2 operations that preserve convexity\n\nin this section we describe some operations that preserve convexity or concavity\nof functions, or allow us to construct new convex and concave functions. we start\nwith some simple operations such as addition, scaling, and pointwise supremum,\nand then describe some more sophisticated operations (some of which include the\nsimple operations as special cases).\n\n3.2.1 nonnegative weighted sums\n\nevidently if f is a convex function and \u03b1 \u2265 0, then the function \u03b1f is convex.\nif f1 and f2 are both convex functions, then so is their sum f1 + f2. combining\nnonnegative scaling and addition, we see that the set of convex functions is itself a\nconvex cone: a nonnegative weighted sum of convex functions,\n\nf = w1f1 + \u00b7\u00b7\u00b7 + wmfm,\n\nis convex. similarly, a nonnegative weighted sum of concave functions is concave. a\nnonnegative, nonzero weighted sum of strictly convex (concave) functions is strictly\nconvex (concave).\n\nthese properties extend to infinite sums and integrals. for example if f (x, y)\nis convex in x for each y \u2208 a, and w(y) \u2265 0 for each y \u2208 a, then the function g\ndefined as\n\ng(x) =za\n\nw(y)f (x, y) dy\n\nis convex in x (provided the integral exists).\n\nthe fact that convexity is preserved under nonnegative scaling and addition is\neasily verified directly, or can be seen in terms of the associated epigraphs. for\nexample, if w \u2265 0 and f is convex, we have\n\nepi(wf ) =(cid:20) i\n\n0 w (cid:21) epi f,\n\n0\n\nwhich is convex because the image of a convex set under a linear mapping is convex.\n\n3.2.2 composition with an affine mapping\n\nsuppose f : rn \u2192 r, a \u2208 rn\u00d7m, and b \u2208 rn. define g : rm \u2192 r by\n\ng(x) = f (ax + b),\n\nwith dom g = {x | ax + b \u2208 dom f}. then if f is convex, so is g; if f is concave,\nso is g.\n\n "}, {"Page_number": 94, "text": "80\n\n3 convex functions\n\n3.2.3 pointwise maximum and supremum\n\nif f1 and f2 are convex functions then their pointwise maximum f , defined by\n\nf (x) = max{f1(x), f2(x)},\n\nwith dom f = dom f1 \u2229 dom f2, is also convex. this property is easily verified: if\n0 \u2264 \u03b8 \u2264 1 and x, y \u2208 dom f , then\n\nf (\u03b8x + (1 \u2212 \u03b8)y) = max{f1(\u03b8x + (1 \u2212 \u03b8)y), f2(\u03b8x + (1 \u2212 \u03b8)y)}\n\n\u2264 max{\u03b8f1(x) + (1 \u2212 \u03b8)f1(y), \u03b8f2(x) + (1 \u2212 \u03b8)f2(y)}\n\u2264 \u03b8 max{f1(x), f2(x)} + (1 \u2212 \u03b8) max{f1(y), f2(y)}\n= \u03b8f (x) + (1 \u2212 \u03b8)f (y),\n\nwhich establishes convexity of f . it is easily shown that if f1, . . . , fm are convex,\nthen their pointwise maximum\n\nis also convex.\n\nf (x) = max{f1(x), . . . , fm(x)}\n\nexample 3.5 piecewise-linear functions. the function\n\nf (x) = max{at\n\n1 x + b1, . . . , at\n\nlx + bl}\n\ndefines a piecewise-linear (or really, affine) function (with l or fewer regions). it is\nconvex since it is the pointwise maximum of affine functions.\n\nthe converse can also be shown: any piecewise-linear convex function with l or fewer\nregions can be expressed in this form. (see exercise 3.29.)\n\nexample 3.6 sum of r largest components. for x \u2208 rn we denote by x[i] the ith\nlargest component of x, i.e.,\n\nare the components of x sorted in nonincreasing order. then the function\n\nx[1] \u2265 x[2] \u2265 \u00b7\u00b7\u00b7 \u2265 x[n]\n\nf (x) =\n\nx[i],\n\nrxi=1\n\ni.e., the sum of the r largest elements of x, is a convex function. this can be seen by\nwriting it as\n\nf (x) =\n\nrxi=1\n\nx[i] = max{xi1 + \u00b7\u00b7\u00b7 + xir | 1 \u2264 i1 < i2 < \u00b7\u00b7\u00b7 < ir \u2264 n},\n\ni.e., the maximum of all possible sums of r different components of x. since it is the\npointwise maximum of n!/(r!(n \u2212 r)!) linear functions, it is convex.\n\nas an extension it can be shown that the functionpr\n\nw1 \u2265 w2 \u2265 \u00b7\u00b7\u00b7 \u2265 wr \u2265 0. (see exercise 3.19.)\n\ni=1 wix[i] is convex, provided\n\n "}, {"Page_number": 95, "text": "3.2 operations that preserve convexity\n\n81\n\nthe pointwise maximum property extends to the pointwise supremum over an\ninfinite set of convex functions. if for each y \u2208 a, f (x, y) is convex in x, then the\nfunction g, defined as\n(3.7)\n\nf (x, y)\n\ng(x) = sup\ny\u2208a\n\nis convex in x. here the domain of g is\n\ndom g = {x | (x, y) \u2208 dom f for all y \u2208 a, sup\n\ny\u2208a\n\nf (x, y) < \u221e}.\n\nsimilarly, the pointwise infimum of a set of concave functions is a concave function.\nin terms of epigraphs, the pointwise supremum of functions corresponds to the\n\nintersection of epigraphs: with f , g, and a as defined in (3.7), we have\n\nepi g = \\y\u2208a\n\nepi f (\u00b7, y).\n\nthus, the result follows from the fact that the intersection of a family of convex\nsets is convex.\n\nexample 3.7 support function of a set. let c \u2286 rn, with c 6= \u2205. the support\nfunction sc associated with the set c is defined as\n\nsc (x) = sup{xt y | y \u2208 c}\n\n(and, naturally, dom sc = {x | supy\u2208c xt y < \u221e}).\nfor each y \u2208 c, xt y is a linear function of x, so sc is the pointwise supremum of a\nfamily of linear functions, hence convex.\n\nexample 3.8 distance to farthest point of a set. let c \u2286 rn. the distance (in any\nnorm) to the farthest point of c,\n\nf (x) = sup\n\ny\u2208c kx \u2212 yk,\n\nis convex. to see this, note that for any y, the function kx \u2212 yk is convex in x. since\nf is the pointwise supremum of a family of convex functions (indexed by y \u2208 c), it\nis a convex function of x.\n\nexample 3.9 least-squares cost as a function of weights. let a1, . . . , an \u2208 rm. in a\ni x \u2212\nbi)2 over x \u2208 rm. we refer to wi as weights, and allow negative wi (which opens the\npossibility that the objective function is unbounded below).\n\nweighted least-squares problem we minimize the objective functionpn\n\ni=1 wi(at\n\nwe define the (optimal) weighted least-squares cost as\n\ng(w) = inf\nx\n\nwi(at\n\ni x \u2212 bi)2,\n\nwith domain\n\ndom g =(w (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n\ninf\nx\n\nwi(at\n\ni x \u2212 bi)2 > \u2212\u221e) .\n\nnxi=1\nnxi=1\n\n "}, {"Page_number": 96, "text": "82\n\n3 convex functions\n\nsince g is the infimum of a family of linear functions of w (indexed by x \u2208 rm), it is\na concave function of w.\n\nwe can derive an explicit expression for g, at least on part of its domain. let\nw = diag(w), the diagonal matrix with elements w1, . . . , wn, and let a \u2208 rn\u00d7m\nhave rows at\n\ni , so we have\n\ng(w) = inf\nx\n\n(ax \u2212 b)t w (ax \u2212 b) = inf\n\nx\n\n(xt at w ax \u2212 2bt w ax + bt w b).\n\nfrom this we see that if at w a 6(cid:23) 0, the quadratic function is unbounded below\nin x, so g(w) = \u2212\u221e, i.e., w 6\u2208 dom g. we can give a simple expression for g\nwhen at w a \u227b 0 (which defines a strict linear matrix inequality), by analytically\nminimizing the quadratic function:\n\ng(w) = bt w b \u2212 bt w a(at w a)\u22121at w b\n\n=\n\nwib2\n\ni \u2212\n\nnxi=1\n\nnxi=1\n\nw2\n\ni b2\n\ni at\n\nwjajat\n\nai.\n\ni   nxj=1\n\nj!\u22121\n\nconcavity of g from this expression is not immediately obvious (but does follow, for\nexample, from convexity of the matrix fractional function; see example 3.4).\n\nexample 3.10 maximum eigenvalue of a symmetric matrix. the function f (x) =\n\u03bbmax(x), with dom f = sm, is convex. to see this, we express f as\n\nf (x) = sup{yt xy | kyk2 = 1},\n\ni.e., as the pointwise supremum of a family of linear functions of x (i.e., yt xy)\nindexed by y \u2208 rm.\n\nexample 3.11 norm of a matrix. consider f (x) = kxk2 with dom f = rp\u00d7q,\nwhere k \u00b7 k2 denotes the spectral norm or maximum singular value. convexity of f\nfollows from\n\nf (x) = sup{ut xv | kuk2 = 1, kvk2 = 1},\n\nwhich shows it is the pointwise supremum of a family of linear functions of x.\nas a generalization suppose k \u00b7 ka and k \u00b7 kb are norms on rp and rq, respectively.\nthe induced norm of a matrix x \u2208 rp\u00d7q is defined as\n.\n\nkxka,b = sup\n\nv6=0\n\nkxvka\nkvkb\n\n(this reduces to the spectral norm when both norms are euclidean.) the induced\nnorm can be expressed as\n\nkxka,b = sup{kxvka | kvkb = 1}\n\n= sup{ut xv | kuka\u2217 = 1, kvkb = 1},\nwhere k \u00b7 ka\u2217 is the dual norm of k \u00b7 ka, and we use the fact that\n\nkzka = sup{ut z | kuka\u2217 = 1}.\n\nsince we have expressed kxka,b as a supremum of linear functions of x, it is a convex\nfunction.\n\n "}, {"Page_number": 97, "text": "3.2 operations that preserve convexity\n\n83\n\nrepresentation as pointwise supremum of affine functions\n\nthe examples above illustrate a good method for establishing convexity of a func-\ntion: by expressing it as the pointwise supremum of a family of affine functions.\nexcept for a technical condition, a converse holds: almost every convex function\ncan be expressed as the pointwise supremum of a family of affine functions. for\nexample, if f : rn \u2192 r is convex, with dom f = rn, then we have\nf (x) = sup{g(x) | g affine, g(z) \u2264 f (z) for all z}.\n\nin other words, f is the pointwise supremum of the set of all affine global under-\nestimators of it. we give the proof of this result below, and leave the case where\ndom f 6= rn as an exercise (exercise 3.28).\n\nsuppose f is convex with dom f = rn. the inequality\n\nf (x) \u2265 sup{g(x) | g affine, g(z) \u2264 f (z) for all z}\n\nis clear, since if g is any affine underestimator of f , we have g(x) \u2264 f (x). to\nestablish equality, we will show that for each x \u2208 rn, there is an affine function g,\nwhich is a global underestimator of f , and satisfies g(x) = f (x).\nthe epigraph of f is, of course, a convex set. hence we can find a supporting\n\nhyperplane to it at (x, f (x)), i.e., a \u2208 rn and b \u2208 r with (a, b) 6= 0 and\n\nb (cid:21)t(cid:20) x \u2212 z\n(cid:20) a\n\nf (x) \u2212 t (cid:21) \u2264 0\n\nfor all (z, t) \u2208 epi f . this means that\n\nat (x \u2212 z) + b(f (x) \u2212 f (z) \u2212 s) \u2264 0\n\n(3.8)\n\nfor all z \u2208 dom f = rn and all s \u2265 0 (since (z, t) \u2208 epi f means t = f (z) + s for\nsome s \u2265 0). for the inequality (3.8) to hold for all s \u2265 0, we must have b \u2265 0.\nif b = 0, then the inequality (3.8) reduces to at (x \u2212 z) \u2264 0 for all z \u2208 rn, which\nimplies a = 0 and contradicts (a, b) 6= 0. we conclude that b > 0, i.e., that the\nsupporting hyperplane is not vertical.\n\nusing the fact that b > 0 we rewrite (3.8) for s = 0 as\n\ng(z) = f (x) + (a/b)t (x \u2212 z) \u2264 f (z)\n\nfor all z. the function g is an affine underestimator of f , and satisfies g(x) = f (x).\n\n3.2.4 composition\n\nin this section we examine conditions on h : rk \u2192 r and g : rn \u2192 rk that\nguarantee convexity or concavity of their composition f = h\u25e6 g : rn \u2192 r, defined\nby\n\nf (x) = h(g(x)),\n\ndom f = {x \u2208 dom g | g(x) \u2208 dom h}.\n\n "}, {"Page_number": 98, "text": "84\n\n3 convex functions\n\nscalar composition\nwe first consider the case k = 1, so h : r \u2192 r and g : rn \u2192 r. we can restrict\nourselves to the case n = 1 (since convexity is determined by the behavior of a\nfunction on arbitrary lines that intersect its domain).\n\nto discover the composition rules, we start by assuming that h and g are twice\ndifferentiable, with dom g = dom h = r. in this case, convexity of f reduces to\nf \u2032\u2032 \u2265 0 (meaning, f \u2032\u2032(x) \u2265 0 for all x \u2208 r).\n\nthe second derivative of the composition function f = h \u25e6 g is given by\n\nf \u2032\u2032(x) = h\u2032\u2032(g(x))g\u2032(x)2 + h\u2032(g(x))g\u2032\u2032(x).\n\n(3.9)\n\nnow suppose, for example, that g is convex (so g\u2032\u2032 \u2265 0) and h is convex and\nnondecreasing (so h\u2032\u2032 \u2265 0 and h\u2032 \u2265 0). it follows from (3.9) that f \u2032\u2032 \u2265 0, i.e., f is\nconvex. in a similar way, the expression (3.9) gives the results:\n\nf is convex if h is convex and nondecreasing, and g is convex,\n\nf is convex if h is convex and nonincreasing, and g is concave,\nf is concave if h is concave and nondecreasing, and g is concave,\n\n(3.10)\n\nf is concave if h is concave and nonincreasing, and g is convex.\n\nthese statements are valid when the functions g and h are twice differentiable and\nhave domains that are all of r. it turns out that very similar composition rules\nhold in the general case n > 1, without assuming differentiability of h and g, or\nthat dom g = rn and dom h = r:\n\nf is convex if h is convex, \u02dch is nondecreasing, and g is convex,\nf is convex if h is convex, \u02dch is nonincreasing, and g is concave,\nf is concave if h is concave, \u02dch is nondecreasing, and g is concave,\nf is concave if h is concave, \u02dch is nonincreasing, and g is convex.\n\n(3.11)\n\nhere \u02dch denotes the extended-value extension of the function h, which assigns the\nvalue \u221e (\u2212\u221e) to points not in dom h for h convex (concave). the only difference\nbetween these results, and the results in (3.10), is that we require that the extended-\nvalue extension function \u02dch be nonincreasing or nondecreasing, on all of r.\n\nto understand what this means, suppose h is convex, so \u02dch takes on the value \u221e\noutside dom h. to say that \u02dch is nondecreasing means that for any x, y \u2208 r, with\nx < y, we have \u02dch(x) \u2264 \u02dch(y). in particular, this means that if y \u2208 dom h, then x \u2208\ndom h. in other words, the domain of h extends infinitely in the negative direction;\nit is either r, or an interval of the form (\u2212\u221e, a) or (\u2212\u221e, a]. in a similar way, to\nsay that h is convex and \u02dch is nonincreasing means that h is nonincreasing and\ndom h extends infinitely in the positive direction. this is illustrated in figure 3.7.\n\nexample 3.12 some simple examples will illustrate the conditions on h that appear\nin the composition theorems.\n\n\u2022 the function h(x) = log x, with dom h = r++, is concave and satisfies \u02dch\n\nnondecreasing.\n\n "}, {"Page_number": 99, "text": "3.2 operations that preserve convexity\n\n85\n\n1\n\n0\n\nepi f\n\nepi f\n\n1\n\n0\n\nx\n\n0\n\n1\n\n0\n\nx\n\n1\n\nfigure 3.7 left. the function x2, with domain r+, is convex and nonde-\ncreasing on its domain, but its extended-value extension is not nondecreas-\ning. right. the function max{x, 0}2, with domain r, is convex, and its\nextended-value extension is nondecreasing.\n\n\u2022 the function h(x) = x1/2, with dom h = r+, is concave and satisfies the\n\ncondition \u02dch nondecreasing.\n\n\u2022 the function h(x) = x3/2, with dom h = r+, is convex but does not satisfy the\n\ncondition \u02dch nondecreasing. for example, we have \u02dch(\u22121) = \u221e, but \u02dch(1) = 1.\nis convex and does satisfy the condition \u02dch nondecreasing.\n\n\u2022 the function h(x) = x3/2 for x \u2265 0, and h(x) = 0 for x < 0, with dom h = r,\n\nthe composition results (3.11) can be proved directly, without assuming dif-\nferentiability, or using the formula (3.9). as an example, we will prove the fol-\nlowing composition theorem: if g is convex, h is convex, and \u02dch is nondecreasing,\nthen f = h \u25e6 g is convex. assume that x, y \u2208 dom f , and 0 \u2264 \u03b8 \u2264 1. since\nx, y \u2208 dom f , we have that x, y \u2208 dom g and g(x), g(y) \u2208 dom h. since dom g\nis convex, we conclude that \u03b8x + (1 \u2212 \u03b8)y \u2208 dom g, and from convexity of g, we\nhave\n(3.12)\nsince g(x), g(y) \u2208 dom h, we conclude that \u03b8g(x) + (1 \u2212 \u03b8)g(y) \u2208 dom h, i.e.,\nthe righthand side of (3.12) is in dom h. now we use the assumption that \u02dch\nis nondecreasing, which means that its domain extends infinitely in the negative\ndirection. since the righthand side of (3.12) is in dom h, we conclude that the\nlefthand side, i.e., g(\u03b8x+(1\u2212\u03b8)y) \u2208 dom h. this means that \u03b8x+(1\u2212\u03b8)y \u2208 dom f .\nat this point, we have shown that dom f is convex.\n\ng(\u03b8x + (1 \u2212 \u03b8)y) \u2264 \u03b8g(x) + (1 \u2212 \u03b8)g(y).\n\nnow using the fact that \u02dch is nondecreasing and the inequality (3.12), we get\n\nh(g(\u03b8x + (1 \u2212 \u03b8)y)) \u2264 h(\u03b8g(x) + (1 \u2212 \u03b8)g(y)).\n\nfrom convexity of h, we have\n\nh(\u03b8g(x) + (1 \u2212 \u03b8)g(y)) \u2264 \u03b8h(g(x)) + (1 \u2212 \u03b8)h(g(y)).\n\n(3.13)\n\n(3.14)\n\n "}, {"Page_number": 100, "text": "86\n\n3 convex functions\n\nputting (3.13) and (3.14) together, we have\n\nh(g(\u03b8x + (1 \u2212 \u03b8)y)) \u2264 \u03b8h(g(x)) + (1 \u2212 \u03b8)h(g(y)).\n\nwhich proves the composition theorem.\n\nexample 3.13 simple composition results.\n\n\u2022 if g is convex then exp g(x) is convex.\n\u2022 if g is concave and positive, then log g(x) is concave.\n\u2022 if g is concave and positive, then 1/g(x) is convex.\n\u2022 if g is convex and nonnegative and p \u2265 1, then g(x)p is convex.\n\u2022 if g is convex then \u2212 log(\u2212g(x)) is convex on {x | g(x) < 0}.\n\nremark 3.3 the requirement that monotonicity hold for the extended-value extension\n\u02dch, and not just the function h, cannot be removed. for example, consider the function\ng(x) = x2, with dom g = r, and h(x) = 0, with dom h = [1, 2]. here g is convex,\nand h is convex and nondecreasing. but the function f = h \u25e6 g, given by\n\nf (x) = 0,\n\ndom f = [\u2212\n\n\u221a2,\u22121] \u222a [1,\u221a2],\n\nis not convex, since its domain is not convex. here, of course, the function \u02dch is not\nnondecreasing.\n\nvector composition\nwe now turn to the more complicated case when k \u2265 1. suppose\n\nf (x) = h(g(x)) = h(g1(x), . . . , gk(x)),\n\nwith h : rk \u2192 r, gi : rn \u2192 r. again without loss of generality we can assume n =\n1. as in the case k = 1, we start by assuming the functions are twice differentiable,\nwith dom g = r and dom h = rk, in order to discover the composition rules. we\nhave\n\nf \u2032\u2032(x) = g\u2032(x)t\u22072h(g(x))g\u2032(x) + \u2207h(g(x))t g\u2032\u2032(x),\n\n(3.15)\n\nwhich is the vector analog of (3.9). again the issue is to determine conditions under\nwhich f \u2032\u2032(x) \u2265 0 for all x (or f \u2032\u2032(x) \u2264 0 for all x for concavity). from (3.15) we\ncan derive many rules, for example:\n\nf is convex if h is convex, h is nondecreasing in each argument,\nand gi are convex,\nf is convex if h is convex, h is nonincreasing in each argument,\nand gi are concave,\nf is concave if h is concave, h is nondecreasing in each argument,\nand gi are concave.\n\n "}, {"Page_number": 101, "text": "3.2 operations that preserve convexity\n\n87\n\nas in the scalar case, similar composition results hold in general, with n > 1, no as-\nsumption of differentiability of h or g, and general domains. for the general results,\nthe monotonicity condition on h must hold for the extended-value extension \u02dch.\n\nto understand the meaning of the condition that the extended-value exten-\nsion \u02dch be monotonic, we consider the case where h : rk \u2192 r is convex, and \u02dch\nnondecreasing, i.e., whenever u (cid:22) v, we have \u02dch(u) \u2264 \u02dch(v). this implies that if\nv \u2208 dom h, then so is u: the domain of h must extend infinitely in the \u2212rk\ndirections. we can express this compactly as dom h \u2212 rk\n\n+ = dom h.\n\n+\n\nexample 3.14 vector composition examples.\n\n\u2022 let h(z) = z[1] +\u00b7\u00b7\u00b7 + z[r], the sum of the r largest components of z \u2208 rk. then\nh is convex and nondecreasing in each argument. suppose g1, . . . , gk are convex\nfunctions on rn. then the composition function f = h \u25e6 g, i.e., the pointwise\nsum of the r largest gi\u2019s, is convex.\n\ni=1 ezi ) is convex and nondecreasing in each argu-\n\n+ is concave, and\nits extension (which has the value \u2212\u221e for z 6(cid:23) 0) is nondecreasing in each\ncomponent. so if gi are concave and nonnegative, we conclude that f (x) =\n\ni )1/p on rk\n\ni=1 egi ) is convex whenever gi are.\ni=1 zp\n\n\u2022 the function h(z) = log(pk\nment, so log(pk\n\u2022 for 0 < p \u2264 1, the function h(z) = (pk\n(pk\n(pk\n\ni=1 gi(x)p)1/p is concave.\n\ni=1 gi(x)p)1/p is convex.\n\nto show this, we consider the function h : rk \u2192 r defined as\n\n\u2022 suppose p \u2265 1, and g1, . . . , gk are convex and nonnegative. then the function\n\nh(z) =  kxi=1\n\nmax{zi, 0}p!1/p\n\n,\n\nwith dom h = rk, so h = \u02dch. this function is convex, and nondecreasing, so\nwe conclude h(g(x)) is a convex function of x. for z (cid:23) 0, we have h(z) =\n\n+ is concave and its extension\nis nondecreasing in each argument. it follows that if g1, . . . , gk are nonnegative\n\ni=1 zp\n\ni )1/p, so our conclusion is that (pk\n\n(pk\n\u2022 the geometric mean h(z) = (qk\nconcave functions, then so is their geometric mean, (qk\n\ni=1 zi)1/k on rk\n\ni=1 gi(x)p)1/p is convex.\n\ni=1 gi)1/k.\n\n3.2.5 minimization\n\nwe have seen that the maximum or supremum of an arbitrary family of convex\nfunctions is convex. it turns out that some special forms of minimization also yield\nconvex functions. if f is convex in (x, y), and c is a convex nonempty set, then\nthe function\n\ng(x) = inf\ny\u2208c\n\nf (x, y)\n\n(3.16)\n\n "}, {"Page_number": 102, "text": "88\n\n3 convex functions\n\nis convex in x, provided g(x) > \u2212\u221e for some x (which implies g(x) > \u2212\u221e for all\nx). the domain of g is the projection of dom f on its x-coordinates, i.e.,\n\ndom g = {x | (x, y) \u2208 dom f for some y \u2208 c}.\n\nwe prove this by verifying jensen\u2019s inequality for x1, x2 \u2208 dom g. let \u01eb > 0.\nthen there are y1, y2 \u2208 c such that f (xi, yi) \u2264 g(xi) + \u01eb for i = 1, 2. now let\n\u03b8 \u2208 [0, 1]. we have\n\ng(\u03b8x1 + (1 \u2212 \u03b8)x2) = inf\n\ny\u2208c\n\nf (\u03b8x1 + (1 \u2212 \u03b8)x2, y)\n\n\u2264 f (\u03b8x1 + (1 \u2212 \u03b8)x2, \u03b8y1 + (1 \u2212 \u03b8)y2)\n\u2264 \u03b8f (x1, y1) + (1 \u2212 \u03b8)f (x2, y2)\n\u2264 \u03b8g(x1) + (1 \u2212 \u03b8)g(x2) + \u01eb.\n\nsince this holds for any \u01eb > 0, we have\n\ng(\u03b8x1 + (1 \u2212 \u03b8)x2) \u2264 \u03b8g(x1) + (1 \u2212 \u03b8)g(x2).\n\nthe result can also be seen in terms of epigraphs. with f , g, and c defined as\n\nin (3.16), and assuming the infimum over y \u2208 c is attained for each x, we have\n\nepi g = {(x, t) | (x, y, t) \u2208 epi f for some y \u2208 c}.\n\nthus epi g is convex, since it is the projection of a convex set on some of its\ncomponents.\n\nexample 3.15 schur complement. suppose the quadratic function\n\nf (x, y) = xt ax + 2xt by + yt cy,\n\n(where a and c are symmetric) is convex in (x, y), which means\n\n(cid:20) a b\nbt c (cid:21) (cid:23) 0.\n\nwe can express g(x) = inf y f (x, y) as\n\ng(x) = xt (a \u2212 bc \u2020bt )x,\n\nwhere c \u2020 is the pseudo-inverse of c (see \u00a7a.5.4). by the minimization rule, g is\nconvex, so we conclude that a \u2212 bc \u2020bt (cid:23) 0.\nif c is invertible, i.e., c \u227b 0, then the matrix a \u2212 bc \u22121bt is called the schur\ncomplement of c in the matrix\n\n(see \u00a7a.5.5).\n\nbt c (cid:21)\n(cid:20) a b\n\nexample 3.16 distance to a set. the distance of a point x to a set s \u2286 rn, in the\nnorm k \u00b7 k, is defined as\n\ndist(x, s) = inf\n\ny\u2208s kx \u2212 yk.\n\nthe function kx\u2212yk is convex in (x, y), so if the set s is convex, the distance function\ndist(x, s) is a convex function of x.\n\n "}, {"Page_number": 103, "text": "3.2 operations that preserve convexity\n\n89\n\nexample 3.17 suppose h is convex. then the function g defined as\n\nis convex. to see this, we define f by\n\ng(x) = inf{h(y) | ay = x}\n\nf (x, y) =(cid:26) h(y)\n\nif ay = x\n\u221e otherwise,\n\nwhich is convex in (x, y). then g is the minimum of f over y, and hence is convex.\n(it is not hard to show directly that g is convex.)\n\n3.2.6 perspective of a function\n\nif f : rn \u2192 r, then the perspective of f is the function g : rn+1 \u2192 r defined by\n\ng(x, t) = tf (x/t),\n\nwith domain\n\ndom g = {(x, t) | x/t \u2208 dom f, t > 0}.\n\nthe perspective operation preserves convexity: if f is a convex function, then so\nis its perspective function g. similarly, if f is concave, then so is g.\n\nthis can be proved several ways, for example, direct verification of the defining\ninequality (see exercise 3.33). we give a short proof here using epigraphs and the\nperspective mapping on rn+1 described in \u00a72.3.3 (which will also explain the name\n\u2018perspective\u2019). for t > 0 we have\n\n(x, t, s) \u2208 epi g \u21d0\u21d2 tf (x/t) \u2264 s\n\u21d0\u21d2 f (x/t) \u2264 s/t\n\u21d0\u21d2 (x/t, s/t) \u2208 epi f.\n\ntherefore epi g is the inverse image of epi f under the perspective mapping that\ntakes (u, v, w) to (u, w)/v. it follows (see \u00a72.3.3) that epi g is convex, so the function\ng is convex.\n\nexample 3.18 euclidean norm squared. the perspective of the convex function\nf (x) = xt x on rn is\n\ng(x, t) = t(x/t)t (x/t) =\n\nxt x\n\nt\n\n,\n\nwhich is convex in (x, t) for t > 0.\n\nwe can deduce convexity of g using several other methods. first, we can express g as\nthe sum of the quadratic-over-linear functions x2\ni /t, which were shown to be convex\nin \u00a73.1.5. we can also express g as a special case of the matrix fractional function\nxt (ti)\u22121x (see example 3.4).\n\n "}, {"Page_number": 104, "text": "90\n\n3 convex functions\n\nexample 3.19 negative logarithm. consider the convex function f (x) = \u2212 log x on\nr++. its perspective is\n\ng(x, t) = \u2212t log(x/t) = t log(t/x) = t log t \u2212 t log x,\n\nand is convex on r2\nx = 1, g reduces to the negative entropy function.\n\n++. the function g is called the relative entropy of t and x. for\n\nfrom convexity of g we can establish convexity or concavity of several interesting\nrelated functions. first, the relative entropy of two vectors u, v \u2208 rn\n\n++, defined as\n\nui log(ui/vi),\n\nnxi=1\n\nnxi=1\n\nis convex in (u, v), since it is a sum of relative entropies of ui, vi.\na closely related function is the kullback-leibler divergence between u, v \u2208 rn\ngiven by\n\n++,\n\ndkl(u, v) =\n\n(ui log(ui/vi) \u2212 ui + vi) ,\n\n(3.17)\n\nwhich is convex, since it is the relative entropy plus a linear function of (u, v). the\nkullback-leibler divergence satisfies dkl(u, v) \u2265 0, and dkl(u, v) = 0 if and only if\nu = v, and so can be used as a measure of deviation between two positive vectors; see\nexercise 3.13. (note that the relative entropy and the kullback-leibler divergence\nare the same when u and v are probability vectors, i.e., satisfy 1t u = 1t v = 1.)\nif we take vi = 1t u in the relative entropy function, we obtain the concave (and\nhomogeneous) function of u \u2208 rn\n\n++ given by\n\nnxi=1\n\nui log(1t u/ui) = (1t u)\n\nzi log(1/zi),\n\nnxi=1\n\nwhere z = u/(1t u), which is called the normalized entropy function. the vector\nz = u/1t u is a normalized vector or probability distribution, since its components\nsum to one; the normalized entropy of u is 1t u times the entropy of this normalized\ndistribution.\n\nexample 3.20 suppose f : rm \u2192 r is convex, and a \u2208 rm\u00d7n, b \u2208 rm, c \u2208 rn,\nand d \u2208 r. we define\n\ng(x) = (ct x + d)f(cid:0)(ax + b)/(ct x + d)(cid:1) ,\n\ndom g = {x | ct x + d > 0, (ax + b)/(ct x + d) \u2208 dom f}.\n\nwith\n\nthen g is convex.\n\n3.3 the conjugate function\n\nin this section we introduce an operation that will play an important role in later\nchapters.\n\n "}, {"Page_number": 105, "text": "3.3 the conjugate function\n\n91\n\nf (x)\n\nxy\n\nx\n\n(0,\u2212f \u2217(y))\n\nfigure 3.8 a function f : r \u2192 r, and a value y \u2208 r. the conjugate\nfunction f \u2217(y) is the maximum gap between the linear function yx and\nf (x), as shown by the dashed line in the figure. if f is differentiable, this\noccurs at a point x where f \u2032(x) = y.\n\n3.3.1 definition and examples\n\nlet f : rn \u2192 r. the function f \u2217 : rn \u2192 r, defined as\nx\u2208dom f(cid:0)yt x \u2212 f (x)(cid:1) ,\n\nf \u2217(y) = sup\n\n(3.18)\n\nis called the conjugate of the function f . the domain of the conjugate function\nconsists of y \u2208 rn for which the supremum is finite, i.e., for which the difference\nyt x\u2212 f (x) is bounded above on dom f . this definition is illustrated in figure 3.8.\nwe see immediately that f \u2217 is a convex function, since it is the pointwise\nsupremum of a family of convex (indeed, affine) functions of y. this is true whether\nor not f is convex. (note that when f is convex, the subscript x \u2208 dom f is not\nnecessary since, by convention, yt x \u2212 f (x) = \u2212\u221e for x 6\u2208 dom f .)\nwe start with some simple examples, and then describe some rules for conjugat-\ning functions. this allows us to derive an analytical expression for the conjugate\nof many common convex functions.\n\nexample 3.21 we derive the conjugates of some convex functions on r.\n\n\u2022 affine function. f (x) = ax + b. as a function of x, yx \u2212 ax \u2212 b is bounded if\nand only if y = a, in which case it is constant. therefore the domain of the\nconjugate function f \u2217 is the singleton {a}, and f \u2217(a) = \u2212b.\n\n\u2022 negative logarithm. f (x) = \u2212 log x, with dom f = r++. the function xy+log x\nis unbounded above if y \u2265 0 and reaches its maximum at x = \u22121/y otherwise.\ntherefore, dom f \u2217 = {y | y < 0} = \u2212r++ and f \u2217(y) = \u2212 log(\u2212y)\u22121 for y < 0.\n\u2022 exponential. f (x) = ex. xy \u2212 ex is unbounded if y < 0. for y > 0, xy \u2212 ex\nreaches its maximum at x = log y, so we have f \u2217(y) = y log y \u2212 y. for y = 0,\n\n "}, {"Page_number": 106, "text": "92\n\n3 convex functions\n\nf \u2217(y) = supx \u2212ex = 0. in summary, dom f \u2217 = r+ and f \u2217(y) = y log y \u2212 y\n(with the interpretation 0 log 0 = 0).\n\n\u2022 negative entropy. f (x) = x log x, with dom f = r+ (and f (0) = 0). the\nfunction xy \u2212 x log x is bounded above on r+ for all y, hence dom f \u2217 = r. it\nattains its maximum at x = ey\u22121, and substituting we find f \u2217(y) = ey\u22121.\n\n\u2022 inverse. f (x) = 1/x on r++. for y > 0, yx \u2212 1/x is unbounded above. for\ny = 0 this function has supremum 0; for y < 0 the supremum is attained at\nx = (\u2212y)\u22121/2. therefore we have f \u2217(y) = \u22122(\u2212y)1/2, with dom f \u2217 = \u2212r+.\n\nexample 3.22 strictly convex quadratic function. consider f (x) = 1\nq \u2208 sn\nit attains its maximum at x = q\u22121y, so\n\n2 xt qx, with\n2 xt qx is bounded above as a function of x for all y.\n\n++. the function yt x \u2212 1\n\nf \u2217(y) =\n\nyt q\u22121y.\n\n1\n2\n\nexample 3.23 log-determinant. we consider f (x) = log det x \u22121 on sn\nconjugate function is defined as\n\n++. the\n\nf \u2217(y ) = sup\nx\u227b0\n\n(tr(y x) + log det x) ,\n\nsince tr(y x) is the standard inner product on sn. we first show that tr(y x) +\nlog det x is unbounded above unless y \u227a 0. if y 6\u227a 0, then y has an eigenvector v,\nwith kvk2 = 1, and eigenvalue \u03bb \u2265 0. taking x = i + tvvt we find that\n\ntr(y x) + log det x = tr y + t\u03bb + log det(i + tvvt ) = tr y + t\u03bb + log(1 + t),\n\nwhich is unbounded above as t \u2192 \u221e.\nnow consider the case y \u227a 0. we can find the maximizing x by setting the gradient\nwith respect to x equal to zero:\n\n\u2207x (tr(y x) + log det x) = y + x \u22121 = 0\n\n(see \u00a7a.4.1), which yields x = \u2212y \u22121 (which is, indeed, positive definite). therefore\nwe have\n\nwith dom f \u2217 = \u2212sn\n\n++.\n\nf \u2217(y ) = log det(\u2212y )\u22121 \u2212 n,\n\nexample 3.24 indicator function. let is be the indicator function of a (not neces-\nsarily convex) set s \u2286 rn, i.e., is(x) = 0 on dom is = s. its conjugate is\n\ni \u2217\ns(y) = sup\nx\u2208s\n\nyt x,\n\nwhich is the support function of the set s.\n\n "}, {"Page_number": 107, "text": "3.3 the conjugate function\n\n93\n\nexample 3.25 log-sum-exp function. to derive the conjugate of the log-sum-exp\ni=1 exi ), we first determine the values of y for which the\nmaximum over x of yt x \u2212 f (x) is attained. by setting the gradient with respect to\nx equal to zero, we obtain the condition\n\nfunction f (x) = log(pn\n\nyi =\n\n,\n\ni = 1, . . . , n.\n\nexi\nj=1 exj\n\npn\n\nthe expression for yi into yt x\u2212f (x) we obtain f \u2217(y) =pn\n\nthese equations are solvable for x if and only if y \u227b 0 and 1t y = 1. by substituting\ni=1 yi log yi. this expression\nfor f \u2217 is still correct if some components of y are zero, as long as y (cid:23) 0 and 1t y = 1,\nand we interpret 0 log 0 as 0.\nin fact the domain of f \u2217 is exactly given by 1t y = 1, y (cid:23) 0. to show this, suppose\nthat a component of y is negative, say, yk < 0. then we can show that yt x \u2212 f (x) is\nunbounded above by choosing xk = \u2212t, and xi = 0, i 6= k, and letting t go to infinity.\nif y (cid:23) 0 but 1t y 6= 1, we choose x = t1, so that\n\nyt x \u2212 f (x) = t1t y \u2212 t \u2212 log n.\n\nif 1t y > 1, this grows unboundedly as t \u2192 \u221e; if 1t y < 1, it grows unboundedly as\nt \u2192 \u2212\u221e.\nin summary,\n\nf \u2217(y) =(cid:26) pn\n\n\u221e\n\ni=1 yi log yi\n\nif y (cid:23) 0 and 1t y = 1\notherwise.\n\nin other words, the conjugate of the log-sum-exp function is the negative entropy\nfunction, restricted to the probability simplex.\n\nexample 3.26 norm. let k \u00b7 k be a norm on rn, with dual norm k \u00b7 k\u2217. we will\nshow that the conjugate of f (x) = kxk is\n\nf \u2217(y) =(cid:26) 0\n\nkyk\u2217 \u2264 1\n\u221e otherwise,\n\ni.e., the conjugate of a norm is the indicator function of the dual norm unit ball.\nif kyk\u2217 > 1, then by definition of the dual norm, there is a z \u2208 rn with kzk \u2264 1 and\nyt z > 1. taking x = tz and letting t \u2192 \u221e, we have\n\nyt x \u2212 kxk = t(yt z \u2212 kzk) \u2192 \u221e,\n\nwhich shows that f \u2217(y) = \u221e. conversely, if kyk\u2217 \u2264 1, then we have yt x \u2264 kxkkyk\u2217\nfor all x, which implies for all x, yt x \u2212 kxk \u2264 0. therefore x = 0 is the value that\nmaximizes yt x \u2212 kxk, with maximum value 0.\n\nexample 3.27 norm squared. now consider the function f (x) = (1/2)kxk2, where k\u00b7k\nis a norm, with dual norm k\u00b7k\u2217. we will show that its conjugate is f \u2217(y) = (1/2)kyk2\n\u2217.\nfrom yt x \u2264 kyk\u2217kxk, we conclude\n\nyt x \u2212 (1/2)kxk2 \u2264 kyk\u2217kxk \u2212 (1/2)kxk2\n\n "}, {"Page_number": 108, "text": "94\n\n3 convex functions\n\nfor all x. the righthand side is a quadratic function of kxk, which has maximum\nvalue (1/2)kyk2\n\n\u2217. therefore for all x, we have\n\nyt x \u2212 (1/2)kxk2 \u2264 (1/2)kyk2\n\u2217,\n\nwhich shows that f \u2217(y) \u2264 (1/2)kyk2\n\u2217.\nto show the other inequality, let x be any vector with yt x = kyk\u2217kxk, scaled so that\nkxk = kyk\u2217. then we have, for this x,\n\nwhich shows that f \u2217(y) \u2265 (1/2)kyk2\n\u2217.\n\nyt x \u2212 (1/2)kxk2 = (1/2)kyk2\n\u2217,\n\nexample 3.28 revenue and profit functions. we consider a business or enterprise that\nconsumes n resources and produces a product that can be sold. we let r = (r1, . . . , rn)\ndenote the vector of resource quantities consumed, and s(r) denote the sales revenue\nderived from the product produced (as a function of the resources consumed). now\nlet pi denote the price (per unit) of resource i, so the total amount paid for resources\nby the enterprise is pt r. the profit derived by the firm is then s(r)\u2212 pt r. let us fix\nthe prices of the resources, and ask what is the maximum profit that can be made, by\nwisely choosing the quantities of resources consumed. this maximum profit is given\nby\n\nm (p) = sup\n\nr (cid:0)s(r) \u2212 pt r(cid:1) .\n\nthe function m (p) gives the maximum profit attainable, as a function of the resource\nprices. in terms of conjugate functions, we can express m as\n\nthus the maximum profit (as a function of resource prices) is closely related to the\nconjugate of gross sales (as a function of resources consumed).\n\nm (p) = (\u2212s)\u2217(\u2212p).\n\n3.3.2 basic properties\n\nfenchel\u2019s inequality\n\nfrom the definition of conjugate function, we immediately obtain the inequality\n\nf (x) + f \u2217(y) \u2265 xt y\n\nfor all x, y. this is called fenchel\u2019s inequality (or young\u2019s inequality when f is\ndifferentiable).\n\nfor example with f (x) = (1/2)xt qx, where q \u2208 sn\n\n++, we obtain the inequality\n\nxt y \u2264 (1/2)xt qx + (1/2)yt q\u22121y.\n\nconjugate of the conjugate\n\nthe examples above, and the name \u2018conjugate\u2019, suggest that the conjugate of the\nconjugate of a convex function is the original function. this is the case provided a\ntechnical condition holds: if f is convex, and f is closed (i.e., epi f is a closed set;\nsee \u00a7a.3.3), then f \u2217\u2217 = f . for example, if dom f = rn, then we have f \u2217\u2217 = f ,\ni.e., the conjugate of the conjugate of f is f again (see exercise 3.39).\n\n "}, {"Page_number": 109, "text": "3.4 quasiconvex functions\n\n95\n\ndifferentiable functions\n\nthe conjugate of a differentiable function f is also called the legendre transform\nof f . (to distinguish the general definition from the differentiable case, the term\nfenchel conjugate is sometimes used instead of conjugate.)\n\nsuppose f is convex and differentiable, with dom f = rn. any maximizer x\u2217\nof yt x\u2212 f (x) satisfies y = \u2207f (x\u2217), and conversely, if x\u2217 satisfies y = \u2207f (x\u2217), then\nx\u2217 maximizes yt x \u2212 f (x). therefore, if y = \u2207f (x\u2217), we have\n\nf \u2217(y) = x\u2217t\u2207f (x\u2217) \u2212 f (x\u2217).\n\nthis allows us to determine f \u2217(y) for any y for which we can solve the gradient\nequation y = \u2207f (z) for z.\nthen we have\n\nwe can express this another way. let z \u2208 rn be arbitrary and define y = \u2207f (z).\n\nf \u2217(y) = zt\u2207f (z) \u2212 f (z).\nscaling and composition with affine transformation\nfor a > 0 and b \u2208 r, the conjugate of g(x) = af (x) + b is g\u2217(y) = af \u2217(y/a) \u2212 b.\nsuppose a \u2208 rn\u00d7n is nonsingular and b \u2208 rn. then the conjugate of g(x) =\nf (ax + b) is\n\nwith dom g\u2217 = at dom f \u2217.\n\ng\u2217(y) = f \u2217(a\u2212t y) \u2212 bt a\u2212t y,\n\nsums of independent functions\n\nif f (u, v) = f1(u) + f2(v), where f1 and f2 are convex functions with conjugates\n1 and f \u2217\nf \u2217\n\n2 , respectively, then\n\nf \u2217(w, z) = f \u2217\n\n1 (w) + f \u2217\n\n2 (z).\n\nin other words, the conjugate of the sum of independent convex functions is the sum\nof the conjugates. (\u2018independent\u2019 means they are functions of different variables.)\n\n3.4 quasiconvex functions\n\n3.4.1 definition and examples\n\na function f : rn \u2192 r is called quasiconvex (or unimodal ) if its domain and all\nits sublevel sets\n\ns\u03b1 = {x \u2208 dom f | f (x) \u2264 \u03b1},\n\nfor \u03b1 \u2208 r, are convex. a function is quasiconcave if \u2212f is quasiconvex, i.e., every\nsuperlevel set {x | f (x) \u2265 \u03b1} is convex. a function that is both quasiconvex and\nquasiconcave is called quasilinear. if a function f is quasilinear, then its domain,\nand every level set {x | f (x) = \u03b1} is convex.\n\n "}, {"Page_number": 110, "text": "96\n\n3 convex functions\n\n\u03b2\n\n\u03b1\n\na\n\nb\n\nc\n\nfigure 3.9 a quasiconvex function on r. for each \u03b1, the \u03b1-sublevel set s\u03b1\nis convex, i.e., an interval. the sublevel set s\u03b1 is the interval [a, b]. the\nsublevel set s\u03b2 is the interval (\u2212\u221e, c].\n\nfor a function on r, quasiconvexity requires that each sublevel set be an interval\n(including, possibly, an infinite interval). an example of a quasiconvex function on\nr is shown in figure 3.9.\n\nconvex functions have convex sublevel sets, and so are quasiconvex. but simple\nexamples, such as the one shown in figure 3.9, show that the converse is not true.\n\nexample 3.29 some examples on r:\n\n\u2022 logarithm. log x on r++ is quasiconvex (and quasiconcave, hence quasilinear).\n\u2022 ceiling function. ceil(x) = inf{z \u2208 z | z \u2265 x} is quasiconvex (and quasicon-\n\ncave).\n\nthese examples show that quasiconvex functions can be concave, or discontinuous.\nwe now give some examples on rn.\n\nexample 3.30 length of a vector. we define the length of x \u2208 rn as the largest\nindex of a nonzero component, i.e.,\n\n(we define the length of the zero vector to be zero.) this function is quasiconvex on\nrn, since its sublevel sets are subspaces:\n\nf (x) = max{i | xi 6= 0}.\n\nf (x) \u2264 \u03b1 \u21d0\u21d2 xi = 0 for i = \u230a\u03b1\u230b + 1, . . . , n.\n\nexample 3.31 consider f : r2 \u2192 r, with dom f = r2\nfunction is neither convex nor concave since its hessian\n\n+ and f (x1, x2) = x1x2. this\n\n\u22072f (x) =(cid:20) 0\n\n1\n\n1\n\n0 (cid:21)\n\n "}, {"Page_number": 111, "text": "3.4 quasiconvex functions\n\n97\n\nis indefinite;\nquasiconcave, however, since the superlevel sets\n\nit has one positive and one negative eigenvalue. the function f is\n\nare convex sets for all \u03b1. (note, however, that f is not quasiconcave on r2.)\n\n{x \u2208 r2\n\n+ | x1x2 \u2265 \u03b1}\n\nexample 3.32 linear-fractional function. the function\n\nf (x) =\n\nat x + b\nct x + d\n\n,\n\nwith dom f = {x | ct x + d > 0}, is quasiconvex, and quasiconcave, i.e., quasilinear.\nits \u03b1-sublevel set is\n\ns\u03b1 = {x | ct x + d > 0, (at x + b)/(ct x + d) \u2264 \u03b1}\n\n= {x | ct x + d > 0, at x + b \u2264 \u03b1(ct x + d)},\n\nwhich is convex, since it is the intersection of an open halfspace and a closed halfspace.\n(the same method can be used to show its superlevel sets are convex.)\n\nexample 3.33 distance ratio function. suppose a, b \u2208 rn, and define\n\nf (x) = kx \u2212 ak2\nkx \u2212 bk2\n\n,\n\ni.e., the ratio of the euclidean distance to a to the distance to b. then f is quasiconvex\non the halfspace {x | kx \u2212 ak2 \u2264 kx \u2212 bk2}. to see this, we consider the \u03b1-sublevel\nset of f , with \u03b1 \u2264 1 since f (x) \u2264 1 on the halfspace {x | kx \u2212 ak2 \u2264 kx \u2212 bk2}. this\nsublevel set is the set of points satisfying\n\nkx \u2212 ak2 \u2264 \u03b1kx \u2212 bk2.\n\nsquaring both sides, and rearranging terms, we see that this is equivalent to\n\n(1 \u2212 \u03b12)xt x \u2212 2(a \u2212 \u03b12b)t x + at a \u2212 \u03b12bt b \u2264 0.\n\nthis describes a convex set (in fact a euclidean ball) if \u03b1 \u2264 1.\n\nexample 3.34 internal rate of return. let x = (x0, x1, . . . , xn) denote a cash flow\nsequence over n periods, where xi > 0 means a payment to us in period i, and xi < 0\nmeans a payment by us in period i. we define the present value of a cash flow, with\ninterest rate r \u2265 0, to be\n\npv(x, r) =\n\n(1 + r)\u2212ixi.\n\nnxi=0\n\n(the factor (1 + r)\u2212i is a discount factor for a payment by or to us in period i.)\nnow we consider cash flows for which x0 < 0 and x0 + x1 + \u00b7\u00b7\u00b7 + xn > 0. this\nmeans that we start with an investment of |x0| in period 0, and that the total of the\n\n "}, {"Page_number": 112, "text": "98\n\n3 convex functions\n\nremaining cash flow, x1 + \u00b7\u00b7\u00b7 + xn, (not taking any discount factors into account)\nexceeds our initial investment.\nfor such a cash flow, pv(x, 0) > 0 and pv(x, r) \u2192 x0 < 0 as r \u2192 \u221e, so it follows\nthat for at least one r \u2265 0, we have pv(x, r) = 0. we define the internal rate of\nreturn of the cash flow as the smallest interest rate r \u2265 0 for which the present value\nis zero:\n\nirr(x) = inf{r \u2265 0 | pv(x, r) = 0}.\n\ninternal rate of return is a quasiconcave function of x (restricted to x0 < 0, x1 +\u00b7\u00b7\u00b7 +\nxn > 0). to see this, we note that\n\nirr(x) \u2265 r \u21d0\u21d2 pv(x, r) > 0 for 0 \u2264 r < r.\n\nthe lefthand side defines the r-superlevel set of irr. the righthand side is the\nintersection of the sets {x | pv(x, r) > 0}, indexed by r, over the range 0 \u2264 r < r.\nfor each r, pv(x, r) > 0 defines an open halfspace, so the righthand side defines a\nconvex set.\n\n3.4.2 basic properties\n\nthe examples above show that quasiconvexity is a considerable generalization of\nconvexity. still, many of the properties of convex functions hold, or have analogs,\nfor quasiconvex functions. for example, there is a variation on jensen\u2019s inequality\nthat characterizes quasiconvexity: a function f is quasiconvex if and only if dom f\nis convex and for any x, y \u2208 dom f and 0 \u2264 \u03b8 \u2264 1,\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u2264 max{f (x), f (y)},\n\n(3.19)\n\ni.e., the value of the function on a segment does not exceed the maximum of\nits values at the endpoints. the inequality (3.19) is sometimes called jensen\u2019s\ninequality for quasiconvex functions, and is illustrated in figure 3.10.\n\nexample 3.35 cardinality of a nonnegative vector. the cardinality or size of a\nvector x \u2208 rn is the number of nonzero components, and denoted card(x). the\nfunction card is quasiconcave on rn\n+ (but not rn). this follows immediately from\nthe modified jensen inequality\n\ncard(x + y) \u2265 min{card(x), card(y)},\n\nwhich holds for x, y (cid:23) 0.\n\nexample 3.36 rank of positive semidefinite matrix. the function rank x is quasi-\nconcave on sn\n\n+. this follows from the modified jensen inequality (3.19),\n\nrank(x + y ) \u2265 min{rank x, rank y }\n\nwhich holds for x, y \u2208 sn\nexample, since rank(diag(x)) = card(x) for x (cid:23) 0.)\n\n+. (this can be considered an extension of the previous\n\n "}, {"Page_number": 113, "text": "3.4 quasiconvex functions\n\n99\n\nmax{f (x), f (y)}\n\n(y, f (y))\n\n(x, f (x))\n\nfigure 3.10 a quasiconvex function on r. the value of f between x and y\nis no more than max{f (x), f (y)}.\n\nlike convexity, quasiconvexity is characterized by the behavior of a function f\non lines: f is quasiconvex if and only if its restriction to any line intersecting its\ndomain is quasiconvex. in particular, quasiconvexity of a function can be verified by\nrestricting it to an arbitrary line, and then checking quasiconvexity of the resulting\nfunction on r.\n\nquasiconvex functions on r\n\nwe can give a simple characterization of quasiconvex functions on r. we consider\ncontinuous functions, since stating the conditions in the general case is cumbersome.\na continuous function f : r \u2192 r is quasiconvex if and only if at least one of the\nfollowing conditions holds:\n\n\u2022 f is nondecreasing\n\u2022 f is nonincreasing\n\u2022 there is a point c \u2208 dom f such that for t \u2264 c (and t \u2208 dom f ), f is\n\nnonincreasing, and for t \u2265 c (and t \u2208 dom f ), f is nondecreasing.\n\nthe point c can be chosen as any point which is a global minimizer of f . figure 3.11\nillustrates this.\n\n3.4.3 differentiable quasiconvex functions\n\nfirst-order conditions\nsuppose f : rn \u2192 r is differentiable. then f is quasiconvex if and only if dom f\nis convex and for all x, y \u2208 dom f\n\nf (y) \u2264 f (x) =\u21d2 \u2207f (x)t (y \u2212 x) \u2264 0.\n\n(3.20)\n\n "}, {"Page_number": 114, "text": "100\n\n3 convex functions\n\nc\n\nt\n\nfigure 3.11 a quasiconvex function on r. the function is nonincreasing for\nt \u2264 c and nondecreasing for t \u2265 c.\n\n\u2207f (x)\n\nx\n\nfigure 3.12 three level curves of a quasiconvex function f are shown. the\nvector \u2207f (x) defines a supporting hyperplane to the sublevel set {z | f (z) \u2264\nf (x)} at x.\n\nthis is the analog of inequality (3.2), for quasiconvex functions. we leave the proof\nas an exercise (exercise 3.43).\n\nthe condition (3.20) has a simple geometric interpretation when \u2207f (x) 6= 0. it\nstates that \u2207f (x) defines a supporting hyperplane to the sublevel set {y | f (y) \u2264\nf (x)}, at the point x, as illustrated in figure 3.12.\n\nwhile the first-order condition for convexity (3.2), and the first-order condition\nfor quasiconvexity (3.20) are similar, there are some important differences. for\nexample, if f is convex and \u2207f (x) = 0, then x is a global minimizer of f . but this\nstatement is false for quasiconvex functions: it is possible that \u2207f (x) = 0, but x\nis not a global minimizer of f .\n\n "}, {"Page_number": 115, "text": "3.4 quasiconvex functions\n\n101\n\nsecond-order conditions\nnow suppose f is twice differentiable. if f is quasiconvex, then for all x \u2208 dom f ,\nand all y \u2208 rn, we have\n\nyt\u2207f (x) = 0 =\u21d2 yt\u22072f (x)y \u2265 0.\n\n(3.21)\n\nfor a quasiconvex function on r, this reduces to the simple condition\n\nf \u2032(x) = 0 =\u21d2 f \u2032\u2032(x) \u2265 0,\n\ni.e., at any point with zero slope, the second derivative is nonnegative. for a\nquasiconvex function on rn, the interpretation of the condition (3.21) is a bit\nmore complicated. as in the case n = 1, we conclude that whenever \u2207f (x) = 0,\nwe must have \u22072f (x) (cid:23) 0. when \u2207f (x) 6= 0, the condition (3.21) means that\n\u22072f (x) is positive semidefinite on the (n \u2212 1)-dimensional subspace \u2207f (x)\u22a5. this\nimplies that \u22072f (x) can have at most one negative eigenvalue.\n\nas a (partial) converse, if f satisfies\n\nyt\u2207f (x) = 0 =\u21d2 yt\u22072f (x)y > 0\n\n(3.22)\nfor all x \u2208 dom f and all y \u2208 rn, y 6= 0, then f is quasiconvex. this condition is\nthe same as requiring \u22072f (x) to be positive definite for any point with \u2207f (x) = 0,\nand for all other points, requiring \u22072f (x) to be positive definite on the (n \u2212 1)-\ndimensional subspace \u2207f (x)\u22a5.\nproof of second-order conditions for quasiconvexity\n\nby restricting the function to an arbitrary line, it suffices to consider the case in\nwhich f : r \u2192 r.\nwe first show that if f : r \u2192 r is quasiconvex on an interval (a, b), then it\nmust satisfy (3.21), i.e., if f \u2032(c) = 0 with c \u2208 (a, b), then we must have f \u2032\u2032(c) \u2265 0. if\nf \u2032(c) = 0 with c \u2208 (a, b), f \u2032\u2032(c) < 0, then for small positive \u01eb we have f (c\u2212\u01eb) < f (c)\nit follows that the sublevel set {x | f (x) \u2264 f (c) \u2212 \u01eb} is\nand f (c + \u01eb) < f (c).\ndisconnected for small positive \u01eb, and therefore not convex, which contradicts our\nassumption that f is quasiconvex.\n\nnow we show that if the condition (3.22) holds, then f is quasiconvex. assume\nthat (3.22) holds, i.e., for each c \u2208 (a, b) with f \u2032(c) = 0, we have f \u2032\u2032(c) > 0. this\nmeans that whenever the function f \u2032 crosses the value 0, it is strictly increasing.\nif f \u2032 does not cross the value\ntherefore it can cross the value 0 at most once.\n0 at all, then f is either nonincreasing or nondecreasing on (a, b), and therefore\nquasiconvex. otherwise it must cross the value 0 exactly once, say at c \u2208 (a, b).\nsince f \u2032\u2032(c) > 0, it follows that f \u2032(t) \u2264 0 for a < t \u2264 c, and f \u2032(t) \u2265 0 for c \u2264 t < b.\nthis shows that f is quasiconvex.\n\n3.4.4 operations that preserve quasiconvexity\n\nnonnegative weighted maximum\n\na nonnegative weighted maximum of quasiconvex functions, i.e.,\n\nf = max{w1f1, . . . , wmfm},\n\n "}, {"Page_number": 116, "text": "102\n\n3 convex functions\n\nwith wi \u2265 0 and fi quasiconvex, is quasiconvex. the property extends to the\ngeneral pointwise supremum\n\nf (x) = sup\ny\u2208c\n\n(w(y)g(x, y))\n\nwhere w(y) \u2265 0 and g(x, y) is quasiconvex in x for each y. this fact can be easily\nverified: f (x) \u2264 \u03b1 if and only if\n\nw(y)g(x, y) \u2264 \u03b1 for all y \u2208 c,\n\ni.e., the \u03b1-sublevel set of f is the intersection of the \u03b1-sublevel sets of the functions\nw(y)g(x, y) in the variable x.\n\nexample 3.37 generalized eigenvalue. the maximum generalized eigenvalue of a\npair of symmetric matrices (x, y ), with y \u227b 0, is defined as\n\n\u03bbmax(x, y ) = sup\nu6=0\n\nut xu\nut y u\n\n= sup{\u03bb | det(\u03bby \u2212 x) = 0}.\n\n(see \u00a7a.5.3). this function is quasiconvex on dom f = sn \u00d7 sn\nto see this we consider the expression\n\n++.\n\n\u03bbmax(x, y ) = sup\nu6=0\n\nut xu\nut y u\n\n.\n\nfor each u 6= 0, the function ut xu/ut y u is linear-fractional in (x, y ), hence a\nquasiconvex function of (x, y ). we conclude that \u03bbmax is quasiconvex, since it is the\nsupremum of a family of quasiconvex functions.\n\ncomposition\nif g : rn \u2192 r is quasiconvex and h : r \u2192 r is nondecreasing, then f = h \u25e6 g is\nquasiconvex.\nthe composition of a quasiconvex function with an affine or linear-fractional\ntransformation yields a quasiconvex function.\nif f is quasiconvex, then g(x) =\nf (ax + b) is quasiconvex, and \u02dcg(x) = f ((ax + b)/(ct x + d)) is quasiconvex on the\nset\n\n{x | ct x + d > 0, (ax + b)/(ct x + d) \u2208 dom f}.\n\nminimization\n\nif f (x, y) is quasiconvex jointly in x and y and c is a convex set, then the function\n\ng(x) = inf\ny\u2208c\n\nf (x, y)\n\nis quasiconvex.\n\nto show this, we need to show that {x | g(x) \u2264 \u03b1} is convex, where \u03b1 \u2208 r is\narbitrary. from the definition of g, g(x) \u2264 \u03b1 if and only if for any \u01eb > 0 there exists\n\n "}, {"Page_number": 117, "text": "3.4 quasiconvex functions\n\n103\n\na y \u2208 c with f (x, y) \u2264 \u03b1 + \u01eb. now let x1 and x2 be two points in the \u03b1-sublevel\nset of g. then for any \u01eb > 0, there exists y1, y2 \u2208 c with\n\nf (x1, y1) \u2264 \u03b1 + \u01eb,\n\nf (x2, y2) \u2264 \u03b1 + \u01eb,\n\nand since f is quasiconvex in x and y, we also have\n\nf (\u03b8x1 + (1 \u2212 \u03b8)x2, \u03b8y1 + (1 \u2212 \u03b8)y2) \u2264 \u03b1 + \u01eb,\n\nfor 0 \u2264 \u03b8 \u2264 1. hence g(\u03b8x1 + (1 \u2212 \u03b8)x2) \u2264 \u03b1, which proves that {x | g(x) \u2264 \u03b1} is\nconvex.\n\n3.4.5 representation via family of convex functions\n\nin the sequel, it will be convenient to represent the sublevel sets of a quasiconvex\nfunction f (which are convex) via inequalities of convex functions. we seek a family\nof convex functions \u03c6t : rn \u2192 r, indexed by t \u2208 r, with\n\nf (x) \u2264 t \u21d0\u21d2 \u03c6t(x) \u2264 0,\n\n(3.23)\n\ni.e., the t-sublevel set of the quasiconvex function f is the 0-sublevel set of the\nconvex function \u03c6t. evidently \u03c6t must satisfy the property that for all x \u2208 rn,\n\u03c6t(x) \u2264 0 =\u21d2 \u03c6s(x) \u2264 0 for s \u2265 t. this is satisfied if for each x, \u03c6t(x) is a\nnonincreasing function of t, i.e., \u03c6s(x) \u2264 \u03c6t(x) whenever s \u2265 t.\nto see that such a representation always exists, we can take\n\n\u03c6t(x) =(cid:26) 0\n\nf (x) \u2264 t\n\u221e otherwise,\n\ni.e., \u03c6t is the indicator function of the t-sublevel of f . obviously this representation\nis not unique; for example if the sublevel sets of f are closed, we can take\n\n\u03c6t(x) = dist (x,{z | f (z) \u2264 t}) .\n\nwe are usually interested in a family \u03c6t with nice properties, such as differentia-\nbility.\n\nexample 3.38 convex over concave function. suppose p is a convex function, q is a\nconcave function, with p(x) \u2265 0 and q(x) > 0 on a convex set c. then the function\nf defined by f (x) = p(x)/q(x), on c, is quasiconvex.\n\nhere we have\n\nf (x) \u2264 t \u21d0\u21d2 p(x) \u2212 tq(x) \u2264 0,\n\nso we can take \u03c6t(x) = p(x) \u2212 tq(x) for t \u2265 0. for each t, \u03c6t is convex and for each\nx, \u03c6t(x) is decreasing in t.\n\n "}, {"Page_number": 118, "text": "104\n\n3 convex functions\n\n3.5 log-concave and log-convex functions\n\n3.5.1 definition\n\na function f : rn \u2192 r is logarithmically concave or log-concave if f (x) > 0\nfor all x \u2208 dom f and log f is concave.\nit is said to be logarithmically convex\nor log-convex if log f is convex. thus f is log-convex if and only if 1/f is log-\nconcave. it is convenient to allow f to take on the value zero, in which case we\ntake log f (x) = \u2212\u221e. in this case we say f is log-concave if the extended-value\nfunction log f is concave.\nwe can express log-concavity directly, without logarithms: a function f : rn \u2192\nr, with convex domain and f (x) > 0 for all x \u2208 dom f , is log-concave if and only\nif for all x, y \u2208 dom f and 0 \u2264 \u03b8 \u2264 1, we have\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u2265 f (x)\u03b8f (y)1\u2212\u03b8.\n\nin particular, the value of a log-concave function at the average of two points is at\nleast the geometric mean of the values at the two points.\n\nfrom the composition rules we know that eh is convex if h is convex, so a log-\nconvex function is convex. similarly, a nonnegative concave function is log-concave.\nit is also clear that a log-convex function is quasiconvex and a log-concave function\nis quasiconcave, since the logarithm is monotone increasing.\n\nexample 3.39 some simple examples of log-concave and log-convex functions.\n\n\u2022 affine function. f (x) = at x + b is log-concave on {x | at x + b > 0}.\n\u2022 powers. f (x) = xa, on r++, is log-convex for a \u2264 0, and log-concave for a \u2265 0.\n\u2022 exponentials. f (x) = eax is log-convex and log-concave.\n\u2022 the cumulative distribution function of a gaussian density,\n\n\u03c6(x) =\n\nis log-concave (see exercise 3.54).\n\n1\n\n\u221a2\u03c0z x\n\n\u2212\u221e\n\ne\u2212u2/2 du,\n\n\u2022 gamma function. the gamma function,\n\n\u03b3(x) =z \u221e\n\n0\n\nux\u22121e\u2212u du,\n\nis log-convex for x \u2265 1 (see exercise 3.52).\n\u2022 determinant. det x is log concave on sn\n++.\n\u2022 determinant over trace. det x/ tr x is log concave on sn\n\n++ (see exercise 3.49).\n\nexample 3.40 log-concave density functions. many common probability density\nfunctions are log-concave. two examples are the multivariate normal distribution,\n\nf (x) =\n\n1\n\np(2\u03c0)n det \u03c3\n\ne\u2212 1\n\n2 (x\u2212\u00afx)t \u03c3\u22121(x\u2212\u00afx)\n\n "}, {"Page_number": 119, "text": "3.5 log-concave and log-convex functions\n\n105\n\n(where \u00afx \u2208 rn and \u03c3 \u2208 sn\n\n++), and the exponential distribution on rn\n+,\n\n\u03bbi! e\u2212\u03bbt x\nf (x) =  nyi=1\nf (x) =(cid:26) 1/\u03b1 x \u2208 c\n\nx 6\u2208 c\n\n0\n\n(where \u03bb \u227b 0). another example is the uniform distribution over a convex set c,\n\nwhere \u03b1 = vol(c) is the volume (lebesgue measure) of c. in this case log f takes\non the value \u2212\u221e outside c, and \u2212 log \u03b1 on c, hence is concave.\nas a more exotic example consider the wishart distribution, defined as follows. let\nx1, . . . , xp \u2208 rn be independent gaussian random vectors with zero mean and co-\ni has the wishart\ndensity\n\nvariance \u03c3 \u2208 sn, with p > n. the random matrix x =pp\n\ni=1 xixt\n\nf (x) = a (det x)(p\u2212n\u22121)/2 e\u2212 1\n\ntr(\u03c3\u22121x),\n\n2\n\n++, and a is a positive constant. the wishart density is log-concave,\n\nwith dom f = sn\nsince\n\nlog f (x) = log a +\n\nwhich is a concave function of x.\n\np \u2212 n \u2212 1\n\n2\n\nlog det x \u2212\n\n1\n2\n\ntr(\u03c3\u22121x),\n\n3.5.2 properties\n\ntwice differentiable log-convex/concave functions\n\nsuppose f is twice differentiable, with dom f convex, so\n\n1\nf (x)2\u2207f (x)\u2207f (x)t .\nwe conclude that f is log-convex if and only if for all x \u2208 dom f ,\n\n1\nf (x)\u22072f (x) \u2212\n\n\u22072 log f (x) =\n\nf (x)\u22072f (x) (cid:23) \u2207f (x)\u2207f (x)t ,\n\nand log-concave if and only if for all x \u2208 dom f ,\n\nf (x)\u22072f (x) (cid:22) \u2207f (x)\u2207f (x)t .\n\nmultiplication, addition, and integration\n\nlog-convexity and log-concavity are closed under multiplication and positive scal-\ning. for example, if f and g are log-concave, then so is the pointwise product\nh(x) = f (x)g(x), since log h(x) = log f (x) + log g(x), and log f (x) and log g(x) are\nconcave functions of x.\n\nsimple examples show that the sum of log-concave functions is not, in general,\nlog-concave. log-convexity, however, is preserved under sums. let f and g be log-\nconvex functions, i.e., f = log f and g = log g are convex. from the composition\nrules for convex functions, it follows that\n\nlog (exp f + exp g) = log(f + g)\n\n "}, {"Page_number": 120, "text": "106\n\n3 convex functions\n\nis convex. therefore the sum of two log-convex functions is log-convex.\n\nmore generally, if f (x, y) is log-convex in x for each y \u2208 c then\n\ng(x) =zc\n\nf (x, y) dy\n\nis log-convex.\n\nexample 3.41 laplace transform of a nonnegative function and the moment and\ncumulant generating functions. suppose p : rn \u2192 r satisfies p(x) \u2265 0 for all x. the\nlaplace transform of p,\n\np (z) =z p(x)e\u2212zt x dx,\n\nis log-convex on rn. (here dom p is, naturally, {z | p (z) < \u221e}.)\n\nnow suppose p is a density, i.e., satisfiesr p(x) dx = 1. the function m (z) = p (\u2212z)\n\nis called the moment generating function of the density. it gets its name from the fact\nthat the moments of the density can be found from the derivatives of the moment\ngenerating function, evaluated at z = 0, e.g.,\n\n\u2207m (0) = e v,\n\n\u22072m (0) = e vvt ,\n\nwhere v is a random variable with density p.\n\nthe function log m (z), which is convex, is called the cumulant generating function\nfor p, since its derivatives give the cumulants of the density. for example, the first\nand second derivatives of the cumulant generating function, evaluated at zero, are\nthe mean and covariance of the associated random variable:\n\n\u2207 log m (0) = e v,\n\n\u22072 log m (0) = e(v \u2212 e v)(v \u2212 e v)t .\n\nintegration of log-concave functions\nin some special cases log-concavity is preserved by integration. if f : rn\u00d7rm \u2192 r\nis log-concave, then\n\ng(x) =z f (x, y) dy\n\nis a log-concave function of x (on rn). (the integration here is over rm.) a proof\nof this result is not simple; see the references.\n\nthis result has many important consequences, some of which we describe in\nthe rest of this section. it implies, for example, that marginal distributions of log-\nconcave probability densities are log-concave. it also implies that log-concavity is\nclosed under convolution, i.e., if f and g are log-concave on rn, then so is the\nconvolution\n\n(f \u2217 g)(x) =z f (x \u2212 y)g(y) dy.\n\n(to see this, note that g(y) and f (x\u2212y) are log-concave in (x, y), hence the product\nf (x \u2212 y)g(y) is; then the integration result applies.)\n\n "}, {"Page_number": 121, "text": "3.5 log-concave and log-convex functions\n\n107\n\nsuppose c \u2286 rn is a convex set and w is a random vector in rn with log-\n\nconcave probability density p. then the function\n\nis log-concave in x. to see this, express f as\n\nf (x) = prob(x + w \u2208 c)\n\nwhere g is defined as\n\nf (x) =z g(x + w)p(w) dw,\ng(u) =(cid:26) 1 u \u2208 c\n\n0 u 6\u2208 c,\n\n(which is log-concave) and apply the integration result.\n\nexample 3.42 the cumulative distribution function of a probability density function\nf : rn \u2192 r is defined as\n\nf (x) = prob(w (cid:22) x) =z xn\n\n\u2212\u221e \u00b7\u00b7\u00b7z x1\n\n\u2212\u221e\n\nf (z) dz1 \u00b7\u00b7\u00b7 dzn,\n\nif f is log-concave, then f is log-\nwhere w is a random variable with density f .\nconcave. we have already encountered a special case: the cumulative distribution\nfunction of a gaussian random variable,\n\nf (x) =\n\n1\n\n\u221a2\u03c0z x\n\n\u2212\u221e\n\ne\u2212t2/2 dt,\n\nis log-concave. (see example 3.39 and exercise 3.54.)\n\nexample 3.43 yield function. let x \u2208 rn denote the nominal or target value of a\nset of parameters of a product that is manufactured. variation in the manufacturing\nprocess causes the parameters of the product, when manufactured, to have the value\nx + w, where w \u2208 rn is a random vector that represents manufacturing variation,\nand is usually assumed to have zero mean. the yield of the manufacturing process,\nas a function of the nominal parameter values, is given by\n\ny (x) = prob(x + w \u2208 s),\n\nwhere s \u2286 rn denotes the set of acceptable parameter values for the product, i.e.,\nthe product specifications.\n\nif the density of the manufacturing error w is log-concave (for example, gaussian) and\nthe set s of product specifications is convex, then the yield function y is log-concave.\nthis implies that the \u03b1-yield region, defined as the set of nominal parameters for\nwhich the yield exceeds \u03b1, is convex. for example, the 95% yield region\n\n{x | y (x) \u2265 0.95} = {x | log y (x) \u2265 log 0.95}\nis convex, since it is a superlevel set of the concave function log y .\n\n "}, {"Page_number": 122, "text": "108\n\n3 convex functions\n\nexample 3.44 volume of polyhedron. let a \u2208 rm\u00d7n. define\n\npu = {x \u2208 rn | ax (cid:22) u}.\nthen its volume vol pu is a log-concave function of u.\n\nto prove this, note that the function\n\nis log-concave. by the integration result, we conclude that\n\notherwise,\n\n0\n\n\u03c8(x, u) =(cid:26) 1 ax (cid:22) u\nz \u03c8(x, u) dx = vol pu\n\nis log-concave.\n\n3.6 convexity with respect to generalized inequalities\n\nwe now consider generalizations of the notions of monotonicity and convexity, using\ngeneralized inequalities instead of the usual ordering on r.\n\n3.6.1 monotonicity with respect to a generalized inequality\n\nsuppose k \u2286 rn is a proper cone with associated generalized inequality (cid:22)k. a\nfunction f : rn \u2192 r is called k-nondecreasing if\n\nand k-increasing if\n\nx (cid:22)k y =\u21d2 f (x) \u2264 f (y),\n\nx (cid:22)k y, x 6= y =\u21d2 f (x) < f (y).\n\nwe define k-nonincreasing and k-decreasing functions in a similar way.\n\nexample 3.45 monotone vector functions. a function f : rn \u2192 r is nondecreasing\nwith respect to rn\n\n+ if and only if\n\nx1 \u2264 y1, . . . , xn \u2264 yn =\u21d2 f (x) \u2264 f (y)\n\nfor all x, y. this is the same as saying that f , when restricted to any component xi\n(i.e., xi is considered the variable while xj for j 6= i are fixed), is nondecreasing.\n\nexample 3.46 matrix monotone functions. a function f : sn \u2192 r is called ma-\ntrix monotone (increasing, decreasing) if it is monotone with respect to the posi-\ntive semidefinite cone. some examples of matrix monotone functions of the variable\nx \u2208 sn:\n\n "}, {"Page_number": 123, "text": "3.6 convexity with respect to generalized inequalities\n\n109\n\n\u2022 tr(w x), where w \u2208 sn, is matrix nondecreasing if w (cid:23) 0, and matrix in-\ncreasing if w \u227b 0 (it is matrix nonincreasing if w (cid:22) 0, and matrix decreasing\nif w \u227a 0).\n\n\u2022 tr(x \u22121) is matrix decreasing on sn\n\u2022 det x is matrix increasing on sn\n\n++.\n\n++, and matrix nondecreasing on sn\n+.\n\ngradient conditions for monotonicity\nrecall that a differentiable function f : r \u2192 r, with convex (i.e., interval) domain,\nis nondecreasing if and only if f \u2032(x) \u2265 0 for all x \u2208 dom f , and increasing if\nf \u2032(x) > 0 for all x \u2208 dom f (but the converse is not true). these conditions\nare readily extended to the case of monotonicity with respect to a generalized\ninequality. a differentiable function f , with convex domain, is k-nondecreasing if\nand only if\n\n(3.24)\nfor all x \u2208 dom f . note the difference with the simple scalar case: the gradi-\nent must be nonnegative in the dual inequality. for the strict case, we have the\nfollowing: if\n\n\u2207f (x) (cid:23)k \u2217 0\n\n\u2207f (x) \u227bk \u2217 0\n\n(3.25)\nfor all x \u2208 dom f , then f is k-increasing. as in the scalar case, the converse is\nnot true.\nlet us prove these first-order conditions for monotonicity. first, assume that\nf satisfies (3.24) for all x, but is not k-nondecreasing, i.e., there exist x, y with\nx (cid:22)k y and f (y) < f (x). by differentiability of f there exists a t \u2208 [0, 1] with\n\nd\ndt\n\nf (x + t(y \u2212 x)) = \u2207f (x + t(y \u2212 x))t (y \u2212 x) < 0.\n\nsince y \u2212 x \u2208 k this means\n\n\u2207f (x + t(y \u2212 x)) 6\u2208 k \u2217,\n\nwhich contradicts our assumption that (3.24) is satisfied everywhere. in a similar\nway it can be shown that (3.25) implies f is k-increasing.\n\nit is also straightforward to see that it is necessary that (3.24) hold everywhere.\nassume (3.24) does not hold for x = z. by the definition of dual cone this means\nthere exists a v \u2208 k with\nnow consider h(t) = f (z + tv) as a function of t. we have h\u2032(0) = \u2207f (z)t v < 0,\nand therefore there exists t > 0 with h(t) = f (z + tv) < h(0) = f (z), which means\nf is not k-nondecreasing.\n\n\u2207f (z)t v < 0.\n\n3.6.2 convexity with respect to a generalized inequality\n\nsuppose k \u2286 rm is a proper cone with associated generalized inequality (cid:22)k. we\nsay f : rn \u2192 rm is k-convex if for all x, y, and 0 \u2264 \u03b8 \u2264 1,\n\nf (\u03b8x + (1 \u2212 \u03b8)y) (cid:22)k \u03b8f (x) + (1 \u2212 \u03b8)f (y).\n\n "}, {"Page_number": 124, "text": "110\n\n3 convex functions\n\nthe function is strictly k-convex if\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u227ak \u03b8f (x) + (1 \u2212 \u03b8)f (y)\n\nfor all x 6= y and 0 < \u03b8 < 1. these definitions reduce to ordinary convexity and\nstrict convexity when m = 1 (and k = r+).\n\nexample 3.47 convexity with respect to componentwise inequality. a function f :\nrn \u2192 rm is convex with respect to componentwise inequality (i.e., the generalized\ninequality induced by rm\n\n+ ) if and only if for all x, y and 0 \u2264 \u03b8 \u2264 1,\n\nf (\u03b8x + (1 \u2212 \u03b8)y) (cid:22) \u03b8f (x) + (1 \u2212 \u03b8)f (y),\n\ni.e., each component fi is a convex function. the function f is strictly convex with\nrespect to componentwise inequality if and only if each component fi is strictly con-\nvex.\n\nexample 3.48 matrix convexity. suppose f is a symmetric matrix valued function,\ni.e., f : rn \u2192 sm. the function f is convex with respect to matrix inequality if\n\nf (\u03b8x + (1 \u2212 \u03b8)y) (cid:22) \u03b8f (x) + (1 \u2212 \u03b8)f (y)\n\nfor any x and y, and for \u03b8 \u2208 [0, 1]. this is sometimes called matrix convexity. an\nequivalent definition is that the scalar function zt f (x)z is convex for all vectors z.\n(this is often a good way to prove matrix convexity). a matrix function is strictly\nmatrix convex if\n\nf (\u03b8x + (1 \u2212 \u03b8)y) \u227a \u03b8f (x) + (1 \u2212 \u03b8)f (y)\n\nwhen x 6= y and 0 < \u03b8 < 1, or, equivalently, if zt f z is strictly convex for every z 6= 0.\nsome examples:\n\n\u2022 the function f (x) = xx t where x \u2208 rn\u00d7m is matrix convex, since for\nfixed z the function zt xx t z = kx t zk2\n2 is a convex quadratic function of (the\ncomponents of) x. for the same reason, f (x) = x 2 is matrix convex on sn.\n++ for 1 \u2264 p \u2264 2 or \u22121 \u2264 p \u2264 0, and\n\n\u2022 the function x p is matrix convex on sn\n\nmatrix concave for 0 \u2264 p \u2264 1.\n\n\u2022 the function f (x) = ex is not matrix convex on sn, for n \u2265 2.\n\nmany of the results for convex functions have extensions to k-convex functions.\nas a simple example, a function is k-convex if and only if its restriction to any\nline in its domain is k-convex. in the rest of this section we list a few results for\nk-convexity that we will use later; more results are explored in the exercises.\n\ndual characterization of k-convexity\na function f is k-convex if and only if for every w (cid:23)k \u2217 0, the (real-valued) function\nwt f is convex (in the ordinary sense); f is strictly k-convex if and only if for every\nnonzero w (cid:23)k \u2217 0 the function wt f is strictly convex. (these follow directly from\nthe definitions and properties of dual inequality.)\n\n "}, {"Page_number": 125, "text": "3.6 convexity with respect to generalized inequalities\n\n111\n\ndifferentiable k-convex functions\n\na differentiable function f is k-convex if and only if its domain is convex, and for\nall x, y \u2208 dom f ,\n\nf (y) (cid:23)k f (x) + df (x)(y \u2212 x).\n\n(here df (x) \u2208 rm\u00d7n is the derivative or jacobian matrix of f at x; see \u00a7a.4.1.)\nthe function f is strictly k-convex if and only if for all x, y \u2208 dom f with x 6= y,\n\nf (y) \u227bk f (x) + df (x)(y \u2212 x).\n\ncomposition theorem\n\nmany of the results on composition can be generalized to k-convexity. for example,\nif g : rn \u2192 rp is k-convex, h : rp \u2192 r is convex, and \u02dch (the extended-value\nextension of h) is k-nondecreasing, then h \u25e6 g is convex. this generalizes the fact\nthat a nondecreasing convex function of a convex function is convex. the condition\nthat \u02dch be k-nondecreasing implies that dom h \u2212 k = dom h.\n\nexample 3.49 the quadratic matrix function g : rm\u00d7n \u2192 sn defined by\n\ng(x) = x t ax + bt x + x t b + c,\n\nwhere a \u2208 sm, b \u2208 rm\u00d7n, and c \u2208 sn, is convex when a (cid:23) 0.\nthe function h : sn \u2192 r defined by h(y ) = \u2212 log det(\u2212y ) is convex and increasing\non dom h = \u2212sn\nby the composition theorem, we conclude that\n\n++.\n\nf (x) = \u2212 log det(\u2212(x t ax + bt x + x t b + c))\n\nis convex on\n\ndom f = {x \u2208 rm\u00d7n | x t ax + bt x + x t b + c \u227a 0}.\n\nthis generalizes the fact that\n\nis convex on\n\nprovided a \u2265 0.\n\n\u2212 log(\u2212(ax2 + bx + c))\n\n{x \u2208 r | ax2 + bx + c < 0},\n\n "}, {"Page_number": 126, "text": "112\n\n3 convex functions\n\nbibliography\n\nthe standard reference on convex analysis is rockafellar [roc70]. other books on convex\nfunctions are stoer and witzgall [sw70], roberts and varberg [rv73], van tiel [vt84],\nhiriart-urruty and lemar\u00b4echal [hul93], ekeland and t\u00b4emam [et99], borwein and lewis\n[bl00], florenzano and le van [fl01], barvinok [bar02], and bertsekas, nedi\u00b4c, and\nozdaglar [ber03]. most nonlinear programming texts also include chapters on convex\nfunctions (see, for example, mangasarian [man94], bazaraa, sherali, and shetty [bss93],\nbertsekas [ber99], polyak [pol87], and peressini, sullivan, and uhl [psu88]).\n\njensen\u2019s inequality appears in [jen06]. a general study of inequalities, in which jensen\u2019s\ninequality plays a central role, is presented by hardy, littlewood, and p\u00b4olya [hlp52],\nand beckenbach and bellman [bb65].\n\nthe term perspective function is from hiriart-urruty and lemar\u00b4echal [hul93, volume\n1, page 100]. for the definitions in example 3.19 (relative entropy and kullback-leibler\ndivergence), and the related exercise 3.13, see cover and thomas [ct91].\n\nsome important early references on quasiconvex functions (as well as other extensions of\nconvexity) are nikaid\u02c6o [nik54], mangasarian [man94, chapter 9], arrow and enthoven\n[ae61], ponstein [pon67], and luenberger [lue68]. for a more comprehensive reference\nlist, we refer to bazaraa, sherali, and shetty [bss93, page 126].\n\npr\u00b4ekopa [pr\u00b4e80] gives a survey of log-concave functions. log-convexity of the laplace\ntransform is mentioned in barndorff-nielsen [bn78, \u00a77]. for a proof of the integration\nresult of log-concave functions, see pr\u00b4ekopa [pr\u00b4e71, pr\u00b4e73].\n\ngeneralized inequalities are used extensively in the recent literature on cone programming,\nstarting with nesterov and nemirovski [nn94, page 156]; see also ben-tal and nemirovski\n[btn01] and the references at the end of chapter 4. convexity with respect to generalized\ninequalities also appears in the work of luenberger [lue69, \u00a78.2] and isii [isi64]. matrix\nmonotonicity and matrix convexity are attributed to l\u00a8owner [l\u00a8ow34], and are discussed\nin detail by davis [dav63], roberts and varberg [rv73, page 216] and marshall and\nolkin [mo79, \u00a716e]. for the result on convexity and concavity of the function x p in\nexample 3.48, see bondar [bon94, theorem 16.1]. for a simple example that demonstrates\nthat ex is not matrix convex, see marshall and olkin [mo79, page 474].\n\n "}, {"Page_number": 127, "text": "113\n\nexercises\n\nexercises\n\ndefinition of convexity\n\n3.1 suppose f : r \u2192 r is convex, and a, b \u2208 dom f with a < b.\n\n(a) show that\n\nf (x) \u2264\n\nb \u2212 x\nb \u2212 a\n\nf (a) +\n\nx \u2212 a\nb \u2212 a\n\nf (b)\n\nfor all x \u2208 [a, b].\n\n(b) show that\n\nf (x) \u2212 f (a)\n\nx \u2212 a\n\n\u2264\n\nf (b) \u2212 f (a)\n\nb \u2212 a\n\n\u2264\n\nf (b) \u2212 f (x)\n\nb \u2212 x\n\nfor all x \u2208 (a, b). draw a sketch that illustrates this inequality.\n(c) suppose f is differentiable. use the result in (b) to show that\n\nf \u2032(a) \u2264\n\nf (b) \u2212 f (a)\n\nb \u2212 a\n\n\u2264 f \u2032(b).\n\nnote that these inequalities also follow from (3.2):\n\nf (b) \u2265 f (a) + f \u2032(a)(b \u2212 a),\n\nf (a) \u2265 f (b) + f \u2032(b)(a \u2212 b).\n\n(d) suppose f is twice differentiable. use the result in (c) to show that f \u2032\u2032(a) \u2265 0 and\n\nf \u2032\u2032(b) \u2265 0.\n\n3.2 level sets of convex, concave, quasiconvex, and quasiconcave functions. some level sets\n\nof a function f are shown below. the curve labeled 1 shows {x | f (x) = 1}, etc.\n\n3\n2\n\n1\n\ncould f be convex (concave, quasiconvex, quasiconcave)? explain your answer. repeat\nfor the level curves shown below.\n\n1 2 3\n\n4\n\n5\n\n6\n\n "}, {"Page_number": 128, "text": "114\n\n3 convex functions\n\n3.3 inverse of an increasing convex function. suppose f : r \u2192 r is increasing and convex\non its domain (a, b). let g denote its inverse, i.e., the function with domain (f (a), f (b))\nand g(f (x)) = x for a < x < b. what can you say about convexity or concavity of g?\n\n3.4 [rv73, page 15] show that a continuous function f : rn \u2192 r is convex if and only if for\nevery line segment, its average value on the segment is less than or equal to the average\nof its values at the endpoints of the segment: for every x, y \u2208 rn,\n\nz 1\n\n0\n\nf (x + \u03bb(y \u2212 x)) d\u03bb \u2264\n\nf (x) + f (y)\n\n2\n\n.\n\n3.5 [rv73, page 22] running average of a convex function. suppose f : r \u2192 r is convex,\n\nwith r+ \u2286 dom f . show that its running average f , defined as\n\nf (x) =\n\nf (t) dt,\n\ndom f = r++,\n\n1\n\nxz x\n\n0\n\nis convex. hint. for each s, f (sx) is convex in x, sor 1\n\n0\n\n3.6 functions and epigraphs. when is the epigraph of a function a halfspace? when is the\nepigraph of a function a convex cone? when is the epigraph of a function a polyhedron?\n3.7 suppose f : rn \u2192 r is convex with dom f = rn, and bounded above on rn. show that\n\nf (sx) ds is convex.\n\nf is constant.\n\n3.8 second-order condition for convexity. prove that a twice differentiable function f is convex\nif and only if its domain is convex and \u22072f (x) (cid:23) 0 for all x \u2208 dom f . hint. first consider\nthe case f : r \u2192 r. you can use the first-order condition for convexity (which was proved\non page 70).\n3.9 second-order conditions for convexity on an affine set. let f \u2208 rn\u00d7m, \u02c6x \u2208 rn. the\nrestriction of f : rn \u2192 r to the affine set {f z + \u02c6x | z \u2208 rm} is defined as the function\n\u02dcf : rm \u2192 r with\n\n\u02dcf (z) = f (f z + \u02c6x),\n\ndom \u02dcf = {z | f z + \u02c6x \u2208 dom f}.\n\nsuppose f is twice differentiable with a convex domain.\n(a) show that \u02dcf is convex if and only if for all z \u2208 dom \u02dcf\nf t\u22072f (f z + \u02c6x)f (cid:23) 0.\n\n(b) suppose a \u2208 rp\u00d7n is a matrix whose nullspace is equal to the range of f , i.e.,\naf = 0 and rank a = n \u2212 rank f . show that \u02dcf is convex if and only if for all\nz \u2208 dom \u02dcf there exists a \u03bb \u2208 r such that\n\n\u22072f (f z + \u02c6x) + \u03bbat a (cid:23) 0.\n\nhint. use the following result: if b \u2208 sn and a \u2208 rp\u00d7n, then xt bx \u2265 0 for all\nx \u2208 n (a) if and only if there exists a \u03bb such that b + \u03bbat a (cid:23) 0.\n\n3.10 an extension of jensen\u2019s inequality. one interpretation of jensen\u2019s inequality is that\nrandomization or dithering hurts, i.e., raises the average value of a convex function: for\nf convex and v a zero mean random variable, we have e f (x0 + v) \u2265 f (x0). this leads\nto the following conjecture. if f0 is convex, then the larger the variance of v, the larger\ne f (x0 + v).\n\n(a) give a counterexample that shows that this conjecture is false. find zero mean\nrandom variables v and w, with var(v) > var(w), a convex function f , and a point\nx0, such that e f (x0 + v) < e f (x0 + w).\n\n "}, {"Page_number": 129, "text": "exercises\n\n115\n\n(b) the conjecture is true when v and w are scaled versions of each other. show that\ne f (x0 + tv) is monotone increasing in t \u2265 0, when f is convex and v is zero mean.\n3.11 monotone mappings. a function \u03c8 : rn \u2192 rn is called monotone if for all x, y \u2208 dom \u03c8,\n\n(\u03c8(x) \u2212 \u03c8(y))t (x \u2212 y) \u2265 0.\n\n(note that \u2018monotone\u2019 as defined here is not the same as the definition given in \u00a73.6.1.\nboth definitions are widely used.) suppose f : rn \u2192 r is a differentiable convex function.\nshow that its gradient \u2207f is monotone.\nis the converse true, i.e., is every monotone\nmapping the gradient of a convex function?\n\n3.12 suppose f : rn \u2192 r is convex, g : rn \u2192 r is concave, dom f = dom g = rn, and\nfor all x, g(x) \u2264 f (x). show that there exists an affine function h such that for all x,\ng(x) \u2264 h(x) \u2264 f (x). in other words, if a concave function g is an underestimator of a\nconvex function f , then we can fit an affine function between f and g.\n\n3.13 kullback-leibler divergence and the information inequality. let dkl be the kullback-\nleibler divergence, as defined in (3.17). prove the information inequality: dkl(u, v) \u2265 0\nfor all u, v \u2208 rn\nhint. the kullback-leibler divergence can be expressed as\n\n++. also show that dkl(u, v) = 0 if and only if u = v.\n\ndkl(u, v) = f (u) \u2212 f (v) \u2212 \u2207f (v)t (u \u2212 v),\n\ni=1 vi log vi is the negative entropy of v.\n\nwhere f (v) =pn\n\n3.14 convex-concave functions and saddle-points. we say the function f : rn \u00d7 rm \u2192 r\nis convex-concave if f (x, z) is a concave function of z, for each fixed x, and a convex\nfunction of x, for each fixed z. we also require its domain to have the product form\ndom f = a \u00d7 b, where a \u2286 rn and b \u2286 rm are convex.\n(a) give a second-order condition for a twice differentiable function f : rn \u00d7 rm \u2192 r\n(b) suppose that f : rn\u00d7rm \u2192 r is convex-concave and differentiable, with \u2207f (\u02dcx, \u02dcz) =\n\nto be convex-concave, in terms of its hessian \u22072f (x, z).\n\n0. show that the saddle-point property holds: for all x, z, we have\n\nshow that this implies that f satisfies the strong max-min property:\n\nf (\u02dcx, z) \u2264 f (\u02dcx, \u02dcz) \u2264 f (x, \u02dcz).\n\nsup\n\nz\n\ninf\nx\n\nf (x, z) = inf\nx\n\nsup\n\nf (x, z)\n\nz\n\n(and their common value is f (\u02dcx, \u02dcz)).\n\n(c) now suppose that f : rn \u00d7 rm \u2192 r is differentiable, but not necessarily convex-\n\nconcave, and the saddle-point property holds at \u02dcx, \u02dcz:\n\nf (\u02dcx, z) \u2264 f (\u02dcx, \u02dcz) \u2264 f (x, \u02dcz)\n\nfor all x, z. show that \u2207f (\u02dcx, \u02dcz) = 0.\n\nexamples\n\n3.15 a family of concave utility functions. for 0 < \u03b1 \u2264 1 let\n\nu\u03b1(x) =\n\nx\u03b1 \u2212 1\n\n\u03b1\n\n,\n\nwith dom u\u03b1 = r+. we also define u0(x) = log x (with dom u0 = r++).\n\n(a) show that for x > 0, u0(x) = lim\u03b1\u21920 u\u03b1(x).\n\n "}, {"Page_number": 130, "text": "116\n\n3 convex functions\n\n(b) show that u\u03b1 are concave, monotone increasing, and all satisfy u\u03b1(1) = 0.\n\nthese functions are often used in economics to model the benefit or utility of some quantity\nof goods or money. concavity of u\u03b1 means that the marginal utility (i.e., the increase\nin utility obtained for a fixed increase in the goods) decreases as the amount of goods\nincreases. in other words, concavity models the effect of satiation.\n\n3.16 for each of the following functions determine whether it is convex, concave, quasiconvex,\n\nor quasiconcave.\n(a) f (x) = ex \u2212 1 on r.\n(b) f (x1, x2) = x1x2 on r2\n(c) f (x1, x2) = 1/(x1x2) on r2\n(d) f (x1, x2) = x1/x2 on r2\n(e) f (x1, x2) = x2\n(f) f (x1, x2) = x\u03b1\n\n++.\n\n++.\n\n1/x2 on r \u00d7 r++.\n1 x1\u2212\u03b1\n\n++.\n\n2\n\n, where 0 \u2264 \u03b1 \u2264 1, on r2\n\n++.\n\n3.17 suppose p < 1, p 6= 0. show that the function\n\nf (x) =  nxi=1\n\ni!1/p\n\nxp\n\n++ is concave. this includes as special cases f (x) = (pn\n\n)2 and\ni=1 1/xi)\u22121. hint. adapt the proofs for the log-sum-exp\n\ni=1 x1/2\n\ni\n\n3.18 adapt the proof of concavity of the log-determinant function in \u00a73.1.5 to show the follow-\n\nwith dom f = rn\n\ning.\n\n(b) f (x) = (det x)1/n is concave on dom f = sn\n\nfunction and the geometric mean in \u00a73.1.5.\n\nthe harmonic mean f (x) = (pn\n(a) f (x) = tr(cid:0)x \u22121(cid:1) is convex on dom f = sn\n(a) show that f (x) = pr\nf (x) =pk\n\ni=1 x[i] is convex on rn.)\n\n(b) let t (x, \u03c9) denote the trigonometric polynomial\n\n++.\n\n++.\n\n3.19 nonnegative weighted sums and integrals.\n\ni=1 \u03b1ix[i] is a convex function of x, where \u03b11 \u2265 \u03b12 \u2265 \u00b7\u00b7\u00b7 \u2265\n\u03b1r \u2265 0, and x[i] denotes the ith largest component of x. (you can use the fact that\n\nt (x, \u03c9) = x1 + x2 cos \u03c9 + x3 cos 2\u03c9 + \u00b7\u00b7\u00b7 + xn cos(n \u2212 1)\u03c9.\n\nshow that the function\n\nf (x) = \u2212z 2\u03c0\n\n0\n\nlog t (x, \u03c9) d\u03c9\n\nis convex on {x \u2208 rn | t (x, \u03c9) > 0, 0 \u2264 \u03c9 \u2264 2\u03c0}.\n\n3.20 composition with an affine function. show that the following functions f : rn \u2192 r are\n\nconvex.\n(a) f (x) = kax \u2212 bk, where a \u2208 rm\u00d7n, b \u2208 rm, and k \u00b7 k is a norm on rm.\n(b) f (x) = \u2212 (det(a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan))1/m, on {x | a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan \u227b 0},\n(c) f (x) = tr (a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan)\u22121, on {x | a0 +x1a1 +\u00b7\u00b7\u00b7 +xnan \u227b 0}, where\n\nwhere ai \u2208 sm.\nai \u2208 sm. (use the fact that tr(x \u22121) is convex on sm\n\n++; see exercise 3.18.)\n\n "}, {"Page_number": 131, "text": "exercises\n\n117\n\n3.21 pointwise maximum and supremum. show that the following functions f : rn \u2192 r are\n\non rm.\n\nconvex.\n(a) f (x) = maxi=1,...,k ka(i)x \u2212 b(i)k, where a(i) \u2208 rm\u00d7n, b(i) \u2208 rm and k \u00b7 k is a norm\ni=1 |x|[i] on rn, where |x| denotes the vector with |x|i = |xi| (i.e., |x| is\nthe absolute value of x, componentwise), and |x|[i] is the ith largest component of\n|x|. in other words, |x|[1], |x|[2], . . . , |x|[n] are the absolute values of the components\nof x, sorted in nonincreasing order.\n\n(b) f (x) =pr\n\n3.22 composition rules. show that the following functions are convex.\n\ni=1 eat\ni=1 eyi ) is convex.\n\ni x+bi )) on dom f = {x | pm\n\n(a) f (x) = \u2212 log(\u2212 log(pm\ni x+bi < 1}. you can\nuse the fact that log(pn\n(b) f (x, u, v) = \u2212\u221auv \u2212 xt x on dom f = {(x, u, v) | uv > xt x, u, v > 0}. use the\nfact that xt x/u is convex in (x, u) for u > 0, and that \u2212\u221ax1x2 is convex on r2\n(c) f (x, u, v) = \u2212 log(uv \u2212 xt x) on dom f = {(x, u, v) | uv > xt x, u, v > 0}.\n(d) f (x, t) = \u2212(tp \u2212kxkp\n\np)1/p where p > 1 and dom f = {(x, t) | t \u2265 kxkp}. you can use\np/up\u22121 is convex in (x, u) for u > 0 (see exercise 3.23), and that\n\ni=1 eat\n\n++.\n\n+ (see exercise 3.16).\n\np) where p > 1 and dom f = {(x, t) | t > kxkp}. you can\n\np/up\u22121 is convex in (x, u) for u > 0 (see exercise 3.23).\n\nthe fact that kxkp\n\u2212x1/py1\u22121/p is convex on r2\nuse the fact that kxkp\n3.23 perspective of a function.\n\n(e) f (x, t) = \u2212 log(tp \u2212 kxkp\n\n(a) show that for p > 1,\n\nf (x, t) = |x1|p + \u00b7\u00b7\u00b7 + |xn|p\n\ntp\u22121\n\n= kxkp\np\ntp\u22121\n\nis convex on {(x, t) | t > 0}.\n\n(b) show that\n\nf (x) = kax + bk2\nct x + d\n\n2\n\nis convex on {x | ct x + d > 0}, where a \u2208 rm\u00d7n, b \u2208 rm, c \u2208 rn and d \u2208 r.\n\n3.24 some functions on the probability simplex. let x be a real-valued random variable which\ntakes values in {a1, . . . , an} where a1 < a2 < \u00b7\u00b7\u00b7 < an, with prob(x = ai) = pi,\ni = 1, . . . , n. for each of the following functions of p (on the probability simplex {p \u2208\n+ | 1t p = 1}), determine if the function is convex, concave, quasiconvex, or quasicon-\nrn\ncave.\n\n(a) e x.\n(b) prob(x \u2265 \u03b1).\n(c) prob(\u03b1 \u2264 x \u2264 \u03b2).\n\n(d) pn\n\ni=1 pi log pi, the negative entropy of the distribution.\n\n(e) var x = e(x \u2212 e x)2.\n(f) quartile(x) = inf{\u03b2 | prob(x \u2264 \u03b2) \u2265 0.25}.\n(g) the cardinality of the smallest set a \u2286 {a1, . . . , an} with probability \u2265 90%. (by\n\ncardinality we mean the number of elements in a.)\n\n(h) the minimum width interval that contains 90% of the probability, i.e.,\n\ninf {\u03b2 \u2212 \u03b1 | prob(\u03b1 \u2264 x \u2264 \u03b2) \u2265 0.9} .\n\n "}, {"Page_number": 132, "text": "118\n\n3 convex functions\n\n3.25 maximum probability distance between distributions. let p, q \u2208 rn represent two proba-\nbility distributions on {1, . . . , n} (so p, q (cid:23) 0, 1t p = 1t q = 1). we define the maximum\nprobability distance dmp(p, q) between p and q as the maximum difference in probability\nassigned by p and q, over all events:\n\ndmp(p, q) = max{| prob(p, c) \u2212 prob(q, c)| | c \u2286 {1, . . . , n}}.\n\nhere prob(p, c) is the probability of c, under the distribution p, i.e., prob(p, c) =\n\npi\u2208c pi.\nfind a simple expression for dmp, involving kp \u2212 qk1 =pn\n\ni=1 |pi \u2212 qi|, and show that dmp\nis a convex function on rn \u00d7 rn. (its domain is {(p, q) | p, q (cid:23) 0, 1t p = 1t q = 1}, but\nit has a natural extension to all of rn \u00d7 rn.)\n3.26 more functions of eigenvalues. let \u03bb1(x) \u2265 \u03bb2(x) \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn(x) denote the eigenvalues\nof a matrix x \u2208 sn. we have already seen several functions of the eigenvalues that are\nconvex or concave functions of x.\n\n\u03bbn(x) is concave.\n\n++ (exercise 3.18).\n\ni=1 1/\u03bbi(x), is convex on sn\n\n\u2022 the maximum eigenvalue \u03bb1(x) is convex (example 3.10). the minimum eigenvalue\n\u2022 the sum of the eigenvalues (or trace), tr x = \u03bb1(x) + \u00b7\u00b7\u00b7 + \u03bbn(x), is linear.\n\u2022 the sum of the inverses of the eigenvalues (or trace of the inverse), tr(x \u22121) =\ni=1 \u03bbi(x))1/n, and the\ni=1 log \u03bbi(x), are concave\n\npn\n\u2022 the geometric mean of the eigenvalues, (det x)1/n = (qn\nlogarithm of the product of the eigenvalues, log det x =pn\n(a) sum of k largest eigenvalues. show thatpk\n\nin this problem we explore some more functions of eigenvalues, by exploiting variational\ncharacterizations.\n\ni=1 \u03bbi(x) is convex on sn. hint. [hj85,\n\npage 191] use the variational characterization\n\n++ (exercise 3.18 and page 74).\n\non x \u2208 sn\n\nkxi=1\n\n\u03bbi(x) = sup{tr(v t xv ) | v \u2208 rn\u00d7k, v t v = i}.\n\n(b) geometric mean of k smallest eigenvalues. show that (qn\n\n++. hint. [mo79, page 513] for x \u227b 0, we have\n\ncave on sn\n\ni=n\u2212k+1 \u03bbi(x))1/k is con-\n\n  nyi=n\u2212k+1\n\n\u03bbi(x)!1/k\n\n=\n\n1\nk\n\ninf{tr(v t xv ) | v \u2208 rn\u00d7k, det v t v = 1}.\n\n(c) log of product of k smallest eigenvalues. show thatpn\n\n++. hint. [mo79, page 513] for x \u227b 0,\n\non sn\n\ni=n\u2212k+1 log \u03bbi(x) is concave\n\nnyi=n\u2212k+1\n\n\u03bbi(x) = inf( kyi=1\n\nv \u2208 rn\u00d7k, v t v = i) .\n\n3.27 diagonal elements of cholesky factor. each x \u2208 sn\n\n++ has a unique cholesky factorization\nx = llt , where l is lower triangular, with lii > 0. show that lii is a concave function\nof x (with domain sn\nhint. lii can be expressed as lii = (w \u2212 zt y \u22121z)1/2, where\n\n++).\n\n(v t xv )ii(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n(cid:20) y\nzt w (cid:21)\n\nz\n\nis the leading i \u00d7 i submatrix of x.\n\n "}, {"Page_number": 133, "text": "exercises\n\n119\n\noperations that preserve convexity\n\n3.28 expressing a convex function as the pointwise supremum of a family of affine functions.\nin this problem we extend the result proved on page 83 to the case where dom f 6= rn.\nlet f : rn \u2192 r be a convex function. define \u02dcf : rn \u2192 r as the pointwise supremum of\nall affine functions that are global underestimators of f :\n\n\u02dcf (x) = sup{g(x) | g affine, g(z) \u2264 f (z) for all z}.\n\n(a) show that f (x) = \u02dcf (x) for x \u2208 int dom f .\n(b) show that f = \u02dcf if f is closed (i.e., epi f is a closed set; see \u00a7a.3.3).\ndom f = rn, is called piecewise-linear if there exists a partition of rn as\n\n3.29 representation of piecewise-linear convex functions. a function f : rn \u2192 r, with\n\nrn = x1 \u222a x2 \u222a \u00b7\u00b7\u00b7 \u222a xl,\n\nwhere int xi 6= \u2205 and int xi \u2229 int xj = \u2205 for i 6= j, and a family of affine functions\n1 x + b1, . . . , at\nlx + bl such that f (x) = at\nat\nshow that this means that f (x) = max{at\nf : rn \u2192 r is defined as\n\n3.30 convex hull or envelope of a function. the convex hull or convex envelope of a function\n\ni x + bi for x \u2208 xi.\n1 x + b1, . . . , at\n\nlx + bl}.\n\ng(x) = inf{t | (x, t) \u2208 conv epi f}.\n\ngeometrically, the epigraph of g is the convex hull of the epigraph of f .\nshow that g is the largest convex underestimator of f . in other words, show that if h is\nconvex and satisfies h(x) \u2264 f (x) for all x, then h(x) \u2264 g(x) for all x.\n\n3.31 [roc70, page 35] largest homogeneous underestimator. let f be a convex function. define\n\nthe function g as\n\ng(x) = inf\n\u03b1>0\n\nf (\u03b1x)\n\n\u03b1\n\n.\n\n(a) show that g is homogeneous (g(tx) = tg(x) for all t \u2265 0).\n(b) show that g is the largest homogeneous underestimator of f : if h is homogeneous\n\nand h(x) \u2264 f (x) for all x, then we have h(x) \u2264 g(x) for all x.\n\n(c) show that g is convex.\n\n3.32 products and ratios of convex functions. in general the product or ratio of two convex\nfunctions is not convex. however, there are some results that apply to functions on r.\nprove the following.\n\n(a) if f and g are convex, both nondecreasing (or nonincreasing), and positive functions\n\non an interval, then f g is convex.\n\n(b) if f , g are concave, positive, with one nondecreasing and the other nonincreasing,\n\nthen f g is concave.\n\n(c) if f is convex, nondecreasing, and positive, and g is concave, nonincreasing, and\n\npositive, then f /g is convex.\n\n3.33 direct proof of perspective theorem. give a direct proof that the perspective function g,\nas defined in \u00a73.2.6, of a convex function f is convex: show that dom g is a convex set,\nand that for (x, t), (y, s) \u2208 dom g, and 0 \u2264 \u03b8 \u2264 1, we have\n\ng(\u03b8x + (1 \u2212 \u03b8)y, \u03b8t + (1 \u2212 \u03b8)s) \u2264 \u03b8g(x, t) + (1 \u2212 \u03b8)g(y, s).\n\n3.34 the minkowski function. the minkowski function of a convex set c is defined as\n\nmc (x) = inf{t > 0 | t\u22121x \u2208 c}.\n\n "}, {"Page_number": 134, "text": "120\n\n3 convex functions\n\n(a) draw a picture giving a geometric interpretation of how to find mc (x).\n(b) show that mc is homogeneous, i.e., mc (\u03b1x) = \u03b1mc (x) for \u03b1 \u2265 0.\n(c) what is dom mc ?\n\n(d) show that mc is a convex function.\n(e) suppose c is also closed, bounded, symmetric (if x \u2208 c then \u2212x \u2208 c), and has\nnonempty interior. show that mc is a norm. what is the corresponding unit ball?\n3.35 support function calculus. recall that the support function of a set c \u2286 rn is defined as\n\nsc (y) = sup{yt x | x \u2208 c}. on page 81 we showed that sc is a convex function.\n(a) show that sb = sconv b.\n\n(b) show that sa+b = sa + sb.\n(c) show that sa\u222ab = max{sa, sb}.\n(d) let b be closed and convex. show that a \u2286 b if and only if sa(y) \u2264 sb(y) for all\n\ny.\n\nconjugate functions\n\n3.36 derive the conjugates of the following functions.\n\n(a) max function. f (x) = maxi=1,...,n xi on rn.\n\n(b) sum of largest elements. f (x) =pr\n\ni=1 x[i] on rn.\n\n(c) piecewise-linear function on r. f (x) = maxi=1,...,m(aix + bi) on r. you can\nassume that the ai are sorted in increasing order, i.e., a1 \u2264 \u00b7\u00b7\u00b7 \u2264 am, and that none\nof the functions aix + bi is redundant, i.e., for each k there is at least one x with\nf (x) = akx + bk.\n\n(d) power function. f (x) = xp on r++, where p > 1. repeat for p < 0.\n\n(e) negative geometric mean. f (x) = \u2212(q xi)1/n on rn\n\n(f) negative generalized logarithm for second-order cone. f (x, t) = \u2212 log(t2 \u2212 xt x) on\n\n++.\n\n{(x, t) \u2208 rn \u00d7 r | kxk2 < t}.\n\n3.37 show that the conjugate of f (x) = tr(x \u22121) with dom f = sn\n\n++ is given by\n\nf \u2217(y ) = \u22122 tr(\u2212y )1/2,\nhint. the gradient of f is \u2207f (x) = \u2212x \u22122.\n\ndom f \u2217 = \u2212sn\n+.\n\n3.38 young\u2019s inequality. let f : r \u2192 r be an increasing function, with f (0) = 0, and let g be\n\nits inverse. define f and g as\n\nf (x) =z x\n\n0\n\nf (a) da,\n\ng(y) =z y\n\n0\n\ng(a) da.\n\nshow that f and g are conjugates. give a simple graphical interpretation of young\u2019s\ninequality,\n\n3.39 properties of conjugate functions.\n\nxy \u2264 f (x) + g(y).\n\n(a) conjugate of convex plus affine function. define g(x) = f (x) + ct x + d, where f is\n\nconvex. express g\u2217 in terms of f \u2217 (and c, d).\n\n(b) conjugate of perspective. express the conjugate of the perspective of a convex\n\nfunction f in terms of f \u2217.\n\n "}, {"Page_number": 135, "text": "exercises\n\n121\n\n(c) conjugate and minimization. let f (x, z) be convex in (x, z) and define g(x) =\n\ninf z f (x, z). express the conjugate g\u2217 in terms of f \u2217.\nas an application, express the conjugate of g(x) = inf z{h(z) | az + b = x}, where h\nis convex, in terms of h\u2217, a, and b.\n(d) conjugate of conjugate. show that the conjugate of the conjugate of a closed convex\nfunction is itself: f = f \u2217\u2217 if f is closed and convex. (a function is closed if its\nepigraph is closed; see \u00a7a.3.3.) hint. show that f \u2217\u2217 is the pointwise supremum of\nall affine global underestimators of f . then apply the result of exercise 3.28.\n\n3.40 gradient and hessian of conjugate function. suppose f : rn \u2192 r is convex and twice\ncontinuously differentiable. suppose \u00afy and \u00afx are related by \u00afy = \u2207f (\u00afx), and that \u22072f (\u00afx) \u227b\n0.\n(a) show that \u2207f \u2217(\u00afy) = \u00afx.\n(b) show that \u22072f \u2217(\u00afy) = \u22072f (\u00afx)\u22121.\n\n3.41 conjugate of negative normalized entropy. show that the conjugate of the negative nor-\n\nmalized entropy\n\nwith dom f = rn\n\n++, is given by\n\nf (x) =\n\nnxi=1\nf \u2217(y) =(cid:26) 0\n\nxi log(xi/1t x),\n\ni=1 eyi \u2264 1\n\n+\u221e otherwise.\n\npn\n\nquasiconvex functions\n\n3.42 approximation width. let f0, . . . , fn : r \u2192 r be given continuous functions. we consider\nthe problem of approximating f0 as a linear combination of f1, . . . , fn. for x \u2208 rn, we\nsay that f = x1f1 + \u00b7\u00b7\u00b7 + xnfn approximates f0 with tolerance \u01eb > 0 over the interval\n[0, t ] if |f (t) \u2212 f0(t)| \u2264 \u01eb for 0 \u2264 t \u2264 t . now we choose a fixed tolerance \u01eb > 0 and define\nthe approximation width as the largest t such that f approximates f0 over the interval\n[0, t ]:\n\nw (x) = sup{t | |x1f1(t) + \u00b7\u00b7\u00b7 + xnfn(t) \u2212 f0(t)| \u2264 \u01eb for 0 \u2264 t \u2264 t}.\n\nshow that w is quasiconcave.\n\n3.43 first-order condition for quasiconvexity. prove the first-order condition for quasiconvexity\ngiven in \u00a73.4.3: a differentiable function f : rn \u2192 r, with dom f convex, is quasiconvex\nif and only if for all x, y \u2208 dom f ,\n\nf (y) \u2264 f (x) =\u21d2 \u2207f (x)t (y \u2212 x) \u2264 0.\n\nit suffices to prove the result for a function on r; the general result follows by\n\nhint.\nrestriction to an arbitrary line.\n\n3.44 second-order conditions for quasiconvexity.\n\nin this problem we derive alternate repre-\nsentations of the second-order conditions for quasiconvexity given in \u00a73.4.3. prove the\nfollowing.\n(a) a point x \u2208 dom f satisfies (3.21) if and only if there exists a \u03c3 such that\n\nit satisfies (3.22) for all y 6= 0 if and only if there exists a \u03c3 such\n\n\u22072f (x) + \u03c3\u2207f (x)\u2207f (x)t (cid:23) 0.\n\nhint. we can assume without loss of generality that \u22072f (x) is diagonal.\n\n\u22072f (x) + \u03c3\u2207f (x)\u2207f (x)t \u227b 0.\n\n(3.26)\n\n(3.27)\n\n "}, {"Page_number": 136, "text": "122\n\n3 convex functions\n\n(b) a point x \u2208 dom f satisfies (3.21) if and only if either \u2207f (x) = 0 and \u22072f (x) (cid:23) 0,\n\nor \u2207f (x) 6= 0 and the matrix\n\nh(x) =(cid:20) \u22072f (x) \u2207f (x)\n\n\u2207f (x)t\n\n0\n\n(cid:21)\n\nhas exactly one negative eigenvalue. it satisfies (3.22) for all y 6= 0 if and only if\nh(x) has exactly one nonpositive eigenvalue.\nhint. you can use the result of part (a). the following result, which follows from\nthe eigenvalue interlacing theorem in linear algebra, may also be useful: if b \u2208 sn\nand a \u2208 rn, then\n\n\u03bbn(cid:18)(cid:20) b a\n\n0 (cid:21)(cid:19) \u2265 \u03bbn(b).\n\nat\n\n3.45 use the first and second-order conditions for quasiconvexity given in \u00a73.4.3 to verify\n\nquasiconvexity of the function f (x) = \u2212x1x2, with dom f = r2\n\n3.46 quasilinear functions with domain rn. a function on r that is quasilinear (i.e., qua-\nsiconvex and quasiconcave) is monotone, i.e., either nondecreasing or nonincreasing. in\nthis problem we consider a generalization of this result to functions on rn.\nsuppose the function f : rn \u2192 r is quasilinear and continuous with dom f = rn. show\nthat it can be expressed as f (x) = g(at x), where g : r \u2192 r is monotone and a \u2208 rn.\nin other words, a quasilinear function with domain rn must be a monotone function of\na linear function. (the converse is also true.)\n\n++.\n\nlog-concave and log-convex functions\n\n3.47 suppose f : rn \u2192 r is differentiable, dom f is convex, and f (x) > 0 for all x \u2208 dom f .\n\nshow that f is log-concave if and only if for all x, y \u2208 dom f ,\n\nf (y)\n\nf (x) \u2264 exp(cid:18)\u2207f (x)t (y \u2212 x)\n\nf (x)\n\n(cid:19) .\n\n3.48 show that if f : rn \u2192 r is log-concave and a \u2265 0, then the function g = f \u2212 a is\n\nlog-concave, where dom g = {x \u2208 dom f | f (x) > a}.\n\n3.49 show that the following functions are log-concave.\n\n(a) logistic function: f (x) = ex/(1 + ex) with dom f = r.\n\n(b) harmonic mean:\n\nf (x) =\n\n1\n\n1/x1 + \u00b7\u00b7\u00b7 + 1/xn\n\n,\n\ndom f = rn\n\n++.\n\n(c) product over sum:\n\n(d) determinant over trace:\n\nf (x) = qn\ni=1 xipn\n\ni=1 xi\n\n,\n\ndom f = rn\n\n++.\n\nf (x) =\n\ndet x\ntr x\n\n,\n\ndom f = sn\n\n++.\n\n "}, {"Page_number": 137, "text": "exercises\n\n123\n\n3.50 coefficients of a polynomial as a function of the roots. show that the coefficients of a\npolynomial with real negative roots are log-concave functions of the roots. in other words,\nthe functions ai : rn \u2192 r, defined by the identity\n\nsn + a1(\u03bb)sn\u22121 + \u00b7\u00b7\u00b7 + an\u22121(\u03bb)s + an(\u03bb) = (s \u2212 \u03bb1)(s \u2212 \u03bb2)\u00b7\u00b7\u00b7 (s \u2212 \u03bbn),\n\nare log-concave on \u2212rn\nhint. the function\n\n++.\n\nsk(x) = x1\u2264i1<i2<\u00b7\u00b7\u00b7<ik\u2264n\n\nxi1 xi2 \u00b7\u00b7\u00b7 xik ,\n\nwith dom sk \u2208 rn\nrn. it can be shown that s1/k\n\nk\n\n+ and 1 \u2264 k \u2264 n, is called the kth elementary symmetric function on\n\nis concave (see [ml57]).\n\n3.51 [bl00, page 41] let p be a polynomial on r, with all its roots real. show that it is\n\nlog-concave on any interval on which it is positive.\n\n3.52 [mo79, \u00a73.e.2] log-convexity of moment functions. suppose f : r \u2192 r is nonnegative\n\nwith r+ \u2286 dom f . for x \u2265 0 define\n\n\u03c6(x) =z \u221e\n\n0\n\nuxf (u) du.\n\nshow that \u03c6 is a log-convex function. (if x is a positive integer, and f is a probability\ndensity function, then \u03c6(x) is the xth moment of the distribution.)\nuse this to show that the gamma function,\n\n\u03b3(x) =z \u221e\n\n0\n\nux\u22121e\u2212u du,\n\nis log-convex for x \u2265 1.\n\n3.53 suppose x and y are independent random vectors in rn, with log-concave probability\ndensity functions f and g, respectively. show that the probability density function of the\nsum z = x + y is log-concave.\n\n3.54 log-concavity of gaussian cumulative distribution function. the cumulative distribution\n\nfunction of a gaussian random variable,\n\nf (x) =\n\n1\n\n\u221a2\u03c0z x\n\n\u2212\u221e\n\ne\u2212t2/2 dt,\n\nis log-concave. this follows from the general result that the convolution of two log-concave\nfunctions is log-concave. in this problem we guide you through a simple self-contained\nproof that f is log-concave. recall that f is log-concave if and only if f \u2032\u2032(x)f (x) \u2264 f \u2032(x)2\nfor all x.\n(a) verify that f \u2032\u2032(x)f (x) \u2264 f \u2032(x)2 for x \u2265 0. that leaves us the hard part, which is to\n(b) verify that for any t and x we have t2/2 \u2265 \u2212x2/2 + xt.\n(c) using part (b) show that e\u2212t2/2 \u2264 ex2/2\u2212xt. conclude that, for x < 0,\n\nshow the inequality for x < 0.\n\nz x\n\n\u2212\u221e\n\ne\u2212t2/2 dt \u2264 ex2/2z x\n\n\u2212\u221e\n\ne\u2212xt dt.\n\n(d) use part (c) to verify that f \u2032\u2032(x)f (x) \u2264 f \u2032(x)2 for x \u2264 0.\n\n "}, {"Page_number": 138, "text": "124\n\n3 convex functions\n\n3.55 log-concavity of the cumulative distribution function of a log-concave probability density.\nin this problem we extend the result of exercise 3.54. let g(t) = exp(\u2212h(t)) be a differ-\nentiable log-concave probability density function, and let\n\nf (x) =z x\n\n\u2212\u221e\n\ng(t) dt =z x\n\n\u2212\u221e\n\ne\u2212h(t) dt\n\nbe its cumulative distribution. we will show that f is log-concave, i.e.,\nf \u2032\u2032(x)f (x) \u2264 (f \u2032(x))2 for all x.\n(a) express the derivatives of f in terms of the function h. verify that f \u2032\u2032(x)f (x) \u2264\n(b) assume that h\u2032(x) < 0. use the inequality\n\n(f \u2032(x))2 if h\u2032(x) \u2265 0.\n\nit satisfies\n\n(which follows from convexity of h), to show that\n\nh(t) \u2265 h(x) + h\u2032(x)(t \u2212 x)\n\nz x\n\n\u2212\u221e\n\ne\u2212h(t) dt \u2264\n\ne\u2212h(x)\n\u2212h\u2032(x)\n\n.\n\nuse this inequality to verify that f \u2032\u2032(x)f (x) \u2264 (f \u2032(x))2 if h\u2032(x) < 0.\n\n3.56 more log-concave densities. show that the following densities are log-concave.\n\n(a) [mo79, page 493] the gamma density, defined by\n\nf (x) =\n\n\u03b1\u03bb\n\u03b3(\u03bb)\n\nx\u03bb\u22121e\u2212\u03b1x,\n\nwith dom f = r+. the parameters \u03bb and \u03b1 satisfy \u03bb \u2265 1, \u03b1 > 0.\n\n(b) [mo79, page 306] the dirichlet density\n\nf (x) =\n\n\u03b3(1t \u03bb)\n\n\u03b3(\u03bb1)\u00b7\u00b7\u00b7 \u03b3(\u03bbn+1)\n\nx\u03bb1\u22121\n1\n\n\u00b7\u00b7\u00b7 x\u03bbn\u22121\n\nn\n\n 1 \u2212\n\nxi!\u03bbn+1\u22121\n\nnxi=1\n\nwith dom f = {x \u2208 rn\n\n++ | 1t x < 1}. the parameter \u03bb satisfies \u03bb (cid:23) 1.\n\nconvexity with respect to a generalized inequality\n\n3.57 show that the function f (x) = x \u22121 is matrix convex on sn\n3.58 schur complement. suppose x \u2208 sn partitioned as\n\n++.\n\nbt c (cid:21) ,\nx =(cid:20) a b\n\nwhere a \u2208 sk. the schur complement of x (with respect to a) is s = c \u2212 bt a\u22121b\n(see \u00a7a.5.5). show that the schur complement, viewed as a function from sn into sn\u2212k,\nis matrix concave on sn\n3.59 second-order conditions for k-convexity. let k \u2286 rm be a proper convex cone, with\nassociated generalized inequality (cid:22)k . show that a twice differentiable function f : rn \u2192\nrm, with convex domain, is k-convex if and only if for all x \u2208 dom f and all y \u2208 rn,\n\n++.\n\n\u22022f (x)\n\u2202xi\u2202xj\n\nyiyj (cid:23)k 0,\n\nnxi,j=1\n\ni.e., the second derivative is a k-nonnegative bilinear form. (here \u22022f /\u2202xi\u2202xj \u2208 rm,\nwith components \u22022fk/\u2202xi\u2202xj, for k = 1, . . . , m; see \u00a7a.4.1.)\n\n "}, {"Page_number": 139, "text": "exercises\n\n125\n\n3.60 sublevel sets and epigraph of k-convex functions. let k \u2286 rm be a proper convex cone\nwith associated generalized inequality (cid:22)k , and let f : rn \u2192 rm. for \u03b1 \u2208 rm, the\n\u03b1-sublevel set of f (with respect to (cid:22)k ) is defined as\n\nc\u03b1 = {x \u2208 rn | f (x) (cid:22)k \u03b1}.\nthe epigraph of f , with respect to (cid:22)k , is defined as the set\n\nepik f = {(x, t) \u2208 rn+m | f (x) (cid:22)k t}.\n\nshow the following:\n\n(a) if f is k-convex, then its sublevel sets c\u03b1 are convex for all \u03b1.\n(b) f is k-convex if and only if epik f is a convex set.\n\n "}, {"Page_number": 140, "text": " "}, {"Page_number": 141, "text": "chapter 4\n\nconvex optimization problems\n\n4.1 optimization problems\n\n4.1.1 basic terminology\n\nwe use the notation\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\n\n(4.1)\n\nto describe the problem of finding an x that minimizes f0(x) among all x that satisfy\nthe conditions fi(x) \u2264 0, i = 1, . . . , m, and hi(x) = 0, i = 1, . . . , p. we call x \u2208 rn\nthe optimization variable and the function f0 : rn \u2192 r the objective function or\ncost function. the inequalities fi(x) \u2264 0 are called inequality constraints, and the\ncorresponding functions fi : rn \u2192 r are called the inequality constraint functions.\nthe equations hi(x) = 0 are called the equality constraints, and the functions\nhi : rn \u2192 r are the equality constraint functions. if there are no constraints (i.e.,\nm = p = 0) we say the problem (4.1) is unconstrained.\nthe set of points for which the objective and all constraint functions are defined,\n\nd =\n\nm\\i=0\n\ndom fi \u2229\n\np\\i=1\n\ndom hi,\n\nis called the domain of the optimization problem (4.1). a point x \u2208 d is feasible\nif it satisfies the constraints fi(x) \u2264 0, i = 1, . . . , m, and hi(x) = 0, i = 1, . . . , p.\nthe problem (4.1) is said to be feasible if there exists at least one feasible point,\nand infeasible otherwise. the set of all feasible points is called the feasible set or\nthe constraint set.\n\nthe optimal value p\u22c6 of the problem (4.1) is defined as\n\np\u22c6 = inf {f0(x) | fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p} .\n\nwe allow p\u22c6 to take on the extended values \u00b1\u221e. if the problem is infeasible, we\nhave p\u22c6 = \u221e (following the standard convention that the infimum of the empty set\n\n "}, {"Page_number": 142, "text": "128\n\n4 convex optimization problems\n\nis \u221e). if there are feasible points xk with f0(xk) \u2192 \u2212\u221e as k \u2192 \u221e, then p\u22c6 = \u2212\u221e,\nand we say the problem (4.1) is unbounded below.\n\noptimal and locally optimal points\n\nwe say x\u22c6 is an optimal point, or solves the problem (4.1), if x\u22c6 is feasible and\nf0(x\u22c6) = p\u22c6. the set of all optimal points is the optimal set, denoted\n\nxopt = {x | fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p, f0(x) = p\u22c6}.\n\nif there exists an optimal point for the problem (4.1), we say the optimal value\nis attained or achieved, and the problem is solvable.\nif xopt is empty, we say\nthe optimal value is not attained or not achieved. (this always occurs when the\nproblem is unbounded below.) a feasible point x with f0(x) \u2264 p\u22c6 + \u01eb (where\n\u01eb > 0) is called \u01eb-suboptimal, and the set of all \u01eb-suboptimal points is called the\n\u01eb-suboptimal set for the problem (4.1).\n\nwe say a feasible point x is locally optimal if there is an r > 0 such that\n\nf0(x) = inf{f0(z) | fi(z) \u2264 0, i = 1, . . . , m,\n\nhi(z) = 0, i = 1, . . . , p, kz \u2212 xk2 \u2264 r},\n\nor, in other words, x solves the optimization problem\n\nminimize\nsubject to\n\nf0(z)\nfi(z) \u2264 0,\nhi(z) = 0,\nkz \u2212 xk2 \u2264 r\n\ni = 1, . . . , m\ni = 1, . . . , p\n\nwith variable z. roughly speaking, this means x minimizes f0 over nearby points\nin the feasible set. the term \u2018globally optimal\u2019 is sometimes used for \u2018optimal\u2019\nto distinguish between \u2018locally optimal\u2019 and \u2018optimal\u2019. throughout this book,\nhowever, optimal will mean globally optimal.\n\nif x is feasible and fi(x) = 0, we say the ith inequality constraint fi(x) \u2264 0 is\nactive at x. if fi(x) < 0, we say the constraint fi(x) \u2264 0 is inactive. (the equality\nconstraints are active at all feasible points.) we say that a constraint is redundant\nif deleting it does not change the feasible set.\n\nexample 4.1 we illustrate these definitions with a few simple unconstrained opti-\nmization problems with variable x \u2208 r, and dom f0 = r++.\n\n\u2022 f0(x) = 1/x: p\u22c6 = 0, but the optimal value is not achieved.\n\u2022 f0(x) = \u2212 log x: p\u22c6 = \u2212\u221e, so this problem is unbounded below.\n\u2022 f0(x) = x log x: p\u22c6 = \u22121/e, achieved at the (unique) optimal point x\u22c6 = 1/e.\n\nfeasibility problems\n\nif the objective function is identically zero, the optimal value is either zero (if the\nfeasible set is nonempty) or \u221e (if the feasible set is empty). we call this the\n\n "}, {"Page_number": 143, "text": "4.1 optimization problems\n\n129\n\nfeasibility problem, and will sometimes write it as\n\nfind\nsubject to\n\nx\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\nthe feasibility problem is thus to determine whether the constraints are consistent,\nand if so, find a point that satisfies them.\n\n4.1.2 expressing problems in standard form\n\nwe refer to (4.1) as an optimization problem in standard form. in the standard\nform problem we adopt the convention that the righthand side of the inequality\nand equality constraints are zero. this can always be arranged by subtracting any\nnonzero righthand side: we represent the equality constraint gi(x) = \u02dcgi(x), for\nexample, as hi(x) = 0, where hi(x) = gi(x) \u2212 \u02dcgi(x). in a similar way we express\ninequalities of the form fi(x) \u2265 0 as \u2212fi(x) \u2264 0.\n\nexample 4.2 box constraints. consider the optimization problem\n\nminimize\nsubject to\n\nf0(x)\nli \u2264 xi \u2264 ui,\n\ni = 1, . . . , n,\n\nwhere x \u2208 rn is the variable. the constraints are called variable bounds (since they\ngive lower and upper bounds for each xi) or box constraints (since the feasible set is\na box).\n\nwe can express this problem in standard form as\n\nminimize\nsubject to\n\nf0(x)\nli \u2212 xi \u2264 0,\nxi \u2212 ui \u2264 0,\n\ni = 1, . . . , n\ni = 1, . . . , n.\n\nthere are 2n inequality constraint functions:\n\nand\n\nfi(x) = li \u2212 xi,\n\ni = 1, . . . , n,\n\nfi(x) = xi\u2212n \u2212 ui\u2212n,\n\ni = n + 1, . . . , 2n.\n\nmaximization problems\n\nwe concentrate on the minimization problem by convention. we can solve the\nmaximization problem\n\nmaximize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\n\n(4.2)\n\n "}, {"Page_number": 144, "text": "130\n\n4 convex optimization problems\n\nby minimizing the function \u2212f0 subject to the constraints. by this correspondence\nwe can define all the terms above for the maximization problem (4.2). for example\nthe optimal value of (4.2) is defined as\n\np\u22c6 = sup{f0(x) | fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p},\n\nand a feasible point x is \u01eb-suboptimal if f0(x) \u2265 p\u22c6 \u2212 \u01eb. when the maximization\nproblem is considered, the objective is sometimes called the utility or satisfaction\nlevel instead of the cost.\n\n4.1.3 equivalent problems\n\nin this book we will use the notion of equivalence of optimization problems in an\ninformal way. we call two problems equivalent if from a solution of one, a solution\nof the other is readily found, and vice versa. (it is possible, but complicated, to\ngive a formal definition of equivalence.)\n\nas a simple example, consider the problem\n\u02dcf (x) = \u03b10f0(x)\n\u02dcfi(x) = \u03b1ifi(x) \u2264 0,\n\u02dchi(x) = \u03b2ihi(x) = 0,\n\nminimize\nsubject to\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.3)\n\nwhere \u03b1i > 0, i = 0, . . . , m, and \u03b2i 6= 0, i = 1, . . . , p. this problem is obtained from\nthe standard form problem (4.1) by scaling the objective and inequality constraint\nfunctions by positive constants, and scaling the equality constraint functions by\nnonzero constants. as a result, the feasible sets of the problem (4.3) and the original\nproblem (4.1) are identical. a point x is optimal for the original problem (4.1) if\nand only if it is optimal for the scaled problem (4.3), so we say the two problems are\nequivalent. the two problems (4.1) and (4.3) are not, however, the same (unless\n\u03b1i and \u03b2i are all equal to one), since the objective and constraint functions differ.\nwe now describe some general transformations that yield equivalent problems.\n\nchange of variables\nsuppose \u03c6 : rn \u2192 rn is one-to-one, with image covering the problem domain d,\ni.e., \u03c6(dom \u03c6) \u2287 d. we define functions \u02dcfi and \u02dchi as\n\n\u02dcfi(z) = fi(\u03c6(z)),\n\ni = 0, . . . , m,\n\n\u02dchi(z) = hi(\u03c6(z)),\n\ni = 1, . . . , p.\n\nnow consider the problem\n\nminimize\nsubject to\n\n\u02dcf0(z)\n\u02dcfi(z) \u2264 0,\n\u02dchi(z) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.4)\n\nwith variable z. we say that the standard form problem (4.1) and the problem (4.4)\nare related by the change of variable or substitution of variable x = \u03c6(z).\n\nthe two problems are clearly equivalent:\n\nif x solves the problem (4.1), then\nz = \u03c6\u22121(x) solves the problem (4.4); if z solves the problem (4.4), then x = \u03c6(z)\nsolves the problem (4.1).\n\n "}, {"Page_number": 145, "text": "4.1 optimization problems\n\n131\n\ntransformation of objective and constraint functions\nsuppose that \u03c80 : r \u2192 r is monotone increasing, \u03c81, . . . , \u03c8m : r \u2192 r satisfy\n\u03c8i(u) \u2264 0 if and only if u \u2264 0, and \u03c8m+1, . . . , \u03c8m+p : r \u2192 r satisfy \u03c8i(u) = 0 if\nand only if u = 0. we define functions \u02dcfi and \u02dchi as the compositions\n\n\u02dcfi(x) = \u03c8i(fi(x)),\n\ni = 0, . . . , m,\n\n\u02dchi(x) = \u03c8m+i(hi(x)),\n\ni = 1, . . . , p.\n\nevidently the associated problem\n\nminimize\nsubject to\n\n\u02dcf0(x)\n\u02dcfi(x) \u2264 0,\n\u02dchi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\n\nand the standard form problem (4.1) are equivalent; indeed, the feasible sets are\nidentical, and the optimal points are identical. (the example (4.3) above, in which\nthe objective and constraint functions are scaled by appropriate constants, is the\nspecial case when all \u03c8i are linear.)\n\nexample 4.3 least-norm and least-norm-squared problems. as a simple example\nconsider the unconstrained euclidean norm minimization problem\n\nminimize\n\nkax \u2212 bk2,\n\n(4.5)\n\nwith variable x \u2208 rn. since the norm is always nonnegative, we can just as well solve\nthe problem\n(4.6)\n\nminimize\n\nkax \u2212 bk2\n\n2 = (ax \u2212 b)t (ax \u2212 b),\n\nin which we minimize the square of the euclidean norm. the problems (4.5) and (4.6)\nare clearly equivalent; the optimal points are the same. the two problems are not\nthe same, however. for example, the objective in (4.5) is not differentiable at any\nx with ax \u2212 b = 0, whereas the objective in (4.6) is differentiable for all x (in fact,\nquadratic).\n\nslack variables\none simple transformation is based on the observation that fi(x) \u2264 0 if and only if\nthere is an si \u2265 0 that satisfies fi(x) + si = 0. using this transformation we obtain\nthe problem\n\nminimize\nsubject to\n\nf0(x)\nsi \u2265 0,\nfi(x) + si = 0,\nhi(x) = 0,\n\ni = 1, . . . , m\n\ni = 1, . . . , m\n\ni = 1, . . . , p,\n\n(4.7)\n\nwhere the variables are x \u2208 rn and s \u2208 rm. this problem has n + m variables,\nm inequality constraints (the nonnegativity constraints on si), and m + p equality\nconstraints. the new variable si is called the slack variable associated with the\noriginal inequality constraint fi(x) \u2264 0. introducing slack variables replaces each\ninequality constraint with an equality constraint, and a nonnegativity constraint.\nthe problem (4.7) is equivalent to the original standard form problem (4.1).\nindeed, if (x, s) is feasible for the problem (4.7), then x is feasible for the original\n\n "}, {"Page_number": 146, "text": "132\n\n4 convex optimization problems\n\nproblem, since si = \u2212fi(x) \u2265 0. conversely, if x is feasible for the original problem,\nthen (x, s) is feasible for the problem (4.7), where we take si = \u2212fi(x). similarly,\nx is optimal for the original problem (4.1) if and only if (x, s) is optimal for the\nproblem (4.7), where si = \u2212fi(x).\neliminating equality constraints\n\nif we can explicitly parametrize all solutions of the equality constraints\n\nhi(x) = 0,\n\n(4.8)\nusing some parameter z \u2208 rk, then we can eliminate the equality constraints\nfrom the problem, as follows. suppose the function \u03c6 : rk \u2192 rn is such that\nx satisfies (4.8) if and only if there is some z \u2208 rk such that x = \u03c6(z). the\noptimization problem\n\ni = 1, . . . , p,\n\nminimize\nsubject to\n\n\u02dcf0(z) = f0(\u03c6(z))\n\u02dcfi(z) = fi(\u03c6(z)) \u2264 0,\n\ni = 1, . . . , m\n\nis then equivalent to the original problem (4.1). this transformed problem has\nvariable z \u2208 rk, m inequality constraints, and no equality constraints.\nif z is\noptimal for the transformed problem, then x = \u03c6(z) is optimal for the original\nproblem. conversely, if x is optimal for the original problem, then (since x is\nfeasible) there is at least one z such that x = \u03c6(z). any such z is optimal for the\ntransformed problem.\n\neliminating linear equality constraints\n\nthe process of eliminating variables can be described more explicitly, and easily\ncarried out numerically, when the equality constraints are all linear, i.e., have the\nform ax = b. if ax = b is inconsistent, i.e., b 6\u2208 r(a), then the original problem is\ninfeasible. assuming this is not the case, let x0 denote any solution of the equality\nconstraints. let f \u2208 rn\u00d7k be any matrix with r(f ) = n (a), so the general\nsolution of the linear equations ax = b is given by f z + x0, where z \u2208 rk. (we\ncan choose f to be full rank, in which case we have k = n \u2212 rank a.)\n\nsubstituting x = f z + x0 into the original problem yields the problem\n\nminimize\nsubject to\n\nf0(f z + x0)\nfi(f z + x0) \u2264 0,\n\ni = 1, . . . , m,\n\nwith variable z, which is equivalent to the original problem, has no equality con-\nstraints, and rank a fewer variables.\n\nintroducing equality constraints\n\nwe can also introduce equality constraints and new variables into a problem. in-\nstead of describing the general case, which is complicated and not very illuminating,\nwe give a typical example that will be useful later. consider the problem\n\nminimize\nsubject to\n\nf0(a0x + b0)\nfi(aix + bi) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , p,\n\ni = 1, . . . , m\n\n "}, {"Page_number": 147, "text": "4.1 optimization problems\n\n133\n\nwhere x \u2208 rn, ai \u2208 rki\u00d7n, and fi : rki \u2192 r.\nin this problem the objective\nand constraint functions are given as compositions of the functions fi with affine\ntransformations defined by aix + bi.\n\nwe introduce new variables yi \u2208 rki, as well as new equality constraints yi =\n\naix + bi, for i = 0, . . . , m, and form the equivalent problem\n\nminimize\nsubject to\n\nf0(y0)\nfi(yi) \u2264 0,\nyi = aix + bi,\nhi(x) = 0,\n\ni = 1, . . . , m\n\ni = 0, . . . , m\n\ni = 1, . . . , p.\n\nthis problem has k0 + \u00b7\u00b7\u00b7 + km new variables,\n\ny0 \u2208 rk0,\n\n. . . ,\n\nym \u2208 rkm,\n\nand k0 + \u00b7\u00b7\u00b7 + km new equality constraints,\n. . . ,\n\ny0 = a0x + b0,\n\nym = amx + bm.\n\nthe objective and inequality constraints in this problem are independent, i.e., in-\nvolve different optimization variables.\n\noptimizing over some variables\n\nwe always have\n\ninf\nx,y\n\nf (x, y) = inf\nx\n\n\u02dcf (x)\n\nwhere \u02dcf (x) = inf y f (x, y). in other words, we can always minimize a function by\nfirst minimizing over some of the variables, and then minimizing over the remaining\nones. this simple and general principle can be used to transform problems into\nequivalent forms. the general case is cumbersome to describe and not illuminating,\nso we describe instead an example.\n\nsuppose the variable x \u2208 rn is partitioned as x = (x1, x2), with x1 \u2208 rn1 ,\n\nx2 \u2208 rn2 , and n1 + n2 = n. we consider the problem\n\nminimize\nsubject to\n\nf0(x1, x2)\nfi(x1) \u2264 0,\n\u02dcfi(x2) \u2264 0,\n\ni = 1, . . . , m1\ni = 1, . . . , m2,\n\n(4.9)\n\nin which the constraints are independent, in the sense that each constraint function\ndepends on x1 or x2. we first minimize over x2. define the function \u02dcf0 of x1 by\n\n\u02dcf0(x1) = inf{f0(x1, z) | \u02dcfi(z) \u2264 0, i = 1, . . . , m2}.\n\nthe problem (4.9) is then equivalent to\n\nminimize\nsubject to\n\n\u02dcf0(x1)\nfi(x1) \u2264 0,\n\ni = 1, . . . , m1.\n\n(4.10)\n\n "}, {"Page_number": 148, "text": "134\n\n4 convex optimization problems\n\nexample 4.4 minimizing a quadratic function with constraints on some variables.\nconsider a problem with strictly convex quadratic objective, with some of the vari-\nables unconstrained:\n\nminimize\nsubject to\n\nxt\n1 p11x1 + 2xt\nfi(x1) \u2264 0,\n\n1 p12x2 + xt\ni = 1, . . . , m,\n\n2 p22x2\n\nwhere p11 and p22 are symmetric. here we can analytically minimize over x2:\n\n1 p11x1 + 2xt\n\n1 p12x2 + xt\n\ninf\n\nx2(cid:0)xt\n\n(see \u00a7a.5.5). therefore the original problem is equivalent to\n\n22 p t\n\n12(cid:1) x1\n\n2 p22x2(cid:1) = xt\n1 (cid:0)p11 \u2212 p12p \u22121\n\nxt\nfi(x1) \u2264 0,\n\n1 (cid:0)p11 \u2212 p12p \u22121\n12(cid:1) x1\n\ni = 1, . . . , m.\n\n22 p t\n\nminimize\nsubject to\n\nepigraph problem form\n\nthe epigraph form of the standard problem (4.1) is the problem\n\nminimize\nsubject to\n\nt\nf0(x) \u2212 t \u2264 0\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.11)\n\nwith variables x \u2208 rn and t \u2208 r. we can easily see that it is equivalent to the\noriginal problem: (x, t) is optimal for (4.11) if and only if x is optimal for (4.1)\nand t = f0(x). note that the objective function of the epigraph form problem is a\nlinear function of the variables x, t.\n\nthe epigraph form problem (4.11) can be interpreted geometrically as an op-\ntimization problem in the \u2018graph space\u2019 (x, t): we minimize t over the epigraph of\nf0, subject to the constraints on x. this is illustrated in figure 4.1.\n\nimplicit and explicit constraints\nby a simple trick already mentioned in \u00a73.1.2, we can include any of the constraints\nimplicitly in the objective function, by redefining its domain. as an extreme ex-\nample, the standard form problem can be expressed as the unconstrained problem\n\nminimize f (x),\n\n(4.12)\n\nwhere we define the function f as f0, but with domain restricted to the feasible\nset:\n\ndom f = {x \u2208 dom f0 | fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p},\n\nand f (x) = f0(x) for x \u2208 dom f . (equivalently, we can define f (x) to have value\n\u221e for x not feasible.) the problems (4.1) and (4.12) are clearly equivalent: they\nhave the same feasible set, optimal points, and optimal value.\nof course this transformation is nothing more than a notational trick. making\nthe constraints implicit has not made the problem any easier to analyze or solve,\n\n "}, {"Page_number": 149, "text": "4.1 optimization problems\n\n135\n\nt\n\nepi f0\n\n(x\u22c6, t\u22c6)\n\nx\n\nfigure 4.1 geometric interpretation of epigraph form problem, for a prob-\nlem with no constraints. the problem is to find the point in the epigraph\n(shown shaded) that minimizes t, i.e., the \u2018lowest\u2019 point in the epigraph.\nthe optimal point is (x\u22c6, t\u22c6).\n\neven though the problem (4.12) is, at least nominally, unconstrained. in some ways\nthe transformation makes the problem more difficult. suppose, for example, that\nthe objective f0 in the original problem is differentiable, so in particular its domain\nis open. the restricted objective function f is probably not differentiable, since\nits domain is likely not to be open.\n\nconversely, we will encounter problems with implicit constraints, which we can\n\nthen make explicit. as a simple example, consider the unconstrained problem\n\nminimize\n\nf (x)\n\n(4.13)\n\nwhere the function f is given by\n\nf (x) =(cid:26) xt x ax = b\n\n\u221e otherwise.\n\nthus, the objective function is equal to the quadratic form xt x on the affine set\ndefined by ax = b, and \u221e off the affine set. since we can clearly restrict our\nattention to points that satisfy ax = b, we say that the problem (4.13) has an\nimplicit equality constraint ax = b hidden in the objective. we can make the\nimplicit equality constraint explicit, by forming the equivalent problem\n\nminimize\nsubject to ax = b.\n\nxt x\n\n(4.14)\n\nwhile the problems (4.13) and (4.14) are clearly equivalent, they are not the same.\nthe problem (4.13) is unconstrained, but its objective function is not differentiable.\nthe problem (4.14), however, has an equality constraint, but its objective and\nconstraint functions are differentiable.\n\n "}, {"Page_number": 150, "text": "136\n\n4 convex optimization problems\n\n4.1.4 parameter and oracle problem descriptions\n\nfor a problem in the standard form (4.1), there is still the question of how the\nobjective and constraint functions are specified.\nin many cases these functions\nhave some analytical or closed form, i.e., are given by a formula or expression that\ninvolves the variable x as well as some parameters. suppose, for example, the\nobjective is quadratic, so it has the form f0(x) = (1/2)xt p x + qt x + r. to specify\nthe objective function we give the coefficients (also called problem parameters or\nproblem data) p \u2208 sn, q \u2208 rn, and r \u2208 r. we call this a parameter problem\ndescription, since the specific problem to be solved (i.e., the problem instance) is\nspecified by giving the values of the parameters that appear in the expressions for\nthe objective and constraint functions.\n\nin other cases the objective and constraint functions are described by oracle\nmodels (which are also called black box or subroutine models). in an oracle model,\nwe do not know f explicitly, but can evaluate f (x) (and usually also some deriva-\ntives) at any x \u2208 dom f . this is referred to as querying the oracle, and is usually\nassociated with some cost, such as time. we are also given some prior information\nabout the function, such as convexity and a bound on its values. as a concrete\nexample of an oracle model, consider an unconstrained problem, in which we are\nto minimize the function f . the function value f (x) and its gradient \u2207f (x) are\nevaluated in a subroutine. we can call the subroutine at any x \u2208 dom f , but do\nnot have access to its source code. calling the subroutine with argument x yields\n(when the subroutine returns) f (x) and \u2207f (x). note that in the oracle model,\nwe never really know the function; we only know the function value (and some\nderivatives) at the points where we have queried the oracle. (we also know some\ngiven prior information about the function, such as differentiability and convexity.)\nin practice the distinction between a parameter and oracle problem description\nis not so sharp. if we are given a parameter problem description, we can construct\nan oracle for it, which simply evaluates the required functions and derivatives when\nqueried. most of the algorithms we study in part iii work with an oracle model, but\ncan be made more efficient when they are restricted to solve a specific parametrized\nfamily of problems.\n\n4.2 convex optimization\n\n4.2.1 convex optimization problems in standard form\n\na convex optimization problem is one of the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nat\ni x = bi,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.15)\n\nwhere f0, . . . , fm are convex functions. comparing (4.15) with the general standard\nform problem (4.1), the convex problem has three additional requirements:\n\n "}, {"Page_number": 151, "text": "4.2 convex optimization\n\n137\n\n\u2022 the objective function must be convex,\n\u2022 the inequality constraint functions must be convex,\n\u2022 the equality constraint functions hi(x) = at\n\ni x \u2212 bi must be affine.\n\nwe immediately note an important property: the feasible set of a convex optimiza-\ntion problem is convex, since it is the intersection of the domain of the problem\n\nd =\n\nm\\i=0\n\ndom fi,\n\nwhich is a convex set, with m (convex) sublevel sets {x | fi(x) \u2264 0} and p hyper-\nplanes {x | at\ni x = bi}. (we can assume without loss of generality that ai 6= 0: if\nai = 0 and bi = 0 for some i, then the ith equality constraint can be deleted; if\nai = 0 and bi 6= 0, the ith equality constraint is inconsistent, and the problem is in-\nfeasible.) thus, in a convex optimization problem, we minimize a convex objective\nfunction over a convex set.\n\nif f0 is quasiconvex instead of convex, we say the problem (4.15) is a (standard\nform) quasiconvex optimization problem. since the sublevel sets of a convex or\nquasiconvex function are convex, we conclude that for a convex or quasiconvex\noptimization problem the \u01eb-suboptimal sets are convex. in particular, the optimal\nset is convex. if the objective is strictly convex, then the optimal set contains at\nmost one point.\n\nconcave maximization problems\n\nwith a slight abuse of notation, we will also refer to\n\nmaximize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nat\ni x = bi,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.16)\n\nas a convex optimization problem if the objective function f0 is concave, and the\ninequality constraint functions f1, . . . , fm are convex. this concave maximization\nproblem is readily solved by minimizing the convex objective function \u2212f0. all\nof the results, conclusions, and algorithms that we describe for the minimization\nproblem are easily transposed to the maximization case.\nin a similar way the\nmaximization problem (4.16) is called quasiconvex if f0 is quasiconcave.\n\nabstract form convex optimization problem\n\nit is important to note a subtlety in our definition of convex optimization problem.\nconsider the example with x \u2208 r2,\n\nminimize\nsubject to\n\n1 + x2\n2\n\nf0(x) = x2\nf1(x) = x1/(1 + x2\n2) \u2264 0\nh1(x) = (x1 + x2)2 = 0,\n\n(4.17)\n\nwhich is in the standard form (4.1). this problem is not a convex optimization\nproblem in standard form since the equality constraint function h1 is not affine, and\n\n "}, {"Page_number": 152, "text": "138\n\n4 convex optimization problems\n\nthe inequality constraint function f1 is not convex. nevertheless the feasible set,\nwhich is {x | x1 \u2264 0, x1 + x2 = 0}, is convex. so although in this problem we are\nminimizing a convex function f0 over a convex set, it is not a convex optimization\nproblem by our definition.\n\nof course, the problem is readily reformulated as\n\nminimize\nsubject to\n\nf0(x) = x2\n1 + x2\n2\n\u02dcf1(x) = x1 \u2264 0\n\u02dch1(x) = x1 + x2 = 0,\n\n(4.18)\n\nwhich is in standard convex optimization form, since f0 and \u02dcf1 are convex, and \u02dch1\nis affine.\n\nsome authors use the term abstract convex optimization problem to describe the\n(abstract) problem of minimizing a convex function over a convex set. using this\nterminology, the problem (4.17) is an abstract convex optimization problem. we\nwill not use this terminology in this book. for us, a convex optimization problem is\nnot just one of minimizing a convex function over a convex set; it is also required\nthat the feasible set be described specifically by a set of inequalities involving\nconvex functions, and a set of linear equality constraints. the problem (4.17) is\nnot a convex optimization problem, but the problem (4.18) is a convex optimization\nproblem. (the two problems are, however, equivalent.)\n\nour adoption of the stricter definition of convex optimization problem does not\nmatter much in practice. to solve the abstract problem of minimizing a convex\nfunction over a convex set, we need to find a description of the set in terms of\nconvex inequalities and linear equality constraints. as the example above suggests,\nthis is usually straightforward.\n\n4.2.2 local and global optima\n\na fundamental property of convex optimization problems is that any locally optimal\npoint is also (globally) optimal. to see this, suppose that x is locally optimal for\na convex optimization problem, i.e., x is feasible and\n\nf0(x) = inf{f0(z) | z feasible, kz \u2212 xk2 \u2264 r},\n\n(4.19)\n\nfor some r > 0. now suppose that x is not globally optimal, i.e., there is a feasible\ny such that f0(y) < f0(x). evidently ky \u2212 xk2 > r, since otherwise f0(x) \u2264 f0(y).\nconsider the point z given by\n\nz = (1 \u2212 \u03b8)x + \u03b8y,\n\n\u03b8 =\n\nr\n\n2ky \u2212 xk2\n\n.\n\nthen we have kz \u2212 xk2 = r/2 < r, and by convexity of the feasible set, z is\nfeasible. by convexity of f0 we have\n\nf0(z) \u2264 (1 \u2212 \u03b8)f0(x) + \u03b8f0(y) < f0(x),\n\nwhich contradicts (4.19). hence there exists no feasible y with f0(y) < f0(x), i.e.,\nx is globally optimal.\n\n "}, {"Page_number": 153, "text": "4.2 convex optimization\n\n139\n\nx\n\nx\n\n\u2212\u2207f0(x)\n\nfigure 4.2 geometric interpretation of the optimality condition (4.21). the\nfeasible set x is shown shaded. some level curves of f0 are shown as dashed\nlines. the point x is optimal: \u2212\u2207f0(x) defines a supporting hyperplane\n(shown as a solid line) to x at x.\n\nit is not true that locally optimal points of quasiconvex optimization problems\n\nare globally optimal; see \u00a74.2.5.\n\n4.2.3 an optimality criterion for differentiable f0\n\nsuppose that the objective f0 in a convex optimization problem is differentiable,\nso that for all x, y \u2208 dom f0,\n\nf0(y) \u2265 f0(x) + \u2207f0(x)t (y \u2212 x)\n\n(4.20)\n\n(see \u00a73.1.3). let x denote the feasible set, i.e.,\n\nx = {x | fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p}.\n\nthen x is optimal if and only if x \u2208 x and\n\n\u2207f0(x)t (y \u2212 x) \u2265 0 for all y \u2208 x.\n\n(4.21)\n\nthis optimality criterion can be understood geometrically: if \u2207f0(x) 6= 0, it means\nthat \u2212\u2207f0(x) defines a supporting hyperplane to the feasible set at x (see fig-\nure 4.2).\n\nproof of optimality condition\nfirst suppose x \u2208 x and satisfies (4.21). then if y \u2208 x we have, by (4.20),\nf0(y) \u2265 f0(x). this shows x is an optimal point for (4.1).\nconversely, suppose x is optimal, but the condition (4.21) does not hold, i.e.,\nfor some y \u2208 x we have\n\n\u2207f0(x)t (y \u2212 x) < 0.\n\n "}, {"Page_number": 154, "text": "140\n\n4 convex optimization problems\n\nconsider the point z(t) = ty + (1\u2212 t)x, where t \u2208 [0, 1] is a parameter. since z(t) is\non the line segment between x and y, and the feasible set is convex, z(t) is feasible.\nwe claim that for small positive t we have f0(z(t)) < f0(x), which will prove that\nx is not optimal. to show this, note that\n\nd\ndt\n\nf0(z(t))(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\n= \u2207f0(x)t (y \u2212 x) < 0,\n\nso for small positive t, we have f0(z(t)) < f0(x).\n\nwe will pursue the topic of optimality conditions in much more depth in chap-\n\nter 5, but here we examine a few simple examples.\n\nunconstrained problems\n\nfor an unconstrained problem (i.e., m = p = 0), the condition (4.21) reduces to\nthe well known necessary and sufficient condition\n\n\u2207f0(x) = 0\n\n(4.22)\n\nfor x to be optimal. while we have already seen this optimality condition, it is\nuseful to see how it follows from (4.21). suppose x is optimal, which means here\nthat x \u2208 dom f0, and for all feasible y we have \u2207f0(x)t (y \u2212 x) \u2265 0. since f0 is\ndifferentiable, its domain is (by definition) open, so all y sufficiently close to x are\nfeasible. let us take y = x\u2212 t\u2207f0(x), where t \u2208 r is a parameter. for t small and\npositive, y is feasible, and so\n\n\u2207f0(x)t (y \u2212 x) = \u2212tk\u2207f0(x)k2\n\n2 \u2265 0,\n\nfrom which we conclude \u2207f0(x) = 0.\nthere are several possible situations, depending on the number of solutions\nof (4.22). if there are no solutions of (4.22), then there are no optimal points; the\noptimal value of the problem is not attained. here we can distinguish between\ntwo cases: the problem is unbounded below, or the optimal value is finite, but not\nattained. on the other hand we can have multiple solutions of the equation (4.22),\nin which case each such solution is a minimizer of f0.\n\nexample 4.5 unconstrained quadratic optimization. consider the problem of mini-\nmizing the quadratic function\n\nf0(x) = (1/2)xt p x + qt x + r,\n\nwhere p \u2208 sn\nx to be a minimizer of f0 is\n\n+ (which makes f0 convex). the necessary and sufficient condition for\n\n\u2207f0(x) = p x + q = 0.\n\nseveral cases can occur, depending on whether this (linear) equation has no solutions,\none solution, or many solutions.\n\n\u2022 if q 6\u2208 r(p ), then there is no solution. in this case f0 is unbounded below.\n\u2022 if p \u227b 0 (which is the condition for f0 to be strictly convex), then there is a\n\nunique minimizer, x\u22c6 = \u2212p \u22121q.\n\n "}, {"Page_number": 155, "text": "4.2 convex optimization\n\n141\n\n\u2022 if p is singular, but q \u2208 r(p ), then the set of optimal points is the (affine) set\nxopt = \u2212p \u2020q + n (p ), where p \u2020 denotes the pseudo-inverse of p (see \u00a7a.5.4).\n\nexample 4.6 analytic centering. consider the (unconstrained) problem of minimiz-\ning the (convex) function f0 : rn \u2192 r, defined as\n\nf0(x) = \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x),\n\ndom f0 = {x | ax \u227a b},\n\nwhere at\nand sufficient conditions for x to be optimal are\n\n1 , . . . , at\n\nm are the rows of a. the function f0 is differentiable, so the necessary\n\nax \u227a b,\n\n\u2207f0(x) =\n\nmxi=1\n\n1\n\nbi \u2212 at\ni x\n\nai = 0.\n\n(4.23)\n\n(the condition ax \u227a b is just x \u2208 dom f0.) if ax \u227a b is infeasible, then the domain\nof f0 is empty. assuming ax \u227a b is feasible, there are still several possible cases (see\nexercise 4.2):\n\n\u2022 there are no solutions of (4.23), and hence no optimal points for the problem.\n\nthis occurs if and only if f0 is unbounded below.\n\n\u2022 there are many solutions of (4.23).\n\nsolutions form an affine set.\n\nin this case it can be shown that the\n\n\u2022 there is a unique solution of (4.23), i.e., a unique minimizer of f0. this occurs\n\nif and only if the open polyhedron {x | ax \u227a b} is nonempty and bounded.\n\nproblems with equality constraints only\n\nconsider the case where there are equality constraints but no inequality constraints,\ni.e.,\n\nminimize\nsubject to ax = b.\n\nf0(x)\n\nhere the feasible set is affine. we assume that it is nonempty; otherwise the\nproblem is infeasible. the optimality condition for a feasible x is that\n\n\u2207f0(x)t (y \u2212 x) \u2265 0\n\nmust hold for all y satisfying ay = b. since x is feasible, every feasible y has the\nform y = x + v for some v \u2208 n (a). the optimality condition can therefore be\nexpressed as:\n\n\u2207f0(x)t v \u2265 0 for all v \u2208 n (a).\n\nif a linear function is nonnegative on a subspace, then it must be zero on the\nsubspace, so it follows that \u2207f0(x)t v = 0 for all v \u2208 n (a). in other words,\n\n\u2207f0(x) \u22a5 n (a).\n\n "}, {"Page_number": 156, "text": "142\n\n4 convex optimization problems\n\nusing the fact that n (a)\u22a5 = r(at ), this optimality condition can be expressed\nas \u2207f0(x) \u2208 r(at ), i.e., there exists a \u03bd \u2208 rp such that\n\n\u2207f0(x) + at \u03bd = 0.\n\ntogether with the requirement ax = b (i.e., that x is feasible), this is the classical\nlagrange multiplier optimality condition, which we will study in greater detail in\nchapter 5.\n\nminimization over the nonnegative orthant\n\nas another example we consider the problem\n\nminimize\nf0(x)\nsubject to x (cid:23) 0,\n\nwhere the only inequality constraints are nonnegativity constraints on the variables.\n\nthe optimality condition (4.21) is then\n\nx (cid:23) 0,\n\n\u2207f0(x)t (y \u2212 x) \u2265 0 for all y (cid:23) 0.\n\nthe term \u2207f0(x)t y, which is a linear function of y, is unbounded below on y (cid:23) 0,\nunless we have \u2207f0(x) (cid:23) 0. the condition then reduces to \u2212\u2207f0(x)t x \u2265 0. but\nx (cid:23) 0 and \u2207f0(x) (cid:23) 0, so we must have \u2207f0(x)t x = 0, i.e.,\n\nnxi=1\n\n(\u2207f0(x))ixi = 0.\n\nnow each of the terms in this sum is the product of two nonnegative numbers, so\nwe conclude that each term must be zero, i.e., (\u2207f0(x))i xi = 0 for i = 1, . . . , n.\n\nthe optimality condition can therefore be expressed as\n\nx (cid:23) 0,\n\n\u2207f0(x) (cid:23) 0,\n\nxi (\u2207f0(x))i = 0,\n\ni = 1, . . . , n.\n\nthe last condition is called complementarity, since it means that the sparsity pat-\nterns (i.e., the set of indices corresponding to nonzero components) of the vectors x\nand \u2207f0(x) are complementary (i.e., have empty intersection). we will encounter\ncomplementarity conditions again in chapter 5.\n\n4.2.4 equivalent convex problems\n\nit is useful to see which of the transformations described in \u00a74.1.3 preserve convex-\nity.\n\neliminating equality constraints\n\nfor a convex problem the equality constraints must be linear, i.e., of the form\nax = b. in this case they can be eliminated by finding a particular solution x0 of\n\n "}, {"Page_number": 157, "text": "4.2 convex optimization\n\n143\n\nax = b, and a matrix f whose range is the nullspace of a, which results in the\nproblem\n\nminimize\nsubject to\n\nf0(f z + x0)\nfi(f z + x0) \u2264 0,\n\ni = 1, . . . , m,\n\nwith variable z. since the composition of a convex function with an affine func-\ntion is convex, eliminating equality constraints preserves convexity of a problem.\nmoreover, the process of eliminating equality constraints (and reconstructing the\nsolution of the original problem from the solution of the transformed problem)\ninvolves standard linear algebra operations.\n\nat least in principle, this means we can restrict our attention to convex opti-\nmization problems which have no equality constraints. in many cases, however, it\nis better to retain the equality constraints, since eliminating them can make the\nproblem harder to understand and analyze, or ruin the efficiency of an algorithm\nthat solves it. this is true, for example, when the variable x has very large dimen-\nsion, and eliminating the equality constraints would destroy sparsity or some other\nuseful structure of the problem.\n\nintroducing equality constraints\n\nwe can introduce new variables and equality constraints into a convex optimization\nproblem, provided the equality constraints are linear, and the resulting problem\nwill also be convex. for example, if an objective or constraint function has the form\nfi(aix + bi), where ai \u2208 rki\u00d7n, we can introduce a new variable yi \u2208 rki, replace\nfi(aix + bi) with fi(yi), and add the linear equality constraint yi = aix + bi.\n\nslack variables\n\nby introducing slack variables we have the new constraints fi(x) + si = 0. since\nequality constraint functions must be affine in a convex problem, we must have fi\naffine. in other words: introducing slack variables for linear inequalities preserves\nconvexity of a problem.\n\nepigraph problem form\n\nthe epigraph form of the convex optimization problem (4.15) is\n\nminimize\nsubject to\n\nt\nf0(x) \u2212 t \u2264 0\nfi(x) \u2264 0,\nat\ni x = bi,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\nthe objective is linear (hence convex) and the new constraint function f0(x) \u2212 t is\nalso convex in (x, t), so the epigraph form problem is convex as well.\nit is sometimes said that a linear objective is universal for convex optimization,\nsince any convex optimization problem is readily transformed to one with linear\nobjective. the epigraph form of a convex problem has several practical uses. by\nassuming the objective of a convex optimization problem is linear, we can simplify\ntheoretical analysis.\nit can also simplify algorithm development, since an algo-\nrithm that solves convex optimization problems with linear objective can, using\n\n "}, {"Page_number": 158, "text": "144\n\n4 convex optimization problems\n\nthe transformation above, solve any convex optimization problem (provided it can\nhandle the constraint f0(x) \u2212 t \u2264 0).\nminimizing over some variables\n\nminimizing a convex function over some variables preserves convexity. therefore,\nif f0 in (4.9) is jointly convex in x1 and x2, and fi, i = 1, . . . , m1, and \u02dcfi, i =\n1, . . . , m2, are convex, then the equivalent problem (4.10) is convex.\n\n4.2.5 quasiconvex optimization\n\nrecall that a quasiconvex optimization problem has the standard form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m\n\n(4.24)\n\nwhere the inequality constraint functions f1, . . . , fm are convex, and the objective\nf0 is quasiconvex (instead of convex, as in a convex optimization problem). (qua-\nsiconvex constraint functions can be replaced with equivalent convex constraint\nfunctions, i.e., constraint functions that are convex and have the same 0-sublevel\nset, as in \u00a73.4.5.)\nin this section we point out some basic differences between convex and quasicon-\nvex optimization problems, and also show how solving a quasiconvex optimization\nproblem can be reduced to solving a sequence of convex optimization problems.\n\nlocally optimal solutions and optimality conditions\n\nthe most important difference between convex and quasiconvex optimization is\nthat a quasiconvex optimization problem can have locally optimal solutions that\nare not (globally) optimal. this phenomenon can be seen even in the simple case\nof unconstrained minimization of a quasiconvex function on r, such as the one\nshown in figure 4.3.\n\nnevertheless, a variation of the optimality condition (4.21) given in \u00a74.2.3 does\nhold for quasiconvex optimization problems with differentiable objective function.\nlet x denote the feasible set for the quasiconvex optimization problem (4.24). it\nfollows from the first-order condition for quasiconvexity (3.20) that x is optimal if\n\nx \u2208 x,\n\n\u2207f0(x)t (y \u2212 x) > 0 for all y \u2208 x \\ {x}.\n\n(4.25)\n\nthere are two important differences between this criterion and the analogous\none (4.21) for convex optimization:\n\n\u2022 the condition (4.25) is only sufficient for optimality; simple examples show\nthat it need not hold for an optimal point. in contrast, the condition (4.21)\nis necessary and sufficient for x to solve the convex problem.\n\n\u2022 the condition (4.25) requires the gradient of f0 to be nonzero, whereas the\ncondition (4.21) does not. indeed, when \u2207f0(x) = 0 in the convex case, the\ncondition (4.21) is satisfied, and x is optimal.\n\n "}, {"Page_number": 159, "text": "4.2 convex optimization\n\n145\n\n(x, f (x))\n\nfigure 4.3 a quasiconvex function f on r, with a locally optimal point x\nthat is not globally optimal. this example shows that the simple optimality\ncondition f \u2032(x) = 0, valid for convex functions, does not hold for quasiconvex\nfunctions.\n\nquasiconvex optimization via convex feasibility problems\n\none general approach to quasiconvex optimization relies on the representation of\nthe sublevel sets of a quasiconvex function via a family of convex inequalities, as\ndescribed in \u00a73.4.5. let \u03c6t : rn \u2192 r, t \u2208 r, be a family of convex functions that\nsatisfy\n\nf0(x) \u2264 t \u21d0\u21d2 \u03c6t(x) \u2264 0,\n\nand also, for each x, \u03c6t(x) is a nonincreasing function of t, i.e., \u03c6s(x) \u2264 \u03c6t(x)\nwhenever s \u2265 t.\nlet p\u22c6 denote the optimal value of the quasiconvex optimization problem (4.24).\nif the feasibility problem\n\nx\n\nfind\nsubject to \u03c6t(x) \u2264 0\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m\n\n(4.26)\n\nis feasible, then we have p\u22c6 \u2264 t. conversely, if the problem (4.26) is infeasible, then\nwe can conclude p\u22c6 \u2265 t. the problem (4.26) is a convex feasibility problem, since\nthe inequality constraint functions are all convex, and the equality constraints\nare linear. thus, we can check whether the optimal value p\u22c6 of a quasiconvex\noptimization problem is less than or more than a given value t by solving the\nconvex feasibility problem (4.26). if the convex feasibility problem is feasible then\nwe have p\u22c6 \u2264 t, and any feasible point x is feasible for the quasiconvex problem\nand satisfies f0(x) \u2264 t. if the convex feasibility problem is infeasible, then we know\nthat p\u22c6 \u2265 t.\nthis observation can be used as the basis of a simple algorithm for solving the\nquasiconvex optimization problem (4.24) using bisection, solving a convex feasi-\nbility problem at each step. we assume that the problem is feasible, and start\nwith an interval [l, u] known to contain the optimal value p\u22c6. we then solve the\nconvex feasibility problem at its midpoint t = (l + u)/2, to determine whether the\n\n "}, {"Page_number": 160, "text": "146\n\n4 convex optimization problems\n\noptimal value is in the lower or upper half of the interval, and update the interval\naccordingly. this produces a new interval, which also contains the optimal value,\nbut has half the width of the initial interval. this is repeated until the width of\nthe interval is small enough:\n\nalgorithm 4.1 bisection method for quasiconvex optimization.\n\ngiven l \u2264 p\u22c6, u \u2265 p\u22c6, tolerance \u01eb > 0.\n\nrepeat\n\n1. t := (l + u)/2.\n2. solve the convex feasibility problem (4.26).\n3. if (4.26) is feasible, u := t;\n\nelse l := t.\n\nuntil u \u2212 l \u2264 \u01eb.\n\nthe interval [l, u] is guaranteed to contain p\u22c6, i.e., we have l \u2264 p\u22c6 \u2264 u at\nin each iteration the interval is divided in two, i.e., bisected, so the\neach step.\nlength of the interval after k iterations is 2\u2212k(u \u2212 l), where u \u2212 l is the length of\nthe initial interval. it follows that exactly \u2308log2((u \u2212 l)/\u01eb)\u2309 iterations are required\nbefore the algorithm terminates. each step involves solving the convex feasibility\nproblem (4.26).\n\n4.3 linear optimization problems\n\nwhen the objective and constraint functions are all affine, the problem is called a\nlinear program (lp). a general linear program has the form\n\nct x + d\nminimize\nsubject to gx (cid:22) h\nax = b,\n\n(4.27)\n\nwhere g \u2208 rm\u00d7n and a \u2208 rp\u00d7n. linear programs are, of course, convex opti-\nmization problems.\nit is common to omit the constant d in the objective function, since it does not\naffect the optimal (or feasible) set. since we can maximize an affine objective ct x+\nd, by minimizing \u2212ct x \u2212 d (which is still convex), we also refer to a maximization\nproblem with affine objective and constraint functions as an lp.\nthe geometric interpretation of an lp is illustrated in figure 4.4. the feasible\nset of the lp (4.27) is a polyhedron p; the problem is to minimize the affine\nfunction ct x + d (or, equivalently, the linear function ct x) over p.\nstandard and inequality form linear programs\n\ntwo special cases of the lp (4.27) are so widely encountered that they have been\ngiven separate names. in a standard form lp the only inequalities are componen-\n\n "}, {"Page_number": 161, "text": "4.3 linear optimization problems\n\n147\n\n\u2212c\n\nx\u22c6\n\np\n\nfigure 4.4 geometric interpretation of an lp. the feasible set p, which\nis a polyhedron, is shaded. the objective ct x is linear, so its level curves\nare hyperplanes orthogonal to c (shown as dashed lines). the point x\u22c6 is\noptimal; it is the point in p as far as possible in the direction \u2212c.\n\ntwise nonnegativity constraints x (cid:23) 0:\n\nct x\n\nminimize\nsubject to ax = b\nx (cid:23) 0.\n\n(4.28)\n\nif the lp has no equality constraints, it is called an inequality form lp, usually\nwritten as\n\nct x\n\nminimize\nsubject to ax (cid:22) b.\n\n(4.29)\n\nconverting lps to standard form\n\nit is sometimes useful to transform a general lp (4.27) to one in standard form (4.28)\n(for example in order to use an algorithm for standard form lps). the first step\nis to introduce slack variables si for the inequalities, which results in\n\nminimize\nsubject to gx + s = h\n\nct x + d\n\nax = b\ns (cid:23) 0.\n\nthe second step is to express the variable x as the difference of two nonnegative\nvariables x+ and x\u2212, i.e., x = x+ \u2212 x\u2212, x+, x\u2212 (cid:23) 0. this yields the problem\n\nminimize\nsubject to gx+ \u2212 gx\u2212 + s = h\n\nct x+ \u2212 ct x\u2212 + d\nax+ \u2212 ax\u2212 = b\nx\u2212 (cid:23) 0,\nx+ (cid:23) 0,\n\ns (cid:23) 0,\n\n "}, {"Page_number": 162, "text": "148\n\n4 convex optimization problems\n\nwhich is an lp in standard form, with variables x+, x\u2212, and s. (for equivalence\nof this problem and the original one (4.27), see exercise 4.10.)\n\nthese techniques for manipulating problems (along with many others we will\nsee in the examples and exercises) can be used to formulate many problems as linear\nprograms. with some abuse of terminology, it is common to refer to a problem\nthat can be formulated as an lp as an lp, even if it does not have the form (4.27).\n\n4.3.1 examples\n\nlps arise in a vast number of fields and applications; here we give a few typical\nexamples.\n\ndiet problem\n\na healthy diet contains m different nutrients in quantities at least equal to b1, . . . ,\nbm. we can compose such a diet by choosing nonnegative quantities x1, . . . , xn of\nn different foods. one unit quantity of food j contains an amount aij of nutrient\ni, and has a cost of cj. we want to determine the cheapest diet that satisfies the\nnutritional requirements. this problem can be formulated as the lp\n\nct x\n\nminimize\nsubject to ax (cid:23) b\nx (cid:23) 0.\n\nseveral variations on this problem can also be formulated as lps. for example,\nwe can insist on an exact amount of a nutrient in the diet (which gives a linear\nequality constraint), or we can impose an upper bound on the amount of a nutrient,\nin addition to the lower bound as above.\n\nchebyshev center of a polyhedron\n\nwe consider the problem of finding the largest euclidean ball that lies in a poly-\nhedron described by linear inequalities,\np = {x \u2208 rn | at\n\ni x \u2264 bi, i = 1, . . . , m}.\n\n(the center of the optimal ball is called the chebyshev center of the polyhedron;\nit is the point deepest inside the polyhedron, i.e., farthest from the boundary;\nsee \u00a78.5.1.) we represent the ball as\n\nb = {xc + u | kuk2 \u2264 r}.\n\nthe variables in the problem are the center xc \u2208 rn and the radius r; we wish to\nmaximize r subject to the constraint b \u2286 p.\nwe start by considering the simpler constraint that b lies in one halfspace\nat\ni x \u2264 bi, i.e.,\n(4.30)\n\nkuk2 \u2264 r =\u21d2 at\n\ni (xc + u) \u2264 bi.\n\nsince\n\nsup{at\n\ni u | kuk2 \u2264 r} = rkaik2\n\n "}, {"Page_number": 163, "text": "4.3 linear optimization problems\n\n149\n\nwe can write (4.30) as\n\nat\ni xc + rkaik2 \u2264 bi,\n\n(4.31)\nwhich is a linear inequality in xc and r. in other words, the constraint that the\nball lies in the halfspace determined by the inequality at\ni x \u2264 bi can be written as\na linear inequality.\ntherefore b \u2286 p if and only if (4.31) holds for all i = 1, . . . , m. hence the\n\nchebyshev center can be determined by solving the lp\n\nmaximize\nr\nsubject to at\n\ni xc + rkaik2 \u2264 bi,\n\ni = 1, . . . , m,\n\nwith variables r and xc. (for more on the chebyshev center, see \u00a78.5.1.)\ndynamic activity planning\n\nwe consider the problem of choosing, or planning, the activity levels of n activities,\nor sectors of an economy, over n time periods. we let xj(t) \u2265 0, t = 1, . . . , n ,\ndenote the activity level of sector j, in period t. the activities both consume and\nproduce products or goods in proportion to their activity levels. the amount of\ngood i produced per unit of activity j is given by aij. similarly, the amount of good i\nconsumed per unit of activity j is bij. the total amount of goods produced in period\nt is given by ax(t) \u2208 rm, and the amount of goods consumed is bx(t) \u2208 rm.\n(although we refer to these products as \u2018goods\u2019, they can also include unwanted\nproducts such as pollutants.)\n\nthe goods consumed in a period cannot exceed those produced in the previous\nperiod: we must have bx(t + 1) (cid:22) ax(t) for t = 1, . . . , n . a vector g0 \u2208 rm of\ninitial goods is given, which constrains the first period activity levels: bx(1) (cid:22) g0.\nthe (vectors of) excess goods not consumed by the activities are given by\n\ns(0) = g0 \u2212 bx(1)\ns(t) = ax(t) \u2212 bx(t + 1),\ns(n ) = ax(n ).\n\nt = 1, . . . , n \u2212 1\n\nthe objective is to maximize a discounted total value of excess goods:\n\nct s(0) + \u03b3ct s(1) + \u00b7\u00b7\u00b7 + \u03b3n ct s(n ),\n\nwhere c \u2208 rm gives the values of the goods, and \u03b3 > 0 is a discount factor. (the\nvalue ci is negative if the ith product is unwanted, e.g., a pollutant; |ci| is then the\ncost of disposal per unit.)\n\nputting it all together we arrive at the lp\n\nct s(0) + \u03b3ct s(1) + \u00b7\u00b7\u00b7 + \u03b3n ct s(n )\nmaximize\nsubject to x(t) (cid:23) 0,\ns(t) (cid:23) 0,\ns(0) = g0 \u2212 bx(1)\ns(t) = ax(t) \u2212 bx(t + 1),\ns(n ) = ax(n ),\n\nt = 1, . . . , n\nt = 0, . . . , n\n\nt = 1, . . . , n \u2212 1\n\nwith variables x(1), . . . , x(n ), s(0), . . . , s(n ). this problem is a standard form lp;\nthe variables s(t) are the slack variables associated with the constraints bx(t+1) (cid:22)\nax(t).\n\n "}, {"Page_number": 164, "text": "150\n\n4 convex optimization problems\n\nchebyshev inequalities\n\nwe consider a probability distribution for a discrete random variable x on a set\n{u1, . . . , un} \u2286 r with n elements. we describe the distribution of x by a vector\np \u2208 rn, where\n\npi = prob(x = ui),\n\nso p satisfies p (cid:23) 0 and 1t p = 1. conversely, if p satisfies p (cid:23) 0 and 1t p = 1, then\nit defines a probability distribution for x. we assume that ui are known and fixed,\nbut the distribution p is not known.\n\nif f is any function of x, then\n\ne f =\n\nnxi=1\n\npif (ui)\n\nis a linear function of p. if s is any subset of r, then\n\nprob(x \u2208 s) = xui\u2208s\n\npi\n\nis a linear function of p.\n\nalthough we do not know p, we are given prior knowledge of the following form:\nwe know upper and lower bounds on expected values of some functions of x, and\nprobabilities of some subsets of r. this prior knowledge can be expressed as linear\ninequality constraints on p,\n\n\u03b1i \u2264 at\n\ni p \u2264 \u03b2i,\n\ni = 1, . . . , m.\n\nthe problem is to give lower and upper bounds on e f0(x) = at\nfunction of x.\n\n0 p, where f0 is some\n\nto find a lower bound we solve the lp\n\nat\n0 p\n\nminimize\nsubject to p (cid:23) 0,\n\u03b1i \u2264 at\n\n1t p = 1\ni p \u2264 \u03b2i,\n\ni = 1, . . . , m,\n\nwith variable p. the optimal value of this lp gives the lowest possible value of\ne f0(x) for any distribution that is consistent with the prior information. more-\nover, the bound is sharp: the optimal solution gives a distribution that is consistent\nwith the prior information and achieves the lower bound. in a similar way, we can\nfind the best upper bound by maximizing at\n0 p subject to the same constraints. (we\nwill consider chebyshev inequalities in more detail in \u00a77.4.1.)\npiecewise-linear minimization\n\nconsider the (unconstrained) problem of minimizing the piecewise-linear, convex\nfunction\n\nf (x) = max\n\ni=1,...,m\n\n(at\n\ni x + bi).\n\nthis problem can be transformed to an equivalent lp by first forming the epigraph\nproblem,\n\nminimize\nsubject to maxi=1,...,m(at\n\nt\n\ni x + bi) \u2264 t,\n\n "}, {"Page_number": 165, "text": "4.3 linear optimization problems\n\n151\n\nand then expressing the inequality as a set of m separate inequalities:\n\nminimize\nsubject to at\n\nt\n\ni x + bi \u2264 t,\n\ni = 1, . . . , m.\n\nthis is an lp (in inequality form), with variables x and t.\n\n4.3.2 linear-fractional programming\n\nthe problem of minimizing a ratio of affine functions over a polyhedron is called a\nlinear-fractional program:\n\nf0(x)\n\nminimize\nsubject to gx (cid:22) h\nax = b\n\n(4.32)\n\nwhere the objective function is given by\n\nf0(x) =\n\nct x + d\net x + f\n\n,\n\ndom f0 = {x | et x + f > 0}.\n\nthe objective function is quasiconvex (in fact, quasilinear) so linear-fractional pro-\ngrams are quasiconvex optimization problems.\n\ntransforming to a linear program\n\nif the feasible set\n\n{x | gx (cid:22) h, ax = b, et x + f > 0}\n\nis nonempty, the linear-fractional program (4.32) can be transformed to an equiv-\nalent linear program\n\nct y + dz\n\nminimize\nsubject to gy \u2212 hz (cid:22) 0\nay \u2212 bz = 0\net y + f z = 1\nz \u2265 0\n\n(4.33)\n\nwith variables y, z.\n\nto show the equivalence, we first note that if x is feasible in (4.32) then the\n\npair\n\ny =\n\nx\n\net x + f\n\n,\n\nz =\n\n1\n\net x + f\n\nis feasible in (4.33), with the same objective value ct y + dz = f0(x). it follows that\nthe optimal value of (4.32) is greater than or equal to the optimal value of (4.33).\nconversely, if (y, z) is feasible in (4.33), with z 6= 0, then x = y/z is feasible\nin (4.32), with the same objective value f0(x) = ct y + dz.\nif (y, z) is feasible\nin (4.33) with z = 0, and x0 is feasible for (4.32), then x = x0 + ty is feasible\nin (4.32) for all t \u2265 0. moreover, limt\u2192\u221e f0(x0 + ty) = ct y + dz, so we can find\nfeasible points in (4.32) with objective values arbitrarily close to the objective value\nof (y, z). we conclude that the optimal value of (4.32) is less than or equal to the\noptimal value of (4.33).\n\n "}, {"Page_number": 166, "text": "152\n\n4 convex optimization problems\n\ngeneralized linear-fractional programming\n\na generalization of the linear-fractional program (4.32) is the generalized linear-\nfractional program in which\n\nf0(x) = max\ni=1,...,r\n\nct\ni x + di\net\ni x + fi\n\n,\n\ndom f0 = {x | et\n\ni x + fi > 0, i = 1, . . . , r}.\n\nthe objective function is the pointwise maximum of r quasiconvex functions, and\ntherefore quasiconvex, so this problem is quasiconvex. when r = 1 it reduces to\nthe standard linear-fractional program.\n\nexample 4.7 von neumann growth problem. we consider an economy with n\nsectors, and activity levels xi > 0 in the current period, and activity levels x+\ni > 0 in\nthe next period. (in this problem we only consider one period.) there are m goods\nwhich are consumed, and also produced, by the activity: an activity level x consumes\ngoods bx \u2208 rm, and produces goods ax. the goods consumed in the next period\ncannot exceed the goods produced in the current period, i.e., bx+ (cid:22) ax. the growth\nrate in sector i, over the period, is given by x+\n\ni /xi.\n\nvon neumann\u2019s growth problem is to find an activity level vector x that maximizes\nthe minimum growth rate across all sectors of the economy. this problem can be\nexpressed as a generalized linear-fractional problem\n\nmaximize mini=1,...,n x+\nsubject to x+ (cid:23) 0\n\ni /xi\n\nbx+ (cid:22) ax\n\nwith domain {(x, x+) | x \u227b 0}. note that this problem is homogeneous in x and x+,\nso we can replace the implicit constraint x \u227b 0 by the explicit constraint x (cid:23) 1.\n\n4.4 quadratic optimization problems\n\nthe convex optimization problem (4.15) is called a quadratic program (qp) if the\nobjective function is (convex) quadratic, and the constraint functions are affine. a\nquadratic program can be expressed in the form\n\n(1/2)xt p x + qt x + r\n\nminimize\nsubject to gx (cid:22) h\nax = b,\n\n(4.34)\n\nwhere p \u2208 sn\na convex quadratic function over a polyhedron, as illustrated in figure 4.5.\n\n+, g \u2208 rm\u00d7n, and a \u2208 rp\u00d7n. in a quadratic program, we minimize\nif the objective in (4.15) as well as the inequality constraint functions are (con-\n\nvex) quadratic, as in\n\nminimize\nsubject to\n\n(1/2)xt p0x + qt\n(1/2)xt pix + qt\nax = b,\n\n0 x + r0\ni x + ri \u2264 0,\n\ni = 1, . . . , m\n\n(4.35)\n\n "}, {"Page_number": 167, "text": "4.4 quadratic optimization problems\n\n153\n\n\u2212\u2207f0(x\u22c6)\n\nx\u22c6\n\np\n\nfigure 4.5 geometric illustration of qp. the feasible set p, which is a poly-\nhedron, is shown shaded. the contour lines of the objective function, which\nis convex quadratic, are shown as dashed curves. the point x\u22c6 is optimal.\n\nwhere pi \u2208 sn\n+, i = 0, 1 . . . , m, the problem is called a quadratically constrained\nquadratic program (qcqp). in a qcqp, we minimize a convex quadratic function\nover a feasible region that is the intersection of ellipsoids (when pi \u227b 0).\nquadratic programs include linear programs as a special case, by taking p = 0\nin (4.34). quadratically constrained quadratic programs include quadratic pro-\ngrams (and therefore also linear programs) as a special case, by taking pi = 0\nin (4.35), for i = 1, . . . , m.\n\n4.4.1 examples\n\nleast-squares and regression\n\nthe problem of minimizing the convex quadratic function\n\nkax \u2212 bk2\n\n2 = xt at ax \u2212 2bt ax + bt b\n\nis an (unconstrained) qp. it arises in many fields and has many names, e.g., re-\ngression analysis or least-squares approximation. this problem is simple enough to\nhave the well known analytical solution x = a\u2020b, where a\u2020 is the pseudo-inverse\nof a (see \u00a7a.5.4).\nwhen linear inequality constraints are added, the problem is called constrained\nregression or constrained least-squares, and there is no longer a simple analytical\nsolution. as an example we can consider regression with lower and upper bounds\non the variables, i.e.,\n\nminimize\nsubject to\n\nkax \u2212 bk2\nli \u2264 xi \u2264 ui,\n\n2\n\ni = 1, . . . , n,\n\n "}, {"Page_number": 168, "text": "154\n\n4 convex optimization problems\n\nwhich is a qp. (we will study least-squares and regression problems in far more\ndepth in chapters 6 and 7.)\n\ndistance between polyhedra\nthe (euclidean) distance between the polyhedra p1 = {x | a1x (cid:22) b1} and p2 =\n{x | a2x (cid:22) b2} in rn is defined as\n\ndist(p1,p2) = inf{kx1 \u2212 x2k2 | x1 \u2208 p1, x2 \u2208 p2}.\n\nif the polyhedra intersect, the distance is zero.\n\nto find the distance between p1 and p2, we can solve the qp\n\nminimize\nsubject to a1x1 (cid:22) b1, a2x2 (cid:22) b2,\n\nkx1 \u2212 x2k2\n\n2\n\nwith variables x1, x2 \u2208 rn. this problem is infeasible if and only if one of the\npolyhedra is empty. the optimal value is zero if and only if the polyhedra intersect,\nin which case the optimal x1 and x2 are equal (and is a point in the intersection\np1\u2229p2). otherwise the optimal x1 and x2 are the points in p1 and p2, respectively,\nthat are closest to each other. (we will study geometric problems involving distance\nin more detail in chapter 8.)\n\nbounding variance\n\nwe consider again the chebyshev inequalities example (page 150), where the vari-\nable is an unknown probability distribution given by p \u2208 rn, about which we have\nsome prior information. the variance of a random variable f (x) is given by\n\ne f 2 \u2212 (e f )2 =\n\nf 2\n\ni pi \u2212  nxi=1\n\nnxi=1\n\nfipi!2\n\n,\n\n(where fi = f (ui)), which is a concave quadratic function of p.\n\nit follows that we can maximize the variance of f (x), subject to the given prior\n\ninformation, by solving the qp\n\ni=1 f 2\n\nmaximize pn\nsubject to p (cid:23) 0,\n\u03b1i \u2264 at\n\ni pi \u2212 (pn\n\n1t p = 1\ni p \u2264 \u03b2i,\n\ni=1 fipi)2\n\ni = 1, . . . , m.\n\nthe optimal value gives the maximum possible variance of f (x), over all distribu-\ntions that are consistent with the prior information; the optimal p gives a distri-\nbution that achieves this maximum variance.\n\nlinear program with random cost\n\nwe consider an lp,\n\nct x\n\nminimize\nsubject to gx (cid:22) h\nax = b,\n\n "}, {"Page_number": 169, "text": "4.4 quadratic optimization problems\n\n155\n\nwith variable x \u2208 rn. we suppose that the cost function (vector) c \u2208 rn is\nrandom, with mean value c and covariance e(c \u2212 c)(c \u2212 c)t = \u03c3. (we assume\nfor simplicity that the other problem parameters are deterministic.) for a given\nx \u2208 rn, the cost ct x is a (scalar) random variable with mean e ct x = ct x and\nvariance\n\nvar(ct x) = e(ct x \u2212 e ct x)2 = xt \u03c3x.\n\nin general there is a trade-off between small expected cost and small cost vari-\nance. one way to take variance into account is to minimize a linear combination\nof the expected value and the variance of the cost, i.e.,\n\ne ct x + \u03b3 var(ct x),\n\nwhich is called the risk-sensitive cost. the parameter \u03b3 \u2265 0 is called the risk-\naversion parameter, since it sets the relative values of cost variance and expected\nvalue. (for \u03b3 > 0, we are willing to trade off an increase in expected cost for a\nsufficiently large decrease in cost variance).\n\nto minimize the risk-sensitive cost we solve the qp\n\nct x + \u03b3xt \u03c3x\n\nminimize\nsubject to gx (cid:22) h\nax = b.\n\nmarkowitz portfolio optimization\n\nwe consider a classical portfolio problem with n assets or stocks held over a period\nof time. we let xi denote the amount of asset i held throughout the period, with\nxi in dollars, at the price at the beginning of the period. a normal long position\nin asset i corresponds to xi > 0; a short position in asset i (i.e., the obligation to\nbuy the asset at the end of the period) corresponds to xi < 0. we let pi denote\nthe relative price change of asset i over the period, i.e., its change in price over\nthe period divided by its price at the beginning of the period. the overall return\non the portfolio is r = pt x (given in dollars). the optimization variable is the\nportfolio vector x \u2208 rn.\na wide variety of constraints on the portfolio can be considered. the simplest\nset of constraints is that xi \u2265 0 (i.e., no short positions) and 1t x = b (i.e., the\ntotal budget to be invested is b, which is often taken to be one).\nwe take a stochastic model for price changes: p \u2208 rn is a random vector, with\nknown mean p and covariance \u03c3. therefore with portfolio x \u2208 rn, the return r\nis a (scalar) random variable with mean pt x and variance xt \u03c3x. the choice of\nportfolio x involves a trade-off between the mean of the return, and its variance.\n\nthe classical portfolio optimization problem, introduced by markowitz, is the\n\nqp\n\nxt \u03c3x\n\nminimize\nsubject to pt x \u2265 rmin\n1t x = 1,\n\nx (cid:23) 0,\n\nwhere x, the portfolio, is the variable. here we find the portfolio that minimizes\nthe return variance (which is associated with the risk of the portfolio) subject to\n\n "}, {"Page_number": 170, "text": "156\n\n4 convex optimization problems\n\nachieving a minimum acceptable mean return rmin, and satisfying the portfolio\nbudget and no-shorting constraints.\n\nmany extensions are possible. one standard extension, for example, is to allow\nshort positions, i.e., xi < 0. to do this we introduce variables xlong and xshort,\nwith\n\nxlong (cid:23) 0,\n\nxshort (cid:23) 0,\n\nx = xlong \u2212 xshort,\n\n1t xshort \u2264 \u03b71t xlong.\n\nthe last constraint limits the total short position at the beginning of the period to\nsome fraction \u03b7 of the total long position at the beginning of the period.\n\nas another extension we can include linear transaction costs in the portfolio\noptimization problem. starting from a given initial portfolio xinit we buy and sell\nassets to achieve the portfolio x, which we then hold over the period as described\nabove. we are charged a transaction fee for buying and selling assets, which is\nproportional to the amount bought or sold. to handle this, we introduce variables\nubuy and usell, which determine the amount of each asset we buy and sell before\nthe holding period. we have the constraints\n\nx = xinit + ubuy \u2212 usell,\n\nubuy (cid:23) 0,\n\nusell (cid:23) 0.\n\nwe replace the simple budget constraint 1t x = 1 with the condition that the initial\nbuying and selling, including transaction fees, involves zero net cash:\n\n(1 \u2212 fsell)1t usell = (1 + fbuy)1t ubuy\n\nhere the lefthand side is the total proceeds from selling assets, less the selling\ntransaction fee, and the righthand side is the total cost, including transaction fee,\nof buying assets. the constants fbuy \u2265 0 and fsell \u2265 0 are the transaction fee rates\nfor buying and selling (assumed the same across assets, for simplicity).\nthe problem of minimizing return variance, subject to a minimum mean return,\n\nand the budget and trading constraints, is a qp with variables x, ubuy, usell.\n\n4.4.2 second-order cone programming\n\na problem that is closely related to quadratic programming is the second-order\ncone program (socp):\n\nminimize\nsubject to\n\nf t x\nkaix + bik2 \u2264 ct\nf x = g,\n\ni x + di,\n\ni = 1, . . . , m\n\n(4.36)\n\nwhere x \u2208 rn is the optimization variable, ai \u2208 rni\u00d7n, and f \u2208 rp\u00d7n. we call a\nconstraint of the form\n\nkax + bk2 \u2264 ct x + d,\n\nwhere a \u2208 rk\u00d7n, a second-order cone constraint, since it is the same as requiring\nthe affine function (ax + b, ct x + d) to lie in the second-order cone in rk+1.\nwhen ci = 0, i = 1, . . . , m, the socp (4.36) is equivalent to a qcqp (which\nis obtained by squaring each of the constraints). similarly, if ai = 0, i = 1, . . . , m,\nthen the socp (4.36) reduces to a (general) lp. second-order cone programs are,\nhowever, more general than qcqps (and of course, lps).\n\n "}, {"Page_number": 171, "text": "4.4 quadratic optimization problems\n\n157\n\nrobust linear programming\n\nwe consider a linear program in inequality form,\n\nminimize\nsubject to at\n\nct x\ni x \u2264 bi,\n\ni = 1, . . . , m,\n\nin which there is some uncertainty or variation in the parameters c, ai, bi. to\nsimplify the exposition we assume that c and bi are fixed, and that ai are known\nto lie in given ellipsoids:\n\nai \u2208 ei = {ai + piu | kuk2 \u2264 1},\n\nwhere pi \u2208 rn\u00d7n. (if pi is singular we obtain \u2018flat\u2019 ellipsoids, of dimension rank pi;\npi = 0 means that ai is known perfectly.)\nwe will require that the constraints be satisfied for all possible values of the\n\nparameters ai, which leads us to the robust linear program\n\nthe robust linear constraint, at\n\nminimize\nsubject to at\n\ni = 1, . . . , m.\n\nct x\ni x \u2264 bi for all ai \u2208 ei,\ni x \u2264 bi for all ai \u2208 ei, can be expressed as\nsup{at\n\ni x | ai \u2208 ei} \u2264 bi,\n\n(4.37)\n\nthe lefthand side of which can be expressed as\n\nsup{at\n\ni x + sup{ut p t\ni x + kp t\ni xk2.\nthus, the robust linear constraint can be expressed as\n\ni x | ai \u2208 ei} = at\n= at\n\ni x | kuk2 \u2264 1}\n\nat\ni x + kp t\n\ni xk2 \u2264 bi,\n\nwhich is evidently a second-order cone constraint. hence the robust lp (4.37) can\nbe expressed as the socp\n\nminimize\nsubject to at\n\nct x\ni x + kp t\n\ni xk2 \u2264 bi,\n\ni = 1, . . . , m.\n\nnote that the additional norm terms act as regularization terms; they prevent x\nfrom being large in directions with considerable uncertainty in the parameters ai.\n\nlinear programming with random constraints\n\nthe robust lp described above can also be considered in a statistical framework.\nhere we suppose that the parameters ai are independent gaussian random vectors,\nwith mean ai and covariance \u03c3i. we require that each constraint at\ni x \u2264 bi should\nhold with a probability (or confidence) exceeding \u03b7, where \u03b7 \u2265 0.5, i.e.,\n\nprob(at\n\ni x \u2264 bi) \u2265 \u03b7.\n\n(4.38)\n\n "}, {"Page_number": 172, "text": "158\n\n4 convex optimization problems\n\nwe will show that this probability constraint can be expressed as a second-order\ncone constraint.\n\nletting u = at\n\ni x, with \u03c32 denoting its variance, this constraint can be written\n\nas\n\nprob(cid:18) u \u2212 u\n\n\u03c3 \u2264\n\nbi \u2212 u\n\n\u03c3 (cid:19) \u2265 \u03b7.\n\nsince (u \u2212 u)/\u03c3 is a zero mean unit variance gaussian variable, the probability\nabove is simply \u03c6((bi \u2212 u)/\u03c3), where\n\n\u03c6(z) =\n\ne\u2212t2/2 dt\n\n1\n\n\u221a2\u03c0z z\n\n\u2212\u221e\n\nis the cumulative distribution function of a zero mean unit variance gaussian ran-\ndom variable. thus the probability constraint (4.38) can be expressed as\n\nbi \u2212 u\n\n\u03c3 \u2265 \u03c6\u22121(\u03b7),\n\nor, equivalently,\n\nu + \u03c6\u22121(\u03b7)\u03c3 \u2264 bi.\n\nfrom u = at\n\ni x and \u03c3 = (xt \u03c3ix)1/2 we obtain\ni x + \u03c6\u22121(\u03b7)k\u03c21/2\nat\n\ni xk2 \u2264 bi.\n\nby our assumption that \u03b7 \u2265 1/2, we have \u03c6\u22121(\u03b7) \u2265 0, so this constraint is a\nsecond-order cone constraint.\nin summary, the problem\n\nminimize\nsubject to prob(at\n\nct x\n\ni x \u2264 bi) \u2265 \u03b7,\n\ni = 1, . . . , m\n\ncan be expressed as the socp\n\nminimize\nsubject to at\n\nct x\ni x + \u03c6\u22121(\u03b7)k\u03c21/2\n\ni xk2 \u2264 bi,\n\ni = 1, . . . , m.\n\n(we will consider robust convex optimization problems in more depth in chapter 6.\nsee also exercises 4.13, 4.28, and 4.59.)\n\nexample 4.8 portfolio optimization with loss risk constraints. we consider again the\nclassical markowitz portfolio problem described above (page 155). we assume here\nthat the price change vector p \u2208 rn is a gaussian random variable, with mean p\nand covariance \u03c3. therefore the return r is a gaussian random variable with mean\nr = pt x and variance \u03c32\n\nr = xt \u03c3x.\n\nconsider a loss risk constraint of the form\n\nwhere \u03b1 is a given unwanted return level (e.g., a large loss) and \u03b2 is a given maximum\nprobability.\n\nprob(r \u2264 \u03b1) \u2264 \u03b2,\n\n(4.39)\n\n "}, {"Page_number": 173, "text": "4.4 quadratic optimization problems\n\n159\n\nas in the stochastic interpretation of the robust lp given above, we can express this\nconstraint using the cumulative distribution function \u03c6 of a unit gaussian random\nvariable. the inequality (4.39) is equivalent to\n\npt x + \u03c6\u22121(\u03b2)k\u03c21/2xk2 \u2265 \u03b1.\n\nprovided \u03b2 \u2264 1/2 (i.e., \u03c6\u22121(\u03b2) \u2264 0), this loss risk constraint is a second-order cone\nconstraint. (if \u03b2 > 1/2, the loss risk constraint becomes nonconvex in x.)\n\nthe problem of maximizing the expected return subject to a bound on the loss\nrisk (with \u03b2 \u2264 1/2), can therefore be cast as an socp with one second-order cone\nconstraint:\n\nmaximize\nsubject to\n\npt x\npt x + \u03c6\u22121(\u03b2)k\u03c21/2xk2 \u2265 \u03b1\nx (cid:23) 0,\n\n1t x = 1.\n\nthere are many extensions of this problem. for example, we can impose several loss\nrisk constraints, i.e.,\n\nprob(r \u2264 \u03b1i) \u2264 \u03b2i,\n\ni = 1, . . . , k,\n\n(where \u03b2i \u2264 1/2), which expresses the risks (\u03b2i) we are willing to accept for various\nlevels of loss (\u03b1i).\n\nminimal surface\nconsider a differentiable function f : r2 \u2192 r with dom f = c. the surface area\nof its graph is given by\n\na =zcq1 + k\u2207f (x)k2\n\n2 dx =zc k(\u2207f (x), 1)k2 dx,\n\nwhich is a convex functional of f . the minimal surface problem is to find the\nfunction f that minimizes a subject to some constraints, for example, some given\nvalues of f on the boundary of c.\n\nwe will approximate this problem by discretizing the function f . let c =\n[0, 1] \u00d7 [0, 1], and let fij denote the value of f at the point (i/k, j/k), for i, j =\n0, . . . , k. an approximate expression for the gradient of f at the point x =\n(i/k, j/k) can be found using forward differences:\n\nsubstituting this into the expression for the area of the graph, and approximating\nthe integral as a sum, we obtain an approximation for the area of the graph:\n\n\u2207f (x) \u2248 k(cid:20) fi+1,j \u2212 fi,j\nfi,j+1 \u2212 fi,j (cid:21) .\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n\uf8ee\uf8f0\n\nk\u22121xi,j=0\n\n1\nk 2\n\n1\n\nk(fi+1,j \u2212 fi,j)\nk(fi,j+1 \u2212 fi,j)\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\uf8f9\uf8fb\n\na \u2248 adisc =\n\nthe discretized area approximation adisc is a convex function of fij.\n\nwe can consider a wide variety of constraints on fij, such as equality or in-\nequality constraints on any of its entries (for example, on the boundary values), or\n\n "}, {"Page_number": 174, "text": "160\n\n4 convex optimization problems\n\non its moments. as an example, we consider the problem of finding the minimal\narea surface with fixed boundary values on the left and right edges of the square:\n\nminimize adisc\nsubject to\n\nf0j = lj,\nfkj = rj,\n\nj = 0, . . . , k\nj = 0, . . . , k\n\n(4.40)\n\nwhere fij, i, j = 0, . . . , k, are the variables, and lj, rj are the given boundary\nvalues on the left and right sides of the square.\n\nwe can transform the problem (4.40) into an socp by introducing new vari-\n\nables tij, i, j = 0, . . . , k \u2212 1:\n\ni,j=0 tij\n\nminimize\n\n(1/k 2)pk\u22121\nsubject to (cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n\uf8ee\uf8f0\n\nf0j = lj,\nfkj = rj,\n\n1\n\nk(fi+1,j \u2212 fi,j)\nk(fi,j+1 \u2212 fi,j)\n\nj = 0, . . . , k\nj = 0, . . . , k.\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\uf8f9\uf8fb\n\n\u2264 tij,\n\ni, j = 0, . . . , k \u2212 1\n\n4.5 geometric programming\n\nin this section we describe a family of optimization problems that are not convex\nin their natural form. these problems can, however, be transformed to convex op-\ntimization problems, by a change of variables and a transformation of the objective\nand constraint functions.\n\n4.5.1 monomials and posynomials\n\na function f : rn \u2192 r with dom f = rn\nf (x) = cxa1\n\n++, defined as\n2 \u00b7\u00b7\u00b7 xan\nn ,\n\n1 xa2\n\n(4.41)\n\nwhere c > 0 and ai \u2208 r, is called a monomial function, or simply, a monomial.\nthe exponents ai of a monomial can be any real numbers, including fractional or\nnegative, but the coefficient c can only be positive. (the term \u2018monomial\u2019 conflicts\nwith the standard definition from algebra, in which the exponents must be non-\nnegative integers, but this should not cause any confusion.) a sum of monomials,\ni.e., a function of the form\n\nf (x) =\n\nkxk=1\n\nckxa1k\n\n1 xa2k\n\n2\n\n\u00b7\u00b7\u00b7 xank\nn ,\n\n(4.42)\n\nwhere ck > 0, is called a posynomial function (with k terms), or simply, a posyn-\nomial.\n\n "}, {"Page_number": 175, "text": "4.5 geometric programming\n\n161\n\nposynomials are closed under addition, multiplication, and nonnegative scal-\ning. monomials are closed under multiplication and division. if a posynomial is\nmultiplied by a monomial, the result is a posynomial; similarly, a posynomial can\nbe divided by a monomial, with the result a posynomial.\n\n4.5.2 geometric programming\n\nan optimization problem of the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 1,\nhi(x) = 1,\n\ni = 1, . . . , m\ni = 1, . . . , p\n\n(4.43)\n\nwhere f0, . . . , fm are posynomials and h1, . . . , hp are monomials, is called a geomet-\nric program (gp). the domain of this problem is d = rn\n++; the constraint x \u227b 0\nis implicit.\n\nextensions of geometric programming\n\nseveral extensions are readily handled. if f is a posynomial and h is a monomial,\nthen the constraint f (x) \u2264 h(x) can be handled by expressing it as f (x)/h(x) \u2264 1\n(since f /h is posynomial). this includes as a special case a constraint of the\nform f (x) \u2264 a, where f is posynomial and a > 0. in a similar way if h1 and h2\nare both nonzero monomial functions, then we can handle the equality constraint\nh1(x) = h2(x) by expressing it as h1(x)/h2(x) = 1 (since h1/h2 is monomial). we\ncan maximize a nonzero monomial objective function, by minimizing its inverse\n(which is also a monomial).\n\nfor example, consider the problem\n\nmaximize\nsubject to\n\nx/y\n2 \u2264 x \u2264 3\nx2 + 3y/z \u2264 \u221ay\nx/y = z2,\n\nwith variables x, y, z \u2208 r (and the implicit constraint x, y, z > 0). using\nthe simple transformations described above, we obtain the equivalent standard\nform gp\n\nminimize\nsubject to\n\nx\u22121y\n2x\u22121 \u2264 1,\n(1/3)x \u2264 1\nx2y\u22121/2 + 3y1/2z\u22121 \u2264 1\nxy\u22121z\u22122 = 1.\n\nwe will refer to a problem like this one, that is easily transformed to an equiva-\nlent gp in the standard form (4.43), also as a gp. (in the same way that we refer\nto a problem easily transformed to an lp as an lp.)\n\n "}, {"Page_number": 176, "text": "162\n\n4 convex optimization problems\n\n4.5.3 geometric program in convex form\n\ngeometric programs are not (in general) convex optimization problems, but they\ncan be transformed to convex problems by a change of variables and a transforma-\ntion of the objective and constraint functions.\n\nwe will use the variables defined as yi = log xi, so xi = eyi. if f is the monomial\n\nfunction of x given in (4.41), i.e.,\n\nf (x) = cxa1\n\n1 xa2\n\n2 \u00b7\u00b7\u00b7 xan\nn ,\n\nthen\n\nf (x) = f (ey1 , . . . , eyn )\n\n= c(ey1 )a1 \u00b7\u00b7\u00b7 (eyn )an\n= eat y+b,\n\nwhere b = log c. the change of variables yi = log xi turns a monomial function\ninto the exponential of an affine function.\n\nsimilarly, if f is the posynomial given by (4.42), i.e.,\n\nf (x) =\n\nkxk=1\n\nckxa1k\n\n1 xa2k\n\n2\n\n\u00b7\u00b7\u00b7 xank\nn ,\n\nthen\n\nf (x) =\n\neat\n\nk y+bk ,\n\nkxk=1\n\nwhere ak = (a1k, . . . , ank) and bk = log ck. after the change of variables, a posyn-\nomial becomes a sum of exponentials of affine functions.\n\nthe geometric program (4.43) can be expressed in terms of the new variable y\n\nas\n\n0ky+b0k\n\nminimize pk0\nsubject to pki\n\negt\n\nk=1 eat\nk=1 eat\ni y+hi = 1,\n\niky+bik \u2264 1,\n\ni = 1, . . . , m\n\ni = 1, . . . , p,\n\nwhere aik \u2208 rn, i = 0, . . . , m, contain the exponents of the posynomial inequality\nconstraints, and gi \u2208 rn, i = 1, . . . , p, contain the exponents of the monomial\nequality constraints of the original geometric program.\nnow we transform the objective and constraint functions, by taking the loga-\n\nrithm. this results in the problem\n\nminimize\n\nsubject to\n\n\u02dcf0(y) = log(cid:16)pk0\n\u02dcfi(y) = log(cid:16)pki\n\nk=1 eat\nk=1 eat\ni y + hi = 0,\n\n\u02dchi(y) = gt\n\n0ky+b0k(cid:17)\niky+bik(cid:17) \u2264 0,\n\ni = 1, . . . , p.\n\ni = 1, . . . , m\n\n(4.44)\n\nsince the functions \u02dcfi are convex, and \u02dchi are affine, this problem is a convex\noptimization problem. we refer to it as a geometric program in convex form. to\n\n "}, {"Page_number": 177, "text": "4.5 geometric programming\n\n163\n\ndistinguish it from the original geometric program, we refer to (4.43) as a geometric\nprogram in posynomial form.\n\nnote that the transformation between the posynomial form geometric pro-\ngram (4.43) and the convex form geometric program (4.44) does not involve any\ncomputation; the problem data for the two problems are the same.\nit simply\nchanges the form of the objective and constraint functions.\n\nif the posynomial objective and constraint functions all have only one term,\ni.e., are monomials, then the convex form geometric program (4.44) reduces to a\n(general) linear program. we can therefore consider geometric programming to be\na generalization, or extension, of linear programming.\n\n4.5.4 examples\n\nfrobenius norm diagonal scaling\nconsider a matrix m \u2208 rn\u00d7n, and the associated linear function that maps u\ninto y = m u. suppose we scale the coordinates, i.e., change variables to \u02dcu = du,\n\u02dcy = dy, where d is diagonal, with dii > 0. in the new coordinates the linear\nfunction is given by \u02dcy = dm d\u22121 \u02dcu.\n\nnow suppose we want to choose the scaling in such a way that the resulting\nmatrix, dm d\u22121, is small. we will use the frobenius norm (squared) to measure\nthe size of the matrix:\n\nkdm d\u22121k2\n\nf = tr(cid:16)(cid:0)dm d\u22121(cid:1)t(cid:0)dm d\u22121(cid:1)(cid:17)\n\n=\n\n=\n\nij\n\nnxi,j=1(cid:0)dm d\u22121(cid:1)2\nnxi,j=1\n\ni /d2\nj ,\n\nijd2\n\nm 2\n\nwhere d = diag(d). since this is a posynomial in d, the problem of choosing the\nscaling d to minimize the frobenius norm is an unconstrained geometric program,\n\nminimize pn\n\ni,j=1 m 2\n\nijd2\n\ni /d2\nj ,\n\nwith variable d. the only exponents in this geometric program are 0, 2, and \u22122.\ndesign of a cantilever beam\n\nwe consider the design of a cantilever beam, which consists of n segments, num-\nbered from right to left as 1, . . . , n , as shown in figure 4.6. each segment has unit\nlength and a uniform rectangular cross-section with width wi and height hi. a\nvertical load (force) f is applied at the right end of the beam. this load causes\nthe beam to deflect (downward), and induces stress in each segment of the beam.\nwe assume that the deflections are small, and that the material is linearly elastic,\nwith young\u2019s modulus e.\n\n "}, {"Page_number": 178, "text": "164\n\n4 convex optimization problems\n\nsegment 4\n\nsegment 3\n\nsegment 2\n\nsegment 1\n\nfigure 4.6 segmented cantilever beam with 4 segments. each segment has\nunit length and a rectangular profile. a vertical force f is applied at the\nright end of the beam.\n\nf\n\nthe design variables in the problem are the widths wi and heights hi of the n\nsegments. we seek to minimize the total volume of the beam (which is proportional\nto its weight),\n\nsubject to some design constraints. we impose upper and lower bounds on width\nand height of the segments,\n\nw1h1 + \u00b7\u00b7\u00b7 + wn hn ,\n\nwmin \u2264 wi \u2264 wmax,\n\nhmin \u2264 hi \u2264 hmax,\n\ni = 1, . . . , n,\n\nas well as the aspect ratios,\n\nsmin \u2264 hi/wi \u2264 smax.\n\nin addition, we have a limit on the maximum allowable stress in the material, and\non the vertical deflection at the end of the beam.\n\nwe first consider the maximum stress constraint. the maximum stress in seg-\ni ). we impose the constraints\n\nment i, which we denote \u03c3i, is given by \u03c3i = 6if/(wih2\n\n6if\nwih2\n\ni \u2264 \u03c3max,\n\ni = 1, . . . , n,\n\nto ensure that the stress does not exceed the maximum allowable value \u03c3max any-\nwhere in the beam.\n\nthe last constraint is a limit on the vertical deflection at the end of the beam,\n\nwhich we will denote y1:\n\ny1 \u2264 ymax.\n\nthe deflection y1 can be found by a recursion that involves the deflection and slope\nof the beam segments:\n\nvi = 12(i \u2212 1/2)\n\nf\n\newih3\ni\n\n+ vi+1,\n\nyi = 6(i \u2212 1/3)\n\nf\n\newih3\ni\n\n+ vi+1 + yi+1,\n\n(4.45)\n\nfor i = n, n \u2212 1, . . . , 1, with starting values vn +1 = yn +1 = 0. in this recursion,\nyi is the deflection at the right end of segment i, and vi is the slope at that point.\nwe can use the recursion (4.45) to show that these deflection and slope quantities\n\n "}, {"Page_number": 179, "text": "4.5 geometric programming\n\n165\n\nare in fact posynomial functions of the variables w and h. we first note that vn +1\nand yn +1 are zero, and therefore posynomials. now assume that vi+1 and yi+1 are\nposynomial functions of w and h. the lefthand equation in (4.45) shows that vi is\nthe sum of a monomial and a posynomial (i.e., vi+1), and therefore is a posynomial.\nfrom the righthand equation in (4.45), we see that the deflection yi is the sum of\na monomial and two posynomials (vi+1 and yi+1), and so is a posynomial.\nin\nparticular, the deflection at the end of the beam, y1, is a posynomial.\n\nthe problem is then\n\ni=1 wihi\n\nminimize pn\n\nsubject to wmin \u2264 wi \u2264 wmax,\nhmin \u2264 hi \u2264 hmax,\nsmin \u2264 hi/wi \u2264 smax,\n6if/(wih2\ni ) \u2264 \u03c3max,\ny1 \u2264 ymax,\n\ni = 1, . . . , n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\n(4.46)\n\nwith variables w and h. this is a gp, since the objective is a posynomial, and\nthe constraints can all be expressed as posynomial inequalities. (in fact, the con-\nstraints can be all be expressed as monomial inequalities, with the exception of the\ndeflection limit, which is a complicated posynomial inequality.)\n\nwhen the number of segments n is large, the number of monomial terms ap-\npearing in the posynomial y1 grows approximately as n 2. another formulation of\nthis problem, explored in exercise 4.31, is obtained by introducing v1, . . . , vn and\ny1, . . . , yn as variables, and including a modified version of the recursion as a set\nof constraints. this formulation avoids this growth in the number of monomial\nterms.\n\nminimizing spectral radius via perron-frobenius theory\nsuppose the matrix a \u2208 rn\u00d7n is elementwise nonnegative, i.e., aij \u2265 0 for i, j =\n1, . . . , n, and irreducible, which means that the matrix (i + a)n\u22121 is elementwise\npositive. the perron-frobenius theorem states that a has a positive real eigenvalue\n\u03bbpf equal to its spectral radius, i.e., the largest magnitude of its eigenvalues. the\nperron-frobenius eigenvalue \u03bbpf determines the asymptotic rate of growth or decay\nof ak, as k \u2192 \u221e; in fact, the matrix ((1/\u03bbpf )a)k converges. roughly speaking,\nthis means that as k \u2192 \u221e, ak grows like \u03bbk\npf , if\n\u03bbpf < 1.\n\npf , if \u03bbpf > 1, or decays like \u03bbk\n\na basic result in the theory of nonnegative matrices states that the perron-\n\nfrobenius eigenvalue is given by\n\n\u03bbpf = inf{\u03bb | av (cid:22) \u03bbv for some v \u227b 0}\n\n(and moreover, that the infimum is achieved). the inequality av (cid:22) \u03bbv can be\nexpressed as\n\nnxj=1\n\naijvj/(\u03bbvi) \u2264 1,\n\ni = 1, . . . , n,\n\n(4.47)\n\nwhich is a set of posynomial inequalities in the variables aij, vi, and \u03bb. thus,\nthe condition that \u03bbpf \u2264 \u03bb can be expressed as a set of posynomial inequalities\n\n "}, {"Page_number": 180, "text": "166\n\n4 convex optimization problems\n\nin a, v, and \u03bb. this allows us to solve some optimization problems involving the\nperron-frobenius eigenvalue using geometric programming.\n\nsuppose that the entries of the matrix a are posynomial functions of some\nunderlying variable x \u2208 rk.\nin this case the inequalities (4.47) are posynomial\ninequalities in the variables x \u2208 rk, v \u2208 rn, and \u03bb \u2208 r. we consider the problem\nof choosing x to minimize the perron-frobenius eigenvalue (or spectral radius) of\na, possibly subject to posynomial inequalities on x,\n\nminimize\nsubject to\n\n\u03bbpf (a(x))\nfi(x) \u2264 1,\n\ni = 1, . . . , p,\n\nwhere fi are posynomials. using the characterization above, we can express this\nproblem as the gp\n\n\u03bb\n\nminimize\n\nsubject to pn\n\nj=1 aijvj/(\u03bbvi) \u2264 1,\ni = 1, . . . , p,\n\nfi(x) \u2264 1,\n\ni = 1, . . . , n\n\nwhere the variables are x, v, and \u03bb.\n\nas a specific example, we consider a simple model for the population dynamics\nfor a bacterium, with time or period denoted by t = 0, 1, 2, . . ., in hours. the vector\np(t) \u2208 r4\n+ characterizes the population age distribution at period t: p1(t) is the\ntotal population between 0 and 1 hours old; p2(t) is the total population between\n1 and 2 hours old; and so on. we (arbitrarily) assume that no bacteria live more\nthan 4 hours. the population propagates in time as p(t + 1) = ap(t), where\n\na =\uf8ee\uf8ef\uf8ef\uf8f0\n\nb1\ns1\n0\n0\n\nb2\n0\ns2\n0\n\nb3\n0\n0\ns3\n\nb4\n0\n0\n0\n\n\uf8f9\uf8fa\uf8fa\uf8fb .\n\nhere bi is the birth rate among bacteria in age group i, and si is the survival rate\nfrom age group i into age group i + 1. we assume that bi > 0 and 0 < si < 1,\nwhich implies that the matrix a is irreducible.\n\nthe perron-frobenius eigenvalue of a determines the asymptotic growth or\ndecay rate of the population.\nif \u03bbpf < 1, the population converges to zero like\n\u03bbt\npf , and so has a half-life of \u22121/ log2 \u03bbpf hours. if \u03bbpf > 1 the population grows\ngeometrically like \u03bbt\npf , with a doubling time of 1/ log2 \u03bbpf hours. minimizing the\nspectral radius of a corresponds to finding the fastest decay rate, or slowest growth\nrate, for the population.\n\nas our underlying variables, on which the matrix a depends, we take c1 and c2,\nthe concentrations of two chemicals in the environment that affect the birth and\nsurvival rates of the bacteria. we model the birth and survival rates as monomial\nfunctions of the two concentrations:\n\nbi = bnom\nsi = snom\n\ni\n\ni\n\n1\n\n(c1/cnom\n(c1/cnom\n\n1\n\n)\u03b1i (c2/cnom\n)\u03b3i(c2/cnom\n\n2\n\n)\u03b2i,\n)\u03b4i ,\n\n2\n\ni = 1, . . . , 4\ni = 1, . . . , 3.\n\nhere, bnom\nis nominal\nconcentration of chemical i. the constants \u03b1i, \u03b2i, \u03b3i, and \u03b4i give the effect on the\n\nis nominal survival rate, and cnom\n\nis nominal birth rate, snom\n\ni\n\ni\n\ni\n\n "}, {"Page_number": 181, "text": "4.6 generalized inequality constraints\n\n167\n\nbirth and survival rates due to changes in the concentrations of the chemicals away\nfrom the nominal values. for example \u03b12 = \u22120.3 and \u03b31 = 0.5 means that an\nincrease in concentration of chemical 1, over the nominal concentration, causes a\ndecrease in the birth rate of bacteria that are between 1 and 2 hours old, and an\nincrease in the survival rate of bacteria from 0 to 1 hours old.\n\nwe assume that the concentrations c1 and c2 can be independently increased or\ndecreased (say, within a factor of 2), by administering drugs, and pose the problem\nof finding the drug mix that maximizes the population decay rate (i.e., minimizes\n\u03bbpf (a)). using the approach described above, this problem can be posed as the\ngp\n\nminimize\nsubject to\n\n\u03bb\nb1v1 + b2v2 + b3v3 + b4v4 \u2264 \u03bbv1\ns1v1 \u2264 \u03bbv2\ns2v2 \u2264 \u03bbv3\ns3v3 \u2264 \u03bbv4\n1/2 \u2264 ci/cnom\nbi = bnom\nsi = snom\n\ni = 1, 2\n)\u03b1i (c2/cnom\n)\u03b3i (c2/cnom\n\ni \u2264 2,\n(c1/cnom\n(c1/cnom\n\n1\n\n2\n\ni\n\n2\n\n1\n\ni\n\n)\u03b2i,\n)\u03b4i ,\n\ni = 1, . . . , 4\ni = 1, . . . , 3,\n\nwith variables bi, si, ci, vi, and \u03bb.\n\n4.6 generalized inequality constraints\n\none very useful generalization of the standard form convex optimization prob-\nlem (4.15) is obtained by allowing the inequality constraint functions to be vector\nvalued, and using generalized inequalities in the constraints:\n\nminimize\nsubject to\n\nf0(x)\nfi(x) (cid:22)ki 0,\nax = b,\n\ni = 1, . . . , m\n\n(4.48)\n\nwhere f0 : rn \u2192 r, ki \u2286 rki are proper cones, and fi : rn \u2192 rki are ki-convex.\nwe refer to this problem as a (standard form) convex optimization problem with\ngeneralized inequality constraints. problem (4.15) is a special case with ki = r+,\ni = 1, . . . , m.\n\nmany of the results for ordinary convex optimization problems hold for problems\n\nwith generalized inequalities. some examples are:\n\n\u2022 the feasible set, any sublevel set, and the optimal set are convex.\n\u2022 any point that is locally optimal for the problem (4.48) is globally optimal.\n\u2022 the optimality condition for differentiable f0, given in \u00a74.2.3, holds without\n\nany change.\n\nwe will also see (in chapter 11) that convex optimization problems with generalized\ninequality constraints can often be solved as easily as ordinary convex optimization\nproblems.\n\n "}, {"Page_number": 182, "text": "168\n\n4 convex optimization problems\n\n4.6.1 conic form problems\n\namong the simplest convex optimization problems with generalized inequalities are\nthe conic form problems (or cone programs), which have a linear objective and one\ninequality constraint function, which is affine (and therefore k-convex):\n\nct x\n\nminimize\nsubject to f x + g (cid:22)k 0\n\nax = b.\n\n(4.49)\n\nwhen k is the nonnegative orthant, the conic form problem reduces to a linear\nprogram. we can view conic form problems as a generalization of linear programs\nin which componentwise inequality is replaced with a generalized linear inequality.\ncontinuing the analogy to linear programming, we refer to the conic form prob-\n\nlem\n\nct x\n\nminimize\nsubject to x (cid:23)k 0\nax = b\n\nas a conic form problem in standard form. similarly, the problem\n\nct x\n\nminimize\nsubject to f x + g (cid:22)k 0\n\nis called a conic form problem in inequality form.\n\n4.6.2 semidefinite programming\n\nwhen k is sk\nconic form problem is called a semidefinite program (sdp), and has the form\n\n+, the cone of positive semidefinite k \u00d7 k matrices, the associated\n\nct x\n\nminimize\nsubject to x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0\n\nax = b,\n\n(4.50)\n\nwhere g, f1, . . . , fn \u2208 sk, and a \u2208 rp\u00d7n. the inequality here is a linear matrix\ninequality (see example 2.10).\nif the matrices g, f1, . . . , fn are all diagonal, then the lmi in (4.50) is equiva-\nlent to a set of n linear inequalities, and the sdp (4.50) reduces to a linear program.\n\nstandard and inequality form semidefinite programs\n\nfollowing the analogy to lp, a standard form sdp has linear equality constraints,\nand a (matrix) nonnegativity constraint on the variable x \u2208 sn:\n\nminimize\nsubject to\n\ntr(cx)\ntr(aix) = bi,\nx (cid:23) 0,\n\ni = 1, . . . , p\n\n(4.51)\n\n "}, {"Page_number": 183, "text": "4.6 generalized inequality constraints\n\n169\n\nwhere c, a1, . . . , ap \u2208 sn. (recall that tr(cx) =pn\n\ni,j=1 cijxij is the form of a\ngeneral real-valued linear function on sn.) this form should be compared to the\nstandard form linear program (4.28). in lp and sdp standard forms, we minimize\na linear function of the variable, subject to p linear equality constraints on the\nvariable, and a nonnegativity constraint on the variable.\n\nan inequality form sdp, analogous to an inequality form lp (4.29), has no\n\nequality constraints, and one lmi:\n\nct x\n\nminimize\nsubject to x1a1 + \u00b7\u00b7\u00b7 + xnan (cid:22) b,\n\nwith variable x \u2208 rn, and parameters b, a1, . . . , an \u2208 sk, c \u2208 rn.\nmultiple lmis and linear inequalities\n\nit is common to refer to a problem with linear objective, linear equality and in-\nequality constraints, and several lmi constraints, i.e.,\n\nminimize\nsubject to f (i)(x) = x1f (i)\n\nct x\n\ngx (cid:22) h,\n\n1 + \u00b7\u00b7\u00b7 + xnf (i)\n\nn + g(i) (cid:22) 0,\n\nax = b,\n\ni = 1, . . . , k\n\nas an sdp as well. such problems are readily transformed to an sdp, by forming\na large block diagonal lmi from the individual lmis and linear inequalities:\n\nct x\n\nminimize\nsubject to diag(gx \u2212 h, f (1)(x), . . . , f (k)(x)) (cid:22) 0\n\nax = b.\n\n4.6.3 examples\n\nsecond-order cone programming\n\nthe socp (4.36) can be expressed as a conic form problem\n\nct x\n\nminimize\nsubject to \u2212(aix + bi, ct\n\nf x = g,\n\ni x + di) (cid:22)ki 0,\n\ni = 1, . . . , m\n\nin which\n\nki = {(y, t) \u2208 rni+1 | kyk2 \u2264 t},\n\ni.e., the second-order cone in rni+1. this explains the name second-order cone\nprogram for the optimization problem (4.36).\n\nmatrix norm minimization\nlet a(x) = a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan, where ai \u2208 rp\u00d7q. we consider the uncon-\nstrained problem\n\nminimize\n\nka(x)k2,\n\n "}, {"Page_number": 184, "text": "170\n\n4 convex optimization problems\n\nwhere k \u00b7 k2 denotes the spectral norm (maximum singular value), and x \u2208 rn is\nthe variable. this is a convex problem since ka(x)k2 is a convex function of x.\nusing the fact that kak2 \u2264 s if and only if at a (cid:22) s2i (and s \u2265 0), we can\nexpress the problem in the form\n\ns\n\nminimize\nsubject to a(x)t a(x) (cid:22) si,\n\nwith variables x and s. since the function a(x)t a(x) \u2212 si is matrix convex in\n(x, s), this is a convex optimization problem with a single q \u00d7 q matrix inequality\nconstraint.\nwe can also formulate the problem using a single linear matrix inequality of\n\nsize (p + q) \u00d7 (p + q), using the fact that\n\nat a (cid:22) t2i (and t \u2265 0) \u21d0\u21d2 (cid:20) ti\n\nat\n\na\n\nti (cid:21) (cid:23) 0.\n\n(see \u00a7a.5.5). this results in the sdp\nt\n\nminimize\n\nsubject to (cid:20)\n\nti\n\na(x)t\n\na(x)\n\nti\n\n(cid:21) (cid:23) 0\n\nin the variables x and t.\n\nmoment problems\n\nlet t be a random variable in r. the expected values e tk (assuming they exist)\nare called the (power) moments of the distribution of t. the following classical\nresults give a characterization of a moment sequence.\n\nif there is a probability distribution on r such that xk = e tk, k = 0, . . . , 2n,\n\nthen x0 = 1 and\n\nh(x0, . . . , x2n) =\n\n(cid:23) 0.\n\n(4.52)\n\nx0\nx1\nx2\n...\nxn\u22121\nxn\n\nx2\nx1\nx3\nx2\nx4\nx3\n...\n...\nxn+1\nxn\nxn+1 xn+2\n\n. . .\n. . .\n. . .\n\nxn\u22121\nxn\nxn+1\n...\n\nxn\nxn+1\nxn+2\n...\n\n. . . x2n\u22122 x2n\u22121\n. . . x2n\u22121\nx2n\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n(the matrix h is called the hankel matrix associated with x0, . . . , x2n.) this is\neasy to see: let xi = e ti, i = 0, . . . , 2n be the moments of some distribution, and\nlet y = (y0, y1, . . . yn) \u2208 rn+1. then we have\n\nyt h(x0, . . . , x2n)y =\n\nnxi,j=0\n\nyiyj e ti+j = e(y0 + y1t1 + \u00b7\u00b7\u00b7 + yntn)2 \u2265 0.\n\nthe following partial converse is less obvious: if x0 = 1 and h(x) \u227b 0, then there\nexists a probability distribution on r such that xi = e ti, i = 0, . . . , 2n. (for a\n\n "}, {"Page_number": 185, "text": "4.6 generalized inequality constraints\n\n171\n\nproof, see exercise 2.37.) now suppose that x0 = 1, and h(x) (cid:23) 0 (but possibly\nh(x) 6\u227b 0), i.e., the linear matrix inequality (4.52) holds, but possibly not strictly.\nin this case, there is a sequence of distributions on r, whose moments converge to\nx. in summary: the condition that x0, . . . , x2n be the moments of some distribution\non r (or the limit of the moments of a sequence of distributions) can be expressed\nas the linear matrix inequality (4.52) in the variable x, together with the linear\nequality x0 = 1. using this fact, we can cast some interesting problems involving\nmoments as sdps.\n\nsuppose t is a random variable on r. we do not know its distribution, but we\n\ndo know some bounds on the moments, i.e.,\n\nk \u2264 e tk \u2264 \u00b5k,\n\u00b5\n\nk = 1, . . . , 2n\n\n(which includes, as a special case, knowing exact values of some of the moments).\nlet p(t) = c0 + c1t + \u00b7\u00b7\u00b7 + c2nt2n be a given polynomial in t. the expected value\nof p(t) is linear in the moments e ti:\n\ne p(t) =\n\nci e ti =\n\n2nxi=0\n\ncixi.\n\n2nxi=0\n\nwe can compute upper and lower bounds for e p(t),\n\nminimize (maximize) e p(t)\nsubject to\n\nk \u2264 e tk \u2264 \u00b5k,\n\u00b5\n\nk = 1, . . . , 2n,\n\nover all probability distributions that satisfy the given moment bounds, by solving\nthe sdp\n\nminimize (maximize)\nsubject to\n\nc1x1 + \u00b7\u00b7\u00b7 + c2nx2n\nk \u2264 xk \u2264 \u00b5k,\n\u00b5\nh(1, x1, . . . , x2n) (cid:23) 0\n\nk = 1, . . . , 2n\n\nwith variables x1, . . . , x2n. this gives bounds on e p(t), over all probability dis-\ntributions that satisfy the known moment constraints. the bounds are sharp in\nthe sense that there exists a sequence of distributions, whose moments satisfy the\ngiven moment bounds, for which e p(t) converges to the upper and lower bounds\nfound by these sdps.\n\nbounding portfolio risk with incomplete covariance information\n\nwe consider once again the setup for the classical markowitz portfolio problem (see\npage 155). we have a portfolio of n assets or stocks, with xi denoting the amount\nof asset i that is held over some investment period, and pi denoting the relative\nprice change of asset i over the period. the change in total value of the portfolio\nis pt x. the price change vector p is modeled as a random vector, with mean and\ncovariance\n\np = e p,\n\n\u03c3 = e(p \u2212 p)(p \u2212 p)t .\n\nthe change in value of the portfolio is therefore a random variable with mean pt x\nand standard deviation \u03c3 = (xt \u03c3x)1/2. the risk of a large loss, i.e., a change\nin portfolio value that is substantially below its expected value, is directly related\n\n "}, {"Page_number": 186, "text": "172\n\n4 convex optimization problems\n\nto the standard deviation \u03c3, and increases with it. for this reason the standard\ndeviation \u03c3 (or the variance \u03c32) is used as a measure of the risk associated with\nthe portfolio.\n\nin the classical portfolio optimization problem, the portfolio x is the optimiza-\ntion variable, and we minimize the risk subject to a minimum mean return and\nother constraints. the price change statistics p and \u03c3 are known problem param-\neters. in the risk bounding problem considered here, we turn the problem around:\nwe assume the portfolio x is known, but only partial information is available about\nthe covariance matrix \u03c3. we might have, for example, an upper and lower bound\non each entry:\n\nlij \u2264 \u03c3ij \u2264 uij,\n\ni, j = 1, . . . , n,\n\nwhere l and u are given. we now pose the question: what is the maximum risk\nfor our portfolio, over all covariance matrices consistent with the given bounds?\nwe define the worst-case variance of the portfolio as\n\n\u03c32\nwc = sup{xt \u03c3x | lij \u2264 \u03c3ij \u2264 uij, i, j = 1, . . . , n, \u03c3 (cid:23) 0}.\n\nwe have added the condition \u03c3 (cid:23) 0, which the covariance matrix must, of course,\nsatisfy.\n\nwe can find \u03c3wc by solving the sdp\n\nxt \u03c3x\n\nmaximize\nsubject to lij \u2264 \u03c3ij \u2264 uij,\n\n\u03c3 (cid:23) 0\n\ni, j = 1, . . . , n\n\nwith variable \u03c3 \u2208 sn (and problem parameters x, l, and u ). the optimal \u03c3 is\nthe worst covariance matrix consistent with our given bounds on the entries, where\n\u2018worst\u2019 means largest risk with the (given) portfolio x. we can easily construct\na distribution for p that is consistent with the given bounds, and achieves the\nworst-case variance, from an optimal \u03c3 for the sdp. for example, we can take\np = p + \u03c31/2v, where v is any random vector with e v = 0 and e vvt = i.\n\nevidently we can use the same method to determine \u03c3wc for any prior informa-\n\ntion about \u03c3 that is convex. we list here some examples.\n\n\u2022 known variance of certain portfolios. we might have equality constraints\n\nsuch as\n\nk \u03c3uk = \u03c32\nut\nk,\n\nwhere uk and \u03c3k are given. this corresponds to prior knowledge that certain\nknown portfolios (given by uk) have known (or very accurately estimated)\nvariance.\n\n\u2022 including effects of estimation error. if the covariance \u03c3 is estimated from\nempirical data, the estimation method will give an estimate \u02c6\u03c3, and some in-\nformation about the reliability of the estimate, such as a confidence ellipsoid.\nthis can be expressed as\n\nwhere c is a positive definite quadratic form on sn, and the constant \u03b1\ndetermines the confidence level.\n\nc(\u03c3 \u2212 \u02c6\u03c3) \u2264 \u03b1,\n\n "}, {"Page_number": 187, "text": "4.6 generalized inequality constraints\n\n173\n\n\u2022 factor models. the covariance might have the form\n\n\u03c3 = f \u03c3factorf t + d,\n\nwhere f \u2208 rn\u00d7k, \u03c3factor \u2208 sk, and d is diagonal. this corresponds to a\nmodel of the price changes of the form\n\np = f z + d,\n\nwhere z is a random variable (the underlying factors that affect the price\nchanges) and di are independent (additional volatility of each asset price).\nwe assume that the factors are known. since \u03c3 is linearly related to \u03c3factor\nand d, we can impose any convex constraint on them (representing prior\ninformation) and still compute \u03c3wc using convex optimization.\n\n\u2022 information about correlation coefficients. in the simplest case, the diagonal\nentries of \u03c3 (i.e., the volatilities of each asset price) are known, and bounds\non correlation coefficients between price changes are known:\n\nlij \u2264 \u03c1ij =\n\n\u03c3ij\n\u03c31/2\nii \u03c31/2\n\njj\n\n\u2264 uij,\n\ni, j = 1, . . . , n.\n\nsince \u03c3ii are known, but \u03c3ij for i 6= j are not, these are linear inequalities.\n\nfastest mixing markov chain on a graph\n\nwe consider an undirected graph, with nodes 1, . . . , n, and a set of edges\n\ne \u2286 {1, . . . , n} \u00d7 {1, . . . , n}.\n\nhere (i, j) \u2208 e means that nodes i and j are connected by an edge. since the\ngraph is undirected, e is symmetric: (i, j) \u2208 e if and only if (j, i) \u2208 e. we allow\nthe possibility of self-loops, i.e., we can have (i, i) \u2208 e.\nwe define a markov chain, with state x(t) \u2208 {1, . . . , n}, for t \u2208 z+ (the set\nof nonnegative integers), as follows. with each edge (i, j) \u2208 e we associate a\nprobability pij, which is the probability that x makes a transition between nodes\ni and j. state transitions can only occur across edges; we have pij = 0 for (i, j) 6\u2208 e.\nthe probabilities associated with the edges must be nonnegative, and for each node,\nthe sum of the probabilities of links connected to the node (including a self-loop,\nif there is one) must equal one.\n\nthe markov chain has transition probability matrix\n\npij = prob(x(t + 1) = i | x(t) = j),\n\ni, j = 1, . . . , n.\n\nthis matrix must satisfy\n\npij \u2265 0,\n\nand also\n\ni, j = 1, . . . , n,\n\n1t p = 1t ,\n\np = p t ,\n\n(4.53)\n\npij = 0 for (i, j) 6\u2208 e.\n\n(4.54)\n\n "}, {"Page_number": 188, "text": "174\n\n4 convex optimization problems\n\nsince p is symmetric and 1t p = 1t , we conclude p 1 = 1, so the uniform\ndistribution (1/n)1 is an equilibrium distribution for the markov chain. conver-\ngence of the distribution of x(t) to (1/n)1 is determined by the second largest (in\nmagnitude) eigenvalue of p , i.e., by r = max{\u03bb2,\u2212\u03bbn}, where\n\n1 = \u03bb1 \u2265 \u03bb2 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn\n\nare the eigenvalues of p . we refer to r as the mixing rate of the markov chain.\nif r = 1, then the distribution of x(t) need not converge to (1/n)1 (which means\nthe markov chain does not mix). when r < 1, the distribution of x(t) approaches\n(1/n)1 asymptotically as rt, as t \u2192 \u221e. thus, the smaller r is, the faster the\nmarkov chain mixes.\nthe fastest mixing markov chain problem is to find p , subject to the con-\nstraints (4.53) and (4.54), that minimizes r. (the problem data is the graph, i.e.,\ne.) we will show that this problem can be formulated as an sdp.\nsince the eigenvalue \u03bb1 = 1 is associated with the eigenvector 1, we can express\nthe mixing rate as the norm of the matrix p , restricted to the subspace 1\u22a5: r =\nkqp qk2, where q = i\u2212(1/n)11t is the matrix representing orthogonal projection\non 1\u22a5. using the property p 1 = 1, we have\n\nr = kqp qk2\n\n= k(i \u2212 (1/n)11t )p (i \u2212 (1/n)11t )k2\n= kp \u2212 (1/n)11tk2.\n\nthis shows that the mixing rate r is a convex function of p , so the fastest mixing\nmarkov chain problem can be cast as the convex optimization problem\n\nkp \u2212 (1/n)11tk2\nminimize\nsubject to p 1 = 1\npij \u2265 0,\npij = 0 for (i, j) 6\u2208 e,\n\ni, j = 1, . . . , n\n\nwith variable p \u2208 sn. we can express the problem as an sdp by introducing a\nscalar variable t to bound the norm of p \u2212 (1/n)11t :\n\nt\n\nminimize\nsubject to \u2212ti (cid:22) p \u2212 (1/n)11t (cid:22) ti\ni, j = 1, . . . , n\n\np 1 = 1\npij \u2265 0,\npij = 0 for (i, j) 6\u2208 e.\n\n(4.55)\n\n4.7 vector optimization\n\n4.7.1 general and convex vector optimization problems\n\nin \u00a74.6 we extended the standard form problem (4.1) to include vector-valued\nconstraint functions. in this section we investigate the meaning of a vector-valued\n\n "}, {"Page_number": 189, "text": "4.7 vector optimization\n\n175\n\nobjective function. we denote a general vector optimization problem as\n\nminimize (with respect to k)\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\n(4.56)\n\nhere x \u2208 rn is the optimization variable, k \u2286 rq is a proper cone, f0 : rn \u2192 rq\nis the objective function, fi : rn \u2192 r are the inequality constraint functions, and\nhi : rn \u2192 r are the equality constraint functions. the only difference between this\nproblem and the standard optimization problem (4.1) is that here, the objective\nfunction takes values in rq, and the problem specification includes a proper cone\nk, which is used to compare objective values. in the context of vector optimization,\nthe standard optimization problem (4.1) is sometimes called a scalar optimization\nproblem.\n\nwe say the vector optimization problem (4.56) is a convex vector optimization\nproblem if the objective function f0 is k-convex, the inequality constraint functions\nf1, . . . , fm are convex, and the equality constraint functions h1, . . . , hp are affine.\n(as in the scalar case, we usually express the equality constraints as ax = b, where\na \u2208 rp\u00d7n.)\nwhat meaning can we give to the vector optimization problem (4.56)? suppose\nx and y are two feasible points (i.e., they satisfy the constraints). their associated\nobjective values, f0(x) and f0(y), are to be compared using the generalized inequal-\nity (cid:22)k. we interpret f0(x) (cid:22)k f0(y) as meaning that x is \u2018better than or equal\u2019 in\nvalue to y (as judged by the objective f0, with respect to k). the confusing aspect\nof vector optimization is that the two objective values f0(x) and f0(y) need not be\ncomparable; we can have neither f0(x) (cid:22)k f0(y) nor f0(y) (cid:22)k f0(x), i.e., neither\nis better than the other. this cannot happen in a scalar objective optimization\nproblem.\n\n4.7.2 optimal points and values\n\nwe first consider a special case, in which the meaning of the vector optimization\nproblem is clear. consider the set of objective values of feasible points,\n\no = {f0(x) | \u2203x \u2208 d, fi(x) \u2264 0, i = 1, . . . , m, hi(x) = 0, i = 1, . . . , p} \u2286 rq,\n\nwhich is called the set of achievable objective values. if this set has a minimum\nelement (see \u00a72.4.2), i.e., there is a feasible x such that f0(x) (cid:22)k f0(y) for all\nfeasible y, then we say x is optimal for the problem (4.56), and refer to f0(x) as\nthe optimal value of the problem. (when a vector optimization problem has an\noptimal value, it is unique.) if x\u22c6 is an optimal point, then f0(x\u22c6), the objective\nat x\u22c6, can be compared to the objective at every other feasible point, and is better\nthan or equal to it. roughly speaking, x\u22c6 is unambiguously a best choice for x,\namong feasible points.\n\na point x\u22c6 is optimal if and only if it is feasible and\n\no \u2286 f0(x\u22c6) + k\n\n(4.57)\n\n "}, {"Page_number": 190, "text": "176\n\n4 convex optimization problems\n\no\n\nf0(x\u22c6)\n\nfigure 4.7 the set o of achievable values for a vector optimization with\nobjective values in r2, with cone k = r2\n+, is shown shaded. in this case,\nthe point labeled f0(x\u22c6) is the optimal value of the problem, and x\u22c6 is an\noptimal point. the objective value f0(x\u22c6) can be compared to every other\nachievable value f0(y), and is better than or equal to f0(y). (here, \u2018better\nthan or equal to\u2019 means \u2018is below and to the left of\u2019.) the lightly shaded\nregion is f0(x\u22c6)+k, which is the set of all z \u2208 r2 corresponding to objective\nvalues worse than (or equal to) f0(x\u22c6).\n\n(see \u00a72.4.2). the set f0(x\u22c6) + k can be interpreted as the set of values that are\nworse than, or equal to, f0(x\u22c6), so the condition (4.57) states that every achievable\nvalue falls in this set. this is illustrated in figure 4.7. most vector optimization\nproblems do not have an optimal point and an optimal value, but this does occur\nin some special cases.\n\nexample 4.9 best linear unbiased estimator. suppose y = ax + v, where v \u2208 rm is\na measurement noise, y \u2208 rm is a vector of measurements, and x \u2208 rn is a vector to\nbe estimated, given the measurement y. we assume that a has rank n, and that the\nmeasurement noise satisfies e v = 0, e vvt = i, i.e., its components are zero mean\nand uncorrelated.\n\na linear estimator of x has the formbx = f y. the estimator is called unbiased if for\nall x we have ebx = x, i.e., if f a = i. the error covariance of an unbiased estimator\n\nis\n\nour goal is to find an unbiased estimator that has a \u2018small\u2019 error covariance matrix.\nwe can compare error covariances using matrix inequality, i.e., with respect to sn\n+.\n\ne(bx \u2212 x)(bx \u2212 x)t = e f vvt f t = f f t .\n\nthis has the following interpretation: supposebx1 = f1y,bx2 = f2y are two unbiased\n\nestimators. then the first estimator is at least as good as the second, i.e., f1f t\nf2f t\n\n2 , if and only if for all c,\n\n1 (cid:22)\n\nin other words, for any linear function of x, the estimator f1 yields at least as good\nan estimate as does f2.\n\ne(ctbx1 \u2212 ct x)2 \u2264 e(ctbx2 \u2212 ct x)2.\n\n "}, {"Page_number": 191, "text": "4.7 vector optimization\n\n177\n\nwe can express the problem of finding an unbiased estimator for x as the vector\noptimization problem\n\nminimize (w.r.t. sn\nsubject to\n\n+) f f t\n\nf a = i,\n\n(4.58)\n\nwith variable f \u2208 rn\u00d7m. the objective f f t is convex with respect to sn\n+, so the\nproblem (4.58) is a convex vector optimization problem. an easy way to see this is\nto observe that vt f f t v = kf t vk2\n2 is a convex function of f for any fixed v.\nit is a famous result that the problem (4.58) has an optimal solution, the least-squares\nestimator, or pseudo-inverse,\n\nf \u22c6 = a\u2020 = (at a)\u22121at .\n\nfor any f with f a = i, we have f f t (cid:23) f \u22c6f \u22c6t . the matrix\n\nf \u22c6f \u22c6t = a\u2020a\u2020t = (at a)\u22121\n\nis the optimal value of the problem (4.58).\n\n4.7.3 pareto optimal points and values\n\nwe now consider the case (which occurs in most vector optimization problems of\ninterest) in which the set of achievable objective values does not have a minimum\nelement, so the problem does not have an optimal point or optimal value. in these\ncases minimal elements of the set of achievable values play an important role. we\nsay that a feasible point x is pareto optimal (or efficient) if f0(x) is a minimal\nelement of the set of achievable values o.\nin this case we say that f0(x) is a\npareto optimal value for the vector optimization problem (4.56). thus, a point x\nis pareto optimal if it is feasible and, for any feasible y, f0(y) (cid:22)k f0(x) implies\nf0(y) = f0(x). in other words: any feasible point y that is better than or equal to\nx (i.e., f0(y) (cid:22)k f0(x)) has exactly the same objective value as x.\n\na point x is pareto optimal if and only if it is feasible and\n\n(f0(x) \u2212 k) \u2229 o = {f0(x)}\n\n(4.59)\n\n(see \u00a72.4.2). the set f0(x) \u2212 k can be interpreted as the set of values that are\nbetter than or equal to f0(x), so the condition (4.59) states that the only achievable\nvalue better than or equal to f0(x) is f0(x) itself. this is illustrated in figure 4.8.\na vector optimization problem can have many pareto optimal values (and\n\npoints). the set of pareto optimal values, denoted p, satisfies\n\np \u2286 o \u2229 bdo,\n\ni.e., every pareto optimal value is an achievable objective value that lies in the\nboundary of the set of achievable objective values (see exercise 4.52).\n\n "}, {"Page_number": 192, "text": "178\n\n4 convex optimization problems\n\no\n\nf0(xpo)\n\nfigure 4.8 the set o of achievable values for a vector optimization problem\nwith objective values in r2, with cone k = r2\n+, is shown shaded. this\nproblem does not have an optimal point or value, but it does have a set of\npareto optimal points, whose corresponding values are shown as the dark-\nened curve on the lower left boundary of o. the point labeled f0(xpo)\nis a pareto optimal value, and xpo is a pareto optimal point. the lightly\nshaded region is f0(xpo) \u2212 k, which is the set of all z \u2208 r2 corresponding\nto objective values better than (or equal to) f0(xpo).\n\n4.7.4 scalarization\n\nscalarization is a standard technique for finding pareto optimal (or optimal) points\nfor a vector optimization problem, based on the characterization of minimum and\nminimal points via dual generalized inequalities given in \u00a72.6.3. choose any \u03bb \u227bk \u2217\n0, i.e., any vector that is positive in the dual generalized inequality. now consider\nthe scalar optimization problem\n\nminimize\nsubject to\n\n\u03bbt f0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.60)\n\nand let x be an optimal point. then x is pareto optimal for the vector optimization\nproblem (4.56). this follows from the dual inequality characterization of minimal\npoints given in \u00a72.6.3, and is also easily shown directly. if x were not pareto optimal,\nthen there is a y that is feasible, satisfies f0(y) (cid:22)k f0(x), and f0(x) 6= f0(y).\nsince f0(x) \u2212 f0(y) (cid:23)k 0 and is nonzero, we have \u03bbt (f0(x) \u2212 f0(y)) > 0, i.e.,\n\u03bbt f0(x) > \u03bbt f0(y). this contradicts the assumption that x is optimal for the\nscalar problem (4.60).\n\nusing scalarization, we can find pareto optimal points for any vector opti-\nmization problem by solving the ordinary scalar optimization problem (4.60). the\nvector \u03bb, which is sometimes called the weight vector, must satisfy \u03bb \u227bk \u2217 0. the\nweight vector is a free parameter; by varying it we obtain (possibly) different pareto\noptimal solutions of the vector optimization problem (4.56). this is illustrated in\nfigure 4.9. the figure also shows an example of a pareto optimal point that cannot\n\n "}, {"Page_number": 193, "text": "4.7 vector optimization\n\n179\n\no\n\nf0(x1)\n\n\u03bb1\n\nf0(x3)\n\n\u03bb2\n\nf0(x2)\n\nfigure 4.9 scalarization. the set o of achievable values for a vector opti-\nmization problem with cone k = r2\n+. three pareto optimal values f0(x1),\nf0(x2), f0(x3) are shown. the first two values can be obtained by scalar-\nization: f0(x1) minimizes \u03bbt\n2 u,\nwhere \u03bb1, \u03bb2 \u227b 0. the value f0(x3) is pareto optimal, but cannot be found\nby scalarization.\n\n1 u over all u \u2208 o and f0(x2) minimizes \u03bbt\n\nbe obtained via scalarization, for any value of the weight vector \u03bb \u227bk \u2217 0.\nthe method of scalarization can be interpreted geometrically. a point x is\noptimal for the scalarized problem, i.e., minimizes \u03bbt f0 over the feasible set, if\nand only if \u03bbt (f0(y) \u2212 f0(x)) \u2265 0 for all feasible y. but this is the same as saying\nthat {u | \u2212 \u03bbt (u \u2212 f0(x)) = 0} is a supporting hyperplane to the set of achievable\nobjective values o at the point f0(x); in particular\n\n{u | \u03bbt (u \u2212 f0(x)) < 0} \u2229 o = \u2205.\n\n(4.61)\n\n(see figure 4.9.) thus, when we find an optimal point for the scalarized problem, we\nnot only find a pareto optimal point for the original vector optimization problem;\nwe also find an entire halfspace in rq, given by (4.61), of objective values that\ncannot be achieved.\n\nscalarization of convex vector optimization problems\n\nnow suppose the vector optimization problem (4.56) is convex. then the scalarized\nproblem (4.60) is also convex, since \u03bbt f0 is a (scalar-valued) convex function (by\nthe results in \u00a73.6). this means that we can find pareto optimal points of a convex\nvector optimization problem by solving a convex scalar optimization problem. for\neach choice of the weight vector \u03bb \u227bk \u2217 0 we get a (usually different) pareto optimal\npoint.\nfor convex vector optimization problems we have a partial converse: for every\npareto optimal point xpo, there is some nonzero \u03bb (cid:23)k \u2217 0 such that xpo is a solution\nof the scalarized problem (4.60). so, roughly speaking, for convex problems the\nmethod of scalarization yields all pareto optimal points, as the weight vector \u03bb\n\n "}, {"Page_number": 194, "text": "180\n\n4 convex optimization problems\n\nvaries over the k \u2217-nonnegative, nonzero values. we have to be careful here, because\nit is not true that every solution of the scalarized problem, with \u03bb (cid:23)k \u2217 0 and \u03bb 6= 0,\nis a pareto optimal point for the vector problem. (in contrast, every solution of\nthe scalarized problem with \u03bb \u227bk \u2217 0 is pareto optimal.)\nin some cases we can use this partial converse to find all pareto optimal points\nof a convex vector optimization problem. scalarization with \u03bb \u227bk \u2217 0 gives a set\nof pareto optimal points (as it would in a nonconvex vector optimization problem\nas well). to find the remaining pareto optimal solutions, we have to consider\nnonzero weight vectors \u03bb that satisfy \u03bb (cid:23)k \u2217 0. for each such weight vector, we\nfirst identify all solutions of the scalarized problem. then among these solutions we\nmust check which are, in fact, pareto optimal for the vector optimization problem.\nthese \u2018extreme\u2019 pareto optimal points can also be found as the limits of the pareto\noptimal points obtained from positive weight vectors.\n\nto establish this partial converse, we consider the set\n\na = o + k = {t \u2208 rq | f0(x) (cid:22)k t for some feasible x},\n\n(4.62)\n\nwhich consists of all values that are worse than or equal to (with respect to (cid:22)k)\nsome achievable objective value. while the set o of achievable objective values\nneed not be convex, the set a is convex, when the problem is convex. moreover,\nthe minimal elements of a are exactly the same as the minimal elements of the\nset o of achievable values, i.e., they are the same as the pareto optimal values.\n(see exercise 4.53.) now we use the results of \u00a72.6.3 to conclude that any minimal\nelement of a minimizes \u03bbt z over a for some nonzero \u03bb (cid:23)k \u2217 0. this means that\nevery pareto optimal point for the vector optimization problem is optimal for the\nscalarized problem, for some nonzero weight \u03bb (cid:23)k \u2217 0.\n\nexample 4.10 minimal upper bound on a set of matrices. we consider the (convex)\nvector optimization problem, with respect to the positive semidefinite cone,\n\nminimize (w.r.t. sn\nsubject to\n\n+) x\n\nx (cid:23) ai,\n\ni = 1, . . . , m,\n\n(4.63)\n\nwhere ai \u2208 sn, i = 1, . . . , m, are given. the constraints mean that x is an upper\nbound on the given matrices a1, . . . , am; a pareto optimal solution of (4.63) is a\nminimal upper bound on the matrices.\nto find a pareto optimal point, we apply scalarization: we choose any w \u2208 sn\nform the problem\n\n++ and\n\nminimize\ntr(w x)\nsubject to x (cid:23) ai,\n\ni = 1, . . . , m,\n\n(4.64)\n\nwhich is an sdp. different choices for w will, in general, give different minimal\nsolutions.\n\nthe partial converse tells us that if x is pareto optimal for the vector problem (4.63)\nthen it is optimal for the sdp (4.64), for some nonzero weight matrix w (cid:23) 0.\n(in this case, however, not every solution of (4.64) is pareto optimal for the vector\noptimization problem.)\n\nwe can give a simple geometric interpretation for this problem. we associate with\neach a \u2208 sn\n\n++ an ellipsoid centered at the origin, given by\n\nea = {u | ut a\u22121u \u2264 1},\n\n "}, {"Page_number": 195, "text": "4.7 vector optimization\n\n181\n\nx2\n\nx1\n\nfigure 4.10 geometric interpretation of the problem (4.63). the three\nshaded ellipsoids correspond to the data a1, a2, a3 \u2208 s2\n++; the pareto\noptimal points correspond to minimal ellipsoids that contain them. the two\nellipsoids, with boundaries labeled x1 and x2, show two minimal ellipsoids\nobtained by solving the sdp (4.64) for two different weight matrices w1 and\nw2.\n\nso that a (cid:22) b if and only if ea \u2286 eb. a pareto optimal point x for the prob-\nlem (4.63) corresponds to a minimal ellipsoid that contains the ellipsoids associated\nwith a1, . . . , am. an example is shown in figure 4.10.\n\n4.7.5 multicriterion optimization\n\nwhen a vector optimization problem involves the cone k = rq\n+, it is called a\nmulticriterion or multi-objective optimization problem. the components of f0,\nsay, f1, . . . , fq, can be interpreted as q different scalar objectives, each of which\nwe would like to minimize. we refer to fi as the ith objective of the problem. a\nmulticriterion optimization problem is convex if f1, . . . , fm are convex, h1, . . . , hp\nare affine, and the objectives f1, . . . , fq are convex.\n\nsince multicriterion problems are vector optimization problems, all of the ma-\nterial of \u00a74.7.1\u2013\u00a74.7.4 applies. for multicriterion problems, though, we can be a\nbit more specific in the interpretations. if x is feasible, we can think of fi(x) as\nits score or value, according to the ith objective.\nif x and y are both feasible,\nfi(x) \u2264 fi(y) means that x is at least as good as y, according to the ith objective;\nfi(x) < fi(y) means that x is better than y, or x beats y, according to the ith ob-\njective. if x and y are both feasible, we say that x is better than y, or x dominates\ny, if fi(x) \u2264 fi(y) for i = 1, . . . , q, and for at least one j, fj(x) < fj(y). roughly\nspeaking, x is better than y if x meets or beats y on all objectives, and beats it in\nat least one objective.\n\nin a multicriterion problem, an optimal point x\u22c6 satisfies\n\nfi(x\u22c6) \u2264 fi(y),\n\ni = 1, . . . , q,\n\n "}, {"Page_number": 196, "text": "182\n\n4 convex optimization problems\n\nfor every feasible y. in other words, x\u22c6 is simultaneously optimal for each of the\nscalar problems\n\nminimize\nsubject to\n\nfj(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nfor j = 1, . . . , q. when there is an optimal point, we say that the objectives are\nnoncompeting, since no compromises have to be made among the objectives; each\nobjective is as small as it could be made, even if the others were ignored.\n\na pareto optimal point xpo satisfies the following: if y is feasible and fi(y) \u2264\nfi(xpo) for i = 1, . . . , q, then fi(xpo) = fi(y), i = 1, . . . , q. this can be restated\nas: a point is pareto optimal if and only if it is feasible and there is no better\nfeasible point. in particular, if a feasible point is not pareto optimal, there is at\nleast one other feasible point that is better. in searching for good points, then, we\ncan clearly limit our search to pareto optimal points.\n\ntrade-off analysis\n\nnow suppose that x and y are pareto optimal points with, say,\n\nfi(x) < fi(y),\nfi(x) = fi(y),\nfi(x) > fi(y),\n\ni \u2208 a\ni \u2208 b\ni \u2208 c,\n\nwhere a\u222a b\u222a c = {1, . . . , q}. in other words, a is the set of (indices of) objectives\nfor which x beats y, b is the set of objectives for which the points x and y are tied,\nand c is the set of objectives for which y beats x. if a and c are empty, then\nthe two points x and y have exactly the same objective values. if this is not the\ncase, then both a and c must be nonempty. in other words, when comparing two\npareto optimal points, they either obtain the same performance (i.e., all objectives\nequal), or, each beats the other in at least one objective.\n\nin comparing the point x to y, we say that we have traded or traded off better\nobjective values for i \u2208 a for worse objective values for i \u2208 c. optimal trade-off\nanalysis (or just trade-off analysis) is the study of how much worse we must do\nin one or more objectives in order to do better in some other objectives, or more\ngenerally, the study of what sets of objective values are achievable.\n\nas an example, consider a bi-criterion (i.e., two criterion) problem. suppose\nx is a pareto optimal point, with objectives f1(x) and f2(x). we might ask how\nmuch larger f2(z) would have to be, in order to obtain a feasible point z with\nf1(z) \u2264 f1(x)\u2212 a, where a > 0 is some constant. roughly speaking, we are asking\nhow much we must pay in the second objective to obtain an improvement of a in\nthe first objective. if a large increase in f2 must be accepted to realize a small\ndecrease in f1, we say that there is a strong trade-off between the objectives, near\nthe pareto optimal value (f1(x), f2(x)). if, on the other hand, a large decrease\nin f1 can be obtained with only a small increase in f2, we say that the trade-off\nbetween the objectives is weak (near the pareto optimal value (f1(x), f2(x))).\n\nwe can also consider the case in which we trade worse performance in the first\nobjective for an improvement in the second. here we find how much smaller f2(z)\n\n "}, {"Page_number": 197, "text": "4.7 vector optimization\n\n183\n\ncan be made, to obtain a feasible point z with f1(z) \u2264 f1(x) + a, where a > 0\nis some constant. in this case we receive a benefit in the second objective, i.e., a\nreduction in f2 compared to f2(x). if this benefit is large (i.e., by increasing f1\na small amount we obtain a large reduction in f2), we say the objectives exhibit\na strong trade-off. if it is small, we say the objectives trade off weakly (near the\npareto optimal value (f1(x), f2(x))).\n\noptimal trade-off surface\n\nthe set of pareto optimal values for a multicriterion problem is called the optimal\ntrade-off surface (in general, when q > 2) or the optimal trade-off curve (when\nq = 2). (since it would be foolish to accept any point that is not pareto optimal,\nwe can restrict our trade-off analysis to pareto optimal points.) trade-off analysis\nis also sometimes called exploring the optimal trade-off surface. (the optimal trade-\noff surface is usually, but not always, a surface in the usual sense. if the problem\nhas an optimal point, for example, the optimal trade-off surface consists of a single\npoint, the optimal value.)\n\nan optimal trade-off curve is readily interpreted. an example is shown in\nfigure 4.11, on page 185, for a (convex) bi-criterion problem. from this curve we\ncan easily visualize and understand the trade-offs between the two objectives.\n\n\u2022 the endpoint at the right shows the smallest possible value of f2, without\n\nany consideration of f1.\n\n\u2022 the endpoint at the left shows the smallest possible value of f1, without any\n\nconsideration of f2.\n\n\u2022 by finding the intersection of the curve with a vertical line at f1 = \u03b1, we can\n\nsee how large f2 must be to achieve f1 \u2264 \u03b1.\n\n\u2022 by finding the intersection of the curve with a horizontal line at f2 = \u03b2, we\n\ncan see how large f1 must be to achieve f2 \u2264 \u03b2.\n\n\u2022 the slope of the optimal trade-off curve at a point on the curve (i.e., a pareto\noptimal value) shows the local optimal trade-off between the two objectives.\nwhere the slope is steep, small changes in f1 are accompanied by large\nchanges in f2.\n\n\u2022 a point of large curvature is one where small decreases in one objective can\nonly be accomplished by a large increase in the other. this is the prover-\nbial knee of the trade-off curve, and in many applications represents a good\ncompromise solution.\n\nall of these have simple extensions to a trade-off surface, although visualizing a\nsurface with more than three objectives is difficult.\n\nscalarizing multicriterion problems\n\nwhen we scalarize a multicriterion problem by forming the weighted sum objective\n\n\u03bbt f0(x) =\n\n\u03bbifi(x),\n\nqxi=1\n\n "}, {"Page_number": 198, "text": "184\n\n4 convex optimization problems\n\nwhere \u03bb \u227b 0, we can interpret \u03bbi as the weight we attach to the ith objective.\nthe weight \u03bbi can be thought of as quantifying our desire to make fi small (or\nour objection to having fi large).\nin particular, we should take \u03bbi large if we\nwant fi to be small; if we care much less about fi, we can take \u03bbi small. we can\ninterpret the ratio \u03bbi/\u03bbj as the relative weight or relative importance of the ith\nobjective compared to the jth objective. alternatively, we can think of \u03bbi/\u03bbj as\nexchange rate between the two objectives, since in the weighted sum objective a\ndecrease (say) in fi by \u03b1 is considered the same as an increase in fj in the amount\n(\u03bbi/\u03bbj)\u03b1.\n\nthese interpretations give us some intuition about how to set or change the\nweights while exploring the optimal trade-off surface. suppose, for example, that\nthe weight vector \u03bb \u227b 0 yields the pareto optimal point xpo, with objective values\nf1(xpo), . . . , fq(xpo). to find a (possibly) new pareto optimal point which trades\noff a better kth objective value (say), for (possibly) worse objective values for the\nother objectives, we form a new weight vector \u02dc\u03bb with\n\n\u02dc\u03bbk > \u03bbk,\n\n\u02dc\u03bbj = \u03bbj,\n\nj 6= k,\n\nj = 1, . . . , q,\n\ni.e., we increase the weight on the kth objective. this yields a new pareto optimal\npoint \u02dcxpo with fk(\u02dcxpo) \u2264 fk(xpo) (and usually, fk(\u02dcxpo) < fk(xpo)), i.e., a new\npareto optimal point with an improved kth objective.\nwe can also see that at any point where the optimal trade-off surface is smooth,\n\u03bb gives the inward normal to the surface at the associated pareto optimal point.\nin particular, when we choose a weight vector \u03bb and apply scalarization, we obtain\na pareto optimal point where \u03bb gives the local trade-offs among objectives.\n\nin practice, optimal trade-off surfaces are explored by ad hoc adjustment of the\nweights, based on the intuitive ideas above. we will see later (in chapter 5) that\nthe basic idea of scalarization, i.e., minimizing a weighted sum of objectives, and\nthen adjusting the weights to obtain a suitable solution, is the essence of duality.\n\n4.7.6 examples\n\nregularized least-squares\nwe are given a \u2208 rm\u00d7n and b \u2208 rm, and want to choose x \u2208 rn taking into\naccount two quadratic objectives:\n\n\u2022 f1(x) = kax \u2212 bk2\nbetween ax and b,\n\n2 = xt at ax \u2212 2bt ax + bt b is a measure of the misfit\n\n\u2022 f2(x) = kxk2\n\n2 = xt x is a measure of the size of x.\n\nour goal is to find x that gives a good fit (i.e., small f1) and that is not large (i.e.,\nsmall f2). we can formulate this problem as a vector optimization problem with\nrespect to the cone r2\n\n+, i.e., a bi-criterion problem (with no constraints):\n\nminimize (w.r.t. r2\n\n+)\n\nf0(x) = (f1(x), f2(x)).\n\n "}, {"Page_number": 199, "text": "4.7 vector optimization\n\n185\n\n15\n\n10\n\n22\nk\nx\nk\n=\n)\nx\n(\n2\nf\n\n5\n\n0\n0\n\n10\n5\nf1(x) = kax \u2212 bk2\n\n2\n\n15\n\nfigure 4.11 optimal trade-off curve for a regularized least-squares problem.\nthe shaded set is the set of achievable values (kax\u2212bk2\n2). the optimal\ntrade-off curve, shown darker, is the lower left part of the boundary.\n\n2,kxk2\n\nwe can scalarize this problem by taking \u03bb1 > 0 and \u03bb2 > 0 and minimizing the\nscalar weighted sum objective\n\n\u03bbt f0(x) = \u03bb1f1(x) + \u03bb2f2(x)\n\n= xt (\u03bb1at a + \u03bb2i)x \u2212 2\u03bb1bt ax + \u03bb1bt b,\n\nwhich yields\n\nx(\u00b5) = (\u03bb1at a + \u03bb2i)\u22121\u03bb1at b = (at a + \u00b5i)\u22121at b,\n\nwhere \u00b5 = \u03bb2/\u03bb1. for any \u00b5 > 0, this point is pareto optimal for the bi-criterion\nproblem. we can interpret \u00b5 = \u03bb2/\u03bb1 as the relative weight we assign f2 compared\nto f1.\n\nthis method produces all pareto optimal points, except two, associated with\nthe extremes \u00b5 \u2192 \u221e and \u00b5 \u2192 0. in the first case we have the pareto optimal\nsolution x = 0, which would be obtained by scalarization with \u03bb = (0, 1). at the\nother extreme we have the pareto optimal solution a\u2020b, where a\u2020 is the pseudo-\ninverse of a. this pareto optimal solution is obtained as the limit of the optimal\nsolution of the scalarized problem as \u00b5 \u2192 0, i.e., as \u03bb \u2192 (1, 0). (we will encounter\nthe regularized least-squares problem again in \u00a76.3.2.)\nfigure 4.11 shows the optimal trade-off curve and the set of achievable values\nfor a regularized least-squares problem with problem data a \u2208 r100\u00d710, b \u2208 r100.\n(see exercise 4.50 for more discussion.)\n\nrisk-return trade-off in portfolio optimization\n\nthe classical markowitz portfolio optimization problem described on page 155 is\nnaturally expressed as a bi-criterion problem, where the objectives are the negative\n\n "}, {"Page_number": 200, "text": "186\n\n4 convex optimization problems\n\nmean return (since we wish to maximize mean return) and the variance of the\nreturn:\n\nminimize (w.r.t. r2\nsubject to\n\n+)\n\n(f1(x), f2(x)) = (\u2212pt x, xt \u03c3x)\n1t x = 1,\n\nx (cid:23) 0.\n\nin forming the associated scalarized problem, we can (without loss of generality)\ntake \u03bb1 = 1 and \u03bb2 = \u00b5 > 0:\n\nminimize \u2212pt x + \u00b5xt \u03c3x\nsubject to 1t x = 1,\n\nx (cid:23) 0,\n\nwhich is a qp. in this example too, we get all pareto optimal portfolios except for\nthe two limiting cases corresponding to \u00b5 \u2192 0 and \u00b5 \u2192 \u221e. roughly speaking, in\nthe first case we get a maximum mean return, without regard for return variance;\nin the second case we form a minimum variance return, without regard for mean\nreturn. assuming that pk > pi for i 6= k, i.e., that asset k is the unique asset with\nmaximum mean return, the portfolio allocation x = ek is the only one correspond-\ning to \u00b5 \u2192 0. (in other words, we concentrate the portfolio entirely in the asset\nthat has maximum mean return.) in many portfolio problems asset n corresponds\nto a risk-free investment, with (deterministic) return rrf . assuming that \u03c3, with its\nlast row and column (which are zero) removed, is full rank, then the other extreme\npareto optimal portfolio is x = en, i.e., the portfolio is concentrated entirely in the\nrisk-free asset.\n\nas a specific example, we consider a simple portfolio optimization problem with\n4 assets, with price change mean and standard deviations given in the following\ntable.\n\nasset\n\n1\n2\n3\n4\n\n\u03c31/2\npi\nii\n12% 20%\n10% 10%\n5%\n7%\n3%\n0%\n\nasset 4 is a risk-free asset, with a (certain) 3% return. assets 3, 2, and 1 have\nincreasing mean returns, ranging from 7% to 12%, as well as increasing standard\ndeviations, which range from 5% to 20%. the correlation coefficients between the\nassets are \u03c112 = 30%, \u03c113 = \u221240%, and \u03c123 = 0%.\nfigure 4.12 shows the optimal trade-off curve for this portfolio optimization\nproblem. the plot is given in the conventional way, with the horizontal axis show-\ning standard deviation (i.e., squareroot of variance) and the vertical axis showing\nexpected return. the lower plot shows the optimal asset allocation vector x for\neach pareto optimal point.\n\nthe results in this simple example agree with our intuition. for small risk,\nthe optimal allocation consists mostly of the risk-free asset, with a mixture of the\nother assets in smaller quantities. note that a mixture of asset 3 and asset 1, which\nare negatively correlated, gives some hedging, i.e., lowers variance for a given level\nof mean return. at the other end of the trade-off curve, we see that aggressive\ngrowth portfolios (i.e., those with large mean returns) concentrate the allocation\nin assets 1 and 2, the ones with the largest mean returns (and variances).\n\n "}, {"Page_number": 201, "text": "4.7 vector optimization\n\n187\n\n15%\n\n10%\n\n5%\n\nn\nr\nu\nt\ne\nr\n\nn\na\ne\nm\n\n0%\n\n0%\n\n1\n\nn\no\ni\nt\na\nc\no\nl\nl\na\n\n0.5\n\n0\n\n0%\n\n10%\n\n20%\n\nx(4)\n\nx(3)\n\nx(2)\n\nx(1)\n\n10%\n\n20%\n\nstandard deviation of return\n\nfigure 4.12 top. optimal risk-return trade-off curve for a simple portfolio\noptimization problem. the lefthand endpoint corresponds to putting all\nresources in the risk-free asset, and so has zero standard deviation. the\nrighthand endpoint corresponds to putting all resources in asset 1, which\nhas highest mean return. bottom. corresponding optimal allocations.\n\n "}, {"Page_number": 202, "text": "188\n\n4 convex optimization problems\n\nbibliography\n\nlinear programming has been studied extensively since the 1940s, and is the subject of\nmany excellent books, including dantzig [dan63], luenberger [lue84], schrijver [sch86],\npapadimitriou and steiglitz [ps98], bertsimas and tsitsiklis [bt97], vanderbei [van96],\nand roos, terlaky, and vial [rtv97]. dantzig and schrijver also provide detailed ac-\ncounts of the history of linear programming. for a recent survey, see todd [tod02].\n\nschaible [sch82, sch83] gives an overview of fractional programming, which includes\nlinear-fractional problems and extensions such as convex-concave fractional problems (see\nexercise 4.7). the model of a growing economy in example 4.7 appears in von neumann\n[vn46].\n\nresearch on quadratic programming began in the 1950s (see, e.g., frank and wolfe\n[fw56], markowitz [mar56], hildreth [hil57]), and was in part motivated by the portfo-\nlio optimization problem discussed on page 155 (markowitz [mar52]), and the lp with\nrandom cost discussed on page 154 (see freund [fre56]).\n\ninterest in second-order cone programming is more recent, and started with nesterov\nand nemirovski [nn94, \u00a76.2.3]. the theory and applications of socps are surveyed by\nalizadeh and goldfarb [ag03], ben-tal and nemirovski [btn01, lecture 3] (where the\nproblem is referred to as conic quadratic programming), and lobo, vandenberghe, boyd,\nand lebret [lvbl98].\n\nrobust linear programming, and robust convex optimization in general, originated with\nben-tal and nemirovski [btn98, btn99] and el ghaoui and lebret [el97]. goldfarb\nand iyengar [gi03a, gi03b] discuss robust qcqps and applications in portfolio optimiza-\ntion. el ghaoui, oustry, and lebret [eol98] focus on robust semidefinite programming.\n\ngeometric programming has been known since the 1960s. its use in engineering design\nwas first advocated by duffin, peterson, and zener [dpz67] and zener [zen71]. peterson\n[pet76] and ecker [eck80] describe the progress made during the 1970s. these articles\nand books also include examples of engineering applications, in particular in chemical\nand civil engineering. fishburn and dunlop [fd85], sapatnekar, rao, vaidya, and kang\n[srvk93], and hershenson, boyd, and lee [hbl01]) apply geometric programming to\nproblems in integrated circuit design. the cantilever beam design example (page 163)\nis from vanderplaats [van84, page 147]. the variational characterization of the perron-\nfrobenius eigenvalue (page 165) is proved in berman and plemmons [bp94, page 31].\n\nnesterov and nemirovski [nn94, chapter 4] introduced the conic form problem (4.49)\nas a standard problem format in nonlinear convex optimization. the cone programming\napproach is further developed in ben-tal and nemirovski [btn01], who also describe\nnumerous applications.\nalizadeh [ali91] and nesterov and nemirovski [nn94, \u00a76.4] were the first to make a\nsystematic study of semidefinite programming, and to point out the wide variety of\napplications in convex optimization. subsequent research in semidefinite programming\nduring the 1990s was driven by applications in combinatorial optimization (goemans\nand williamson [gw95]), control (boyd, el ghaoui, feron, and balakrishnan [befb94],\nscherer, gahinet, and chilali [sgc97], dullerud and paganini [dp00]), communications\nand signal processing (luo [luo03], davidson, luo, wong, and ma [dlw00, mdw+02]),\nand other areas of engineering. the book edited by wolkowicz, saigal, and vandenberghe\n[wsv00] and the articles by todd [tod01], lewis and overton [lo96], and vandenberghe\nand boyd [vb95] provide overviews and extensive bibliographies. connections between\nsdp and moment problems, of which we give a simple example on page 170, are explored\nin detail by bertsimas and sethuraman [bs00], nesterov [nes00], and lasserre [las02].\nthe fastest mixing markov chain problem is from boyd, diaconis, and xiao [bdx04].\n\nmulticriterion optimization and pareto optimality are fundamental tools in economics;\nsee pareto [par71], debreu [deb59] and luenberger [lue95]. the result in example 4.9 is\nknown as the gauss-markov theorem (kailath, sayed, and hassibi [ksh00, page 97]).\n\n "}, {"Page_number": 203, "text": "189\n\nexercises\n\nexercises\n\nbasic terminology and optimality conditions\n\n4.1 consider the optimization problem\n\nminimize\nsubject to\n\nf0(x1, x2)\n2x1 + x2 \u2265 1\nx1 + 3x2 \u2265 1\nx1 \u2265 0,\n\nx2 \u2265 0.\n\nmake a sketch of the feasible set. for each of the following objective functions, give the\noptimal set and the optimal value.\n\n(a) f0(x1, x2) = x1 + x2.\n(b) f0(x1, x2) = \u2212x1 \u2212 x2.\n(c) f0(x1, x2) = x1.\n(d) f0(x1, x2) = max{x1, x2}.\n(e) f0(x1, x2) = x2\n\n1 + 9x2\n2.\n\n4.2 consider the optimization problem\n\nminimize\n\nf0(x) = \u2212pm\n\ni=1 log(bi \u2212 at\n\ni x)\n\nwith domain dom f0 = {x | ax \u227a b}, where a \u2208 rm\u00d7n (with rows at\ndom f0 is nonempty.\nprove the following facts (which include the results quoted without proof on page 141).\n\ni ). we assume that\n\n(a) dom f0 is unbounded if and only if there exists a v 6= 0 with av (cid:22) 0.\n(b) f0 is unbounded below if and only if there exists a v with av (cid:22) 0, av 6= 0. hint.\nthere exists a v such that av (cid:22) 0, av 6= 0 if and only if there exists no z \u227b 0\nsuch that at z = 0. this follows from the theorem of alternatives in example 2.21,\npage 50.\n\n(c) if f0 is bounded below then its minimum is attained, i.e., there exists an x that\n\nsatisfies the optimality condition (4.23).\n\n(d) the optimal set is affine: xopt = {x\u22c6 + v | av = 0}, where x\u22c6 is any optimal point.\n\n4.3 prove that x\u22c6 = (1, 1/2,\u22121) is optimal for the optimization problem\n\n(1/2)xt p x + qt x + r\n\nminimize\nsubject to \u22121 \u2264 xi \u2264 1,\n\ni = 1, 2, 3,\n\nwhere\n\np =\" 13\n\n12\n\u22122\n\n12 \u22122\n17\n6\n6\n\n12 # ,\n\n13.0 # ,\nq =\" \u221222.0\n\n\u221214.5\n\nr = 1.\n\n4.4 [p. parrilo] symmetries and convex optimization. suppose g = {q1, . . . , qk} \u2286 rn\u00d7n is a\ngroup, i.e., closed under products and inverse. we say that the function f : rn \u2192 r is g-\ninvariant, or symmetric with respect to g, if f (qix) = f (x) holds for all x and i = 1, . . . , k.\ni=1 qix, which is the average of x over its g-orbit. we define the\nfixed subspace of g as\n\nwe define x = (1/k)pk\n\nf = {x | qix = x, i = 1, . . . , k}.\n\n(a) show that for any x \u2208 rn, we have x \u2208 f .\n\n "}, {"Page_number": 204, "text": "190\n\n4 convex optimization problems\n\n(b) show that if f : rn \u2192 r is convex and g-invariant, then f (x) \u2264 f (x).\n(c) we say the optimization problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m\n\nis g-invariant if the objective f0 is g-invariant, and the feasible set is g-invariant,\nwhich means\n\nf1(x) \u2264 0, . . . , fm(x) \u2264 0 =\u21d2 f1(qix) \u2264 0, . . . , fm(qix) \u2264 0,\n\nfor i = 1, . . . , k. show that if the problem is convex and g-invariant, and there exists\nan optimal point, then there exists an optimal point in f . in other words, we can\nadjoin the equality constraints x \u2208 f to the problem, without loss of generality.\n\n(d) as an example, suppose f is convex and symmetric, i.e., f (p x) = f (x) for every\npermutation p . show that if f has a minimizer, then it has a minimizer of the form\n\u03b11. (this means to minimize f over x \u2208 rn, we can just as well minimize f (t1)\nover t \u2208 r.)\n\n4.5 equivalent convex problems. show that the following three convex problems are equiva-\nlent. carefully explain how the solution of each problem is obtained from the solution of\nthe other problems. the problem data are the matrix a \u2208 rm\u00d7n (with rows at\ni ), the\nvector b \u2208 rm, and the constant m > 0.\n(a) the robust least-squares problem\n\nwith variable x \u2208 rn, where \u03c6 : r \u2192 r is defined as\n\ni=1 \u03c6(at\n\ni x \u2212 bi),\n\nminimize pm\n\u03c6(u) =(cid:26) u2\n\nm (2|u| \u2212 m )\n\n|u| \u2264 m\n|u| > m.\n\n(this function is known as the huber penalty function; see \u00a76.1.2.)\n\n(b) the least-squares problem with variable weights\n\nminimize pm\n\nsubject to w (cid:23) 0,\n\ni=1(at\n\ni x \u2212 bi)2/(wi + 1) + m 21t w\n\nwith variables x \u2208 rn and w \u2208 rm, and domain d = {(x, w) \u2208 rn\u00d7rm | w \u227b \u22121}.\nhint. optimize over w assuming x is fixed, to establish a relation with the problem\nin part (a).\n(this problem can be interpreted as a weighted least-squares problem in which we\nare allowed to adjust the weight of the ith residual. the weight is one if wi = 0, and\ndecreases if we increase wi. the second term in the objective penalizes large values\nof w, i.e., large adjustments of the weights.)\n\n(c) the quadratic program\n\nminimize pm\n\nsubject to \u2212u \u2212 v (cid:22) ax \u2212 b (cid:22) u + v\n\ni=1(u2\n\ni + 2m vi)\n\n0 (cid:22) u (cid:22) m 1\nv (cid:23) 0.\n\n "}, {"Page_number": 205, "text": "exercises\n\n191\n\n4.6 handling convex equality constraints. a convex optimization problem can have only linear\nequality constraint functions.\nin some special cases, however, it is possible to handle\nconvex equality constraint functions, i.e., constraints of the form h(x) = 0, where h is\nconvex. we explore this idea in this problem.\nconsider the optimization problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nh(x) = 0,\n\ni = 1, . . . , m\n\n(4.65)\n\nwhere fi and h are convex functions with domain rn. unless h is affine, this is not a\nconvex optimization problem. consider the related problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nh(x) \u2264 0,\n\ni = 1, . . . , m,\n\n(4.66)\n\nwhere the convex equality constraint has been relaxed to a convex inequality. this prob-\nlem is, of course, convex.\nnow suppose we can guarantee that at any optimal solution x\u22c6 of the convex prob-\nlem (4.66), we have h(x\u22c6) = 0, i.e., the inequality h(x) \u2264 0 is always active at the solution.\nthen we can solve the (nonconvex) problem (4.65) by solving the convex problem (4.66).\nshow that this is the case if there is an index r such that\n\n\u2022 f0 is monotonically increasing in xr\n\u2022 f1, . . . , fm are nondecreasing in xr\n\u2022 h is monotonically decreasing in xr.\n\nwe will see specific examples in exercises 4.31 and 4.58.\n\n4.7 convex-concave fractional problems. consider a problem of the form\n\nminimize\nsubject to\n\nf0(x)/(ct x + d)\nfi(x) \u2264 0,\nax = b\n\ni = 1, . . . , m\n\nwhere f0, f1, . . . , fm are convex, and the domain of the objective function is defined as\n{x \u2208 dom f0 | ct x + d > 0}.\n(a) show that this is a quasiconvex optimization problem.\n\n(b) show that the problem is equivalent to\n\nminimize\nsubject to\n\ng0(y, t)\ngi(y, t) \u2264 0,\nay = bt\nct y + dt = 1,\n\ni = 1, . . . , m\n\nwhere gi is the perspective of fi (see \u00a73.2.6). the variables are y \u2208 rn and t \u2208 r.\nshow that this problem is convex.\n\n(c) following a similar argument, derive a convex formulation for the convex-concave\n\nfractional problem\n\nminimize\nsubject to\n\nf0(x)/h(x)\nfi(x) \u2264 0,\nax = b\n\ni = 1, . . . , m\n\n "}, {"Page_number": 206, "text": "192\n\n4 convex optimization problems\n\nwhere f0, f1, . . . , fm are convex, h is concave, the domain of the objective function\nis defined as {x \u2208 dom f0 \u2229 dom h | h(x) > 0} and f0(x) \u2265 0 everywhere.\nas an example, apply your technique to the (unconstrained) problem with\n\nf0(x) = (tr f (x))/m,\n\nh(x) = (det(f (x))1/m,\n\nwith dom(f0/h) = {x | f (x) \u227b 0}, where f (x) = f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn for given\nfi \u2208 sm. in this problem, we minimize the ratio of the arithmetic mean over the\ngeometric mean of the eigenvalues of an affine matrix function f (x).\n\nlinear optimization problems\n\n4.8 some simple lps. give an explicit solution of each of the following lps.\n\n(a) minimizing a linear function over an affine set.\n\nminimize\nsubject to ax = b.\n\nct x\n\n(b) minimizing a linear function over a halfspace.\n\nminimize\nsubject to\n\nct x\nat x \u2264 b,\n\nwhere a 6= 0.\n\n(c) minimizing a linear function over a rectangle.\n\nminimize\nsubject to\n\nct x\nl (cid:22) x (cid:22) u,\n\nwhere l and u satisfy l (cid:22) u.\n\n(d) minimizing a linear function over the probability simplex.\n\nminimize\nsubject to 1t x = 1,\n\nct x\n\nx (cid:23) 0.\n\nwhat happens if the equality constraint is replaced by an inequality 1t x \u2264 1?\nwe can interpret this lp as a simple portfolio optimization problem. the vector\nx represents the allocation of our total budget over different assets, with xi the\nfraction invested in asset i. the return of each investment is fixed and given by \u2212ci,\nso our total return (which we want to maximize) is \u2212ct x. if we replace the budget\nconstraint 1t x = 1 with an inequality 1t x \u2264 1, we have the option of not investing\na portion of the total budget.\n\n(e) minimizing a linear function over a unit box with a total budget constraint.\n\nminimize\nsubject to 1t x = \u03b1,\n\nct x\n\n0 (cid:22) x (cid:22) 1,\n\nwhere \u03b1 is an integer between 0 and n. what happens if \u03b1 is not an integer (but\nsatisfies 0 \u2264 \u03b1 \u2264 n)? what if we change the equality to an inequality 1t x \u2264 \u03b1?\n(f) minimizing a linear function over a unit box with a weighted budget constraint.\n\nminimize\nsubject to\n\nct x\ndt x = \u03b1,\n\n0 (cid:22) x (cid:22) 1,\n\nwith d \u227b 0, and 0 \u2264 \u03b1 \u2264 1t d.\n\n "}, {"Page_number": 207, "text": "exercises\n\n193\n\n4.9 square lp. consider the lp\n\nwith a square and nonsingular. show that the optimal value is given by\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\np\u22c6 =(cid:26) ct a\u22121b a\u2212t c (cid:22) 0\n\notherwise.\n\n\u2212\u221e\n\n4.10 converting general lp to standard form. work out the details on page 147 of \u00a74.3.\nexplain in detail the relation between the feasible sets, the optimal solutions, and the\noptimal values of the standard form lp and the original lp.\n\n4.11 problems involving \u21131- and \u2113\u221e-norms. formulate the following problems as lps. explain\nin detail the relation between the optimal solution of each problem and the solution of its\nequivalent lp.\n(a) minimize kax \u2212 bk\u221e (\u2113\u221e-norm approximation).\n(b) minimize kax \u2212 bk1 (\u21131-norm approximation).\n(c) minimize kax \u2212 bk1 subject to kxk\u221e \u2264 1.\n(d) minimize kxk1 subject to kax \u2212 bk\u221e \u2264 1.\n(e) minimize kax \u2212 bk1 + kxk\u221e.\nin each problem, a \u2208 rm\u00d7n and b \u2208 rm are given. (see \u00a76.1 for more problems involving\napproximation and constrained approximation.)\n4.12 network flow problem. consider a network of n nodes, with directed links connecting each\npair of nodes. the variables in the problem are the flows on each link: xij will denote the\nflow from node i to node j. the cost of the flow along the link from node i to node j is\ngiven by cijxij, where cij are given constants. the total cost across the network is\n\nc =\n\nnxi,j=1\n\ncijxij.\n\neach link flow xij is also subject to a given lower bound lij (usually assumed to be\nnonnegative) and an upper bound uij.\nthe external supply at node i is given by bi, where bi > 0 means an external flow enters\nthe network at node i, and bi < 0 means that at node i, an amount |bi| flows out of the\nnetwork. we assume that 1t b = 0, i.e., the total external supply equals total external\ndemand. at each node we have conservation of flow: the total flow into node i along links\nand the external supply, minus the total flow out along the links, equals zero.\nthe problem is to minimize the total cost of flow through the network, subject to the\nconstraints described above. formulate this problem as an lp.\n\n4.13 robust lp with interval coefficients. consider the problem, with variable x \u2208 rn,\n\nct x\n\nminimize\nsubject to ax (cid:22) b for all a \u2208 a,\n\nwhere a \u2286 rm\u00d7n is the set\n\na = {a \u2208 rm\u00d7n | \u00afaij \u2212 vij \u2264 aij \u2264 \u00afaij + vij, i = 1, . . . , m, j = 1, . . . , n}.\n\n(the matrices \u00afa and v are given.) this problem can be interpreted as an lp where each\ncoefficient of a is only known to lie in an interval, and we require that x must satisfy the\nconstraints for all possible values of the coefficients.\nexpress this problem as an lp. the lp you construct should be efficient, i.e., it should\nnot have dimensions that grow exponentially with n or m.\n\n "}, {"Page_number": 208, "text": "194\n\n4 convex optimization problems\n\n4.14 approximating a matrix in infinity norm. the \u2113\u221e-norm induced norm of a matrix a \u2208\n\nrm\u00d7n, denoted kak\u221e, is given by\n\nkak\u221e = sup\n\nx6=0\n\nkaxk\u221e\nkxk\u221e\n\n= max\n\ni=1,...,m\n\nnxj=1\n\n|aij|.\n\nthis norm is sometimes called the max-row-sum norm, for obvious reasons (see \u00a7a.1.5).\nconsider the problem of approximating a matrix, in the max-row-sum norm, by a linear\ncombination of other matrices. that is, we are given k + 1 matrices a0, . . . , ak \u2208 rm\u00d7n,\nand need to find x \u2208 rk that minimizes\n\nka0 + x1a1 + \u00b7\u00b7\u00b7 + xkakk\u221e.\n\nexpress this problem as a linear program. explain the significance of any extra variables\nin your lp. carefully explain how your lp formulation solves this problem, e.g., what is\nthe relation between the feasible set for your lp and this problem?\n\n4.15 relaxation of boolean lp. in a boolean linear program, the variable x is constrained to\n\nhave components equal to zero or one:\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\nxi \u2208 {0, 1},\n\ni = 1, . . . , n.\n\n(4.67)\n\nin general, such problems are very difficult to solve, even though the feasible set is finite\n(containing at most 2n points).\nin a general method called relaxation, the constraint that xi be zero or one is replaced\nwith the linear inequalities 0 \u2264 xi \u2264 1:\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\n0 \u2264 xi \u2264 1,\n\ni = 1, . . . , n.\n\n(4.68)\n\nwe refer to this problem as the lp relaxation of the boolean lp (4.67). the lp relaxation\nis far easier to solve than the original boolean lp.\n\n(a) show that the optimal value of the lp relaxation (4.68) is a lower bound on the\noptimal value of the boolean lp (4.67). what can you say about the boolean lp\nif the lp relaxation is infeasible?\n\n(b) it sometimes happens that the lp relaxation has a solution with xi \u2208 {0, 1}. what\n\ncan you say in this case?\n\n4.16 minimum fuel optimal control. we consider a linear dynamical system with state x(t) \u2208\nrn, t = 0, . . . , n , and actuator or input signal u(t) \u2208 r, for t = 0, . . . , n \u2212 1. the\ndynamics of the system is given by the linear recurrence\n\nx(t + 1) = ax(t) + bu(t),\n\nt = 0, . . . , n \u2212 1,\n\nwhere a \u2208 rn\u00d7n and b \u2208 rn are given. we assume that the initial state is zero, i.e.,\nx(0) = 0.\nthe minimum fuel optimal control problem is to choose the inputs u(0), . . . , u(n \u2212 1) so\nas to minimize the total fuel consumed, which is given by\n\nf =\n\nn \u22121xt=0\n\nf (u(t)),\n\n "}, {"Page_number": 209, "text": "exercises\n\n195\n\nsubject to the constraint that x(n ) = xdes, where n is the (given) time horizon, and\nxdes \u2208 rn is the (given) desired final or target state. the function f : r \u2192 r is the fuel\nuse map for the actuator, and gives the amount of fuel used as a function of the actuator\nsignal amplitude. in this problem we use\n\nf (a) =(cid:26) |a|\n\n2|a| \u2212 1\n\n|a| \u2264 1\n|a| > 1.\n\nthis means that fuel use is proportional to the absolute value of the actuator signal, for\nactuator signals between \u22121 and 1; for larger actuator signals the marginal fuel efficiency\nis half.\nformulate the minimum fuel optimal control problem as an lp.\n\n4.17 optimal activity levels. we consider the selection of n nonnegative activity levels, denoted\nx1, . . . , xn. these activities consume m resources, which are limited. activity j consumes\naijxj of resource i, where aij are given. the total resource consumption is additive, so\nj=1 aijxj. (ordinarily we have aij \u2265 0, i.e.,\nactivity j consumes resource i. but we allow the possibility that aij < 0, which means\nthat activity j actually generates resource i as a by-product.) each resource consumption\nis limited: we must have ci \u2264 cmax\nare given. each activity generates revenue,\nwhich is a piecewise-linear concave function of the activity level:\n\nthe total of resource i consumed is ci =pn\n\n, where cmax\n\ni\n\ni\n\nrj(xj) =(cid:26) pjxj\n\npjqj + pdisc\n\nj\n\n0 \u2264 xj \u2264 qj\n\n(xj \u2212 qj) xj \u2265 qj.\n\nhere pj > 0 is the basic price, qj > 0 is the quantity discount level, and pdisc\nquantity discount price, for (the product of) activity j. (we have 0 < pdisc\n\nis the\nj < pj.) the\nj=1 rj(xj).\nthe goal is to choose activity levels that maximize the total revenue while respecting the\nresource limits. show how to formulate this problem as an lp.\n\ntotal revenue is the sum of the revenues associated with each activity, i.e.,pn\n\nj\n\n4.18 separating hyperplanes and spheres. suppose you are given two sets of points in rn,\n{v1, v2, . . . , vk} and {w1, w2, . . . , wl}. formulate the following two problems as lp fea-\nsibility problems.\n(a) determine a hyperplane that separates the two sets, i.e., find a \u2208 rn and b \u2208 r\n\nwith a 6= 0 such that\n\nat vi \u2264 b,\n\ni = 1, . . . , k,\n\nat wi \u2265 b,\n\ni = 1, . . . , l.\n\nnote that we require a 6= 0, so you have to make sure that your formulation excludes\nthe trivial solution a = 0, b = 0. you can assume that\n\nrank(cid:20) v1\n\n1\n\nv2\n1\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\nvk w1 w2\n1\n1\n\n1\n\n\u00b7\u00b7\u00b7 wl\n\u00b7\u00b7\u00b7\n\n1 (cid:21) = n + 1\n\n(i.e., the affine hull of the k + l points has dimension n).\n\n(b) determine a sphere separating the two sets of points, i.e., find xc \u2208 rn and r \u2265 0\n\nsuch that\n\nkvi \u2212 xck2 \u2264 r,\n\ni = 1, . . . , k,\n\nkwi \u2212 xck2 \u2265 r,\n\ni = 1, . . . , l.\n\n(here xc is the center of the sphere; r is its radius.)\n\n(see chapter 8 for more on separating hyperplanes, separating spheres, and related topics.)\n\n "}, {"Page_number": 210, "text": "196\n\n4 convex optimization problems\n\n4.19 consider the problem\n\nminimize\nsubject to\n\nkax \u2212 bk1/(ct x + d)\nkxk\u221e \u2264 1,\n\nwhere a \u2208 rm\u00d7n, b \u2208 rm, c \u2208 rn, and d \u2208 r. we assume that d > kck1, which implies\nthat ct x + d > 0 for all feasible x.\n\n(a) show that this is a quasiconvex optimization problem.\n(b) show that it is equivalent to the convex optimization problem\n\nminimize\nsubject to\n\nkay \u2212 btk1\nkyk\u221e \u2264 t\nct y + dt = 1,\n\nwith variables y \u2208 rn, t \u2208 r.\n\n4.20 power assignment in a wireless communication system. we consider n transmitters with\npowers p1, . . . , pn \u2265 0, transmitting to n receivers. these powers are the optimization\nvariables in the problem. we let g \u2208 rn\u00d7n denote the matrix of path gains from the\ntransmitters to the receivers; gij \u2265 0 is the path gain from transmitter j to receiver i.\nthe signal power at receiver i is then si = giipi, and the interference power at receiver i\n\nis ii =pk6=i gikpk. the signal to interference plus noise ratio, denoted sinr, at receiver\n\ni, is given by si/(ii + \u03c3i), where \u03c3i > 0 is the (self-) noise power in receiver i. the\nobjective in the problem is to maximize the minimum sinr ratio, over all receivers, i.e.,\nto maximize\n\nsi\n\nmin\n\ni=1,...,n\n\n.\n\nii + \u03c3i\n\ni\n\n, where p max\n\nthere are a number of constraints on the powers that must be satisfied, in addition to the\nobvious one pi \u2265 0. the first is a maximum allowable power for each transmitter, i.e.,\npi \u2264 p max\n> 0 is given. in addition, the transmitters are partitioned into\ngroups, with each group sharing the same power supply, so there is a total power constraint\nfor each group of transmitter powers. more precisely, we have subsets k1, . . . , km of\n{1, . . . , n} with k1 \u222a \u00b7\u00b7\u00b7 \u222a km = {1, . . . , n}, and kj \u2229 kl = 0 if j 6= l. for each group kl,\nthe total associated transmitter power cannot exceed p gp\n\ni\n\nl > 0:\n\nfinally, we have a limit p rc\n\nk > 0 on the total received power at each receiver:\n\nxk\u2208kl\nnxk=1\n\npk \u2264 p gp\n\nl\n\n,\n\nl = 1, . . . , m.\n\ngikpk \u2264 p rc\ni ,\n\ni = 1, . . . , n.\n\n(this constraint reflects the fact that the receivers will saturate if the total received power\nis too large.)\nformulate the sinr maximization problem as a generalized linear-fractional program.\n\nquadratic optimization problems\n\n4.21 some simple qcqps. give an explicit solution of each of the following qcqps.\n\n(a) minimizing a linear function over an ellipsoid centered at the origin.\n\nct x\n\nminimize\nsubject to xt ax \u2264 1,\n\nwhere a \u2208 sn\n(a 6\u2208 sn\n\n+)?\n\n++ and c 6= 0. what is the solution if the problem is not convex\n\n "}, {"Page_number": 211, "text": "exercises\n\n197\n\n(b) minimizing a linear function over an ellipsoid.\n\nminimize\nsubject to\n\nct x\n(x \u2212 xc)t a(x \u2212 xc) \u2264 1,\n\nwhere a \u2208 sn\n\n++ and c 6= 0.\n\n(c) minimizing a quadratic form over an ellipsoid centered at the origin.\n\nxt bx\n\nminimize\nsubject to xt ax \u2264 1,\n\nwhere a \u2208 sn\n(see \u00a7b.1.)\n\n++ and b \u2208 sn\n\n+. also consider the nonconvex extension with b 6\u2208 sn\n+.\n\n4.22 consider the qcqp\n\n(1/2)xt p x + qt x + r\n\nminimize\nsubject to xt x \u2264 1,\n\nwith p \u2208 sn\nsolution of the nonlinear equation\n\n++. show that x\u22c6 = \u2212(p + \u03bbi)\u22121q where \u03bb = max{0, \u00af\u03bb} and \u00af\u03bb is the largest\n\n4.23 \u21134-norm approximation via qcqp. formulate the \u21134-norm approximation problem\n\nqt (p + \u03bbi)\u22122q = 1.\n\nas a qcqp. the matrix a \u2208 rm\u00d7n (with rows at\n\n4.24 complex \u21131-, \u21132- and \u2113\u221e-norm approximation. consider the problem\n\nminimize\n\nkax \u2212 bk4 = (pm\n\ni x \u2212 bi)4)1/4\n\ni=1(at\ni ) and the vector b \u2208 rm are given.\n\nminimize\n\nkax \u2212 bkp,\n\nwhere a \u2208 cm\u00d7n, b \u2208 cm, and the variable is x \u2208 cn. the complex \u2113p-norm is defined\nby\n\nkykp =  mxi=1\n\n|yi|p!1/p\n\nfor p \u2265 1, and kyk\u221e = maxi=1,...,m |yi|. for p = 1, 2, and \u221e, express the complex \u2113p-norm\napproximation problem as a qcqp or socp with real variables and data.\n\n4.25 linear separation of two sets of ellipsoids. suppose we are given k + l ellipsoids\n\nei = {piu + qi | kuk2 \u2264 1},\n\ni = 1, . . . , k + l,\n\nwhere pi \u2208 sn. we are interested in finding a hyperplane that strictly separates e1, . . . ,\nek from ek+1, . . . , ek+l, i.e., we want to compute a \u2208 rn, b \u2208 r such that\n\nat x + b > 0 for x \u2208 e1 \u222a \u00b7\u00b7\u00b7 \u222a ek ,\n\nat x + b < 0 for x \u2208 ek+1 \u222a \u00b7\u00b7\u00b7 \u222a ek+l,\n\nor prove that no such hyperplane exists. express this problem as an socp feasibility\nproblem.\n\n4.26 hyperbolic constraints as soc constraints. verify that x \u2208 rn, y, z \u2208 r satisfy\n\nxt x \u2264 yz,\n\ny \u2265 0,\n\nz \u2265 0\n\nif and only if\n\nuse this observation to cast the following problems as socps.\n\n\u2264 y + z,\n\ny \u2265 0,\n\nz \u2265 0.\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:20) 2x\ny \u2212 z (cid:21)(cid:13)(cid:13)(cid:13)(cid:13)2\n\n "}, {"Page_number": 212, "text": "198\n\n4 convex optimization problems\n\n(a) maximizing harmonic mean.\n\nmaximize\n\nwith domain {x | ax \u227b b}, where at\n\ni\n\n(b) maximizing geometric mean.\n\ni=1 1/(at\n\n(cid:0)pm\n\ni x \u2212 bi)(cid:1)\u22121\n\n,\n\nis the ith row of a.\n\nmaximize\n\nwith domain {x | ax (cid:23) b}, where at\n\ni\n\ni=1(at\n\n(cid:0)qm\n\ni x \u2212 bi)(cid:1)1/m\n\n,\n\nis the ith row of a.\n\n4.27 matrix fractional minimization via socp. express the following problem as an socp:\n\n(ax + b)t (i + b diag(x)bt )\u22121(ax + b)\n\nminimize\nsubject to x (cid:23) 0,\n\nwith a \u2208 rm\u00d7n, b \u2208 rm, b \u2208 rm\u00d7n. the variable is x \u2208 rn.\nhint. first show that the problem is equivalent to\n\nminimize\nsubject to\n\nvt v + wt diag(x)\u22121w\nv + bw = ax + b\nx (cid:23) 0,\n\nwith variables v \u2208 rm, w, x \u2208 rn. (if xi = 0 we interpret w2\n\u221e otherwise.) then use the results of exercise 4.26.\n\ni /xi as zero if wi = 0 and as\n\n4.28 robust quadratic programming. in \u00a74.4.2 we discussed robust linear programming as an\nin this problem we consider a similar\n\napplication of second-order cone programming.\nrobust variation of the (convex) quadratic program\n\n(1/2)xt p x + qt x + r\n\nminimize\nsubject to ax (cid:22) b.\n\nfor simplicity we assume that only the matrix p is subject to errors, and the other\nparameters (q, r, a, b) are exactly known. the robust quadratic program is defined as\n\nsupp \u2208e ((1/2)xt p x + qt x + r)\n\nminimize\nsubject to ax (cid:22) b\nwhere e is the set of possible matrices p .\nfor each of the following sets e, express the robust qp as a convex problem. be as specific\nas you can. if the problem can be expressed in a standard form (e.g., qp, qcqp, socp,\nsdp), say so.\n(a) a finite set of matrices: e = {p1, . . . , pk}, where pi \u2208 sn\n(b) a set specified by a nominal value p0 \u2208 sn\n\n+ plus a bound on the eigenvalues of the\n\n+, i = 1, . . . , k.\n\ndeviation p \u2212 p0:\ne = {p \u2208 sn | \u2212\u03b3i (cid:22) p \u2212 p0 (cid:22) \u03b3i}\nwhere \u03b3 \u2208 r and p0 \u2208 sn\n+,\n(c) an ellipsoid of matrices:\n\ne =( p0 +\n\nkxi=1\n\npiui(cid:12)(cid:12)(cid:12)(cid:12)(cid:12) kuk2 \u2264 1) .\n\nyou can assume pi \u2208 sn\n\n+, i = 0, . . . , k.\n\n "}, {"Page_number": 213, "text": "exercises\n\n199\n\n4.29 maximizing probability of satisfying a linear inequality. let c be a random variable in rn,\n\nnormally distributed with mean \u00afc and covariance matrix r. consider the problem\n\nmaximize\nsubject to f x (cid:22) g, ax = b.\n\nprob(ct x \u2265 \u03b1)\n\nassuming there exists a feasible point \u02dcx for which \u00afct \u02dcx \u2265 \u03b1, show that this problem is\nequivalent to a convex or quasiconvex optimization problem. formulate the problem as a\nqp, qcqp, or socp (if the problem is convex), or explain how you can solve it by solving\na sequence of qp, qcqp, or socp feasibility problems (if the problem is quasiconvex).\n\ngeometric programming\n\n4.30 a heated fluid at temperature t (degrees above ambient temperature) flows in a pipe\nwith fixed length and circular cross section with radius r. a layer of insulation, with\nthickness w \u226a r, surrounds the pipe to reduce heat loss through the pipe walls. the\ndesign variables in this problem are t , r, and w.\nthe heat loss is (approximately) proportional to t r/w, so over a fixed lifetime, the energy\ncost due to heat loss is given by \u03b11t r/w. the cost of the pipe, which has a fixed wall\nthickness, is approximately proportional to the total material, i.e., it is given by \u03b12r. the\ncost of the insulation is also approximately proportional to the total insulation material,\ni.e., \u03b13rw (using w \u226a r). the total cost is the sum of these three costs.\nthe heat flow down the pipe is entirely due to the flow of the fluid, which has a fixed\nvelocity, i.e., it is given by \u03b14t r2. the constants \u03b1i are all positive, as are the variables\nt , r, and w.\nnow the problem: maximize the total heat flow down the pipe, subject to an upper limit\ncmax on total cost, and the constraints\n\ntmin \u2264 t \u2264 tmax,\n\nrmin \u2264 r \u2264 rmax,\nexpress this problem as a geometric program.\n\nwmin \u2264 w \u2264 wmax, w \u2264 0.1r.\n\n4.31 recursive formulation of optimal beam design problem. show that the gp (4.46) is equiv-\n\nalent to the gp\n\nminimize pn\n\ni=1 wihi\n\nsubject to wi/wmax \u2264 1, wmin/wi \u2264 1,\nhmin/hi \u2264 1,\ni ) \u2264 1,\n\nhi/hmax \u2264 1,\nhi/(wismax) \u2264 1, sminwi/hi \u2264 1,\n6if/(\u03c3maxwih2\ni = 1, . . . , n\n(2i \u2212 1)di/vi + vi+1/vi \u2264 1,\n(i \u2212 1/3)di/yi + vi+1/yi + yi+1/yi \u2264 1,\ny1/ymax \u2264 1\newih3\n\ni = 1, . . . , n.\n\ni di/(6f ) = 1,\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\nthe variables are wi, hi, vi, di, yi for i = 1, . . . , n .\n\n4.32 approximating a function as a monomial. suppose the function f : rn \u2192 r is differ-\nentiable at a point x0 \u227b 0, with f (x0) > 0. how would you find a monomial function\n\u02c6f : rn \u2192 r such that f (x0) = \u02c6f (x0) and for x near x0, \u02c6f (x) is very near f (x)?\n\n4.33 express the following problems as convex optimization problems.\n(a) minimize max{p(x), q(x)}, where p and q are posynomials.\n(b) minimize exp(p(x)) + exp(q(x)), where p and q are posynomials.\n(c) minimize p(x)/(r(x) \u2212 q(x)), subject to r(x) > q(x), where p, q are posynomials,\n\nand r is a monomial.\n\n "}, {"Page_number": 214, "text": "200\n\n4 convex optimization problems\n\n4.34 log-convexity of perron-frobenius eigenvalue. let a \u2208 rn\u00d7n be an elementwise positive\nmatrix, i.e., aij > 0.\n(the results of this problem hold for irreducible nonnegative\nmatrices as well.) let \u03bbpf (a) denotes its perron-frobenius eigenvalue, i.e., its eigenvalue\nof largest magnitude.\n(see the definition and the example on page 165.) show that\nlog \u03bbpf (a) is a convex function of log aij. this means, for example, that we have the\ninequality\n\n\u03bbpf (c) \u2264 (\u03bbpf (a)\u03bbpf (b))1/2 ,\n\nwhere cij = (aijbij)1/2, and a and b are elementwise positive matrices.\nhint. use the characterization of the perron-frobenius eigenvalue given in (4.47), or,\nalternatively, use the characterization\n\nlog \u03bbpf (a) = lim\nk\u2192\u221e\n\n(1/k) log(1t ak1).\n\n4.35 signomial and geometric programs. a signomial is a linear combination of monomials of\nsome positive variables x1, . . . , xn. signomials are more general than posynomials, which\nare signomials with all positive coefficients. a signomial program is an optimization\nproblem of the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nwhere f0, . . . , fm and h1, . . . , hp are signomials. in general, signomial programs are very\ndifficult to solve.\nsome signomial programs can be transformed to gps, and therefore solved efficiently.\nshow how to do this for a signomial program of the following form:\n\ncients.\n\n\u2022 the objective signomial f0 is a posynomial, i.e., its terms have only positive coeffi-\n\u2022 each inequality constraint signomial f1, . . . , fm has exactly one term with a negative\ncoefficient: fi = pi \u2212 qi where pi is posynomial, and qi is monomial.\n\u2022 each equality constraint signomial h1, . . . , hp has exactly one term with a positive\ncoefficient and one term with a negative coefficient: hi = ri \u2212 si where ri and si are\nmonomials.\n\n4.36 explain how to reformulate a general gp as an equivalent gp in which every posynomial\n(in the objective and constraints) has at most two monomial terms. hint. express each\nsum (of monomials) as a sum of sums, each with two terms.\n\n4.37 generalized posynomials and geometric programming. let x1, . . . , xn be positive variables,\nand suppose the functions fi : rn \u2192 r, i = 1, . . . , k, are posynomials of x1, . . . , xn. if\n\u03c6 : rk \u2192 r is a polynomial with nonnegative coefficients, then the composition\n\nh(x) = \u03c6(f1(x), . . . , fk(x))\n\n(4.69)\n\n1 f2 + 2f1 + f 3\n\n1z2 + 2z1 + 3z3\n\n2 is a posynomial.\n\nis a posynomial, since posynomials are closed under products, sums, and multiplication\nby nonnegative scalars. for example, suppose f1 and f2 are posynomials, and consider\nthe polynomial \u03c6(z1, z2) = 3z2\n2 (which has nonnegative coefficients). then\nh = 3f 2\nin this problem we consider a generalization of this idea, in which \u03c6 is allowed to be\na posynomial, i.e., can have fractional exponents. specifically, assume that \u03c6 : rk \u2192\nr is a posynomial, with all its exponents nonnegative.\nin this case we will call the\nfunction h defined in (4.69) a generalized posynomial. as an example, suppose f1 and f2\nare posynomials, and consider the posynomial (with nonnegative exponents) \u03c6(z1, z2) =\n2z0.3\n\n2 + 2. then the function\n\n2 + z1z0.5\n\n1 z1.2\n\nh(x) = 2f1(x)0.3f2(x)1.2 + f1(x)f2(x)0.5 + 2\n\n "}, {"Page_number": 215, "text": "exercises\n\n201\n\nis a generalized posynomial. note that it is not a posynomial, however (unless f1 and f2\nare monomials or constants).\na generalized geometric program (ggp) is an optimization problem of the form\n\nh0(x)\n\nminimize\nsubject to hi(x) \u2264 1,\ngi(x) = 1,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(4.70)\n\nwhere g1, . . . , gp are monomials, and h0, . . . , hm are generalized posynomials.\nshow how to express this generalized geometric program as an equivalent geometric pro-\ngram. explain any new variables you introduce, and explain how your gp is equivalent\nto the ggp (4.70).\n\nsemidefinite programming and conic form problems\n\n4.38 lmis and sdps with one variable. the generalized eigenvalues of a matrix pair (a, b),\n\nwhere a, b \u2208 sn, are defined as the roots of the polynomial det(\u03bbb \u2212 a) (see \u00a7a.5.3).\nsuppose b is nonsingular, and that a and b can be simultaneously diagonalized by a\ncongruence, i.e., there exists a nonsingular r \u2208 rn\u00d7n such that\nrt br = diag(b),\n\nrt ar = diag(a),\n\nwhere a, b \u2208 rn. (a sufficient condition for this to hold is that there exists t1, t2 such\nthat t1a + t2b \u227b 0.)\n(a) show that the generalized eigenvalues of (a, b) are real, and given by \u03bbi = ai/bi,\n\ni = 1, . . . , n.\n\n(b) express the solution of the sdp\n\nminimize\nsubject to\n\nct\ntb (cid:22) a,\n\nwith variable t \u2208 r, in terms of a and b.\n\n4.39 sdps and congruence transformations. consider the sdp\n\nct x\n\nminimize\nsubject to x1f1 + x2f2 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0,\n\nwith fi, g \u2208 sk, c \u2208 rn.\n(a) suppose r \u2208 rk\u00d7k is nonsingular. show that the sdp is equivalent to the sdp\n\nct x\n\nminimize\nsubject to x1 \u02dcf1 + x2 \u02dcf2 + \u00b7\u00b7\u00b7 + xn \u02dcfn + \u02dcg (cid:22) 0,\n\nwhere \u02dcfi = rt fir, \u02dcg = rt gr.\n\n(b) suppose there exists a nonsingular r such that \u02dcfi and \u02dcg are diagonal. show that\n\nthe sdp is equivalent to an lp.\n\n(c) suppose there exists a nonsingular r such that \u02dcfi and \u02dcg have the form\n\n\u02dcfi =(cid:20) \u03b1ii\n\nat\ni\n\nai\n\n\u03b1i (cid:21) ,\n\ni = 1, . . . , n,\n\n\u02dcg =(cid:20) \u03b2i\n\nbt\n\nb\n\n\u03b2 (cid:21) ,\n\nwhere \u03b1i, \u03b2 \u2208 r, ai, b \u2208 rk\u22121. show that the sdp is equivalent to an socp with\na single second-order cone constraint.\n\n "}, {"Page_number": 216, "text": "202\n\n4 convex optimization problems\n\n4.40 lps, qps, qcqps, and socps as sdps. express the following problems as sdps.\n\n(a) the lp (4.27).\n(b) the qp (4.34), the qcqp (4.35) and the socp (4.36). hint. suppose a \u2208 sr\n\n++,\n\nc \u2208 ss, and b \u2208 rr\u00d7s. then\n\nbt c (cid:21) (cid:23) 0 \u21d0\u21d2 c \u2212 bt a\u22121b (cid:23) 0.\n(cid:20) a b\n\nfor a more complete statement, which applies also to singular a, and a proof,\nsee \u00a7a.5.5.\n\n(c) the matrix fractional optimization problem\n\nminimize\n\n(ax + b)t f (x)\u22121(ax + b)\n\nwhere a \u2208 rm\u00d7n, b \u2208 rm,\n\nf (x) = f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn,\n\nwith fi \u2208 sm, and we take the domain of the objective to be {x | f (x) \u227b 0}. you\ncan assume the problem is feasible (there exists at least one x with f (x) \u227b 0).\n\n4.41 lmi tests for copositive matrices and p0-matrices. a matrix a \u2208 sn is said to be copositive\nif xt ax \u2265 0 for all x (cid:23) 0 (see exercise 2.35). a matrix a \u2208 rn\u00d7n is said to be a p0-\nmatrix if maxi=1,...,n xi(ax)i \u2265 0 for all x. checking whether a matrix is copositive or\na p0-matrix is very difficult in general. however, there exist useful sufficient conditions\nthat can be verified using semidefinite programming.\n\n(a) show that a is copositive if it can be decomposed as a sum of a positive semidefinite\n\nand an elementwise nonnegative matrix:\n\na = b + c,\n\nb (cid:23) 0,\n\ncij \u2265 0,\n\ni, j = 1, . . . , n.\n\n(4.71)\n\nexpress the problem of finding b and c that satisfy (4.71) as an sdp feasibility\nproblem.\n\n(b) show that a is a p0-matrix if there exists a positive diagonal matrix d such that\n\nexpress the problem of finding a d that satisfies (4.72) as an sdp feasibility problem.\n\nda + at d (cid:23) 0.\n\n(4.72)\n\n4.42 complex lmis and sdps. a complex lmi has the form\n\nx1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0\n\nwhere f1, . . . , fn, g are complex n \u00d7 n hermitian matrices, i.e., f h\ni = fi, gh = g, and\nx \u2208 rn is a real variable. a complex sdp is the problem of minimizing a (real) linear\nfunction of x subject to a complex lmi constraint.\ncomplex lmis and sdps can be transformed to real lmis and sdps, using the fact that\n\nx (cid:23) 0 \u21d0\u21d2 (cid:20) \u211cx \u2212\u2111x\n\n\u2111x \u211cx (cid:21) (cid:23) 0,\n\nwhere \u211cx \u2208 rn\u00d7n is the real part of the complex hermitian matrix x, and \u2111x \u2208 rn\u00d7n\nis the imaginary part of x.\nverify this result, and show how to pose a complex sdp as a real sdp.\n\n "}, {"Page_number": 217, "text": "exercises\n\n203\n\n4.43 eigenvalue optimization via sdp. suppose a : rn \u2192 sm is affine, i.e.,\n\na(x) = a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan\n\nwhere ai \u2208 sm. let \u03bb1(x) \u2265 \u03bb2(x) \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbm(x) denote the eigenvalues of a(x). show\nhow to pose the following problems as sdps.\n\n(a) minimize the maximum eigenvalue \u03bb1(x).\n(b) minimize the spread of the eigenvalues, \u03bb1(x) \u2212 \u03bbm(x).\n(c) minimize the condition number of a(x), subject to a(x) \u227b 0. the condition number\nis defined as \u03ba(a(x)) = \u03bb1(x)/\u03bbm(x), with domain {x | a(x) \u227b 0}. you may assume\nthat a(x) \u227b 0 for at least one x.\nhint. you need to minimize \u03bb/\u03b3, subject to\n\nchange variables to y = x/\u03b3, t = \u03bb/\u03b3, s = 1/\u03b3.\n\n0 \u227a \u03b3i (cid:22) a(x) (cid:22) \u03bbi.\n\n(d) minimize the sum of the absolute values of the eigenvalues, |\u03bb1(x)| + \u00b7\u00b7\u00b7 + |\u03bbm(x)|.\n\nhint. express a(x) as a(x) = a+ \u2212 a\u2212, where a+ (cid:23) 0, a\u2212 (cid:23) 0.\n\n4.44 optimization over polynomials. pose the following problem as an sdp. find the polyno-\n\nmial p : r \u2192 r,\n\np(t) = x1 + x2t + \u00b7\u00b7\u00b7 + x2k+1t2k,\n\nthat satisfies given bounds li \u2264 p(ti) \u2264 ui, at m specified points ti, and, of all the\npolynomials that satisfy these bounds, has the greatest minimum value:\n\nmaximize\nsubject to\n\ninf t p(t)\nli \u2264 p(ti) \u2264 ui,\n\ni = 1, . . . , m.\n\nthe variables are x \u2208 r2k+1.\nhint. use the lmi characterization of nonnegative polynomials derived in exercise 2.37,\npart (b).\n\n4.45 [nes00, par00] sum-of-squares representation via lmis. consider a polynomial p : rn \u2192\nr of degree 2k. the polynomial is said to be positive semidefinite (psd) if p(x) \u2265 0\nfor all x \u2208 rn. except for special cases (e.g., n = 1 or k = 1), it is extremely difficult\nto determine whether or not a given polynomial is psd, let alone solve an optimization\nproblem, with the coefficients of p as variables, with the constraint that p be psd.\na famous sufficient condition for a polynomial to be psd is that it have the form\n\np(x) =\n\nqi(x)2,\n\nrxi=1\n\nfor some polynomials qi, with degree no more than k. a polynomial p that has this\nsum-of-squares form is called sos.\nthe condition that a polynomial p be sos (viewed as a constraint on its coefficients)\nturns out to be equivalent to an lmi, and therefore a variety of optimization problems,\nwith sos constraints, can be posed as sdps. you will explore these ideas in this problem.\n\n(a) let f1, . . . , fs be all monomials of degree k or less. (here we mean monomial in\nthe standard sense, i.e., xm1\nn , where mi \u2208 z+, and not in the sense used in\ngeometric programming.) show that if p can be expressed as a positive semidefinite\nquadratic form p = f t v f , with v \u2208 ss\n+, then p is sos. conversely, show that if\np is sos, then it can be expressed as a positive semidefinite quadratic form in the\nmonomials, i.e., p = f t v f , for some v \u2208 ss\n+.\n\n\u00b7\u00b7\u00b7 xmn\n\n1\n\n "}, {"Page_number": 218, "text": "204\n\n4 convex optimization problems\n\n(b) show that the condition p = f t v f is a set of linear equality constraints relating the\ncoefficients of p and the matrix v . combined with part (a) above, this shows that\nthe condition that p be sos is equivalent to a set of linear equalities relating v and\nthe coefficients of p, and the matrix inequality v (cid:23) 0.\n\n(c) work out the lmi conditions for sos explicitly for the case where p is polynomial\n\nof degree four in two variables.\n\n1tj\n\n2, where i, j are nonnegative integers.\n\n4.46 multidimensional moments. the moments of a random variable t on r2 are defined as\n\u00b5ij = e ti\nin this problem we derive necessary\nconditions for a set of numbers \u00b5ij, 0 \u2264 i, j \u2264 2k, i + j \u2264 2k, to be the moments of a\ndistribution on r2.\nlet p : r2 \u2192 r be a polynomial of degree k with coefficients cij,\n\np(t) =\n\nkxi=0\n\nk\u2212ixj=0\n\ncijti\n\n1tj\n2,\n\nand let t be a random variable with moments \u00b5ij. suppose c \u2208 r(k+1)(k+2)/2 contains\nthe coefficients cij in some specific order, and \u00b5 \u2208 r(k+1)(2k+1) contains the moments \u00b5ij\nin the same order. show that e p(t)2 can be expressed as a quadratic form in c:\n\ne p(t)2 = ct h(\u00b5)c,\n\nwhere h : r(k+1)(2k+1) \u2192 s(k+1)(k+2)/2 is a linear function of \u00b5. from this, conclude\nthat \u00b5 must satisfy the lmi h(\u00b5) (cid:23) 0.\nremark: for random variables on r, the matrix h can be taken as the hankel matrix\ndefined in (4.52). in this case, h(\u00b5) (cid:23) 0 is a necessary and sufficient condition for \u00b5 to be\nthe moments of a distribution, or the limit of a sequence of moments. on r2, however,\nthe lmi is only a necessary condition.\n\n4.47 maximum determinant positive semidefinite matrix completion. we consider a matrix\na \u2208 sn, with some entries specified, and the others not specified. the positive semidefinite\nmatrix completion problem is to determine values of the unspecified entries of the matrix\nso that a (cid:23) 0 (or to determine that such a completion does not exist).\n(a) explain why we can assume without loss of generality that the diagonal entries of\n\na are specified.\n\n(b) show how to formulate the positive semidefinite completion problem as an sdp\n\nfeasibility problem.\n\n(c) assume that a has at least one completion that is positive definite, and the diag-\nonal entries of a are specified (i.e., fixed). the positive definite completion with\nlargest determinant is called the maximum determinant completion. show that the\nmaximum determinant completion is unique. show that if a\u22c6 is the maximum de-\nterminant completion, then (a\u22c6)\u22121 has zeros in all the entries of the original matrix\nthat were not specified. hint. the gradient of the function f (x) = log det x is\n\u2207f (x) = x \u22121 (see \u00a7a.4.1).\n(d) suppose a is specified on its tridiagonal part, i.e., we are given a11, . . . , ann and\na12, . . . , an\u22121,n. show that if there exists a positive definite completion of a, then\nthere is a positive definite completion whose inverse is tridiagonal.\n\n4.48 generalized eigenvalue minimization. recall (from example 3.37, or \u00a7a.5.3) that the\n\nlargest generalized eigenvalue of a pair of matrices (a, b) \u2208 sk \u00d7 sk\n\n++ is given by\n\n\u03bbmax(a, b) = sup\nu6=0\n\nut au\nut bu\n\n= max{\u03bb | det(\u03bbb \u2212 a) = 0}.\n\nas we have seen, this function is quasiconvex (if we take sk \u00d7 sk\n\n++ as its domain).\n\n "}, {"Page_number": 219, "text": "exercises\n\nwe consider the problem\n\n205\n\nminimize \u03bbmax(a(x), b(x))\n\n(4.73)\n\nwhere a, b : rn \u2192 sk are affine functions, defined as\n\na(x) = a0 + x1a1 + \u00b7\u00b7\u00b7 + xnan,\n\nb(x) = b0 + x1b1 + \u00b7\u00b7\u00b7 + xnbn.\n\nwith ai, bi \u2208 sk.\n(a) give a family of convex functions \u03c6t : sk \u00d7 sk \u2192 r, that satisfy\n\nfor all (a, b) \u2208 sk \u00d7 sk\nsequence of convex feasibility problems.\n\n\u03bbmax(a, b) \u2264 t \u21d0\u21d2 \u03c6t(a, b) \u2264 0\n++. show that this allows us to solve (4.73) by solving a\n\n(b) give a family of matrix-convex functions \u03c6t : sk \u00d7 sk \u2192 sk that satisfy\n\nfor all (a, b) \u2208 sk \u00d7 sk\nsequence of convex feasibility problems with lmi constraints.\n\n\u03bbmax(a, b) \u2264 t \u21d0\u21d2 \u03c6t(a, b) (cid:22) 0\n++. show that this allows us to solve (4.73) by solving a\n\n(c) suppose b(x) = (at x+b)i, with a 6= 0. show that (4.73) is equivalent to the convex\n\nproblem\n\nminimize\nsubject to\n\nwith variables y \u2208 rn, s \u2208 r.\n\n\u03bbmax(sa0 + y1a1 + \u00b7\u00b7\u00b7 + ynan)\nat y + bs = 1\ns \u2265 0,\n\n4.49 generalized fractional programming. let k \u2208 rm be a proper cone. show that the\n\nfunction f0 : rn \u2192 rm, defined by\n\nf0(x) = inf{t | cx + d (cid:22)k t(f x + g)},\nwith c, f \u2208 rm\u00d7n, d, g \u2208 rm, is quasiconvex.\na quasiconvex optimization problem with objective function of this form is called a gen-\neralized fractional program. express the generalized linear-fractional program of page 152\nand the generalized eigenvalue minimization problem (4.73) as generalized fractional pro-\ngrams.\n\ndom f0 = {x | f x + g \u227bk 0},\n\nvector and multicriterion optimization\n\n4.50 bi-criterion optimization. figure 4.11 shows the optimal trade-off curve and the set of\n\nachievable values for the bi-criterion optimization problem\n\nminimize (w.r.t. r2\n\n+)\n\n(kax \u2212 bk2,kxk2\n2),\n\nfor some a \u2208 r100\u00d710, b \u2208 r100. answer the following questions using information from\nthe plot. we denote by xls the solution of the least-squares problem\n\nminimize\n\nkax \u2212 bk2\n2.\n\n(a) what is kxlsk2?\n(b) what is kaxls \u2212 bk2?\n(c) what is kbk2?\n\n "}, {"Page_number": 220, "text": "206\n\n4 convex optimization problems\n\n(d) give the optimal value of the problem\n\nminimize\nsubject to\n\nkax \u2212 bk2\n2\nkxk2\n2 = 1.\n\n(e) give the optimal value of the problem\n\nminimize\nsubject to\n\nkax \u2212 bk2\nkxk2\n2 \u2264 1.\n\n2\n\n(f) give the optimal value of the problem\n\n(g) what is the rank of a?\n\nminimize kax \u2212 bk2\n\n2 + kxk2\n2.\n\n4.51 monotone transformation of objective in vector optimization. consider the vector opti-\nmization problem (4.56). suppose we form a new vector optimization problem by replacing\nthe objective f0 with \u03c6 \u25e6 f0, where \u03c6 : rq \u2192 rq satisfies\n\nu (cid:22)k v, u 6= v =\u21d2 \u03c6(u) (cid:22)k \u03c6(v), \u03c6(u) 6= \u03c6(v).\n\nshow that a point x is pareto optimal (or optimal) for one problem if and only if it is\npareto optimal (optimal) for the other, so the two problems are equivalent. in particular,\ncomposing each objective in a multicriterion problem with an increasing function does\nnot affect the pareto optimal points.\n\n4.52 pareto optimal points and the boundary of the set of achievable values. consider a vector\noptimization problem with cone k. let p denote the set of pareto optimal values, and\nlet o denote the set of achievable objective values. show that p \u2286 o \u2229 bdo, i.e., every\npareto optimal value is an achievable objective value that lies in the boundary of the set\nof achievable objective values.\n\n4.53 suppose the vector optimization problem (4.56) is convex. show that the set\n\na = o + k = {t \u2208 rq | f0(x) (cid:22)k t for some feasible x},\n\nis convex. also show that the minimal elements of a are the same as the minimal points\nof o.\n\n4.54 scalarization and optimal points. suppose a (not necessarily convex) vector optimization\nproblem has an optimal point x\u22c6. show that x\u22c6 is a solution of the associated scalarized\nproblem for any choice of \u03bb \u227bk \u2217 0. also show the converse: if a point x is a solution of\nthe scalarized problem for any choice of \u03bb \u227bk \u2217 0, then it is an optimal point for the (not\nnecessarily convex) vector optimization problem.\n\n4.55 generalization of weighted-sum scalarization. in \u00a74.7.4 we showed how to obtain pareto\noptimal solutions of a vector optimization problem by replacing the vector objective f0 :\nrn \u2192 rq with the scalar objective \u03bbt f0, where \u03bb \u227bk \u2217 0. let \u03c8 : rq \u2192 r be a\nk-increasing function, i.e., satisfying\n\nshow that any solution of the problem\n\nu (cid:22)k v, u 6= v =\u21d2 \u03c8(u) < \u03c8(v).\n\nminimize\nsubject to\n\n\u03c8(f0(x))\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\n\n "}, {"Page_number": 221, "text": "exercises\n\n207\n\nis pareto optimal for the vector optimization problem\n\nminimize (w.r.t. k)\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\nnote that \u03c8(u) = \u03bbt u, where \u03bb \u227bk \u2217 0, is a special case.\nas a related example, show that in a multicriterion optimization problem (i.e., a vector\noptimization problem with f0 = f : rn \u2192 rq, and k = rq\n+), a unique solution of the\nscalar optimization problem\n\nminimize maxi=1,...,q fi(x)\nsubject to\n\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nis pareto optimal.\n\nmiscellaneous problems\n\n4.56 [p. parrilo] we consider the problem of minimizing the convex function f0 : rn \u2192 r\n\nover the convex hull of the union of some convex sets, conv(cid:0)sq\n\ndescribed via convex inequalities,\n\ni=1 ci(cid:1). these sets are\n\nci = {x | fij(x) \u2264 0, j = 1, . . . , ki},\n\nwhere fij : rn \u2192 r are convex. our goal is to formulate this problem as a convex\noptimization problem.\nthe obvious approach is to introduce variables x1, . . . , xq \u2208 rn, with xi \u2208 ci, \u03b8 \u2208 rq\nwith \u03b8 (cid:23) 0, 1t \u03b8 = 1, and a variable x \u2208 rn, with x = \u03b81x1 + \u00b7\u00b7\u00b7 + \u03b8qxq. this equality\nconstraint is not affine in the variables, so this approach does not yield a convex problem.\na more sophisticated formulation is given by\n\nminimize\nsubject to\n\nf0(x)\nsifij(zi/si) \u2264 0,\n1t s = 1,\ns (cid:23) 0\nx = z1 + \u00b7\u00b7\u00b7 + zq,\n\ni = 1, . . . , q,\n\nj = 1, . . . , ki\n\nwith variables z1, . . . , zq \u2208 rn, x \u2208 rn, and s1, . . . , sq \u2208 r. (when si = 0, we take\nsifij(zi/si) to be 0 if zi = 0 and \u221e if zi 6= 0.) explain why this problem is convex, and\nequivalent to the original problem.\n\n4.57 capacity of a communication channel. we consider a communication channel, with input\nx(t) \u2208 {1, . . . , n}, and output y (t) \u2208 {1, . . . , m}, for t = 1, 2, . . . (in seconds, say). the\nrelation between the input and the output is given statistically:\n\npij = prob(y (t) = i|x(t) = j),\n\ni = 1, . . . , m,\n\nj = 1, . . . , n.\n\nthe matrix p \u2208 rm\u00d7n is called the channel transition matrix, and the channel is called\na discrete memoryless channel.\na famous result of shannon states that information can be sent over the communication\nchannel, with arbitrarily small probability of error, at any rate less than a number c,\ncalled the channel capacity, in bits per second. shannon also showed that the capacity of\na discrete memoryless channel can be found by solving an optimization problem. assume\nthat x has a probability distribution denoted x \u2208 rn, i.e.,\n\nxj = prob(x = j),\n\nj = 1, . . . , n.\n\n "}, {"Page_number": 222, "text": "208\n\n4 convex optimization problems\n\nthe mutual information between x and y is given by\n\ni(x; y ) =\n\nmxi=1\n\nnxj=1\n\nxjpij log2\n\nthen the channel capacity c is given by\n\n.\n\nk=1 xkpik\n\npijpn\n\nc = sup\n\ni(x; y ),\n\nx\n\nwhere the supremum is over all possible probability distributions for the input x, i.e.,\nover x (cid:23) 0, 1t x = 1.\nshow how the channel capacity can be computed using convex optimization.\nhint.\noutput y , and show that the mutual information can be expressed as\n\nintroduce the variable y = p x, which gives the probability distribution of the\n\ni(x; y ) = ct x \u2212\n\nyi log2 yi,\n\nmxi=1\n\nwhere cj =pm\n\ni=1 pij log2 pij, j = 1, . . . , n.\n\n4.58 optimal consumption. in this problem we consider the optimal way to consume (or spend)\nan initial amount of money (or other asset) k0 over time. the variables are c0, . . . , ct ,\nwhere ct \u2265 0 denotes the consumption in period t. the utility derived from a consumption\nlevel c is given by u(c), where u : r \u2192 r is an increasing concave function. the present\nvalue of the utility derived from the consumption is given by\n\nu =\n\ntxt=0\n\n\u03b2tu(ct),\n\nwhere 0 < \u03b2 < 1 is a discount factor.\nlet kt denote the amount of money available for investment in period t. we assume\nthat it earns an investment return given by f (kt), where f : r \u2192 r is an increasing,\nconcave investment return function, which satisfies f (0) = 0. for example if the funds\nearn simple interest at rate r percent per period, we have f (a) = (r/100)a. the amount\nto be consumed, i.e., ct, is withdrawn at the end of the period, so we have the recursion\n\nkt+1 = kt + f (kt) \u2212 ct,\n\nt = 0, . . . , t.\n\nthe initial sum k0 > 0 is given. we require kt \u2265 0, t = 1, . . . , t +1 (but more sophisticated\nmodels, which allow kt < 0, can be considered).\nshow how to formulate the problem of maximizing u as a convex optimization problem.\nexplain how the problem you formulate is equivalent to this one, and exactly how the\ntwo are related.\nhint. show that we can replace the recursion for kt given above with the inequalities\n\nkt+1 \u2264 kt + f (kt) \u2212 ct,\n\nt = 0, . . . , t.\n\n(interpretation: the inequalities give you the option of throwing money away in each\nperiod.) for a more general version of this trick, see exercise 4.6.\n\n4.59 robust optimization.\n\nin some optimization problems there is uncertainty or variation\nin the objective and constraint functions, due to parameters or factors that are either\nbeyond our control or unknown. we can model this situation by making the objective\nand constraint functions f0, . . . , fm functions of the optimization variable x \u2208 rn and\na parameter vector u \u2208 rk that is unknown, or varies. in the stochastic optimization\n\n "}, {"Page_number": 223, "text": "exercises\n\n209\n\napproach, the parameter vector u is modeled as a random variable with a known dis-\ntribution, and we work with the expected values eu fi(x, u). in the worst-case analysis\napproach, we are given a set u that u is known to lie in, and we work with the maximum\nor worst-case values supu\u2208u fi(x, u). to simplify the discussion, we assume there are no\nequality constraints.\n\n(a) stochastic optimization. we consider the problem\n\nminimize e f0(x, u)\nsubject to e fi(x, u) \u2264 0,\n\ni = 1, . . . , m,\n\nwhere the expectation is with respect to u. show that if fi are convex in x for each\nu, then this stochastic optimization problem is convex.\n\n(b) worst-case optimization. we consider the problem\n\nminimize\nsubject to\n\nsupu\u2208u f0(x, u)\nsupu\u2208u fi(x, u) \u2264 0,\n\ni = 1, . . . , m.\n\nshow that if fi are convex in x for each u, then this worst-case optimization problem\nis convex.\n\n(c) finite set of possible parameter values. the observations made in parts (a) and (b)\nare most useful when we have analytical or easily evaluated expressions for the\nexpected values e fi(x, u) or the worst-case values supu\u2208u fi(x, u).\nsuppose we are given the set of possible values of the parameter is finite, i.e., we\nhave u \u2208 {u1, . . . , un}. for the stochastic case, we are also given the probabilities\nof each value: prob(u = ui) = pi, where p \u2208 rn , p (cid:23) 0, 1t p = 1. in the worst-case\nformulation, we simply take u \u2208 {u1, . . . , un}.\nshow how to set up the worst-case and stochastic optimization problems explicitly\n(i.e., give explicit expressions for supu\u2208u fi and eu fi).\n\n4.60 log-optimal investment strategy. we consider a portfolio problem with n assets held over\nn periods. at the beginning of each period, we re-invest our total wealth, redistributing\nit over the n assets using a fixed, constant, allocation strategy x \u2208 rn, where x (cid:23) 0,\n1t x = 1. in other words, if w (t \u2212 1) is our wealth at the beginning of period t, then\nduring period t we invest xiw (t\u2212 1) in asset i. we denote by \u03bb(t) the total return during\nperiod t, i.e., \u03bb(t) = w (t)/w (t \u2212 1). at the end of the n periods our wealth has been\n\nmultiplied by the factorqn\n\nt=1 \u03bb(t). we call\n\n1\nn\n\nnxt=1\n\nlog \u03bb(t)\n\nthe growth rate of the investment over the n periods. we are interested in determining\nan allocation strategy x that maximizes growth of our total wealth for large n .\nwe use a discrete stochastic model to account for the uncertainty in the returns. we\nassume that during each period there are m possible scenarios, with probabilities \u03c0j,\nj = 1, . . . , m.\nin scenario j, the return for asset i over one period is given by pij.\ntherefore, the return \u03bb(t) of our portfolio during period t is a random variable, with\nm possible values pt\n\nmx, and distribution\n\n1 x, . . . , pt\n\n\u03c0j = prob(\u03bb(t) = pt\n\nj x),\n\nj = 1, . . . , m.\n\nwe assume the same scenarios for each period, with (identical) independent distributions.\nusing the law of large numbers, we have\n\nlim\nn\u2192\u221e\n\n1\nn\n\nlog(cid:18) w (n )\n\nw (0)(cid:19) = lim\n\nn\u2192\u221e\n\n1\nn\n\nnxt=1\n\nlog \u03bb(t) = e log \u03bb(t) =\n\n\u03c0j log(pt\n\nj x).\n\nmxj=1\n\n "}, {"Page_number": 224, "text": "210\n\n4 convex optimization problems\n\nin other words, with investment strategy x, the long term growth rate is given by\n\nrlt =\n\nmxj=1\n\n\u03c0j log(pt\n\nj x).\n\nthe investment strategy x that maximizes this quantity is called the log-optimal invest-\nment strategy, and can be found by solving the optimization problem\n\nmaximize pm\n\nsubject to x (cid:23) 0,\n\nj=1 \u03c0j log(pt\n\nj x)\n1t x = 1,\n\nwith variable x \u2208 rn.\nshow that this is a convex optimization problem.\n\n4.61 optimization with logistic model. a random variable x \u2208 {0, 1} satisfies\n\nprob(x = 1) = p =\n\nexp(at x + b)\n\n1 + exp(at x + b)\n\n,\n\nwhere x \u2208 rn is a vector of variables that affect the probability, and a and b are known\nparameters. we can think of x = 1 as the event that a consumer buys a product, and\nx as a vector of variables that affect the probability, e.g., advertising effort, retail price,\ndiscounted price, packaging expense, and other factors. the variable x, which we are to\noptimize over, is subject to a set of linear constraints, f x (cid:22) g.\nformulate the following problems as convex optimization problems.\n\n(a) maximizing buying probability. the goal is to choose x to maximize p.\n(b) maximizing expected profit. let ct x+d be the profit derived from selling the product,\nwhich we assume is positive for all feasible x. the goal is to maximize the expected\nprofit, which is p(ct x + d).\n\n4.62 optimal power and bandwidth allocation in a gaussian broadcast channel. we consider a\ncommunication system in which a central node transmits messages to n receivers. (\u2018gaus-\nsian\u2019 refers to the type of noise that corrupts the transmissions.) each receiver channel\nis characterized by its (transmit) power level pi \u2265 0 and its bandwidth wi \u2265 0. the\npower and bandwidth of a receiver channel determine its bit rate ri (the rate at which\ninformation can be sent) via\n\nri = \u03b1iwi log(1 + \u03b2ipi/wi),\n\nwhere \u03b1i and \u03b2i are known positive constants. for wi = 0, we take ri = 0 (which is\nwhat you get if you take the limit as wi \u2192 0).\nthe powers must satisfy a total power constraint, which has the form\n\np1 + \u00b7\u00b7\u00b7 + pn = ptot,\n\nwhere ptot > 0 is a given total power available to allocate among the channels. similarly,\nthe bandwidths must satisfy\n\nw1 + \u00b7\u00b7\u00b7 + wn = wtot,\n\nwhere wtot > 0 is the (given) total available bandwidth. the optimization variables in\nthis problem are the powers and bandwidths, i.e., p1, . . . , pn, w1, . . . , wn.\nthe objective is to maximize the total utility,\n\nui(ri),\n\nnxi=1\n\n "}, {"Page_number": 225, "text": "exercises\n\n211\n\nwhere ui : r \u2192 r is the utility function associated with the ith receiver.\n(you can\nthink of ui(ri) as the revenue obtained for providing a bit rate ri to receiver i, so the\nobjective is to maximize the total revenue.) you can assume that the utility functions ui\nare nondecreasing and concave.\npose this problem as a convex optimization problem.\n\n4.63 optimally balancing manufacturing cost and yield. the vector x \u2208 rn denotes the nomi-\nnal parameters in a manufacturing process. the yield of the process, i.e., the fraction of\nmanufactured goods that is acceptable, is given by y (x). we assume that y is log-concave\n(which is often the case; see example 3.43). the cost per unit to manufacture the product\nis given by ct x, where c \u2208 rn. the cost per acceptable unit is ct x/y (x). we want to\nminimize ct x/y (x), subject to some convex constraints on x such as a linear inequalities\nax (cid:22) b. (you can assume that over the feasible set we have ct x > 0 and y (x) > 0.)\nthis problem is not a convex or quasiconvex optimization problem, but it can be solved\nusing convex optimization and a one-dimensional search. the basic ideas are given below;\nyou must supply all details and justification.\n(a) show that the function f : r \u2192 r given by\n\nf (a) = sup{y (x) | ax (cid:22) b, ct x = a},\n\nwhich gives the maximum yield versus cost, is log-concave. this means that by\nsolving a convex optimization problem (in x) we can evaluate the function f .\n\n(b) suppose that we evaluate the function f for enough values of a to give a good approx-\nimation over the range of interest. explain how to use these data to (approximately)\nsolve the problem of minimizing cost per good product.\n\n4.64 optimization with recourse. in an optimization problem with recourse, also called two-\nstage optimization, the cost function and constraints depend not only on our choice of\nvariables, but also on a discrete random variable s \u2208 {1, . . . , s}, which is interpreted as\nspecifying which of s scenarios occurred. the scenario random variable s has known\nprobability distribution \u03c0, with \u03c0i = prob(s = i), i = 1, . . . , s.\nin two-stage optimization, we are to choose the values of two variables, x \u2208 rn and\nz \u2208 rq. the variable x must be chosen before the particular scenario s is known; the\nvariable z, however, is chosen after the value of the scenario random variable is known.\nin other words, z is a function of the scenario random variable s. to describe our choice\nz, we list the values we would choose under the different scenarios, i.e., we list the vectors\n\nhere z3 is our choice of z when s = 3 occurs, and so on. the set of values\n\nz1, . . . , zs \u2208 rq.\n\nx \u2208 rn,\n\nz1, . . . , zs \u2208 rq\n\nis called the policy, since it tells us what choice to make for x (independent of which\nscenario occurs), and also, what choice to make for z in each possible scenario.\nthe variable z is called the recourse variable (or second-stage variable), since it allows\nus to take some action or make a choice after we know which scenario occurred.\nin\ncontrast, our choice of x (which is called the first-stage variable) must be made without\nany knowledge of the scenario.\nfor simplicity we will consider the case with no constraints. the cost function is given by\n\nf : rn \u00d7 rq \u00d7 {1, . . . , s} \u2192 r,\n\nwhere f (x, z, i) gives the cost when the first-stage choice x is made, second-stage choice\nz is made, and scenario i occurs. we will take as the overall objective, to be minimized\nover all policies, the expected cost\n\ne f (x, zs, s) =\n\n\u03c0if (x, zi, i).\n\nsxi=1\n\n "}, {"Page_number": 226, "text": "212\n\n4 convex optimization problems\n\nsuppose that f is a convex function of (x, z), for each scenario i = 1, . . . , s. explain\nhow to find an optimal policy, i.e., one that minimizes the expected cost over all possible\npolicies, using convex optimization.\n\n4.65 optimal operation of a hybrid vehicle. a hybrid vehicle has an internal combustion engine,\na motor/generator connected to a storage battery, and a conventional (friction) brake. in\nthis exercise we consider a (highly simplified) model of a parallel hybrid vehicle, in which\nboth the motor/generator and the engine are directly connected to the drive wheels. the\nengine can provide power to the wheels, and the brake can take power from the wheels,\nturning it into heat. the motor/generator can act as a motor, when it uses energy stored\nin the battery to deliver power to the wheels, or as a generator, when it takes power from\nthe wheels or engine, and uses the power to charge the battery. when the generator takes\npower from the wheels and charges the battery, it is called regenerative braking; unlike\nordinary friction braking, the energy taken from the wheels is stored, and can be used\nlater. the vehicle is judged by driving it over a known, fixed test track to evaluate its\nfuel efficiency.\na diagram illustrating the power flow in the hybrid vehicle is shown below. the arrows\nindicate the direction in which the power flow is considered positive. the engine power\npeng, for example, is positive when it is delivering power; the brake power pbr is positive\nwhen it is taking power from the wheels. the power preq is the required power at the\nwheels. it is positive when the wheels require power (e.g., when the vehicle accelerates,\nclimbs a hill, or cruises on level terrain). the required wheel power is negative when the\nvehicle must decelerate rapidly, or descend a hill.\n\nengine\n\npeng\n\nbrake\n\npbr\n\npreq\n\nwheels\n\nbattery\n\npmg\n\nmotor/\ngenerator\n\nall of these powers are functions of time, which we discretize in one second intervals, with\nt = 1, 2, . . . , t . the required wheel power preq(1), . . . , preq(t ) is given. (the speed of\nthe vehicle on the track is specified, so together with known road slope information, and\nknown aerodynamic and other losses, the power required at the wheels can be calculated.)\npower is conserved, which means we have\n\npreq(t) = peng(t) + pmg(t) \u2212 pbr(t),\n\nt = 1, . . . , t.\n\nthe brake can only dissipate power, so we have pbr(t) \u2265 0 for each t. the engine can only\nprovide power, and only up to a given limit p max\n\neng , i.e., we have\n\nthe motor/generator power is also limited: pmg must satisfy\n\n0 \u2264 peng(t) \u2264 p max\neng ,\n\nt = 1, . . . , t.\n\np min\nmg \u2264 pmg(t) \u2264 p max\nmg ,\n\nt = 1, . . . , t.\n\nmg > 0 is the maximum motor power, and \u2212p min\n\nhere p max\npower.\nthe battery charge or energy at time t is denoted e(t), t = 1, . . . , t + 1. the battery\nenergy satisfies\n\nmg > 0 is the maximum generator\n\ne(t + 1) = e(t) \u2212 pmg(t) \u2212 \u03b7|pmg(t)|,\n\nt = 1, . . . , t,\n\n "}, {"Page_number": 227, "text": "exercises\n\n213\n\nwhere \u03b7 > 0 is a known parameter. (the term \u2212pmg(t) represents the energy removed\nor added the battery by the motor/generator, ignoring any losses. the term \u2212\u03b7|pmg(t)|\nrepresents energy lost through inefficiencies in the battery or motor/generator.)\nthe battery charge must be between 0 (empty) and its limit emax\nbatt (full), at all times. (if\ne(t) = 0, the battery is fully discharged, and no more energy can be extracted from it;\nwhen e(t) = emax\nbatt , the battery is full and cannot be charged.) to make the comparison\nwith non-hybrid vehicles fair, we fix the initial battery charge to equal the final battery\ncharge, so the net energy change is zero over the track: e(1) = e(t + 1). we do not\nspecify the value of the initial (and final) energy.\nthe objective in the problem is the total fuel consumed by the engine, which is\n\nftotal =\n\ntxt=1\n\nf (peng(t)),\n\nwhere f : r \u2192 r is the fuel use characteristic of the engine. we assume that f is\npositive, increasing, and convex.\nformulate this problem as a convex optimization problem, with variables peng(t), pmg(t),\nand pbr(t) for t = 1, . . . , t , and e(t) for t = 1, . . . , t + 1. explain why your formulation\nis equivalent to the problem described above.\n\n "}, {"Page_number": 228, "text": " "}, {"Page_number": 229, "text": "chapter 5\n\nduality\n\n5.1 the lagrange dual function\n\n5.1.1 the lagrangian\n\nwe consider an optimization problem in the standard form (4.1):\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(5.1)\n\nwith variable x \u2208 rn. we assume its domain d =tm\n\ni=1 dom hi\nis nonempty, and denote the optimal value of (5.1) by p\u22c6. we do not assume the\nproblem (5.1) is convex.\n\ni=0 dom fi \u2229 tp\n\nthe basic idea in lagrangian duality is to take the constraints in (5.1) into\naccount by augmenting the objective function with a weighted sum of the constraint\nfunctions. we define the lagrangian l : rn \u00d7 rm \u00d7 rp \u2192 r associated with the\nproblem (5.1) as\n\nl(x, \u03bb, \u03bd) = f0(x) +\n\n\u03bbifi(x) +\n\nmxi=1\n\n\u03bdihi(x),\n\npxi=1\n\nwith dom l = d \u00d7 rm \u00d7 rp. we refer to \u03bbi as the lagrange multiplier associated\nwith the ith inequality constraint fi(x) \u2264 0; similarly we refer to \u03bdi as the lagrange\nmultiplier associated with the ith equality constraint hi(x) = 0. the vectors \u03bb and\n\u03bd are called the dual variables or lagrange multiplier vectors associated with the\nproblem (5.1).\n\n "}, {"Page_number": 230, "text": "216\n\n5 duality\n\n5.1.2 the lagrange dual function\n\nwe define the lagrange dual function (or just dual function) g : rm \u00d7 rp \u2192 r as\nthe minimum value of the lagrangian over x: for \u03bb \u2208 rm, \u03bd \u2208 rp,\npxi=1\n\nx\u2208d f0(x) +\n\n\u03bdihi(x)! .\n\ng(\u03bb, \u03bd) = inf\nx\u2208d\n\nl(x, \u03bb, \u03bd) = inf\n\nmxi=1\n\n\u03bbifi(x) +\n\nwhen the lagrangian is unbounded below in x, the dual function takes on the\nvalue \u2212\u221e. since the dual function is the pointwise infimum of a family of affine\nfunctions of (\u03bb, \u03bd), it is concave, even when the problem (5.1) is not convex.\n\n5.1.3 lower bounds on optimal value\n\nthe dual function yields lower bounds on the optimal value p\u22c6 of the problem (5.1):\nfor any \u03bb (cid:23) 0 and any \u03bd we have\n\ng(\u03bb, \u03bd) \u2264 p\u22c6.\n\n(5.2)\n\nthis important property is easily verified. suppose \u02dcx is a feasible point for the\nproblem (5.1), i.e., fi(\u02dcx) \u2264 0 and hi(\u02dcx) = 0, and \u03bb (cid:23) 0. then we have\n\n\u03bbifi(\u02dcx) +\n\nmxi=1\n\npxi=1\n\n\u03bdihi(\u02dcx) \u2264 0,\n\nsince each term in the first sum is nonpositive, and each term in the second sum is\nzero, and therefore\n\nl(\u02dcx, \u03bb, \u03bd) = f0(\u02dcx) +\n\n\u03bbifi(\u02dcx) +\n\nmxi=1\n\npxi=1\n\n\u03bdihi(\u02dcx) \u2264 f0(\u02dcx).\n\ng(\u03bb, \u03bd) = inf\nx\u2208d\n\nl(x, \u03bb, \u03bd) \u2264 l(\u02dcx, \u03bb, \u03bd) \u2264 f0(\u02dcx).\n\nhence\n\nsince g(\u03bb, \u03bd) \u2264 f0(\u02dcx) holds for every feasible point \u02dcx, the inequality (5.2) follows.\nthe lower bound (5.2) is illustrated in figure 5.1, for a simple problem with x \u2208 r\nand one inequality constraint.\nthe inequality (5.2) holds, but is vacuous, when g(\u03bb, \u03bd) = \u2212\u221e. the dual\nfunction gives a nontrivial lower bound on p\u22c6 only when \u03bb (cid:23) 0 and (\u03bb, \u03bd) \u2208 dom g,\ni.e., g(\u03bb, \u03bd) > \u2212\u221e. we refer to a pair (\u03bb, \u03bd) with \u03bb (cid:23) 0 and (\u03bb, \u03bd) \u2208 dom g as dual\nfeasible, for reasons that will become clear later.\n\n5.1.4 linear approximation interpretation\n\nthe lagrangian and lower bound property can be given a simple interpretation,\nbased on a linear approximation of the indicator functions of the sets {0} and \u2212r+.\n\n "}, {"Page_number": 231, "text": "5.1 the lagrange dual function\n\n217\n\n5\n\n4\n\n3\n\n2\n\n1\n\n0\n\n\u22121\n\u22122\n\u22121\n\n\u22120.5\n\n0\nx\n\n0.5\n\n1\n\nfigure 5.1 lower bound from a dual feasible point. the solid curve shows the\nobjective function f0, and the dashed curve shows the constraint function f1.\nthe feasible set is the interval [\u22120.46, 0.46], which is indicated by the two\ndotted vertical lines. the optimal point and value are x\u22c6 = \u22120.46, p\u22c6 = 1.54\n(shown as a circle). the dotted curves show l(x, \u03bb) for \u03bb = 0.1, 0.2, . . . , 1.0.\neach of these has a minimum value smaller than p\u22c6, since on the feasible set\n(and for \u03bb \u2265 0) we have l(x, \u03bb) \u2264 f0(x).\n\n)\n\u03bb\n(\ng\n\n1.6\n\n1.5\n\n1.4\n\n1.3\n\n1.2\n\n1.1\n\n1\n0\n\n0.2\n\n0.4\n\n\u03bb\n\n0.6\n\n0.8\n\n1\n\nfigure 5.2 the dual function g for the problem in figure 5.1. neither f0 nor\nf1 is convex, but the dual function is concave. the horizontal dashed line\nshows p\u22c6, the optimal value of the problem.\n\n "}, {"Page_number": 232, "text": "218\n\n5 duality\n\nwe first rewrite the original problem (5.1) as an unconstrained problem,\n\ni=1 i0(hi(x)),\nwhere i\u2212 : r \u2192 r is the indicator function for the nonpositive reals,\n\ni=1 i\u2212(fi(x)) +pp\n\nminimize\n\nf0(x) +pm\ni\u2212(u) =(cid:26) 0\n\nu \u2264 0\n\u221e u > 0,\n\n(5.3)\n\nand similarly, i0 is the indicator function of {0}. in the formulation (5.3), the func-\ntion i\u2212(u) can be interpreted as expressing our irritation or displeasure associated\nwith a constraint function value u = fi(x): it is zero if fi(x) \u2264 0, and infinite if\nfi(x) > 0. in a similar way, i0(u) gives our displeasure for an equality constraint\nvalue u = hi(x). we can think of i\u2212 as a \u201cbrick wall\u201d or \u201cinfinitely hard\u201d displea-\nsure function; our displeasure rises from zero to infinite as fi(x) transitions from\nnonpositive to positive.\n\nnow suppose in the formulation (5.3) we replace the function i\u2212(u) with the\nlinear function \u03bbiu, where \u03bbi \u2265 0, and the function i0(u) with \u03bdiu. the objective\nbecomes the lagrangian function l(x, \u03bb, \u03bd), and the dual function value g(\u03bb, \u03bd) is\nthe optimal value of the problem\n\nminimize l(x, \u03bb, \u03bd) = f0(x) +pm\n\ni=1 \u03bbifi(x) +pp\n\nin this formulation, we use a linear or \u201csoft\u201d displeasure function in place of i\u2212\nand i0. for an inequality constraint, our displeasure is zero when fi(x) = 0, and is\npositive when fi(x) > 0 (assuming \u03bbi > 0); our displeasure grows as the constraint\nbecomes \u201cmore violated\u201d. unlike the original formulation, in which any nonpositive\nvalue of fi(x) is acceptable, in the soft formulation we actually derive pleasure from\nconstraints that have margin, i.e., from fi(x) < 0.\n\ni=1 \u03bdihi(x).\n\n(5.4)\n\nclearly the approximation of the indicator function i\u2212(u) with a linear function\n\u03bbiu is rather poor. but the linear function is at least an underestimator of the\nindicator function. since \u03bbiu \u2264 i\u2212(u) and \u03bdiu \u2264 i0(u) for all u, we see immediately\nthat the dual function yields a lower bound on the optimal value of the original\nproblem.\n\nthe idea of replacing the \u201chard\u201d constraints with \u201csoft\u201d versions will come up\n\nagain when we consider interior-point methods (\u00a711.2.1).\n\n5.1.5 examples\n\nin this section we give some examples for which we can derive an analytical ex-\npression for the lagrange dual function.\n\nleast-squares solution of linear equations\n\nwe consider the problem\n\nminimize\nsubject to ax = b,\n\nxt x\n\n(5.5)\n\nwhere a \u2208 rp\u00d7n. this problem has no inequality constraints and p (linear) equality\nconstraints. the lagrangian is l(x, \u03bd) = xt x + \u03bdt (ax \u2212 b), with domain rn \u00d7\n\n "}, {"Page_number": 233, "text": "5.1 the lagrange dual function\n\n219\n\nrp. the dual function is given by g(\u03bd) = inf x l(x, \u03bd). since l(x, \u03bd) is a convex\nquadratic function of x, we can find the minimizing x from the optimality condition\n\n\u2207xl(x, \u03bd) = 2x + at \u03bd = 0,\n\nwhich yields x = \u2212(1/2)at \u03bd. therefore the dual function is\n\ng(\u03bd) = l(\u2212(1/2)at \u03bd, \u03bd) = \u2212(1/4)\u03bdt aat \u03bd \u2212 bt \u03bd,\n\nwhich is a concave quadratic function, with domain rp. the lower bound prop-\nerty (5.2) states that for any \u03bd \u2208 rp, we have\n\n\u2212(1/4)\u03bdt aat \u03bd \u2212 bt \u03bd \u2264 inf{xt x | ax = b}.\n\nstandard form lp\n\nconsider an lp in standard form,\n\nct x\n\nminimize\nsubject to ax = b\nx (cid:23) 0,\n\n(5.6)\n\nwhich has inequality constraint functions fi(x) = \u2212xi, i = 1, . . . , n. to form\nthe lagrangian we introduce multipliers \u03bbi for the n inequality constraints and\nmultipliers \u03bdi for the equality constraints, and obtain\n\nl(x, \u03bb, \u03bd) = ct x \u2212\n\nnxi=1\n\nthe dual function is\n\n\u03bbixi + \u03bdt (ax \u2212 b) = \u2212bt \u03bd + (c + at \u03bd \u2212 \u03bb)t x.\n\ng(\u03bb, \u03bd) = inf\nx\n\nl(x, \u03bb, \u03bd) = \u2212bt \u03bd + inf\n\nx\n\n(c + at \u03bd \u2212 \u03bb)t x,\n\nwhich is easily determined analytically, since a linear function is bounded below\nonly when it is identically zero. thus, g(\u03bb, \u03bd) = \u2212\u221e except when c + at \u03bd \u2212 \u03bb = 0,\nin which case it is \u2212bt \u03bd:\n\ng(\u03bb, \u03bd) =(cid:26) \u2212bt \u03bd at \u03bd \u2212 \u03bb + c = 0\n\n\u2212\u221e otherwise.\n\nnote that the dual function g is finite only on a proper affine subset of rm \u00d7 rp.\nwe will see that this is a common occurrence.\nthe lower bound property (5.2) is nontrivial only when \u03bb and \u03bd satisfy \u03bb (cid:23) 0\nand at \u03bd \u2212 \u03bb + c = 0. when this occurs, \u2212bt \u03bd is a lower bound on the optimal\nvalue of the lp (5.6).\n\ntwo-way partitioning problem\n\nwe consider the (nonconvex) problem\n\nminimize\nsubject to x2\n\nxt w x\ni = 1,\n\ni = 1, . . . , n,\n\n(5.7)\n\n "}, {"Page_number": 234, "text": "220\n\n5 duality\n\nwhere w \u2208 sn. the constraints restrict the values of xi to 1 or \u22121, so the problem\nis equivalent to finding the vector with components \u00b11 that minimizes xt w x. the\nfeasible set here is finite (it contains 2n points) so this problem can in principle\nbe solved by simply checking the objective value of each feasible point. since the\nnumber of feasible points grows exponentially, however, this is possible only for\nsmall problems (say, with n \u2264 30). in general (and for n larger than, say, 50) the\nproblem (5.7) is very difficult to solve.\nwe can interpret the problem (5.7) as a two-way partitioning problem on a set\n\nof n elements, say, {1, . . . , n}: a feasible x corresponds to the partition\n\n{1, . . . , n} = {i | xi = \u22121} \u222a {i | xi = 1}.\n\nthe matrix coefficient wij can be interpreted as the cost of having the elements i\nand j in the same partition, and \u2212wij is the cost of having i and j in different\npartitions. the objective in (5.7) is the total cost, over all pairs of elements, and\nthe problem (5.7) is to find the partition with least total cost.\n\nwe now derive the dual function for this problem. the lagrangian is\n\nl(x, \u03bd) = xt w x +\n\nnxi=1\n\n\u03bdi(x2\n\ni \u2212 1)\n\n= xt (w + diag(\u03bd))x \u2212 1t \u03bd.\nwe obtain the lagrange dual function by minimizing over x:\n\ng(\u03bd) = inf\nx\n\nxt (w + diag(\u03bd))x \u2212 1t \u03bd\n= (cid:26) \u22121t \u03bd w + diag(\u03bd) (cid:23) 0\n\n\u2212\u221e otherwise,\n\nwhere we use the fact that the infimum of a quadratic form is either zero (if the\nform is positive semidefinite) or \u2212\u221e (if the form is not positive semidefinite).\nproblem (5.7). for example, we can take the specific value of the dual variable\n\nthis dual function provides lower bounds on the optimal value of the difficult\n\n\u03bd = \u2212\u03bbmin(w )1,\n\nwhich is dual feasible, since\n\nw + diag(\u03bd) = w \u2212 \u03bbmin(w )i (cid:23) 0.\n\nthis yields the bound on the optimal value p\u22c6\n\np\u22c6 \u2265 \u22121t \u03bd = n\u03bbmin(w ).\n\n(5.8)\n\nremark 5.1 this lower bound on p\u22c6 can also be obtained without using the lagrange\ndual function. first, we replace the constraints x2\ni = n,\nto obtain the modified problem\n\n1 = 1, . . . , x2\n\ni=1 x2\n\nn = 1 withpn\n\nxt w x\n\nminimize\n\nsubject to pn\n\ni=1 x2\n\ni = n.\n\n(5.9)\n\n "}, {"Page_number": 235, "text": "5.1 the lagrange dual function\n\n221\n\nthe constraints of the original problem (5.7) imply the constraint here, so the optimal\nvalue of the problem (5.9) is a lower bound on p\u22c6, the optimal value of (5.7). but the\nmodified problem (5.9) is easily solved as an eigenvalue problem, with optimal value\nn\u03bbmin(w ).\n\n5.1.6 the lagrange dual function and conjugate functions\n\nrecall from \u00a73.3 that the conjugate f \u2217 of a function f : rn \u2192 r is given by\n\nf \u2217(y) = sup\n\nx\u2208dom f(cid:0)yt x \u2212 f (x)(cid:1) .\n\nthe conjugate function and lagrange dual function are closely related. to see one\nsimple connection, consider the problem\n\nminimize\nf (x)\nsubject to x = 0\n\n(which is not very interesting, and solvable by inspection). this problem has\nlagrangian l(x, \u03bd) = f (x) + \u03bdt x, and dual function\n\ng(\u03bd) = inf\n\nx (cid:0)f (x) + \u03bdt x(cid:1) = \u2212 sup\n\nx (cid:0)(\u2212\u03bd)t x \u2212 f (x)(cid:1) = \u2212f \u2217(\u2212\u03bd).\n\nmore generally (and more usefully), consider an optimization problem with\n\nlinear inequality and equality constraints,\n\nminimize\nf0(x)\nsubject to ax (cid:22) b\ncx = d.\n\n(5.10)\n\nusing the conjugate of f0 we can write the dual function for the problem (5.10) as\n\ng(\u03bb, \u03bd) = inf\n\nx (cid:0)f0(x) + \u03bbt (ax \u2212 b) + \u03bdt (cx \u2212 d)(cid:1)\n\n= \u2212bt \u03bb \u2212 dt \u03bd + inf\n= \u2212bt \u03bb \u2212 dt \u03bd \u2212 f \u2217\n\nx (cid:0)f0(x) + (at \u03bb + c t \u03bd)t x(cid:1)\n0 (\u2212at \u03bb \u2212 c t \u03bd).\n\n(5.11)\n\nthe domain of g follows from the domain of f \u2217\n0 :\n\ndom g = {(\u03bb, \u03bd) | \u2212 at \u03bb \u2212 c t \u03bd \u2208 dom f \u2217\n0}.\n\nlet us illustrate this with a few examples.\n\nequality constrained norm minimization\n\nconsider the problem\n\nminimize\nsubject to ax = b,\n\nkxk\n\n(5.12)\n\n "}, {"Page_number": 236, "text": "222\n\n5 duality\n\nwhere k \u00b7 k is any norm. recall (from example 3.26 on page 93) that the conjugate\nof f0 = k \u00b7 k is given by\n\nf \u2217\n\n0 (y) =(cid:26) 0\n\nkyk\u2217 \u2264 1\n\u221e otherwise,\n\nthe indicator function of the dual norm unit ball.\n\nusing the result (5.11) above, the dual function for the problem (5.12) is given\n\nby\n\ng(\u03bd) = \u2212bt \u03bd \u2212 f \u2217\n\n0 (\u2212at \u03bd) =(cid:26) \u2212bt \u03bd\n\nkat \u03bdk\u2217 \u2264 1\n\u2212\u221e otherwise.\n\nentropy maximization\n\nconsider the entropy maximization problem\n\nminimize\nsubject to ax (cid:22) b\n1t x = 1\n\nf0(x) =pn\n\ni=1 xi log xi\n\n(5.13)\n\nwhere dom f0 = rn\n++. the conjugate of the negative entropy function u log u,\nwith scalar variable u, is ev\u22121 (see example 3.21 on page 91). since f0 is a sum of\nnegative entropy functions of different variables, we conclude that its conjugate is\n\nf \u2217\n0 (y) =\n\neyi\u22121,\n\nnxi=1\n\nwith dom f \u2217\ngiven by\n\n0 = rn. using the result (5.11) above, the dual function of (5.13) is\n\ng(\u03bb, \u03bd) = \u2212bt \u03bb \u2212 \u03bd \u2212\n\nnxi=1\n\nwhere ai is the ith column of a.\n\ne\u2212at\n\ni \u03bb\u2212\u03bd\u22121 = \u2212bt \u03bb \u2212 \u03bd \u2212 e\u2212\u03bd\u22121\n\ne\u2212at\ni \u03bb\n\nnxi=1\n\nminimum volume covering ellipsoid\nconsider the problem with variable x \u2208 sn,\n\nminimize\nsubject to at\n\nf0(x) = log det x \u22121\ni xai \u2264 1,\n\ni = 1, . . . , m,\n\n(5.14)\n\nwhere dom f0 = sn\nwith each x \u2208 sn\n\n++. the problem (5.14) has a simple geometric interpretation.\n\n++ we associate the ellipsoid, centered at the origin,\n\nex = {z | zt xz \u2264 1}.\n\nthe volume of this ellipsoid is proportional to (cid:0)det x \u22121(cid:1)1/2\n\n, so the objective\nof (5.14) is, except for a constant and a factor of two, the logarithm of the volume\n\n "}, {"Page_number": 237, "text": "5.2 the lagrange dual problem\n\n223\n\nof ex . the constraints of the problem (5.14) are that ai \u2208 ex . thus the prob-\nlem (5.14) is to determine the minimum volume ellipsoid, centered at the origin,\nthat includes the points a1, . . . , am.\n\nthe inequality constraints in problem (5.14) are affine; they can be expressed\n\nas\n\nin example 3.23 (page 92) we found that the conjugate of f0 is\n\ni )x(cid:1) \u2264 1.\n\ntr(cid:0)(aiat\nf \u2217\n0 (y ) = log det(\u2212y )\u22121 \u2212 n,\n\nwith dom f \u2217\nproblem (5.14) is given by\n\n0 = \u2212sn\n\n++. applying the result (5.11) above, the dual function for the\n\ni(cid:1) \u2212 1t \u03bb + n pm\n\ni=1 \u03bbiaiat\n\ni \u227b 0\n\notherwise.\n\n(5.15)\n\n\u2212\u221e\n\ni=1 \u03bbiaiat\n\ng(\u03bb) =(cid:26) log det(cid:0)pm\nthus, for any \u03bb (cid:23) 0 withpm\nlog det  mxi=1\n\ni=1 \u03bbiaiat\n\ni \u227b 0, the number\n\n\u03bbiaiat\n\ni! \u2212 1t \u03bb + n\n\nis a lower bound on the optimal value of the problem (5.14).\n\n5.2 the lagrange dual problem\n\nfor each pair (\u03bb, \u03bd) with \u03bb (cid:23) 0, the lagrange dual function gives us a lower bound\non the optimal value p\u22c6 of the optimization problem (5.1). thus we have a lower\nbound that depends on some parameters \u03bb, \u03bd. a natural question is: what is the\nbest lower bound that can be obtained from the lagrange dual function?\n\nthis leads to the optimization problem\n\nmaximize\ng(\u03bb, \u03bd)\nsubject to \u03bb (cid:23) 0.\n\n(5.16)\n\nthis problem is called the lagrange dual problem associated with the problem (5.1).\nin this context the original problem (5.1) is sometimes called the primal problem.\nthe term dual feasible, to describe a pair (\u03bb, \u03bd) with \u03bb (cid:23) 0 and g(\u03bb, \u03bd) > \u2212\u221e,\nnow makes sense. it means, as the name implies, that (\u03bb, \u03bd) is feasible for the dual\nproblem (5.16). we refer to (\u03bb\u22c6, \u03bd\u22c6) as dual optimal or optimal lagrange multipliers\nif they are optimal for the problem (5.16).\n\nthe lagrange dual problem (5.16) is a convex optimization problem, since the\nobjective to be maximized is concave and the constraint is convex. this is the case\nwhether or not the primal problem (5.1) is convex.\n\n "}, {"Page_number": 238, "text": "224\n\n5 duality\n\n5.2.1 making dual constraints explicit\n\nthe examples above show that it is not uncommon for the domain of the dual\nfunction,\n\ndom g = {(\u03bb, \u03bd) | g(\u03bb, \u03bd) > \u2212\u221e},\n\nto have dimension smaller than m + p. in many cases we can identify the affine\nhull of dom g, and describe it as a set of linear equality constraints. roughly\nspeaking, this means we can identify the equality constraints that are \u2018hidden\u2019 or\n\u2018implicit\u2019 in the objective g of the dual problem (5.16). in this case we can form\nan equivalent problem, in which these equality constraints are given explicitly as\nconstraints. the following examples demonstrate this idea.\n\nlagrange dual of standard form lp\n\non page 219 we found that the lagrange dual function for the standard form lp\n\nct x\n\nminimize\nsubject to ax = b\nx (cid:23) 0\n\n(5.17)\n\nis given by\n\ng(\u03bb, \u03bd) =(cid:26) \u2212bt \u03bd at \u03bd \u2212 \u03bb + c = 0\n\n\u2212\u221e otherwise.\n\nstrictly speaking, the lagrange dual problem of the standard form lp is to maxi-\nmize this dual function g subject to \u03bb (cid:23) 0, i.e.,\n\ng(\u03bb, \u03bd) =(cid:26) \u2212bt \u03bd at \u03bd \u2212 \u03bb + c = 0\n\n\u2212\u221e otherwise\n\nmaximize\nsubject to \u03bb (cid:23) 0.\n\n(5.18)\n\nhere g is finite only when at \u03bd \u2212 \u03bb + c = 0. we can form an equivalent problem\nby making these equality constraints explicit:\n\nmaximize \u2212bt \u03bd\nsubject to at \u03bd \u2212 \u03bb + c = 0\n\u03bb (cid:23) 0.\n\nthis problem, in turn, can be expressed as\n\nmaximize \u2212bt \u03bd\nsubject to at \u03bd + c (cid:23) 0,\n\n(5.19)\n\n(5.20)\n\nwhich is an lp in inequality form.\n\nnote the subtle distinctions between these three problems. the lagrange dual\nof the standard form lp (5.17) is the problem (5.18), which is equivalent to (but\nnot the same as) the problems (5.19) and (5.20). with some abuse of terminology,\nwe refer to the problem (5.19) or the problem (5.20) as the lagrange dual of the\nstandard form lp (5.17).\n\n "}, {"Page_number": 239, "text": "5.2 the lagrange dual problem\n\n225\n\nlagrange dual of inequality form lp\n\nin a similar way we can find the lagrange dual problem of a linear program in\ninequality form\n\nct x\n\nminimize\nsubject to ax (cid:22) b.\n\n(5.21)\n\nthe lagrangian is\n\nl(x, \u03bb) = ct x + \u03bbt (ax \u2212 b) = \u2212bt \u03bb + (at \u03bb + c)t x,\n\nso the dual function is\n\ng(\u03bb) = inf\nx\n\nl(x, \u03bb) = \u2212bt \u03bb + inf\n\nx\n\n(at \u03bb + c)t x.\n\nthe infimum of a linear function is \u2212\u221e, except in the special case when it is\nidentically zero, so the dual function is\n\ng(\u03bb) =(cid:26) \u2212bt \u03bb at \u03bb + c = 0\n\n\u2212\u221e otherwise.\n\nthe dual variable \u03bb is dual feasible if \u03bb (cid:23) 0 and at \u03bb + c = 0.\nthe lagrange dual of the lp (5.21) is to maximize g over all \u03bb (cid:23) 0. again\nwe can reformulate this by explicitly including the dual feasibility conditions as\nconstraints, as in\n\nmaximize \u2212bt \u03bb\nsubject to at \u03bb + c = 0\n\u03bb (cid:23) 0,\n\n(5.22)\n\nwhich is an lp in standard form.\n\nnote the interesting symmetry between the standard and inequality form lps\nand their duals: the dual of a standard form lp is an lp with only inequality\nconstraints, and vice versa. one can also verify that the lagrange dual of (5.22) is\n(equivalent to) the primal problem (5.21).\n\n5.2.2 weak duality\n\nthe optimal value of the lagrange dual problem, which we denote d\u22c6, is, by def-\ninition, the best lower bound on p\u22c6 that can be obtained from the lagrange dual\nfunction. in particular, we have the simple but important inequality\n\nd\u22c6 \u2264 p\u22c6,\n\n(5.23)\n\nwhich holds even if the original problem is not convex. this property is called weak\nduality.\n\nthe weak duality inequality (5.23) holds when d\u22c6 and p\u22c6 are infinite. for\nexample, if the primal problem is unbounded below, so that p\u22c6 = \u2212\u221e, we must\nhave d\u22c6 = \u2212\u221e, i.e., the lagrange dual problem is infeasible. conversely, if the\ndual problem is unbounded above, so that d\u22c6 = \u221e, we must have p\u22c6 = \u221e, i.e., the\nprimal problem is infeasible.\n\n "}, {"Page_number": 240, "text": "226\n\n5 duality\n\nwe refer to the difference p\u22c6 \u2212 d\u22c6 as the optimal duality gap of the original\nproblem, since it gives the gap between the optimal value of the primal problem\nand the best (i.e., greatest) lower bound on it that can be obtained from the\nlagrange dual function. the optimal duality gap is always nonnegative.\n\nthe bound (5.23) can sometimes be used to find a lower bound on the optimal\nvalue of a problem that is difficult to solve, since the dual problem is always convex,\nand in many cases can be solved efficiently, to find d\u22c6. as an example, consider\nthe two-way partitioning problem (5.7) described on page 219. the dual problem\nis an sdp,\n\nmaximize \u22121t \u03bd\nsubject to w + diag(\u03bd) (cid:23) 0,\n\nwith variable \u03bd \u2208 rn. this problem can be solved efficiently, even for relatively\nits optimal value is a lower bound on the\nlarge values of n, such as n = 1000.\noptimal value of the two-way partitioning problem, and is always at least as good\nas the lower bound (5.8) based on \u03bbmin(w ).\n\n5.2.3 strong duality and slater\u2019s constraint qualification\n\nif the equality\n\nd\u22c6 = p\u22c6\n\n(5.24)\n\nholds, i.e., the optimal duality gap is zero, then we say that strong duality holds.\nthis means that the best bound that can be obtained from the lagrange dual\nfunction is tight.\n\nstrong duality does not, in general, hold. but if the primal problem (5.1) is\n\nconvex, i.e., of the form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m,\n\n(5.25)\n\nwith f0, . . . , fm convex, we usually (but not always) have strong duality. there are\nmany results that establish conditions on the problem, beyond convexity, under\nwhich strong duality holds. these conditions are called constraint qualifications.\none simple constraint qualification is slater\u2019s condition: there exists an x \u2208\n\nrelintd such that\n\nfi(x) < 0,\n\ni = 1, . . . , m,\n\nax = b.\n\n(5.26)\n\nsuch a point is sometimes called strictly feasible, since the inequality constraints\nhold with strict inequalities. slater\u2019s theorem states that strong duality holds, if\nslater\u2019s condition holds (and the problem is convex).\n\nslater\u2019s condition can be refined when some of the inequality constraint func-\ntions fi are affine.\nif the first k constraint functions f1, . . . , fk are affine, then\nstrong duality holds provided the following weaker condition holds: there exists\nan x \u2208 relintd with\n\nfi(x) \u2264 0,\n\ni = 1, . . . , k,\n\nfi(x) < 0,\n\ni = k + 1, . . . , m,\n\nax = b.\n\n(5.27)\n\n "}, {"Page_number": 241, "text": "5.2 the lagrange dual problem\n\n227\n\nin other words, the affine inequalities do not need to hold with strict inequal-\nity. note that the refined slater condition (5.27) reduces to feasibility when the\nconstraints are all linear equalities and inequalities, and dom f0 is open.\n\nslater\u2019s condition (and the refinement (5.27)) not only implies strong duality\nfor convex problems. it also implies that the dual optimal value is attained when\nd\u22c6 > \u2212\u221e, i.e., there exists a dual feasible (\u03bb\u22c6, \u03bd\u22c6) with g(\u03bb\u22c6, \u03bd\u22c6) = d\u22c6 = p\u22c6. we\nwill prove that strong duality obtains, when the primal problem is convex and\nslater\u2019s condition holds, in \u00a75.3.2.\n\n5.2.4 examples\n\nleast-squares solution of linear equations\n\nrecall the problem (5.5):\n\nminimize\nsubject to ax = b.\n\nxt x\n\nthe associated dual problem is\n\nmaximize \u2212(1/4)\u03bdt aat \u03bd \u2212 bt \u03bd,\n\nwhich is an unconstrained concave quadratic maximization problem.\n\nslater\u2019s condition is simply that the primal problem is feasible, so p\u22c6 = d\u22c6\nprovided b \u2208 r(a), i.e., p\u22c6 < \u221e. in fact for this problem we always have strong\nduality, even when p\u22c6 = \u221e. this is the case when b 6\u2208 r(a), so there is a z with\nat z = 0, bt z 6= 0. it follows that the dual function is unbounded above along the\nline {tz | t \u2208 r}, so d\u22c6 = \u221e as well.\nlagrange dual of lp\n\nby the weaker form of slater\u2019s condition, we find that strong duality holds for\nany lp (in standard or inequality form) provided the primal problem is feasible.\napplying this result to the duals, we conclude that strong duality holds for lps\nif the dual is feasible. this leaves only one possible situation in which strong\nduality for lps can fail: both the primal and dual problems are infeasible. this\npathological case can, in fact, occur; see exercise 5.23.\n\nlagrange dual of qcqp\n\nwe consider the qcqp\n\nwith p0 \u2208 sn\n\n(1/2)xt p0x + qt\nminimize\nsubject to (1/2)xt pix + qt\n++, and pi \u2208 sn\n\n0 x + r0\ni x + ri \u2264 0,\n\n+, i = 1, . . . , m. the lagrangian is\nl(x, \u03bb) = (1/2)xt p (\u03bb)x + q(\u03bb)t x + r(\u03bb),\n\ni = 1, . . . , m,\n\n(5.28)\n\nwhere\n\np (\u03bb) = p0 +\n\nmxi=1\n\n\u03bbipi,\n\nq(\u03bb) = q0 +\n\n\u03bbiqi,\n\nr(\u03bb) = r0 +\n\nmxi=1\n\n\u03bbiri.\n\nmxi=1\n\n "}, {"Page_number": 242, "text": "228\n\n5 duality\n\nit is possible to derive an expression for g(\u03bb) for general \u03bb, but it is quite compli-\ncated. if \u03bb (cid:23) 0, however, we have p (\u03bb) \u227b 0 and\n\ng(\u03bb) = inf\nx\n\nl(x, \u03bb) = \u2212(1/2)q(\u03bb)t p (\u03bb)\u22121q(\u03bb) + r(\u03bb).\n\nwe can therefore express the dual problem as\n\nmaximize \u2212(1/2)q(\u03bb)t p (\u03bb)\u22121q(\u03bb) + r(\u03bb)\nsubject to \u03bb (cid:23) 0.\n\n(5.29)\n\nthe slater condition says that strong duality between (5.29) and (5.28) holds if the\nquadratic inequality constraints are strictly feasible, i.e., there exists an x with\n\n(1/2)xt pix + qt\n\ni x + ri < 0,\n\ni = 1, . . . , m.\n\nentropy maximization\n\nour next example is the entropy maximization problem (5.13):\n\nminimize pn\n\nsubject to ax (cid:22) b\n1t x = 1,\n\ni=1 xi log xi\n\nwith domain d = rn\ndual problem is\n\n+. the lagrange dual function was derived on page 222; the\n\nmaximize \u2212bt \u03bb \u2212 \u03bd \u2212 e\u2212\u03bd\u22121pn\n\nsubject to \u03bb (cid:23) 0,\n\ni=1 e\u2212at\ni \u03bb\n\n(5.30)\n\nwith variables \u03bb \u2208 rm, \u03bd \u2208 r. the (weaker) slater condition for (5.13) tells us\nthat the optimal duality gap is zero if there exists an x \u227b 0 with ax (cid:22) b and\n1t x = 1.\nwe can simplify the dual problem (5.30) by maximizing over the dual variable\n\u03bd analytically. for fixed \u03bb, the objective function is maximized when the derivative\nwith respect to \u03bd is zero, i.e.,\n\n\u03bd = log\n\nnxi=1\n\ne\u2212at\n\ni \u03bb \u2212 1.\n\nsubstituting this optimal value of \u03bd into the dual problem gives\n\nmaximize \u2212bt \u03bb \u2212 log(cid:16)pn\n\nsubject to \u03bb (cid:23) 0,\n\ni=1 e\u2212at\n\ni \u03bb(cid:17)\n\nwhich is a geometric program (in convex form) with nonnegativity constraints.\n\nminimum volume covering ellipsoid\n\nwe consider the problem (5.14):\n\nminimize\nsubject to at\n\nlog det x \u22121\ni xai \u2264 1,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 243, "text": "5.2 the lagrange dual problem\n\n229\n\nwith domain d = sn\nproblem can be expressed as\n\n++. the lagrange dual function is given by (5.15), so the dual\n\nmaximize\nsubject to \u03bb (cid:23) 0\n\nlog det(cid:0)pm\n\ni=1 \u03bbiaiat\n\ni(cid:1) \u2212 1t \u03bb + n\n\n(5.31)\n\nwhere we take log det x = \u2212\u221e if x 6\u227b 0.\nx \u2208 sn\nduality always obtains between (5.14) and the dual problem (5.31).\n\nthe (weaker) slater condition for the problem (5.14) is that there exists an\ni xai \u2264 1, for i = 1, . . . , m. this is always satisfied, so strong\n\n++ with at\n\na nonconvex quadratic problem with strong duality\n\non rare occasions strong duality obtains for a nonconvex problem. as an important\nexample, we consider the problem of minimizing a nonconvex quadratic function\nover the unit ball,\n\nxt ax + 2bt x\n\nminimize\nsubject to xt x \u2264 1,\n\n(5.32)\n\nwhere a \u2208 sn, a 6(cid:23) 0, and b \u2208 rn. since a 6(cid:23) 0, this is not a convex problem. this\nproblem is sometimes called the trust region problem, and arises in minimizing a\nsecond-order approximation of a function over the unit ball, which is the region in\nwhich the approximation is assumed to be approximately valid.\n\nthe lagrangian is\n\nl(x, \u03bb) = xt ax + 2bt x + \u03bb(xt x \u2212 1) = xt (a + \u03bbi)x + 2bt x \u2212 \u03bb,\n\nso the dual function is given by\n\ng(\u03bb) =(cid:26) \u2212bt (a + \u03bbi)\u2020b \u2212 \u03bb a + \u03bbi (cid:23) 0,\n\notherwise,\n\n\u2212\u221e\n\nb \u2208 r(a + \u03bbi)\n\nwhere (a + \u03bbi)\u2020 is the pseudo-inverse of a + \u03bbi. the lagrange dual problem is\nthus\n\nmaximize \u2212bt (a + \u03bbi)\u2020b \u2212 \u03bb\nsubject to a + \u03bbi (cid:23) 0,\n\nb \u2208 r(a + \u03bbi),\n\n(5.33)\n\nwith variable \u03bb \u2208 r. although it is not obvious from this expression, this is a\nconvex optimization problem. in fact, it is readily solved since it can be expressed\nas\n\nmaximize \u2212pn\n\nsubject to \u03bb \u2265 \u2212\u03bbmin(a),\n\ni=1(qt\n\ni b)2/(\u03bbi + \u03bb) \u2212 \u03bb\n\nwhere \u03bbi and qi are the eigenvalues and corresponding (orthonormal) eigenvectors\nof a, and we interpret (qt\n\ni b)2/0 as 0 if qt\n\ni b = 0 and as \u221e otherwise.\n\ndespite the fact that the original problem (5.32) is not convex, we always have\nzero optimal duality gap for this problem: the optimal values of (5.32) and (5.33)\nare always the same. in fact, a more general result holds: strong duality holds for\nany optimization problem with quadratic objective and one quadratic inequality\nconstraint, provided slater\u2019s condition holds; see \u00a7b.1.\n\n "}, {"Page_number": 244, "text": "230\n\n5 duality\n\n5.2.5 mixed strategies for matrix games\n\nin this section we use strong duality to derive a basic result for zero-sum matrix\ngames. we consider a game with two players. player 1 makes a choice (or move)\nk \u2208 {1, . . . , n}, and player 2 makes a choice l \u2208 {1, . . . , m}. player 1 then makes a\npayment of pkl to player 2, where p \u2208 rn\u00d7m is the payoff matrix for the game.\nthe goal of player 1 is to make the payment as small as possible, while the goal of\nplayer 2 is to maximize it.\n\nthe players use randomized or mixed strategies, which means that each player\nmakes his or her choice randomly and independently of the other player\u2019s choice,\naccording to a probability distribution:\n\nprob(k = i) = ui,\n\ni = 1, . . . , n,\n\nprob(l = i) = vi,\n\ni = 1, . . . , m.\n\nhere u and v give the probability distributions of the choices of the two players,\ni.e., their associated strategies. the expected payoff from player 1 to player 2 is\nthen\n\nnxk=1\n\nmxl=1\n\nukvlpkl = ut p v.\n\nplayer 1 wishes to choose u to minimize ut p v, while player 2 wishes to choose v\nto maximize ut p v.\n\nlet us first analyze the game from the point of view of player 1, assuming her\nstrategy u is known to player 2 (which clearly gives an advantage to player 2).\nplayer 2 will choose v to maximize ut p v, which results in the expected payoff\n\nsup{ut p v | v (cid:23) 0, 1t v = 1} = max\n\ni=1,...,m\n\n(p t u)i.\n\nthe best thing player 1 can do is to choose u to minimize this worst-case payoff to\nplayer 2, i.e., to choose a strategy u that solves the problem\n\nminimize maxi=1,...,m(p t u)i\n1t u = 1,\nsubject to u (cid:23) 0,\n\n(5.34)\n\nwhich is a piecewise-linear convex optimization problem. we will denote the opti-\nmal value of this problem as p\u22c6\n1. this is the smallest expected payoff player 1 can\narrange to have, assuming that player 2 knows the strategy of player 1, and plays\nto his own maximum advantage.\n\nin a similar way we can consider the situation in which v, the strategy of\nplayer 2, is known to player 1 (which gives an advantage to player 1). in this case\nplayer 1 chooses u to minimize ut p v, which results in an expected payoff of\n\ninf{ut p v | u (cid:23) 0, 1t u = 1} = min\n\ni=1,...,n\n\n(p v)i.\n\nplayer 2 chooses v to maximize this, i.e., chooses a strategy v that solves the\nproblem\n\nmaximize mini=1,...,n(p v)i\nsubject to\n\n1t v = 1,\n\nv (cid:23) 0,\n\n(5.35)\n\n "}, {"Page_number": 245, "text": "5.2 the lagrange dual problem\n\n231\n\nwhich is another convex optimization problem, with piecewise-linear (concave) ob-\njective. we will denote the optimal value of this problem as p\u22c6\n2. this is the largest\nexpected payoff player 2 can guarantee getting, assuming that player 1 knows the\nstrategy of player 2.\n\nit is intuitively obvious that knowing your opponent\u2019s strategy gives an advan-\ntage (or at least, cannot hurt), and indeed, it is easily shown that we always have\n1 \u2265 p\u22c6\np\u22c6\n2, which is nonnegative, as the\nadvantage conferred on a player by knowing the opponent\u2019s strategy.\n\n2. we can interpret the difference, p\u22c6\n\n1 \u2212 p\u22c6\n\nusing duality, we can establish a result that is at first surprising: p\u22c6\n\n1 = p\u22c6\n2.\nin other words, in a matrix game with mixed strategies, there is no advantage to\nknowing your opponent\u2019s strategy. we will establish this result by showing that\nthe two problems (5.34) and (5.35) are lagrange dual problems, for which strong\nduality obtains.\n\nwe start by formulating (5.34) as an lp,\n\nt\n\nminimize\nsubject to u (cid:23) 0,\n\np t u (cid:22) t1,\n\n1t u = 1\n\nwith extra variable t \u2208 r. introducing the multiplier \u03bb for p t u (cid:22) t1, \u00b5 for u (cid:23) 0,\nand \u03bd for 1t u = 1, the lagrangian is\n\nt + \u03bbt (p t u \u2212 t1) \u2212 \u00b5t u + \u03bd(1 \u2212 1t u) = \u03bd + (1 \u2212 1t \u03bb)t + (p \u03bb \u2212 \u03bd1 \u2212 \u00b5)t u,\n\nso the dual function is\n\ng(\u03bb, \u00b5, \u03bd) =(cid:26) \u03bd\n\n1t \u03bb = 1, p \u03bb \u2212 \u03bd1 = \u00b5\n\n\u2212\u221e otherwise.\n\nthe dual problem is then\n\n\u03bd\n\nmaximize\nsubject to \u03bb (cid:23) 0,\n\n1t \u03bb = 1, \u00b5 (cid:23) 0\n\np \u03bb \u2212 \u03bd1 = \u00b5.\n\neliminating \u00b5 we obtain the following lagrange dual of (5.34):\n\n\u03bd\n\nmaximize\nsubject to \u03bb (cid:23) 0,\n\np \u03bb (cid:23) \u03bd1,\n\n1t \u03bb = 1\n\nwith variables \u03bb, \u03bd. but this is clearly equivalent to (5.35). since the lps are\nfeasible, we have strong duality; the optimal values of (5.34) and (5.35) are equal.\n\n "}, {"Page_number": 246, "text": "232\n\n5 duality\n\n5.3 geometric interpretation\n\n5.3.1 weak and strong duality via set of values\n\nwe can give a simple geometric interpretation of the dual function in terms of the\nset\ng = {(f1(x), . . . , fm(x), h1(x), . . . , hp(x), f0(x)) \u2208 rm \u00d7 rp \u00d7 r | x \u2208 d}, (5.36)\nwhich is the set of values taken on by the constraint and objective functions. the\noptimal value p\u22c6 of (5.1) is easily expressed in terms of g as\np\u22c6 = inf{t | (u, v, t) \u2208 g, u (cid:22) 0, v = 0}.\n\nto evaluate the dual function at (\u03bb, \u03bd), we minimize the affine function\n\n(\u03bb, \u03bd, 1)t (u, v, t) =\n\n\u03bbiui +\n\nmxi=1\n\npxi=1\n\n\u03bdivi + t\n\nover (u, v, t) \u2208 g, i.e., we have\n\ng(\u03bb, \u03bd) = inf{(\u03bb, \u03bd, 1)t (u, v, t) | (u, v, t) \u2208 g}.\n\nin particular, we see that if the infimum is finite, then the inequality\n\n(\u03bb, \u03bd, 1)t (u, v, t) \u2265 g(\u03bb, \u03bd)\n\ndefines a supporting hyperplane to g. this is sometimes referred to as a nonvertical\nsupporting hyperplane, because the last component of the normal vector is nonzero.\nnow suppose \u03bb (cid:23) 0. then, obviously, t \u2265 (\u03bb, \u03bd, 1)t (u, v, t) if u (cid:22) 0 and v = 0.\n\ntherefore\n\np\u22c6 = inf{t | (u, v, t) \u2208 g, u (cid:22) 0, v = 0}\n\n\u2265 inf{(\u03bb, \u03bd, 1)t (u, v, t) | (u, v, t) \u2208 g, u (cid:22) 0, v = 0}\n\u2265 inf{(\u03bb, \u03bd, 1)t (u, v, t) | (u, v, t) \u2208 g}\n= g(\u03bb, \u03bd),\n\ni.e., we have weak duality. this interpretation is illustrated in figures 5.3 and 5.4,\nfor a simple problem with one inequality constraint.\n\nepigraph variation\n\nin this section we describe a variation on the geometric interpretation of duality in\nterms of g, which explains why strong duality obtains for (most) convex problems.\nwe define the set a \u2286 rm \u00d7 rp \u00d7 r as\na = g +(cid:0)rm\n\n+ \u00d7 {0} \u00d7 r+(cid:1) ,\n\nor, more explicitly,\n\n(5.37)\n\na = {(u, v, t) | \u2203x \u2208 d, fi(x) \u2264 ui, i = 1, . . . , m,\n\nhi(x) = vi, i = 1, . . . , p, f0(x) \u2264 t},\n\n "}, {"Page_number": 247, "text": "5.3 geometric interpretation\n\n233\n\n\u03bbu + t = g(\u03bb)\n\nt\n\ng\n\np\u22c6\n\ng(\u03bb)\n\nu\n\nfigure 5.3 geometric interpretation of dual function and lower bound g(\u03bb) \u2264\np\u22c6, for a problem with one (inequality) constraint. given \u03bb, we minimize\n(\u03bb, 1)t (u, t) over g = {(f1(x), f0(x)) | x \u2208 d}. this yields a supporting\nhyperplane with slope \u2212\u03bb. the intersection of this hyperplane with the\nu = 0 axis gives g(\u03bb).\n\n\u03bb2u + t = g(\u03bb2)\n\n\u03bb\u22c6u + t = g(\u03bb\u22c6)\n\n\u03bb1u + t = g(\u03bb1)\n\nt\n\ng\n\np\u22c6\nd\u22c6\n\nu\n\nfigure 5.4 supporting hyperplanes corresponding to three dual feasible val-\nues of \u03bb, including the optimum \u03bb\u22c6. strong duality does not hold; the\noptimal duality gap p\u22c6 \u2212 d\u22c6 is positive.\n\n "}, {"Page_number": 248, "text": "234\n\n5 duality\n\nt\n\n(0, p\u22c6)\n\n(0, g(\u03bb))\n\na\n\nu\n\n\u03bbu + t = g(\u03bb)\n\nfigure 5.5 geometric interpretation of dual function and lower bound g(\u03bb) \u2264\np\u22c6, for a problem with one (inequality) constraint. given \u03bb, we minimize\n(\u03bb, 1)t (u, t) over a = {(u, t) | \u2203x \u2208 d, f0(x) \u2264 t, f1(x) \u2264 u}. this yields\na supporting hyperplane with slope \u2212\u03bb. the intersection of this hyperplane\nwith the u = 0 axis gives g(\u03bb).\n\nwe can think of a as a sort of epigraph form of g, since a includes all the points in\ng, as well as points that are \u2018worse\u2019, i.e., those with larger objective or inequality\nconstraint function values.\n\nwe can express the optimal value in terms of a as\np\u22c6 = inf{t | (0, 0, t) \u2208 a}.\n\nto evaluate the dual function at a point (\u03bb, \u03bd) with \u03bb (cid:23) 0, we can minimize the\naffine function (\u03bb, \u03bd, 1)t (u, v, t) over a: if \u03bb (cid:23) 0, then\n\ng(\u03bb, \u03bd) = inf{(\u03bb, \u03bd, 1)t (u, v, t) | (u, v, t) \u2208 a}.\n\nif the infimum is finite, then\n\n(\u03bb, \u03bd, 1)t (u, v, t) \u2265 g(\u03bb, \u03bd)\n\ndefines a nonvertical supporting hyperplane to a.\nin particular, since (0, 0, p\u22c6) \u2208 bda, we have\n\np\u22c6 = (\u03bb, \u03bd, 1)t (0, 0, p\u22c6) \u2265 g(\u03bb, \u03bd),\n\n(5.38)\n\nthe weak duality lower bound. strong duality holds if and only if we have equality\nin (5.38) for some dual feasible (\u03bb, \u03bd), i.e., there exists a nonvertical supporting\nhyperplane to a at its boundary point (0, 0, p\u22c6).\n\nthis second interpretation is illustrated in figure 5.5.\n\n5.3.2 proof of strong duality under constraint qualification\n\nin this section we prove that slater\u2019s constraint qualification guarantees strong\nduality (and that the dual optimum is attained) for a convex problem. we consider\n\n "}, {"Page_number": 249, "text": "5.3 geometric interpretation\n\n235\n\nthe primal problem (5.25), with f0, . . . , fm convex, and assume slater\u2019s condition\nholds: there exists \u02dcx \u2208 relintd with fi(\u02dcx) < 0, i = 1, . . . , m, and a\u02dcx = b. in\norder to simplify the proof, we make two additional assumptions: first that d has\nnonempty interior (hence, relintd = intd) and second, that rank a = p. we\nassume that p\u22c6 is finite. (since there is a feasible point, we can only have p\u22c6 = \u2212\u221e\nor p\u22c6 finite; if p\u22c6 = \u2212\u221e, then d\u22c6 = \u2212\u221e by weak duality.)\nthe set a defined in (5.37) is readily shown to be convex if the underlying\nproblem is convex. we define a second convex set b as\n\nb = {(0, 0, s) \u2208 rm \u00d7 rp \u00d7 r | s < p\u22c6}.\n\nthe sets a and b do not intersect. to see this, suppose (u, v, t) \u2208 a \u2229 b. since\n(u, v, t) \u2208 b we have u = 0, v = 0, and t < p\u22c6. since (u, v, t) \u2208 a, there exists an x\nwith fi(x) \u2264 0, i = 1, . . . , m, ax \u2212 b = 0, and f0(x) \u2264 t < p\u22c6, which is impossible\nsince p\u22c6 is the optimal value of the primal problem.\nby the separating hyperplane theorem of \u00a72.5.1 there exists (\u02dc\u03bb, \u02dc\u03bd, \u00b5) 6= 0 and \u03b1\n(5.39)\n\n(u, v, t) \u2208 a =\u21d2 \u02dc\u03bbt u + \u02dc\u03bdt v + \u00b5t \u2265 \u03b1,\n\nsuch that\n\nand\n\n(u, v, t) \u2208 b =\u21d2 \u02dc\u03bbt u + \u02dc\u03bdt v + \u00b5t \u2264 \u03b1.\n\n(5.40)\nfrom (5.39) we conclude that \u02dc\u03bb (cid:23) 0 and \u00b5 \u2265 0. (otherwise \u02dc\u03bbt u + \u00b5t is unbounded\nbelow over a, contradicting (5.39).) the condition (5.40) simply means that \u00b5t \u2264 \u03b1\nfor all t < p\u22c6, and hence, \u00b5p\u22c6 \u2264 \u03b1. together with (5.39) we conclude that for any\nx \u2208 d,\n\n\u02dc\u03bbifi(x) + \u02dc\u03bdt (ax \u2212 b) + \u00b5f0(x) \u2265 \u03b1 \u2265 \u00b5p\u22c6.\n\n(5.41)\n\nmxi=1\n\nassume that \u00b5 > 0. in that case we can divide (5.41) by \u00b5 to obtain\n\nl(x, \u02dc\u03bb/\u00b5, \u02dc\u03bd/\u00b5) \u2265 p\u22c6\n\nfor all x \u2208 d, from which it follows, by minimizing over x, that g(\u03bb, \u03bd) \u2265 p\u22c6, where\nwe define\n\n\u03bb = \u02dc\u03bb/\u00b5,\n\n\u03bd = \u02dc\u03bd/\u00b5.\n\nby weak duality we have g(\u03bb, \u03bd) \u2264 p\u22c6, so in fact g(\u03bb, \u03bd) = p\u22c6. this shows that\nstrong duality holds, and that the dual optimum is attained, at least in the case\nwhen \u00b5 > 0.\n\nnow consider the case \u00b5 = 0. from (5.41), we conclude that for all x \u2208 d,\n\nmxi=1\n\n\u02dc\u03bbifi(x) + \u02dc\u03bdt (ax \u2212 b) \u2265 0.\n\n(5.42)\n\napplying this to the point \u02dcx that satisfies the slater condition, we have\n\nmxi=1\n\n\u02dc\u03bbifi(\u02dcx) \u2265 0.\n\n "}, {"Page_number": 250, "text": "236\n\n5 duality\n\nt\n\n(\u02dcu, \u02dct)\n\nb\n\na\n\nu\n\nfigure 5.6 illustration of strong duality proof, for a convex problem that sat-\nisfies slater\u2019s constraint qualification. the set a is shown shaded, and the\nset b is the thick vertical line segment, not including the point (0, p\u22c6), shown\nas a small open circle. the two sets are convex and do not intersect, so they\ncan be separated by a hyperplane. slater\u2019s constraint qualification guaran-\ntees that any separating hyperplane must be nonvertical, since it must pass\nto the left of the point (\u02dcu, \u02dct) = (f1(\u02dcx), f0(\u02dcx)), where \u02dcx is strictly feasible.\n\nsince fi(\u02dcx) < 0 and \u02dc\u03bbi \u2265 0, we conclude that \u02dc\u03bb = 0. from (\u02dc\u03bb, \u02dc\u03bd, \u00b5) 6= 0 and\n\u02dc\u03bb = 0, \u00b5 = 0, we conclude that \u02dc\u03bd 6= 0. then (5.42) implies that for all x \u2208 d,\n\u02dc\u03bdt (ax \u2212 b) \u2265 0. but \u02dcx satisfies \u02dc\u03bdt (a\u02dcx \u2212 b) = 0, and since \u02dcx \u2208 intd, there are\npoints in d with \u02dc\u03bdt (ax \u2212 b) < 0 unless at \u02dc\u03bd = 0. this, of course, contradicts our\nassumption that rank a = p.\n\nthe geometric idea behind the proof is illustrated in figure 5.6, for a simple\nproblem with one inequality constraint. the hyperplane separating a and b defines\na supporting hyperplane to a at (0, p\u22c6). slater\u2019s constraint qualification is used\nto establish that the hyperplane must be nonvertical (i.e., has a normal vector of\nthe form (\u03bb\u22c6, 1)). (for a simple example of a convex problem with one inequality\nconstraint for which strong duality fails, see exercise 5.21.)\n\n5.3.3 multicriterion interpretation\n\nthere is a natural connection between lagrange duality for a problem without\nequality constraints,\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\n(5.43)\n\n "}, {"Page_number": 251, "text": "5.4 saddle-point interpretation\n\n237\n\nand the scalarization method for the (unconstrained) multicriterion problem\n\nminimize (w.r.t. rm+1\n\n+ ) f (x) = (f1(x), . . . , fm(x), f0(x))\n\n(5.44)\n\n(see \u00a74.7.4). in scalarization, we choose a positive vector \u02dc\u03bb, and minimize the scalar\nfunction \u02dc\u03bbt f (x); any minimizer is guaranteed to be pareto optimal. since we can\nscale \u02dc\u03bb by a positive constant, without affecting the minimizers, we can, without\nloss of generality, take \u02dc\u03bb = (\u03bb, 1). thus, in scalarization we minimize the function\n\n\u02dc\u03bbt f (x) = f0(x) +\n\n\u03bbifi(x),\n\nmxi=1\n\nwhich is exactly the lagrangian for the problem (5.43).\n\nto establish that every pareto optimal point of a convex multicriterion problem\nminimizes the function \u02dc\u03bbt f (x) for some nonnegative weight vector \u02dc\u03bb, we considered\nthe set a, defined in (4.62),\n\na = {t \u2208 rm+1 | \u2203x \u2208 d, fi(x) \u2264 ti, i = 0, . . . , m},\n\nwhich is exactly the same as the set a defined in (5.37), that arises in lagrange dual-\nity. here too we constructed the required weight vector as a supporting hyperplane\nto the set, at an arbitrary pareto optimal point. in multicriterion optimization,\nwe interpret the components of the weight vector as giving the relative weights\nbetween the objective functions. when we fix the last component of the weight\nvector (associated with f0) to be one, the other weights have the interpretation of\nthe cost relative to f0, i.e., the cost relative to the objective.\n\n5.4 saddle-point interpretation\n\nin this section we give several interpretations of lagrange duality. the material of\nthis section will not be used in the sequel.\n\n5.4.1 max-min characterization of weak and strong duality\n\nit is possible to express the primal and the dual optimization problems in a form\nthat is more symmetric. to simplify the discussion we assume there are no equality\nconstraints; the results are easily extended to cover them.\n\nfirst note that\n\nl(x, \u03bb) = sup\n\nsup\n\u03bb(cid:23)0\n\n\u03bbifi(x)!\n\nmxi=1\n\n\u03bb(cid:23)0 f0(x) +\n= (cid:26) f0(x)\n\n\u221e\n\nfi(x) \u2264 0,\notherwise.\n\ni = 1, . . . , m\n\n "}, {"Page_number": 252, "text": "238\n\n5 duality\n\nindeed, suppose x is not feasible, and fi(x) > 0 for some i. then sup\u03bb(cid:23)0 l(x, \u03bb) =\n\u221e, as can be seen by choosing \u03bbj = 0, j 6= i, and \u03bbi \u2192 \u221e. on the other\nhand, if fi(x) \u2264 0, i = 1, . . . , m, then the optimal choice of \u03bb is \u03bb = 0 and\nsup\u03bb(cid:23)0 l(x, \u03bb) = f0(x). this means that we can express the optimal value of the\nprimal problem as\n\np\u22c6 = inf\nx\n\nsup\n\u03bb(cid:23)0\n\nl(x, \u03bb).\n\nby the definition of the dual function, we also have\n\nd\u22c6 = sup\n\u03bb(cid:23)0\n\ninf\nx\n\nl(x, \u03bb).\n\nthus, weak duality can be expressed as the inequality\n\nsup\n\u03bb(cid:23)0\n\ninf\nx\n\nl(x, \u03bb) \u2264 inf\n\nx\n\nsup\n\u03bb(cid:23)0\n\nl(x, \u03bb),\n\n(5.45)\n\nand strong duality as the equality\n\nsup\n\u03bb(cid:23)0\n\ninf\nx\n\nl(x, \u03bb) = inf\nx\n\nsup\n\u03bb(cid:23)0\n\nl(x, \u03bb).\n\nstrong duality means that the order of the minimization over x and the maximiza-\ntion over \u03bb (cid:23) 0 can be switched without affecting the result.\n\nin fact, the inequality (5.45) does not depend on any properties of l: we have\n\nsup\nz\u2208z\n\ninf\nw\u2208w\n\nf (w, z) \u2264 inf\n\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z)\n\n(5.46)\n\nfor any f : rn\u00d7rm \u2192 r (and any w \u2286 rn and z \u2286 rm). this general inequality\nis called the max-min inequality. when equality holds, i.e.,\n\nsup\nz\u2208z\n\ninf\nw\u2208w\n\nf (w, z) = inf\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z)\n\n(5.47)\n\nwe say that f (and w and z) satisfy the strong max-min property or the saddle-\npoint property. of course the strong max-min property holds only in special cases,\nfor example, when f : rn \u00d7 rm \u2192 r is the lagrangian of a problem for which\nstrong duality obtains, w = rn, and z = rm\n+ .\n\n5.4.2 saddle-point interpretation\n\nwe refer to a pair \u02dcw \u2208 w , \u02dcz \u2208 z as a saddle-point for f (and w and z) if\n\nf ( \u02dcw, z) \u2264 f ( \u02dcw, \u02dcz) \u2264 f (w, \u02dcz)\n\nfor all w \u2208 w and z \u2208 z. in other words, \u02dcw minimizes f (w, \u02dcz) (over w \u2208 w ) and\n\u02dcz maximizes f ( \u02dcw, z) (over z \u2208 z):\n\nf ( \u02dcw, \u02dcz) = inf\nw\u2208w\n\nf (w, \u02dcz),\n\nf ( \u02dcw, \u02dcz) = sup\nz\u2208z\n\nf ( \u02dcw, z).\n\n "}, {"Page_number": 253, "text": "5.4 saddle-point interpretation\n\n239\n\nthis implies that the strong max-min property (5.47) holds, and that the common\nvalue is f ( \u02dcw, \u02dcz).\n\nreturning to our discussion of lagrange duality, we see that if x\u22c6 and \u03bb\u22c6 are\nprimal and dual optimal points for a problem in which strong duality obtains, they\nform a saddle-point for the lagrangian. the converse is also true: if (x, \u03bb) is a\nsaddle-point of the lagrangian, then x is primal optimal, \u03bb is dual optimal, and\nthe optimal duality gap is zero.\n\n5.4.3 game interpretation\n\nwe can interpret the max-min inequality (5.46), the max-min equality (5.47), and\nthe saddle-point property, in terms of a continuous zero-sum game.\nif the first\nplayer chooses w \u2208 w , and the second player selects z \u2208 z, then player 1 pays an\namount f (w, z) to player 2. player 1 therefore wants to minimize f , while player 2\nwants to maximize f . (the game is called continuous since the choices are vectors,\nand not discrete.)\n\nsuppose that player 1 makes his choice first, and then player 2, after learning\nthe choice of player 1, makes her selection. player 2 wants to maximize the payoff\nf (w, z), and so will choose z \u2208 z to maximize f (w, z). the resulting payoff will\nbe supz\u2208z f (w, z), which depends on w, the choice of the first player. (we assume\nhere that the supremum is achieved; if not the optimal payoff can be arbitrarily\nclose to supz\u2208z f (w, z).) player 1 knows (or assumes) that player 2 will follow this\nstrategy, and so will choose w \u2208 w to make this worst-case payoff to player 2 as\nsmall as possible. thus player 1 chooses\n\nwhich results in the payoff\n\nfrom player 1 to player 2.\n\nargmin\n\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z),\n\ninf\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z)\n\nnow suppose the order of play is reversed: player 2 must choose z \u2208 z first, and\nthen player 1 chooses w \u2208 w (with knowledge of z). following a similar argument,\nif the players follow the optimal strategy, player 2 should choose z \u2208 z to maximize\ninf w\u2208w f (w, z), which results in the payoff of\n\nsup\nz\u2208z\n\ninf\nw\u2208w\n\nf (w, z)\n\nfrom player 1 to player 2.\n\nthe max-min inequality (5.46) states the (intuitively obvious) fact that it is\nbetter for a player to go second, or more precisely, for a player to know his or her\nopponent\u2019s choice before choosing. in other words, the payoff to player 2 will be\nlarger if player 1 must choose first. when the saddle-point property (5.47) holds,\nthere is no advantage to playing second.\n\nif ( \u02dcw, \u02dcz) is a saddle-point for f (and w and z), then it is called a solution of\nthe game; \u02dcw is called the optimal choice or strategy for player 1, and \u02dcz is called\n\n "}, {"Page_number": 254, "text": "240\n\n5 duality\n\nthe optimal choice or strategy for player 2. in this case there is no advantage to\nplaying second.\n\nnow consider the special case where the payoff function is the lagrangian,\nw = rn and z = rm\n+ . here player 1 chooses the primal variable x, while player 2\nchooses the dual variable \u03bb (cid:23) 0. by the argument above, the optimal choice for\nplayer 2, if she must choose first, is any \u03bb\u22c6 which is dual optimal, which results\nin a payoff to player 2 of d\u22c6. conversely, if player 1 must choose first, his optimal\nchoice is any primal optimal x\u22c6, which results in a payoff of p\u22c6.\n\nthe optimal duality gap for the problem is exactly equal to the advantage\nafforded the player who goes second, i.e., the player who has the advantage of\nknowing his or her opponent\u2019s choice before choosing. if strong duality holds, then\nthere is no advantage to the players of knowing their opponent\u2019s choice.\n\n5.4.4 price or tax interpretation\n\nlagrange duality has an interesting economic interpretation. suppose the variable\nx denotes how an enterprise operates and f0(x) denotes the cost of operating at\nx, i.e., \u2212f0(x) is the profit (say, in dollars) made at the operating condition x.\neach constraint fi(x) \u2264 0 represents some limit, such as a limit on resources (e.g.,\nwarehouse space, labor) or a regulatory limit (e.g., environmental). the operating\ncondition that maximizes profit while respecting the limits can be found by solving\nthe problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m.\n\nthe resulting optimal profit is \u2212p\u22c6.\nnow imagine a second scenario in which the limits can be violated, by paying an\nadditional cost which is linear in the amount of violation, measured by fi. thus the\npayment made by the enterprise for the ith limit or constraint is \u03bbifi(x). payments\nare also made to the firm for constraints that are not tight; if fi(x) < 0, then \u03bbifi(x)\nrepresents a payment to the firm. the coefficient \u03bbi has the interpretation of the\nprice for violating fi(x) \u2264 0; its units are dollars per unit violation (as measured\nby fi). for the same price the enterprise can sell any \u2018unused\u2019 portion of the ith\nconstraint. we assume \u03bbi \u2265 0, i.e., the firm must pay for violations (and receives\nincome if a constraint is not tight).\nas an example, suppose the first constraint in the original problem, f1(x) \u2264\nin this new\n0, represents a limit on warehouse space (say, in square meters).\narrangement, we open the possibility that the firm can rent extra warehouse space\nat a cost of \u03bb1 dollars per square meter and also rent out unused space, at the same\nrate.\n\n\u03bbi, is l(x, \u03bb) = f0(x) +pm\n\nthe total cost to the firm, for operating condition x, and constraint prices\ni=1 \u03bbifi(x). the firm will obviously operate so as to\nminimize its total cost l(x, \u03bb), which yields a cost g(\u03bb). the dual function therefore\nrepresents the optimal cost to the firm, as a function of the constraint price vector\n\u03bb. the optimal dual value, d\u22c6, is the optimal cost to the enterprise under the least\nfavorable set of prices.\n\n "}, {"Page_number": 255, "text": "5.5 optimality conditions\n\n241\n\nusing this interpretation we can paraphrase weak duality as follows: the opti-\nmal cost to the firm in the second scenario (in which constraint violations can be\nbought and sold) is less than or equal to the cost in the original situation (which\nhas constraints that cannot be violated), even with the most unfavorable prices.\nthis is obvious: if x\u22c6 is optimal in the first scenario, then the operating cost of x\u22c6\nin the second scenario will be lower than f0(x\u22c6), since some income can be derived\nfrom the constraints that are not tight. the optimal duality gap is then the min-\nimum possible advantage to the enterprise of being allowed to pay for constraint\nviolations (and receive payments for nontight constraints).\n\nnow suppose strong duality holds, and the dual optimum is attained. we can\ninterpret a dual optimal \u03bb\u22c6 as a set of prices for which there is no advantage to\nthe firm in being allowed to pay for constraint violations (or receive payments for\nnontight constraints). for this reason a dual optimal \u03bb\u22c6 is sometimes called a set\nof shadow prices for the original problem.\n\n5.5 optimality conditions\n\nwe remind the reader that we do not assume the problem (5.1) is convex, unless\nexplicitly stated.\n\n5.5.1 certificate of suboptimality and stopping criteria\n\nif we can find a dual feasible (\u03bb, \u03bd), we establish a lower bound on the optimal value\nof the primal problem: p\u22c6 \u2265 g(\u03bb, \u03bd). thus a dual feasible point (\u03bb, \u03bd) provides a\nproof or certificate that p\u22c6 \u2265 g(\u03bb, \u03bd). strong duality means there exist arbitrarily\ngood certificates.\ndual feasible points allow us to bound how suboptimal a given feasible point\nis, without knowing the exact value of p\u22c6. indeed, if x is primal feasible and (\u03bb, \u03bd)\nis dual feasible, then\n\nf0(x) \u2212 p\u22c6 \u2264 f0(x) \u2212 g(\u03bb, \u03bd).\n\nin particular, this establishes that x is \u01eb-suboptimal, with \u01eb = f0(x) \u2212 g(\u03bb, \u03bd). (it\nalso establishes that (\u03bb, \u03bd) is \u01eb-suboptimal for the dual problem.)\n\nwe refer to the gap between primal and dual objectives,\n\nf0(x) \u2212 g(\u03bb, \u03bd),\n\nas the duality gap associated with the primal feasible point x and dual feasible\npoint (\u03bb, \u03bd). a primal dual feasible pair x, (\u03bb, \u03bd) localizes the optimal value of the\nprimal (and dual) problems to an interval:\n\np\u22c6 \u2208 [g(\u03bb, \u03bd), f0(x)],\nthe width of which is the duality gap.\n\nd\u22c6 \u2208 [g(\u03bb, \u03bd), f0(x)],\n\nif the duality gap of the primal dual feasible pair x, (\u03bb, \u03bd) is zero, i.e., f0(x) =\ng(\u03bb, \u03bd), then x is primal optimal and (\u03bb, \u03bd) is dual optimal. we can think of (\u03bb, \u03bd)\n\n "}, {"Page_number": 256, "text": "242\n\n5 duality\n\nas a certificate that proves x is optimal (and, similarly, we can think of x as a\ncertificate that proves (\u03bb, \u03bd) is dual optimal).\n\nthese observations can be used in optimization algorithms to provide nonheuris-\ntic stopping criteria. suppose an algorithm produces a sequence of primal feasible\nx(k) and dual feasible (\u03bb(k), \u03bd(k)), for k = 1, 2, . . ., and \u01ebabs > 0 is a given required\nabsolute accuracy. then the stopping criterion (i.e., the condition for terminating\nthe algorithm)\n\nf0(x(k)) \u2212 g(\u03bb(k), \u03bd(k)) \u2264 \u01ebabs\n\nguarantees that when the algorithm terminates, x(k) is \u01ebabs-suboptimal. indeed,\n(\u03bb(k), \u03bd(k)) is a certificate that proves it. (of course strong duality must hold if\nthis method is to work for arbitrarily small tolerances \u01ebabs.)\n\na similar condition can be used to guarantee a given relative accuracy \u01ebrel > 0.\n\nif\n\nholds, or\n\ng(\u03bb(k), \u03bd(k)) > 0,\n\nf0(x(k)) \u2212 g(\u03bb(k), \u03bd(k))\n\ng(\u03bb(k), \u03bd(k))\n\n\u2264 \u01ebrel\n\nf0(x(k)) < 0,\n\nf0(x(k)) \u2212 g(\u03bb(k), \u03bd(k))\n\n\u2212f0(x(k))\n\n\u2264 \u01ebrel\n\nholds, then p\u22c6 6= 0 and the relative error\n\nf0(x(k)) \u2212 p\u22c6\n\n|p\u22c6|\n\nis guaranteed to be less than or equal to \u01ebrel.\n\n5.5.2 complementary slackness\n\nsuppose that the primal and dual optimal values are attained and equal (so, in\nparticular, strong duality holds). let x\u22c6 be a primal optimal and (\u03bb\u22c6, \u03bd\u22c6) be a dual\noptimal point. this means that\n\nf0(x\u22c6) = g(\u03bb\u22c6, \u03bd\u22c6)\n\n= inf\n\nx  f0(x) +\nmxi=1\n\u2264 f0(x\u22c6) +\n\u2264 f0(x\u22c6).\n\ni hi(x)!\n\n\u03bd\u22c6\n\n\u03bb\u22c6\ni fi(x) +\n\nmxi=1\n\npxi=1\npxi=1\n\n\u03bb\u22c6\ni fi(x\u22c6) +\n\n\u03bd\u22c6\ni hi(x\u22c6)\n\nthe first line states that the optimal duality gap is zero, and the second line is\nthe definition of the dual function. the third line follows since the infimum of the\nlagrangian over x is less than or equal to its value at x = x\u22c6. the last inequality\nfollows from \u03bb\u22c6\ni \u2265 0, fi(x\u22c6) \u2264 0, i = 1, . . . , m, and hi(x\u22c6) = 0, i = 1, . . . , p. we\nconclude that the two inequalities in this chain hold with equality.\n\n "}, {"Page_number": 257, "text": "5.5 optimality conditions\n\n243\n\nwe can draw several interesting conclusions from this. for example, since the\ninequality in the third line is an equality, we conclude that x\u22c6 minimizes l(x, \u03bb\u22c6, \u03bd\u22c6)\nover x. (the lagrangian l(x, \u03bb\u22c6, \u03bd\u22c6) can have other minimizers; x\u22c6 is simply a\nminimizer.)\n\nanother important conclusion is that\n\n\u03bb\u22c6\ni fi(x\u22c6) = 0.\n\nmxi=1\n\nsince each term in this sum is nonpositive, we conclude that\n\n\u03bb\u22c6\ni fi(x\u22c6) = 0,\n\ni = 1, . . . , m.\n\n(5.48)\n\nthis condition is known as complementary slackness; it holds for any primal opti-\nmal x\u22c6 and any dual optimal (\u03bb\u22c6, \u03bd\u22c6) (when strong duality holds). we can express\nthe complementary slackness condition as\n\nor, equivalently,\n\n\u03bb\u22c6\ni > 0 =\u21d2 fi(x\u22c6) = 0,\n\nroughly speaking, this means the ith optimal lagrange multiplier is zero unless\nthe ith constraint is active at the optimum.\n\nfi(x\u22c6) < 0 =\u21d2 \u03bb\u22c6\n\ni = 0.\n\n5.5.3 kkt optimality conditions\n\nwe now assume that the functions f0, . . . , fm, h1, . . . , hp are differentiable (and\ntherefore have open domains), but we make no assumptions yet about convexity.\n\nkkt conditions for nonconvex problems\n\nas above, let x\u22c6 and (\u03bb\u22c6, \u03bd\u22c6) be any primal and dual optimal points with zero\nduality gap. since x\u22c6 minimizes l(x, \u03bb\u22c6, \u03bd\u22c6) over x, it follows that its gradient\nmust vanish at x\u22c6, i.e.,\n\n\u2207f0(x\u22c6) +\n\nmxi=1\n\n\u03bb\u22c6\ni \u2207fi(x\u22c6) +\n\npxi=1\n\n\u03bd\u22c6\ni \u2207hi(x\u22c6) = 0.\n\nthus we have\n\n\u2207f0(x\u22c6) +pm\n\ni=1 \u03bb\u22c6\n\ni \u2207fi(x\u22c6) +pp\n\ni=1 \u03bd\u22c6\n\nwhich are called the karush-kuhn-tucker (kkt) conditions.\n\nfi(x\u22c6) \u2264 0,\nhi(x\u22c6) = 0,\n\u03bb\u22c6\ni \u2265 0,\ni fi(x\u22c6) = 0,\n\u03bb\u22c6\ni \u2207hi(x\u22c6) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\ni = 1, . . . , m\ni = 1, . . . , m\n\n(5.49)\n\nto summarize, for any optimization problem with differentiable objective and\nconstraint functions for which strong duality obtains, any pair of primal and dual\noptimal points must satisfy the kkt conditions (5.49).\n\n "}, {"Page_number": 258, "text": "244\n\n5 duality\n\nkkt conditions for convex problems\n\nwhen the primal problem is convex, the kkt conditions are also sufficient for the\npoints to be primal and dual optimal. in other words, if fi are convex and hi are\naffine, and \u02dcx, \u02dc\u03bb, \u02dc\u03bd are any points that satisfy the kkt conditions\n\nfi(\u02dcx) \u2264 0,\nhi(\u02dcx) = 0,\n\u02dc\u03bbi \u2265 0,\n\u02dc\u03bbifi(\u02dcx) = 0,\ni=1 \u02dc\u03bdi\u2207hi(\u02dcx) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p\ni = 1, . . . , m\ni = 1, . . . , m\n\n\u2207f0(\u02dcx) +pm\n\ni=1\n\n\u02dc\u03bbi\u2207fi(\u02dcx) +pp\n\nthen \u02dcx and (\u02dc\u03bb, \u02dc\u03bd) are primal and dual optimal, with zero duality gap.\n\nto see this, note that the first two conditions state that \u02dcx is primal feasible.\nsince \u02dc\u03bbi \u2265 0, l(x, \u02dc\u03bb, \u02dc\u03bd) is convex in x; the last kkt condition states that its\ngradient with respect to x vanishes at x = \u02dcx, so it follows that \u02dcx minimizes l(x, \u02dc\u03bb, \u02dc\u03bd)\nover x. from this we conclude that\n\ng(\u02dc\u03bb, \u02dc\u03bd) = l(\u02dcx, \u02dc\u03bb, \u02dc\u03bd)\n\nmxi=1\n\n= f0(\u02dcx) +\n\n= f0(\u02dcx),\n\n\u02dc\u03bbifi(\u02dcx) +\n\n\u02dc\u03bdihi(\u02dcx)\n\npxi=1\n\nwhere in the last line we use hi(\u02dcx) = 0 and \u02dc\u03bbifi(\u02dcx) = 0. this shows that \u02dcx\nand (\u02dc\u03bb, \u02dc\u03bd) have zero duality gap, and therefore are primal and dual optimal. in\nsummary, for any convex optimization problem with differentiable objective and\nconstraint functions, any points that satisfy the kkt conditions are primal and\ndual optimal, and have zero duality gap.\n\nif a convex optimization problem with differentiable objective and constraint\nfunctions satisfies slater\u2019s condition, then the kkt conditions provide necessary\nand sufficient conditions for optimality: slater\u2019s condition implies that the optimal\nduality gap is zero and the dual optimum is attained, so x is optimal if and only if\nthere are (\u03bb, \u03bd) that, together with x, satisfy the kkt conditions.\n\nthe kkt conditions play an important role in optimization. in a few special\ncases it is possible to solve the kkt conditions (and therefore, the optimization\nproblem) analytically. more generally, many algorithms for convex optimization are\nconceived as, or can be interpreted as, methods for solving the kkt conditions.\n\nexample 5.1 equality constrained convex quadratic minimization. we consider the\nproblem\n\nminimize\nsubject to ax = b,\n\n(1/2)xt p x + qt x + r\n\n(5.50)\n\nwhere p \u2208 sn\n\n+. the kkt conditions for this problem are\n\nax\u22c6 = b,\n\np x\u22c6 + q + at \u03bd\u22c6 = 0,\n\nwhich we can write as\n\n(cid:20) p at\n\n0 (cid:21)(cid:20) x\u22c6\n\nb (cid:21) .\n\u03bd\u22c6 (cid:21) =(cid:20) \u2212q\n\na\n\n "}, {"Page_number": 259, "text": "5.5 optimality conditions\n\n245\n\nsolving this set of m + n equations in the m + n variables x\u22c6, \u03bd\u22c6 gives the optimal\nprimal and dual variables for (5.50).\n\nexample 5.2 water-filling. we consider the convex optimization problem\n\nminimize \u2212pn\n\nsubject to x (cid:23) 0,\n\ni=1 log(\u03b1i + xi)\n\n1t x = 1,\n\nwhere \u03b1i > 0. this problem arises in information theory, in allocating power to a\nset of n communication channels. the variable xi represents the transmitter power\nallocated to the ith channel, and log(\u03b1i + xi) gives the capacity or communication\nrate of the channel, so the problem is to allocate a total power of one to the channels,\nin order to maximize the total communication rate.\nintroducing lagrange multipliers \u03bb\u22c6 \u2208 rn for the inequality constraints x\u22c6 (cid:23) 0,\nand a multiplier \u03bd\u22c6 \u2208 r for the equality constraint 1t x = 1, we obtain the kkt\nconditions\n\nx\u22c6 (cid:23) 0,\n\n1t x\u22c6 = 1,\n\n\u22121/(\u03b1i + x\u22c6\n\ni ) \u2212 \u03bb\u22c6\n\n\u03bb\u22c6 (cid:23) 0,\ni + \u03bd\u22c6 = 0,\n\n\u03bb\u22c6\ni x\u22c6\n\ni = 0,\n\ni = 1, . . . , n,\n\ni = 1, . . . , n.\n\nwe can directly solve these equations to find x\u22c6, \u03bb\u22c6, and \u03bd\u22c6. we start by noting that\n\u03bb\u22c6 acts as a slack variable in the last equation, so it can be eliminated, leaving\n\nx\u22c6 (cid:23) 0,\n\n1t x\u22c6 = 1,\n\nx\u22c6\ni (\u03bd\u22c6 \u2212 1/(\u03b1i + x\u22c6\n\ni )) = 0,\n\ni = 1, . . . , n,\n\n\u03bd\u22c6 \u2265 1/(\u03b1i + x\u22c6\ni ),\n\ni = 1, . . . , n.\n\nif \u03bd\u22c6 < 1/\u03b1i, this last condition can only hold if x\u22c6\nimplies that \u03bd\u22c6 = 1/(\u03b1i + x\u22c6\nif \u03bd\u22c6 < 1/\u03b1i.\n\u03bd\u22c6 \u2265 1/\u03b1i > 1/(\u03b1i + x\u22c6\ntherefore, x\u22c6\n\ni > 0, which by the third condition\ni = 1/\u03bd\u22c6 \u2212 \u03b1i\ni > 0 is impossible, because it would imply\ni ), which violates the complementary slackness condition.\n\nif \u03bd\u22c6 \u2265 1/\u03b1i, then x\u22c6\n\ni , we conclude that x\u22c6\n\ni ). solving for x\u22c6\n\ni = 0 if \u03bd\u22c6 \u2265 1/\u03b1i. thus we have\n\nx\u22c6\n\ni =(cid:26) 1/\u03bd\u22c6 \u2212 \u03b1i\n\n0\n\n\u03bd\u22c6 < 1/\u03b1i\n\u03bd\u22c6 \u2265 1/\u03b1i,\n\nor, put more simply, x\u22c6\ninto the condition 1t x\u22c6 = 1 we obtain\n\ni = max{0, 1/\u03bd\u22c6 \u2212 \u03b1i}. substituting this expression for x\u22c6\n\ni\n\nnxi=1\n\nmax{0, 1/\u03bd\u22c6 \u2212 \u03b1i} = 1.\n\nthe lefthand side is a piecewise-linear increasing function of 1/\u03bd\u22c6, with breakpoints\nat \u03b1i, so the equation has a unique solution which is readily determined.\n\nthis solution method is called water-filling for the following reason. we think of\n\u03b1i as the ground level above patch i, and then flood the region with water to a\ndepth 1/\u03bd, as illustrated in figure 5.7. the total amount of water used is then\ni=1 max{0, 1/\u03bd\u22c6 \u2212 \u03b1i}. we then increase the flood level until we have used a total\namount of water equal to one. the depth of water above patch i is then the optimal\nvalue x\u22c6\ni .\n\npn\n\n "}, {"Page_number": 260, "text": "246\n\n5 duality\n\n1/\u03bd\u22c6\n\nxi\n\n\u03b1i\n\ni\n\nfigure 5.7 illustration of water-filling algorithm. the height of each patch is\ngiven by \u03b1i. the region is flooded to a level 1/\u03bd\u22c6 which uses a total quantity\nof water equal to one. the height of the water (shown shaded) above each\npatch is the optimal value of x\u22c6\ni .\n\nw\n\nw\n\nx1\n\nx2\n\nl\n\nfigure 5.8 two blocks connected by springs to each other, and the left and\nright walls. the blocks have width w > 0, and cannot penetrate each other\nor the walls.\n\n5.5.4 mechanics interpretation of kkt conditions\n\nthe kkt conditions can be given a nice interpretation in mechanics (which indeed,\nwas one of lagrange\u2019s primary motivations). we illustrate the idea with a simple\nexample. the system shown in figure 5.8 consists of two blocks attached to each\nother, and to walls at the left and right, by three springs. the position of the\nblocks are given by x \u2208 r2, where x1 is the displacement of the (middle of the) left\nblock, and x2 is the displacement of the right block. the left wall is at position 0,\nand the right wall is at position l.\n\nthe potential energy in the springs, as a function of the block positions, is given\n\nby\n\nf0(x1, x2) =\n\n1\n2\n\nk1x2\n\n1 +\n\n1\n2\n\nk2(x2 \u2212 x1)2 +\n\n1\n2\n\nk3(l \u2212 x2)2,\n\nwhere ki > 0 are the stiffness constants of the three springs. the equilibrium\nposition x\u22c6 is the position that minimizes the potential energy subject to the in-\nequalities\n\nw/2 \u2212 x1 \u2264 0,\n\nw + x1 \u2212 x2 \u2264 0,\n\nw/2 \u2212 l + x2 \u2264 0.\n\n(5.51)\n\n "}, {"Page_number": 261, "text": "5.5 optimality conditions\n\n247\n\n\u03bb1\nk1x1\n\n\u03bb2\nk2(x2 \u2212 x1)\n\n\u03bb2\nk2(x2 \u2212 x1)\n\n\u03bb3\nk3(l \u2212 x2)\n\nfigure 5.9 force analysis of the block-spring system. the total force on\neach block, due to the springs and also to contact forces, must be zero. the\nlagrange multipliers, shown on top, are the contact forces between the walls\nand blocks. the spring forces are shown at bottom.\n\nthese constraints are called kinematic constraints, and express the fact that the\nblocks have width w > 0, and cannot penetrate each other or the walls. the\nequilibrium position is therefore given by the solution of the optimization problem\n\nminimize\nsubject to w/2 \u2212 x1 \u2264 0\n\n(1/2)(cid:0)k1x2\n\n1 + k2(x2 \u2212 x1)2 + k3(l \u2212 x2)2(cid:1)\n\nw + x1 \u2212 x2 \u2264 0\nw/2 \u2212 l + x2 \u2264 0,\n\n(5.52)\n\nwhich is a qp.\n\nwith \u03bb1, \u03bb2, \u03bb3 as lagrange multipliers, the kkt conditions for this problem\nconsist of the kinematic constraints (5.51), the nonnegativity constraints \u03bbi \u2265 0,\nthe complementary slackness conditions\n\n\u03bb1(w/2 \u2212 x1) = 0,\n\n\u03bb2(w \u2212 x2 + x1) = 0,\n\n\u03bb3(w/2 \u2212 l + x2) = 0,\n\n(5.53)\n\nand the zero gradient condition\n\n(cid:20)\n\nk1x1 \u2212 k2(x2 \u2212 x1)\n\nk2(x2 \u2212 x1) \u2212 k3(l \u2212 x2) (cid:21) + \u03bb1(cid:20) \u22121\n\n0 (cid:21) + \u03bb2(cid:20) 1\n\n\u22121 (cid:21) + \u03bb3(cid:20) 0\n\n1 (cid:21) = 0.\n\n(5.54)\n\nthe equation (5.54) can be interpreted as the force balance equations for the two\nblocks, provided we interpret the lagrange multipliers as contact forces that act\nbetween the walls and blocks, as illustrated in figure 5.9. the first equation states\nthat the sum of the forces on the first block is zero: the term \u2212k1x1 is the force\nexerted on the left block by the left spring, the term k2(x2\u2212 x1) is the force exerted\nby the middle spring, \u03bb1 is the force exerted by the left wall, and \u2212\u03bb2 is the force\nexerted by the right block. the contact forces must point away from the contact\nsurface (as expressed by the constraints \u03bb1 \u2265 0 and \u2212\u03bb2 \u2264 0), and are nonzero\nonly when there is contact (as expressed by the first two complementary slackness\nconditions (5.53)).\nin a similar way, the second equation in (5.54) is the force\nbalance for the second block, and the last condition in (5.53) states that \u03bb3 is zero\nunless the right block touches the wall.\n\nin this example, the potential energy and kinematic constraint functions are\nconvex, and (the refined form of) slater\u2019s constraint qualification holds provided\n2w \u2264 l, i.e., there is enough room between the walls to fit the two blocks, so we\ncan conclude that the energy formulation of the equilibrium given by (5.52), gives\nthe same result as the force balance formulation, given by the kkt conditions.\n\n "}, {"Page_number": 262, "text": "248\n\n5 duality\n\n5.5.5 solving the primal problem via the dual\n\nwe mentioned at the beginning of \u00a75.5.3 that if strong duality holds and a dual\noptimal solution (\u03bb\u22c6, \u03bd\u22c6) exists, then any primal optimal point is also a minimizer\nof l(x, \u03bb\u22c6, \u03bd\u22c6). this fact sometimes allows us to compute a primal optimal solution\nfrom a dual optimal solution.\n\nmore precisely, suppose we have strong duality and an optimal (\u03bb\u22c6, \u03bd\u22c6) is known.\n\nsuppose that the minimizer of l(x, \u03bb\u22c6, \u03bd\u22c6), i.e., the solution of\n\nminimize\n\nf0(x) +pm\n\ni=1 \u03bb\u22c6\n\ni fi(x) +pp\n\ni=1 \u03bd\u22c6\n\ni hi(x),\n\n(5.55)\n\nis unique. (for a convex problem this occurs, for example, if l(x, \u03bb\u22c6, \u03bd\u22c6) is a strictly\nconvex function of x.) then if the solution of (5.55) is primal feasible, it must be\nprimal optimal; if it is not primal feasible, then no primal optimal point can exist,\ni.e., we can conclude that the primal optimum is not attained. this observation is\ninteresting when the dual problem is easier to solve than the primal problem, for\nexample, because it can be solved analytically, or has some special structure that\ncan be exploited.\n\nexample 5.3 entropy maximization. we consider the entropy maximization problem\n\nminimize\nsubject to ax (cid:22) b\n1t x = 1\n\nf0(x) =pn\n\ni=1 xi log xi\n\nwith domain rn\n\n++, and its dual problem\n\nmaximize \u2212bt \u03bb \u2212 \u03bd \u2212 e\u2212\u03bd\u22121pn\n\nsubject to \u03bb (cid:23) 0\n\ni=1 e\u2212at\ni \u03bb\n\nwhere ai are the columns of a (see pages 222 and 228). we assume that the weak\nform of slater\u2019s condition holds, i.e., there exists an x \u227b 0 with ax (cid:22) b and 1t x = 1,\nso strong duality holds and an optimal solution (\u03bb\u22c6, \u03bd\u22c6) exists.\nsuppose we have solved the dual problem. the lagrangian at (\u03bb\u22c6, \u03bd\u22c6) is\n\nl(x, \u03bb\u22c6, \u03bd\u22c6) =\n\nxi log xi + \u03bb\u22c6t (ax \u2212 b) + \u03bd\u22c6(1t x \u2212 1)\n\nnxi=1\n\nwhich is strictly convex on d and bounded below, so it has a unique solution x\u22c6,\ngiven by\n\nx\u22c6\ni = 1/ exp(at\n\ni \u03bb\u22c6 + \u03bd\u22c6 + 1),\n\ni = 1, . . . , n.\n\nif x\u22c6 is primal feasible, it must be the optimal solution of the primal problem (5.13).\nif x\u22c6 is not primal feasible, then we can conclude that the primal optimum is not\nattained.\n\nexample 5.4 minimizing a separable function subject to an equality constraint. we\nconsider the problem\n\nminimize\nsubject to\n\nf0(x) =pn\n\nat x = b,\n\ni=1 fi(xi)\n\n "}, {"Page_number": 263, "text": "5.6 perturbation and sensitivity analysis\n\n249\n\nwhere a \u2208 rn, b \u2208 r, and fi : r \u2192 r are differentiable and strictly convex. the\nobjective function is called separable since it is a sum of functions of the individual\nvariables x1, . . . , xn. we assume that the domain of f0 intersects the constraint set,\ni.e., there exists a point x0 \u2208 dom f0 with at x0 = b. this implies the problem has\na unique optimal point x\u22c6.\n\nthe lagrangian is\n\nl(x, \u03bd) =\n\nnxi=1\n\nfi(xi) + \u03bd(at x \u2212 b) = \u2212b\u03bd +\n\n(fi(xi) + \u03bdaixi),\n\nnxi=1\n\nwhich is also separable, so the dual function is\n\ng(\u03bd) = \u2212b\u03bd + inf\n\n= \u2212b\u03bd +\n\n= \u2212b\u03bd \u2212\n\nthe dual problem is thus\n\n(fi(xi) + \u03bdaixi)!\n\n(fi(xi) + \u03bdaixi)\n\nx   nxi=1\nnxi=1\nnxi=1\n\ninf\nxi\n\nf \u2217\ni (\u2212\u03bdai).\n\nmaximize \u2212b\u03bd \u2212pn\n\ni=1 f \u2217\n\ni (\u2212\u03bdai),\n\nwith (scalar) variable \u03bd \u2208 r.\nnow suppose we have found an optimal dual variable \u03bd\u22c6. (there are several simple\nmethods for solving a convex problem with one scalar variable, such as the bisection\nmethod.) since each fi is strictly convex, the function l(x, \u03bd\u22c6) is strictly convex in\nx, and so has a unique minimizer \u02dcx. but we also know that x\u22c6 minimizes l(x, \u03bd\u22c6),\nso we must have \u02dcx = x\u22c6. we can recover x\u22c6 from \u2207xl(x, \u03bd\u22c6) = 0, i.e., by solving the\nequations f \u2032\n\ni (x\u22c6\n\ni ) = \u2212\u03bd\u22c6ai.\n\n5.6 perturbation and sensitivity analysis\n\nwhen strong duality obtains, the optimal dual variables give very useful informa-\ntion about the sensitivity of the optimal value with respect to perturbations of the\nconstraints.\n\n5.6.1 the perturbed problem\n\nwe consider the following perturbed version of the original optimization prob-\nlem (5.1):\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 ui,\nhi(x) = vi,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\n(5.56)\n\n "}, {"Page_number": 264, "text": "250\n\n5 duality\n\nwith variable x \u2208 rn. this problem coincides with the original problem (5.1) when\nu = 0, v = 0. when ui is positive it means that we have relaxed the ith inequality\nconstraint; when ui is negative, it means that we have tightened the constraint.\nthus the perturbed problem (5.56) results from the original problem (5.1) by tight-\nening or relaxing each inequality constraint by ui, and changing the righthand side\nof the equality constraints by vi.\n\nwe define p\u22c6(u, v) as the optimal value of the perturbed problem (5.56):\n\np\u22c6(u, v) = inf{f0(x) | \u2203x \u2208 d, fi(x) \u2264 ui, i = 1, . . . , m,\n\nhi(x) = vi, i = 1, . . . , p}.\n\nwe can have p\u22c6(u, v) = \u221e, which corresponds to perturbations of the constraints\nthat result in infeasibility. note that p\u22c6(0, 0) = p\u22c6, the optimal value of the un-\nperturbed problem (5.1).\n(we hope this slight abuse of notation will cause no\nconfusion.) roughly speaking, the function p\u22c6 : rm \u00d7 rp \u2192 r gives the optimal\nvalue of the problem as a function of perturbations to the righthand sides of the\nconstraints.\n\nwhen the original problem is convex, the function p\u22c6 is a convex function of u\nand v; indeed, its epigraph is precisely the closure of the set a defined in (5.37)\n(see exercise 5.32).\n\n5.6.2 a global inequality\n\nnow we assume that strong duality holds, and that the dual optimum is attained.\n(this is the case if the original problem is convex, and slater\u2019s condition is satisfied).\nlet (\u03bb\u22c6, \u03bd\u22c6) be optimal for the dual (5.16) of the unperturbed problem. then for\nall u and v we have\n\np\u22c6(u, v) \u2265 p\u22c6(0, 0) \u2212 \u03bb\u22c6t u \u2212 \u03bd\u22c6t v.\n\n(5.57)\n\nto establish this inequality, suppose that x is any feasible point for the per-\nturbed problem, i.e., fi(x) \u2264 ui for i = 1, . . . , m, and hi(x) = vi for i = 1, . . . , p.\nthen we have, by strong duality,\n\np\u22c6(0, 0) = g(\u03bb\u22c6, \u03bd\u22c6) \u2264 f0(x) +\n\n\u03bb\u22c6\ni fi(x) +\n\nmxi=1\n\n\u03bd\u22c6\ni hi(x)\n\npxi=1\n\n\u2264 f0(x) + \u03bb\u22c6t u + \u03bd\u22c6t v.\n\n(the first inequality follows from the definition of g(\u03bb\u22c6, \u03bd\u22c6); the second follows\nsince \u03bb\u22c6 (cid:23) 0.) we conclude that for any x feasible for the perturbed problem, we\nhave\n\nfrom which (5.57) follows.\n\nf0(x) \u2265 p\u22c6(0, 0) \u2212 \u03bb\u22c6t u \u2212 \u03bd\u22c6t v,\n\nsensitivity interpretations\n\nwhen strong duality holds, various sensitivity interpretations of the optimal la-\ngrange variables follow directly from the inequality (5.57). some of the conclusions\nare:\n\n "}, {"Page_number": 265, "text": "5.6 perturbation and sensitivity analysis\n\n251\n\nu = 0\n\nu\np\u22c6(u)\n\np\u22c6(0) \u2212 \u03bb\u22c6u\n\nfigure 5.10 optimal value p\u22c6(u) of a convex problem with one constraint\nf1(x) \u2264 u, as a function of u. for u = 0, we have the original unperturbed\nproblem; for u < 0 the constraint is tightened, and for u > 0 the constraint\nis loosened. the affine function p\u22c6(0) \u2212 \u03bb\u22c6u is a lower bound on p\u22c6.\n\n\u2022 if \u03bb\u22c6\n\ni is large and we tighten the ith constraint (i.e., choose ui < 0), then the\n\noptimal value p\u22c6(u, v) is guaranteed to increase greatly.\n\ni\n\n\u2022 if \u03bd\u22c6\n\nis large and positive and we take vi < 0, or if \u03bd\u22c6\ni\n\nis large and negative\nand we take vi > 0, then the optimal value p\u22c6(u, v) is guaranteed to increase\ngreatly.\n\n\u2022 if \u03bb\u22c6\n\ni\n\n\u2022 if \u03bd\u22c6\n\ni\n\nis small, and we loosen the ith constraint (ui > 0), then the optimal\n\nvalue p\u22c6(u, v) will not decrease too much.\n\nis small and positive, and vi > 0, or if \u03bd\u22c6\ni\n\nis small and negative and\n\nvi < 0, then the optimal value p\u22c6(u, v) will not decrease too much.\n\nthe inequality (5.57), and the conclusions listed above, give a lower bound on\nthe perturbed optimal value, but no upper bound. for this reason the results are\nnot symmetric with respect to loosening or tightening a constraint. for example,\nsuppose that \u03bb\u22c6\ni is large, and we loosen the ith constraint a bit (i.e., take ui small\nand positive).\nin this case the inequality (5.57) is not useful; it does not, for\nexample, imply that the optimal value will decrease considerably.\n\nthe inequality (5.57) is illustrated in figure 5.10 for a convex problem with one\ninequality constraint. the inequality states that the affine function p\u22c6(0) \u2212 \u03bb\u22c6u is\na lower bound on the convex function p\u22c6.\n\n5.6.3 local sensitivity analysis\n\nsuppose now that p\u22c6(u, v) is differentiable at u = 0, v = 0. then, provided strong\nduality holds, the optimal dual variables \u03bb\u22c6, \u03bd\u22c6 are related to the gradient of p\u22c6 at\n\n "}, {"Page_number": 266, "text": "252\n\n5 duality\n\nu = 0, v = 0:\n\n\u03bb\u22c6\ni = \u2212\n\n\u2202p\u22c6(0, 0)\n\n\u2202ui\n\n,\n\n\u03bd\u22c6\ni = \u2212\n\n\u2202p\u22c6(0, 0)\n\n\u2202vi\n\n.\n\n(5.58)\n\nthis property can be seen in the example shown in figure 5.10, where \u2212\u03bb\u22c6 is the\nslope of p\u22c6 near u = 0.\nthus, when p\u22c6(u, v) is differentiable at u = 0, v = 0, and strong duality holds,\nthe optimal lagrange multipliers are exactly the local sensitivities of the optimal\nvalue with respect to constraint perturbations. in contrast to the nondifferentiable\ncase, this interpretation is symmetric: tightening the ith inequality constraint\na small amount (i.e., taking ui small and negative) yields an increase in p\u22c6 of\napproximately \u2212\u03bb\u22c6\ni ui; loosening the ith constraint a small amount (i.e., taking ui\nsmall and positive) yields a decrease in p\u22c6 of approximately \u03bb\u22c6\n\ni ui.\n\nto show (5.58), suppose p\u22c6(u, v) is differentiable and strong duality holds. for\n\nthe perturbation u = tei, v = 0, where ei is the ith unit vector, we have\n\np\u22c6(tei, 0) \u2212 p\u22c6\n\nt\n\nlim\nt\u21920\n\n=\n\n\u2202p\u22c6(0, 0)\n\n\u2202ui\n\n.\n\nthe inequality (5.57) states that for t > 0,\n\np\u22c6(tei, 0) \u2212 p\u22c6\n\nt\n\n\u2265 \u2212\u03bb\u22c6\ni ,\n\nwhile for t < 0 we have the opposite inequality. taking the limit t \u2192 0, with t > 0,\nyields\n\n\u2202p\u22c6(0, 0)\n\n\u2202ui\n\n\u2265 \u2212\u03bb\u22c6\ni ,\n\nwhile taking the limit with t < 0 yields the opposite inequality, so we conclude that\n\n\u2202p\u22c6(0, 0)\n\n\u2202ui\n\n= \u2212\u03bb\u22c6\ni .\n\nthe same method can be used to establish\n\n\u2202p\u22c6(0, 0)\n\n\u2202vi\n\n= \u2212\u03bd\u22c6\ni .\n\nthe local sensitivity result (5.58) gives us a quantitative measure of how active\na constraint is at the optimum x\u22c6. if fi(x\u22c6) < 0, then the constraint is inactive,\nand it follows that the constraint can be tightened or loosened a small amount\nwithout affecting the optimal value. by complementary slackness, the associated\noptimal lagrange multiplier must be zero. but now suppose that fi(x\u22c6) = 0, i.e.,\nthe ith constraint is active at the optimum. the ith optimal lagrange multiplier\ntells us how active the constraint is: if \u03bb\u22c6\nis small, it means that the constraint\ni\ncan be loosened or tightened a bit without much effect on the optimal value; if \u03bb\u22c6\ni\nis large, it means that if the constraint is loosened or tightened a bit, the effect on\nthe optimal value will be great.\n\n "}, {"Page_number": 267, "text": "5.7 examples\n\n253\n\nshadow price interpretation\n\nwe can also give a simple geometric interpretation of the result (5.58) in terms\nof economics. we consider (for simplicity) a convex problem with no equality\nconstraints, which satisfies slater\u2019s condition. the variable x \u2208 rm determines\nhow a firm operates, and the objective f0 is the cost, i.e., \u2212f0 is the profit. each\nconstraint fi(x) \u2264 0 represents a limit on some resource such as labor, steel, or\nwarehouse space. the (negative) perturbed optimal cost function \u2212p\u22c6(u) tells us\nhow much more or less profit could be made if more, or less, of each resource were\nmade available to the firm. if it is differentiable near u = 0, then we have\n\n\u03bb\u22c6\ni = \u2212\n\n\u2202p\u22c6(0)\n\n\u2202ui\n\n.\n\nin other words, \u03bb\u22c6\nmake, for a small increase in availability of resource i.\n\ni tells us approximately how much more profit the firm could\n\nit follows that \u03bb\u22c6\n\ni would be the natural or equilibrium price for resource i, if\nit were possible for the firm to buy or sell it. suppose, for example, that the firm\ncan buy or sell resource i, at a price that is less than \u03bb\u22c6\ni . in this case it would\ncertainly buy some of the resource, which would allow it to operate in a way that\nincreases its profit more than the cost of buying the resource. conversely, if the\nprice exceeds \u03bb\u22c6\ni , the firm would sell some of its allocation of resource i, and obtain\na net gain since its income from selling some of the resource would be larger than\nits drop in profit due to the reduction in availability of the resource.\n\n5.7 examples\n\nin this section we show by example that simple equivalent reformulations of a\nproblem can lead to very different dual problems. we consider the following types\nof reformulations:\n\n\u2022 introducing new variables and associated equality constraints.\n\u2022 replacing the objective with an increasing function of the original objective.\n\u2022 making explicit constraints implicit, i.e., incorporating them into the domain\n\nof the objective.\n\n5.7.1 introducing new variables and equality constraints\n\nconsider an unconstrained problem of the form\n\nminimize\n\nf0(ax + b).\n\n(5.59)\n\nits lagrange dual function is the constant p\u22c6. so while we do have strong duality,\ni.e., p\u22c6 = d\u22c6, the lagrangian dual is neither useful nor interesting.\n\n "}, {"Page_number": 268, "text": "254\n\n5 duality\n\nnow let us reformulate the problem (5.59) as\n\nminimize\nsubject to ax + b = y.\n\nf0(y)\n\n(5.60)\n\nhere we have introduced new variables y, as well as new equality constraints ax +\nb = y. the problems (5.59) and (5.60) are clearly equivalent.\n\nthe lagrangian of the reformulated problem is\n\nl(x, y, \u03bd) = f0(y) + \u03bdt (ax + b \u2212 y).\n\nto find the dual function we minimize l over x and y. minimizing over x we find\nthat g(\u03bd) = \u2212\u221e unless at \u03bd = 0, in which case we are left with\n0 (\u03bd),\n\n(f0(y) \u2212 \u03bdt y) = bt \u03bd \u2212 f \u2217\n\ng(\u03bd) = bt \u03bd + inf\ny\n\nwhere f \u2217\nexpressed as\n\n0 is the conjugate of f0. the dual problem of (5.60) can therefore be\n\nbt \u03bd \u2212 f \u2217\nmaximize\nsubject to at \u03bd = 0.\n\n0 (\u03bd)\n\n(5.61)\n\nthus, the dual of the reformulated problem (5.60) is considerably more useful than\nthe dual of the original problem (5.59).\n\nexample 5.5 unconstrained geometric program. consider the unconstrained geomet-\nric program\n\nwe first reformulate it by introducing new variables and equality constraints:\n\nminimize\n\ni=1 exp(at\n\nlog(cid:0)pm\nf0(y) = log(cid:0)pm\n\ni x + bi)(cid:1) .\ni=1 exp yi(cid:1)\n\nminimize\nsubject to ax + b = y,\n\nwhere at\n\ni are the rows of a. the conjugate of the log-sum-exp function is\n\nf \u2217\n\n0 (\u03bd) =(cid:26) pm\n\n\u221e\n\ni=1 \u03bdi log \u03bdi\n\n\u03bd (cid:23) 0, 1t \u03bd = 1\notherwise\n\n(example 3.25, page 93), so the dual of the reformulated problem can be expressed\nas\n\nmaximize\nsubject to 1t \u03bd = 1\nat \u03bd = 0\n\u03bd (cid:23) 0,\nwhich is an entropy maximization problem.\n\nbt \u03bd \u2212pm\n\ni=1 \u03bdi log \u03bdi\n\n(5.62)\n\nexample 5.6 norm approximation problem. we consider the unconstrained norm\napproximation problem\n\n(5.63)\nwhere k \u00b7 k is any norm. here too the lagrange dual function is constant, equal to\nthe optimal value of (5.63), and therefore not useful.\n\nkax \u2212 bk,\n\nminimize\n\n "}, {"Page_number": 269, "text": "5.7 examples\n\n255\n\nonce again we reformulate the problem as\n\nminimize\nsubject to ax \u2212 b = y.\n\nkyk\n\nthe lagrange dual problem is, following (5.61),\n\nmaximize\nsubject to\n\nbt \u03bd\nk\u03bdk\u2217 \u2264 1\nat \u03bd = 0,\n\n(5.64)\n\nwhere we use the fact that the conjugate of a norm is the indicator function of the\ndual norm unit ball (example 3.26, page 93).\n\nthe idea of introducing new equality constraints can be applied to the constraint\n\nfunctions as well. consider, for example, the problem\n\nminimize\nsubject to\n\nf0(a0x + b0)\nfi(aix + bi) \u2264 0,\n\ni = 1, . . . , m,\n\n(5.65)\n\nwhere ai \u2208 rki\u00d7n and fi : rki \u2192 r are convex. (for simplicity we do not include\nequality constraints here.) we introduce a new variable yi \u2208 rki, for i = 0, . . . , m,\nand reformulate the problem as\n\nminimize\nsubject to\n\nf0(y0)\nfi(yi) \u2264 0,\naix + bi = yi,\n\ni = 1, . . . , m\n\ni = 0, . . . , m.\n\n(5.66)\n\nthe lagrangian for this problem is\n\nl(x, y0, . . . , ym, \u03bb, \u03bd0, . . . , \u03bdm) = f0(y0) +\n\n\u03bbifi(yi) +\n\nmxi=1\n\nmxi=0\n\n\u03bdt\ni (aix + bi \u2212 yi).\n\nto find the dual function we minimize over x and yi. the minimum over x is \u2212\u221e\nunless\n\nat\n\ni \u03bdi = 0,\n\nmxi=0\n\nin which case we have, for \u03bb \u227b 0,\n\ng(\u03bb, \u03bd0, . . . , \u03bdm)\n\n=\n\n=\n\n=\n\nmxi=0\nmxi=0\nmxi=0\n\n\u03bdt\ni bi + inf\n\ny0,...,ym  f0(y0) +\nmxi=1\nmxi=1\n0 y0(cid:1) +\ny0 (cid:0)f0(y0) \u2212 \u03bdt\nmxi=1\n\n0 (\u03bd0) \u2212\n\ni (\u03bdi/\u03bbi).\n\n\u03bbif \u2217\n\n\u03bdt\ni bi + inf\n\ni bi \u2212 f \u2217\n\u03bdt\n\n\u03bbifi(yi) \u2212\n\ni yi!\n\n\u03bdt\n\nmxi=0\n\n\u03bbi inf\n\nyi (cid:0)fi(yi) \u2212 (\u03bdi/\u03bbi)t yi(cid:1)\n\n "}, {"Page_number": 270, "text": "256\n\n5 duality\n\nthe last expression involves the perspective of the conjugate function, and is there-\nfore concave in the dual variables. finally, we address the question of what happens\nwhen \u03bb (cid:23) 0, but some \u03bbi are zero. if \u03bbi = 0 and \u03bdi 6= 0, then the dual function is\n\u2212\u221e. if \u03bbi = 0 and \u03bdi = 0, however, the terms involving yi, \u03bdi, and \u03bbi are all zero.\nthus, the expression above for g is valid for all \u03bb (cid:23) 0, if we take \u03bbif \u2217\ni (\u03bdi/\u03bbi) = 0\nwhen \u03bbi = 0 and \u03bdi = 0, and \u03bbif \u2217\ni (\u03bdi/\u03bbi) = \u221e when \u03bbi = 0 and \u03bdi 6= 0.\n\ntherefore we can express the dual of the problem (5.66) as\n\nexample 5.7 inequality constrained geometric program. the inequality constrained\ngeometric program\n\n0 (\u03bd0) \u2212pm\n\ni bi \u2212 f \u2217\ni \u03bdi = 0.\n\ni=1 \u03bbif \u2217\n\ni (\u03bdi/\u03bbi)\n\n(5.67)\n\nf \u2217\n\nminimize\n\ni=0 \u03bdt\n\nsubject to\n\ni=0 at\n\nsubject to \u03bb (cid:23) 0\n\nmaximize pm\npm\nlog(cid:16)pk0\nlog(cid:16)pki\ni (\u03bd) =(cid:26) pki\n0 \u03bd0 \u2212pk0\npm\n0 \u03bd0 \u2212pk0\npm\n\nbt\n\u03bd0 (cid:23) 0,\n\u03bdi (cid:23) 0,\n\u03bbi \u2265 0,\ni=0 at\n\nbt\n\u03bdi (cid:23) 0,\n1t \u03bd0 = 1\ni=0 at\n\ni = 0, . . . , m\n\ni \u03bdi = 0,\n\ni \u03bdi = 0.\n\n\u221e\n\nk=1 eat\nk=1 eat\n\n0kx+b0k(cid:17)\nikx+bik(cid:17) \u2264 0,\n\ni = 1, . . . , m\n\nis of the form (5.65) with fi : rki \u2192 r given by fi(y) = log(cid:0)pki\n\nconjugate of this function is\n\nk=1 eyk(cid:1). the\n\nk=1 \u03bdk log \u03bdk\n\n1t \u03bd = 1\n\n\u03bd (cid:23) 0,\notherwise.\n\nusing (5.67) we can immediately write down the dual problem as\n\nmaximize\nsubject to\n\nk=1 \u03bd0k log \u03bd0k +pm\n\n1t \u03bd0 = 1\n1t \u03bdi = \u03bbi,\ni = 1, . . . , m\n\ni = 1, . . . , m\n\ni=1(cid:0)bt\n\ni \u03bdi \u2212pki\n\nk=1 \u03bdik log(\u03bdik/\u03bbi)(cid:1)\n\nwhich further simplifies to\n\nmaximize\nsubject to\n\nk=1 \u03bd0k log \u03bd0k +pm\n\ni=1(cid:0)bt\n\ni \u03bdi \u2212pki\n\nk=1 \u03bdik log(\u03bdik/1t \u03bdi)(cid:1)\n\n5.7.2 transforming the objective\n\nif we replace the objective f0 by an increasing function of f0, the resulting problem\nis clearly equivalent (see \u00a74.1.3). the dual of this equivalent problem, however, can\nbe very different from the dual of the original problem.\n\nexample 5.8 we consider again the minimum norm problem\n\nminimize\n\nkax \u2212 bk,\n\n "}, {"Page_number": 271, "text": "5.7 examples\n\n257\n\nwhere k \u00b7 k is some norm. we reformulate this problem as\n\n(1/2)kyk2\nminimize\nsubject to ax \u2212 b = y.\n\nhere we have introduced new variables, and replaced the objective by half its square.\nevidently it is equivalent to the original problem.\n\nthe dual of the reformulated problem is\n\nmaximize \u2212(1/2)k\u03bdk2\nsubject to at \u03bd = 0,\n\n\u2217 + bt \u03bd\n\nwhere we use the fact that the conjugate of (1/2)k\u00b7k2 is (1/2)k\u00b7k2\npage 93).\n\n\u2217 (see example 3.27,\n\nnote that this dual problem is not the same as the dual problem (5.64) derived earlier.\n\n5.7.3 implicit constraints\n\nthe next simple reformulation we study is to include some of the constraints in\nthe objective function, by modifying the objective function to be infinite when the\nconstraint is violated.\n\nexample 5.9 linear program with box constraints. we consider the linear program\n\nminimize\nsubject to ax = b\n\nct x\n\nl (cid:22) x (cid:22) u\n\n(5.68)\n\nwhere a \u2208 rp\u00d7n and l \u227a u. the constraints l (cid:22) x (cid:22) u are sometimes called box\nconstraints or variable bounds.\n\nwe can, of course, derive the dual of this linear program. the dual will have a\nlagrange multiplier \u03bd associated with the equality constraint, \u03bb1 associated with the\ninequality constraint x (cid:22) u, and \u03bb2 associated with the inequality constraint l (cid:22) x.\nthe dual is\n\nmaximize \u2212bt \u03bd \u2212 \u03bbt\nsubject to at \u03bd + \u03bb1 \u2212 \u03bb2 + c = 0\n\n1 u + \u03bbt\n2 l\n\n\u03bb1 (cid:23) 0, \u03bb2 (cid:23) 0.\ninstead, let us first reformulate the problem (5.68) as\n\n(5.69)\n\n(5.70)\n\nwhere we define\n\nminimize\nsubject to ax = b,\n\nf0(x)\n\nf0(x) =(cid:26) ct x l (cid:22) x (cid:22) u\n\n\u221e otherwise.\n\nthe problem (5.70) is clearly equivalent to (5.68); we have merely made the explicit\nbox constraints implicit.\n\n "}, {"Page_number": 272, "text": "258\n\n5 duality\n\nthe dual function for the problem (5.70) is\n\ng(\u03bd) =\n\ninf\n\nl(cid:22)x(cid:22)u(cid:0)ct x + \u03bdt (ax \u2212 b)(cid:1)\n\nwhere y+\nical formula for g, which is a concave piecewise-linear function.\n\ni = max{yi, 0}, y\u2212\n\n= \u2212bt \u03bd \u2212 ut (at \u03bd + c)\u2212 + lt (at \u03bd + c)+\ni = max{\u2212yi, 0}. so here we are able to derive an analyt-\n\nthe dual problem is the unconstrained problem\n\nmaximize \u2212bt \u03bd \u2212 ut (at \u03bd + c)\u2212 + lt (at \u03bd + c)+,\n\n(5.71)\n\nwhich has a quite different form from the dual of the original problem.\n\n(the problems (5.69) and (5.71) are closely related, in fact, equivalent; see exer-\ncise 5.8.)\n\n5.8 theorems of alternatives\n\n5.8.1 weak alternatives via the dual function\n\nin this section we apply lagrange duality theory to the problem of determining\nfeasibility of a system of inequalities and equalities\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nhi(x) = 0,\n\ni = 1, . . . , p.\n\n(5.72)\n\ni=1 dom fi \u2229\ni=1 dom hi, is nonempty. we can think of (5.72) as the standard problem (5.1),\n\nwe assume the domain of the inequality system (5.72), d = tm\ntp\n\nwith objective f0 = 0, i.e.,\n\nminimize\nsubject to\n\n0\nfi(x) \u2264 0,\nhi(x) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\nthis problem has optimal value\n\np\u22c6 =(cid:26) 0\n\n(5.72) is feasible\n\n\u221e (5.72) is infeasible,\n\n(5.73)\n\n(5.74)\n\nso solving the optimization problem (5.73) is the same as solving the inequality\nsystem (5.72).\n\nthe dual function\n\nwe associate with the inequality system (5.72) the dual function\n\ng(\u03bb, \u03bd) = inf\n\nx\u2208d  mxi=1\n\n\u03bbifi(x) +\n\n\u03bdihi(x)! ,\n\npxi=1\n\n "}, {"Page_number": 273, "text": "5.8 theorems of alternatives\n\n259\n\nwhich is the same as the dual function for the optimization problem (5.73). since\nf0 = 0, the dual function is positive homogeneous in (\u03bb, \u03bd): for \u03b1 > 0, g(\u03b1\u03bb, \u03b1\u03bd) =\n\u03b1g(\u03bb, \u03bd). the dual problem associated with (5.73) is to maximize g(\u03bb, \u03bd) subject\nto \u03bb (cid:23) 0. since g is homogeneous, the optimal value of this dual problem is given\nby\n\nd\u22c6 =(cid:26) \u221e \u03bb (cid:23) 0, g(\u03bb, \u03bd) > 0 is feasible\n\n\u03bb (cid:23) 0, g(\u03bb, \u03bd) > 0 is infeasible.\n\n0\n\n(5.75)\n\nweak duality tells us that d\u22c6 \u2264 p\u22c6. combining this fact with (5.74) and (5.75)\n\nyields the following: if the inequality system\n\n\u03bb (cid:23) 0,\n\ng(\u03bb, \u03bd) > 0\n\n(5.76)\n\nis feasible (which means d\u22c6 = \u221e), then the inequality system (5.72) is infeasible\n(since we then have p\u22c6 = \u221e). indeed, we can interpret any solution (\u03bb, \u03bd) of the\ninequalities (5.76) as a proof or certificate of infeasibility of the system (5.72).\nwe can restate this implication in terms of feasibility of the original system: if\nthe original inequality system (5.72) is feasible, then the inequality system (5.76)\nmust be infeasible. we can interpret an x which satisfies (5.72) as a certificate\nestablishing infeasibility of the inequality system (5.76).\n\ntwo systems of inequalities (and equalities) are called weak alternatives if at\nmost one of the two is feasible. thus, the systems (5.72) and (5.76) are weak\nalternatives. this is true whether or not the inequalities (5.72) are convex (i.e.,\nfi convex, hi affine); moreover, the alternative inequality system (5.76) is always\nconvex (i.e., g is concave and the constraints \u03bbi \u2265 0 are convex).\nstrict inequalities\n\nwe can also study feasibility of the strict inequality system\n\nfi(x) < 0,\n\ni = 1, . . . , m,\n\nhi(x) = 0,\n\ni = 1, . . . , p.\n\n(5.77)\n\nwith g defined as for the nonstrict inequality system, we have the alternative\ninequality system\n\n\u03bb (cid:23) 0,\n\n\u03bb 6= 0,\n\ng(\u03bb, \u03bd) \u2265 0.\n\n(5.78)\n\nwe can show directly that (5.77) and (5.78) are weak alternatives. suppose there\nexists an \u02dcx with fi(\u02dcx) < 0, hi(\u02dcx) = 0. then for any \u03bb (cid:23) 0, \u03bb 6= 0, and \u03bd,\n\n\u03bb1f1(\u02dcx) + \u00b7\u00b7\u00b7 + \u03bbmfm(\u02dcx) + \u03bd1h1(\u02dcx) + \u00b7\u00b7\u00b7 + \u03bdphp(\u02dcx) < 0.\n\nit follows that\n\ng(\u03bb, \u03bd) = inf\n\n\u03bbifi(x) +\n\n\u03bdihi(x)!\n\npxi=1\n\nx\u2208d  mxi=1\nmxi=1\n\n\u2264\n< 0.\n\n\u03bbifi(\u02dcx) +\n\n\u03bdihi(\u02dcx)\n\npxi=1\n\n "}, {"Page_number": 274, "text": "260\n\n5 duality\n\ntherefore, feasibility of (5.77) implies that there does not exist (\u03bb, \u03bd) satisfy-\ning (5.78).\n\nthus, we can prove infeasibility of (5.77) by producing a solution of the sys-\ntem (5.78); we can prove infeasibility of (5.78) by producing a solution of the\nsystem (5.77).\n\n5.8.2 strong alternatives\n\nwhen the original inequality system is convex, i.e., fi are convex and hi are affine,\nand some type of constraint qualification holds, then the pairs of weak alternatives\ndescribed above are strong alternatives, which means that exactly one of the two\nalternatives holds. in other words, each of the inequality systems is feasible if and\nonly if the other is infeasible.\n\nin this section we assume that fi are convex and hi are affine, so the inequality\n\nsystem (5.72) can be expressed as\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nax = b,\n\nwhere a \u2208 rp\u00d7n.\nstrict inequalities\n\nwe first study the strict inequality system\n\nfi(x) < 0,\n\ni = 1, . . . , m,\n\nax = b,\n\nand its alternative\n\n\u03bb (cid:23) 0,\n\n\u03bb 6= 0,\n\ng(\u03bb, \u03bd) \u2265 0.\n\n(5.79)\n\n(5.80)\n\nwe need one technical condition: there exists an x \u2208 relintd with ax = b. in\nother words we not only assume that the linear equality constraints are consistent,\nbut also that they have a solution in relintd. (very often d = rn, so the condition\nis satisfied if the equality constraints are consistent.) under this condition, exactly\none of the inequality systems (5.79) and (5.80) is feasible.\nin other words, the\ninequality systems (5.79) and (5.80) are strong alternatives.\n\nwe will establish this result by considering the related optimization problem\n\nminimize\nsubject to\n\ns\nfi(x) \u2212 s \u2264 0,\nax = b\n\ni = 1, . . . , m\n\n(5.81)\n\nwith variables x, s, and domain d \u00d7 r. the optimal value p\u22c6 of this problem is\nnegative if and only if there exists a solution to the strict inequality system (5.79).\n\nthe lagrange dual function for the problem (5.81) is\n\nx\u2208d, s s +\n\ninf\n\nmxi=1\n\n\u03bbi(fi(x) \u2212 s) + \u03bdt (ax \u2212 b)! =(cid:26) g(\u03bb, \u03bd) 1t \u03bb = 1\n\n\u2212\u221e\n\notherwise.\n\n "}, {"Page_number": 275, "text": "5.8 theorems of alternatives\n\n261\n\ntherefore we can express the dual problem of (5.81) as\n\nmaximize\ng(\u03bb, \u03bd)\nsubject to \u03bb (cid:23) 0,\n\n1t \u03bb = 1.\n\nnow we observe that slater\u2019s condition holds for the problem (5.81). by the\nhypothesis there exists an \u02dcx \u2208 relintd with a\u02dcx = b. choosing any \u02dcs > maxi fi(\u02dcx)\nyields a point (\u02dcx, \u02dcs) which is strictly feasible for (5.81). therefore we have d\u22c6 = p\u22c6,\nand the dual optimum d\u22c6 is attained. in other words, there exist (\u03bb\u22c6, \u03bd\u22c6) such that\n\ng(\u03bb\u22c6, \u03bd\u22c6) = p\u22c6,\n\n\u03bb\u22c6 (cid:23) 0,\n\n1t \u03bb\u22c6 = 1.\n\n(5.82)\n\nnow suppose that the strict inequality system (5.79) is infeasible, which means that\np\u22c6 \u2265 0. then (\u03bb\u22c6, \u03bd\u22c6) from (5.82) satisfy the alternate inequality system (5.80).\nsimilarly, if the alternate inequality system (5.80) is feasible, then d\u22c6 = p\u22c6 \u2265\n0, which shows that the strict inequality system (5.79) is infeasible. thus, the\ninequality systems (5.79) and (5.80) are strong alternatives; each is feasible if and\nonly if the other is not.\n\nnonstrict inequalities\n\nwe now consider the nonstrict inequality system\n\nand its alternative\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nax = b,\n\n\u03bb (cid:23) 0,\n\ng(\u03bb, \u03bd) > 0.\n\n(5.83)\n\n(5.84)\n\nwe will show these are strong alternatives, provided the following conditions hold:\nthere exists an x \u2208 relintd with ax = b, and the optimal value p\u22c6 of (5.81) is\nattained. this holds, for example, if d = rn and maxi fi(x) \u2192 \u221e as x \u2192 \u221e.\nwith these assumptions we have, as in the strict case, that p\u22c6 = d\u22c6, and that both\nthe primal and dual optimal values are attained. now suppose that the nonstrict\ninequality system (5.83) is infeasible, which means that p\u22c6 > 0. (here we use the\nassumption that the primal optimal value is attained.) then (\u03bb\u22c6, \u03bd\u22c6) from (5.82)\nsatisfy the alternate inequality system (5.84). thus, the inequality systems (5.83)\nand (5.84) are strong alternatives; each is feasible if and only if the other is not.\n\n5.8.3 examples\n\nlinear inequalities\nconsider the system of linear inequalities ax (cid:22) b. the dual function is\n\ng(\u03bb) = inf\nx\n\n\u03bbt (ax \u2212 b) =(cid:26) \u2212bt \u03bb at \u03bb = 0\n\n\u2212\u221e otherwise.\n\nthe alternative inequality system is therefore\n\n\u03bb (cid:23) 0,\n\nat \u03bb = 0,\n\nbt \u03bb < 0.\n\n "}, {"Page_number": 276, "text": "262\n\n5 duality\n\nthese are, in fact, strong alternatives. this follows since the optimum in the related\nproblem (5.81) is achieved, unless it is unbounded below.\n\nwe now consider the system of strict linear inequalities ax \u227a b, which has the\n\nstrong alternative system\n\u03bb (cid:23) 0,\n\n\u03bb 6= 0,\n\nat \u03bb = 0,\n\nbt \u03bb \u2264 0.\n\nin fact we have encountered (and proved) this result before, in \u00a72.5.1; see (2.17)\nand (2.18) (on page 50).\n\nintersection of ellipsoids\n\nwe consider m ellipsoids, described as\n\nei = {x | fi(x) \u2264 0},\n\nwith fi(x) = xt aix + 2bt\n++. we ask when\nthe intersection of these ellipsoids has nonempty interior. this is equivalent to\nfeasibility of the set of strict quadratic inequalities\n\ni x + ci, i = 1, . . . , m, where ai \u2208 sn\n\nfi(x) = xt aix + 2bt\n\ni x + ci < 0,\n\ni = 1, . . . , m.\n\n(5.85)\n\nthe dual function g is\n\ng(\u03bb) = inf\n\nx (cid:0)xt a(\u03bb)x + 2b(\u03bb)t x + c(\u03bb)(cid:1)\n\n= (cid:26) \u2212b(\u03bb)t a(\u03bb)\u2020b(\u03bb) + c(\u03bb) a(\u03bb) (cid:23) 0,\n\notherwise,\n\n\u2212\u221e\n\nb(\u03bb) \u2208 r(a(\u03bb))\n\nwhere\n\na(\u03bb) =\n\n\u03bbiai,\n\nb(\u03bb) =\n\n\u03bbibi,\n\nc(\u03bb) =\n\n\u03bbici.\n\nmxi=1\n\nmxi=1\n\nmxi=1\n\nnote that for \u03bb (cid:23) 0, \u03bb 6= 0, we have a(\u03bb) \u227b 0, so we can simplify the expression\nfor the dual function as\n\nthe strong alternative of the system (5.85) is therefore\n\ng(\u03bb) = \u2212b(\u03bb)t a(\u03bb)\u22121b(\u03bb) + c(\u03bb).\n\n\u03bb (cid:23) 0,\n\n\u03bb 6= 0,\n\n\u2212b(\u03bb)t a(\u03bb)\u22121b(\u03bb) + c(\u03bb) \u2265 0.\n\n(5.86)\n\nwe can give a simple geometric interpretation of this pair of strong alternatives.\n\nfor any nonzero \u03bb (cid:23) 0, the (possibly empty) ellipsoid\n\ne\u03bb = {x | xt a(\u03bb)x + 2b(\u03bb)t x + c(\u03bb) \u2264 0}\n\ncontains e1 \u2229 \u00b7\u00b7\u00b7 \u2229 em, since fi(x) \u2264 0 implies pm\n\nempty interior if and only if\n\ninf\n\nx (cid:0)xt a(\u03bb)x + 2b(\u03bb)t x + c(\u03bb)(cid:1) = \u2212b(\u03bb)t a(\u03bb)\u22121b(\u03bb) + c(\u03bb) \u2265 0.\n\ntherefore the alternative system (5.86) means that e\u03bb has empty interior.\nweak duality is obvious: if (5.86) holds, then e\u03bb contains the intersection e1 \u2229\n\u00b7\u00b7\u00b7 \u2229 em, and has empty interior, so naturally the intersection has empty interior.\nthe fact that these are strong alternatives states the (not obvious) fact that if the\nintersection e1 \u2229\u00b7\u00b7\u00b7 \u2229em has empty interior, then we can construct an ellipsoid e\u03bb\nthat contains the intersection and has empty interior.\n\ni=1 \u03bbifi(x) \u2264 0. now, e\u03bb has\n\n "}, {"Page_number": 277, "text": "5.8 theorems of alternatives\n\n263\n\nfarkas\u2019 lemma\n\nin this section we describe a pair of strong alternatives for a mixture of strict and\nnonstrict linear inequalities, known as farkas\u2019 lemma: the system of inequalities\n\nax (cid:22) 0,\n\nct x < 0,\n\nwhere a \u2208 rm\u00d7n and c \u2208 rn, and the system of equalities and inequalities\n\nat y + c = 0,\n\ny (cid:23) 0,\n\n(5.87)\n\n(5.88)\n\nare strong alternatives.\n\nwe can prove farkas\u2019 lemma directly, using lp duality. consider the lp\n\nand its dual\n\nct x\n\nminimize\nsubject to ax (cid:22) 0,\n\nmaximize\nsubject to at y + c = 0\n\n0\n\ny (cid:23) 0.\n\n(5.89)\n\n(5.90)\n\nthe primal lp (5.89) is homogeneous, and so has optimal value 0, if (5.87) is\nnot feasible, and optimal value \u2212\u221e, if (5.87) is feasible. the dual lp (5.90) has\noptimal value 0, if (5.88) is feasible, and optimal value \u2212\u221e, if (5.88) is infeasible.\nsince x = 0 is feasible in (5.89), we can rule out the one case in which strong\nduality can fail for lps, so we must have p\u22c6 = d\u22c6. combined with the remarks\nabove, this shows that (5.87) and (5.88) are strong alternatives.\n\nexample 5.10 arbitrage-free bounds on price. we consider a set of n assets, with\nprices at the beginning of an investment period p1, . . . , pn, respectively. at the end\nof the investment period, the value of the assets is v1, . . . , vn. if x1, . . . , xn represents\nthe initial investment in each asset (with xj < 0 meaning a short position in asset j),\nthe cost of the initial investment is pt x, and the final value of the investment is vt x.\n\nthe value of the assets at the end of the investment period, v, is uncertain. we will\nassume that only m possible scenarios, or outcomes, are possible. if outcome i occurs,\nthe final value of the assets is v(i), and therefore, the overall value of the investments\nis v(i)t x.\nif there is an investment vector x with pt x < 0, and in all possible scenarios, the\nfinal value is nonnegative, i.e., v(i)t x \u2265 0 for i = 1, . . . , m, then an arbitrage is said\nto exist. the condition pt x < 0 means you are paid to accept the investment mix,\nand the condition v(i)t x \u2265 0 for i = 1, . . . , m means that no matter what outcome\noccurs, the final value is nonnegative, so an arbitrage corresponds to a guaranteed\nmoney-making investment strategy. it is generally assumed that the prices and values\nare such that no arbitrage exists. this means that the inequality system\n\nv x (cid:23) 0,\n\npt x < 0\n\nis infeasible, where vij = v(i)\nj\nusing farkas\u2019 lemma, we have no arbitrage if and only if there exists y such that\n\n.\n\n\u2212v t y + p = 0,\n\ny (cid:23) 0.\n\n "}, {"Page_number": 278, "text": "264\n\n5 duality\n\nwe can use this characterization of arbitrage-free prices and values to solve several\ninteresting problems.\n\nsuppose, for example, that the values v are known, and all prices except the last\none, pn, are known. the set of prices pn that are consistent with the no-arbitrage\nassumption is an interval, which can be found by solving a pair of lps. the optimal\nvalue of the lp\n\nminimize\nsubject to v t y = p,\n\npn\n\ny (cid:23) 0,\n\nwith variables pn and y, gives the smallest possible arbitrage-free price for asset n.\nsolving the same lp with maximization instead of minimization yields the largest\npossible price for asset n. if the two values are equal, i.e., the no-arbitrage assumption\nleads us to a unique price for asset n, we say the market is complete. for an example,\nsee exercise 5.38.\n\nthis method can be used to find bounds on the price of a derivative or option that\nis based on the final value of other underlying assets, i.e., when the value or payoff\nof asset n is a function of the values of the other assets.\n\n5.9 generalized inequalities\n\nin this section we examine how lagrange duality extends to a problem with gen-\neralized inequality constraints\n\nminimize\nsubject to\n\nf0(x)\nfi(x) (cid:22)ki 0,\nhi(x) = 0,\n\ni = 1, . . . , m\n\ni = 1, . . . , p,\n\n(5.91)\n\nwhere ki \u2286 rki are proper cones. for now, we do not assume convexity of the prob-\nlem (5.91). we assume the domain of (5.91), d =tm\ni=1 dom hi, is\nnonempty.\n\ni=0 dom fi \u2229 tp\n\n5.9.1 the lagrange dual\n\nwith each generalized inequality fi(x) (cid:22)ki 0 in (5.91) we associate a lagrange\nmultiplier vector \u03bbi \u2208 rki and define the associated lagrangian as\n\nl(x, \u03bb, \u03bd) = f0(x) + \u03bbt\n\n1 f1(x) + \u00b7\u00b7\u00b7 + \u03bbt\n\nmfm(x) + \u03bd1h1(x) + \u00b7\u00b7\u00b7 + \u03bdphp(x),\n\nwhere \u03bb = (\u03bb1, . . . , \u03bbm) and \u03bd = (\u03bd1, . . . , \u03bdp). the dual function is defined exactly\nas in a problem with scalar inequalities:\n\ng(\u03bb, \u03bd) = inf\nx\u2208d\n\nl(x, \u03bb, \u03bd) = inf\n\nx\u2208d f0(x) +\n\n\u03bbt\ni fi(x) +\n\nmxi=1\n\n\u03bdihi(x)! .\n\npxi=1\n\nsince the lagrangian is affine in the dual variables (\u03bb, \u03bd), and the dual function is\na pointwise infimum of the lagrangian, the dual function is concave.\n\n "}, {"Page_number": 279, "text": "5.9 generalized inequalities\n\n265\n\nas in a problem with scalar inequalities, the dual function gives lower bounds\non p\u22c6, the optimal value of the primal problem (5.91). for a problem with scalar\ninequalities, we require \u03bbi \u2265 0. here the nonnegativity requirement on the dual\nvariables is replaced by the condition\n\n\u03bbi (cid:23)k \u2217\n\ni\n\n0,\n\ni = 1, . . . , m,\n\nwhere k \u2217\nassociated with inequalities must be dual nonnegative.\n\ni denotes the dual cone of ki. in other words, the lagrange multipliers\n\nweak duality follows immediately from the definition of dual cone. if \u03bbi (cid:23)k \u2217\n\n0\ni fi(\u02dcx) \u2264 0. therefore for any primal feasible point \u02dcx and\n\ni\n\nand fi(\u02dcx) (cid:22)ki 0, then \u03bbt\nany \u03bbi (cid:23)k \u2217\n\n0, we have\n\ni\n\nf0(\u02dcx) +\n\n\u03bbt\ni fi(\u02dcx) +\n\n\u03bdihi(\u02dcx) \u2264 f0(\u02dcx).\n\nmxi=1\n\npxi=1\n\ntaking the infimum over \u02dcx yields g(\u03bb, \u03bd) \u2264 p\u22c6.\nthe lagrange dual optimization problem is\n\nmaximize\ng(\u03bb, \u03bd)\nsubject to \u03bbi (cid:23)k \u2217\n\ni\n\n0,\n\ni = 1, . . . , m.\n\n(5.92)\n\nwe always have weak duality, i.e., d\u22c6 \u2264 p\u22c6, where d\u22c6 denotes the optimal value of\nthe dual problem (5.92), whether or not the primal problem (5.91) is convex.\n\nslater\u2019s condition and strong duality\n\nas might be expected, strong duality (d\u22c6 = p\u22c6) holds when the primal problem\nis convex and satisfies an appropriate constraint qualification. for example, a\ngeneralized version of slater\u2019s condition for the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) (cid:22)ki 0,\nax = b,\n\ni = 1, . . . , m\n\nwhere f0 is convex and fi is ki-convex, is that there exists an x \u2208 relintd with\nax = b and fi(x) \u227aki 0, i = 1, . . . , m. this condition implies strong duality (and\nalso, that the dual optimum is attained).\n\nexample 5.11 lagrange dual of semidefinite program. we consider a semidefinite\nprogram in inequality form,\n\nct x\n\nminimize\nsubject to x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0\n\n(5.93)\n\nwhere f1, . . . , fn, g \u2208 sk. (here f1 is affine, and k1 is sk\ncone.)\nwe associate with the constraint a dual variable or multiplier z \u2208 sk, so the la-\ngrangian is\n\n+, the positive semidefinite\n\nl(x, z) = ct x + tr ((x1f1 + \u00b7\u00b7\u00b7 + xnfn + g) z)\n\n= x1(c1 + tr(f1z)) + \u00b7\u00b7\u00b7 + xn(cn + tr(fnz)) + tr(gz),\n\n "}, {"Page_number": 280, "text": "266\n\n5 duality\n\nwhich is affine in x. the dual function is given by\n\ng(z) = inf\nx\n\nl(x, z) =(cid:26) tr(gz)\n\n\u2212\u221e\n\ntr(fiz) + ci = 0,\notherwise.\n\ni = 1, . . . , n\n\nthe dual problem can therefore be expressed as\n\nmaximize\nsubject to\n\ntr(gz)\ntr(fiz) + ci = 0,\nz (cid:23) 0.\n\ni = 1, . . . , n\n\n(we use the fact that sk\n\n+ is self-dual, i.e., (sk\n\n+)\u2217 = sk\n\n+; see \u00a72.6.)\n\nstrong duality obtains if the semidefinite program (5.93) is strictly feasible, i.e., there\nexists an x with\n\nx1f1 + \u00b7\u00b7\u00b7 + xnfn + g \u227a 0.\n\nexample 5.12 lagrange dual of cone program in standard form. we consider the\ncone program\n\nct x\n\nminimize\nsubject to ax = b\nx (cid:23)k 0,\n\nwhere a \u2208 rm\u00d7n, b \u2208 rm, and k \u2286 rn is a proper cone. we associate with the\nequality constraint a multiplier \u03bd \u2208 rm, and with the nonnegativity constraint a\nmultiplier \u03bb \u2208 rn. the lagrangian is\n\nl(x, \u03bb, \u03bd) = ct x \u2212 \u03bbt x + \u03bdt (ax \u2212 b),\n\nso the dual function is\n\ng(\u03bb, \u03bd) = inf\nx\n\nl(x, \u03bb, \u03bd) =(cid:26) \u2212bt \u03bd at \u03bd \u2212 \u03bb + c = 0\n\n\u2212\u221e otherwise.\n\nthe dual problem can be expressed as\n\nmaximize \u2212bt \u03bd\nsubject to at \u03bd + c = \u03bb\n\n\u03bb (cid:23)k \u2217 0.\n\nby eliminating \u03bb and defining y = \u2212\u03bd, this problem can be simplified to\n\nbt y\n\nmaximize\nsubject to at y (cid:22)k \u2217 c,\n\nwhich is a cone program in inequality form, involving the dual generalized inequality.\nstrong duality obtains if the slater condition holds, i.e., there is an x \u227bk 0 with\nax = b.\n\n5.9.2 optimality conditions\n\nthe optimality conditions of \u00a75.5 are readily extended to problems with generalized\ninequalities. we first derive the complementary slackness conditions.\n\n "}, {"Page_number": 281, "text": "5.9 generalized inequalities\n\n267\n\ncomplementary slackness\n\nassume that the primal and dual optimal values are equal, and attained at the\noptimal points x\u22c6, \u03bb\u22c6, \u03bd\u22c6. as in \u00a75.5.2, the complementary slackness conditions\nfollow directly from the equality f0(x\u22c6) = g(\u03bb\u22c6, \u03bd\u22c6), along with the definition of g.\nwe have\n\nf0(x\u22c6) = g(\u03bb\u22c6, \u03bd\u22c6)\n\nmxi=1\n\n\u2264 f0(x\u22c6) +\n\u2264 f0(x\u22c6),\n\n\u03bb\u22c6\ni\n\nt fi(x\u22c6) +\n\n\u03bd\u22c6\ni hi(x\u22c6)\n\npxi=1\n\nand therefore we conclude that x\u22c6 minimizes l(x, \u03bb\u22c6, \u03bd\u22c6), and also that the two\nsums in the second line are zero. since the second sum is zero (since x\u22c6 satisfies\nt fi(x\u22c6) = 0. since each term in this\n\ni=1 \u03bb\u22c6\ni\n\nthe equality constraints), we have pm\n\nsum is nonpositive, we conclude that\n\n\u03bb\u22c6\ni\n\nt fi(x\u22c6) = 0,\n\ni = 1, . . . , m,\n\n(5.94)\n\nwhich generalizes the complementary slackness condition (5.48). from (5.94) we\ncan conclude that\n\n\u03bb\u22c6\ni \u227bk \u2217\n\ni\n\n0 =\u21d2 fi(x\u22c6) = 0,\n\nfi(x\u22c6) \u227aki 0, =\u21d2 \u03bb\u22c6\n\ni = 0.\n\nhowever, in contrast to problems with scalar inequalities, it is possible to sat-\nisfy (5.94) with \u03bb\u22c6\n\ni 6= 0 and fi(x\u22c6) 6= 0.\n\nkkt conditions\n\nnow we add the assumption that the functions fi, hi are differentiable, and gener-\nalize the kkt conditions of \u00a75.5.3 to problems with generalized inequalities. since\nx\u22c6 minimizes l(x, \u03bb\u22c6, \u03bd\u22c6), its gradient with respect to x vanishes at x\u22c6:\n\n\u2207f0(x\u22c6) +\n\nmxi=1\n\ndfi(x\u22c6)t \u03bb\u22c6\n\ni +\n\npxi=1\n\n\u03bd\u22c6\ni \u2207hi(x\u22c6) = 0,\n\nwhere dfi(x\u22c6) \u2208 rki\u00d7n is the derivative of fi evaluated at x\u22c6 (see \u00a7a.4.1). thus,\nif strong duality holds, any primal optimal x\u22c6 and any dual optimal (\u03bb\u22c6, \u03bd\u22c6) must\nsatisfy the optimality conditions (or kkt conditions)\n\nfi(x\u22c6) (cid:22)ki\nhi(x\u22c6)\n=\n\u03bb\u22c6\ni (cid:23)k \u2217\nt fi(x\u22c6)\n\u03bb\u22c6\n=\ni\ni=1 \u03bd\u22c6\ni \u2207hi(x\u22c6)\n=\n\ni\n\ni = 1, . . . , m\ni = 1, . . . , p\ni = 1, . . . , m\ni = 1, . . . , m\n\n0,\n0,\n0,\n0,\n0.\n\n\u2207f0(x\u22c6) +pm\n\ni=1 dfi(x\u22c6)t \u03bb\u22c6\n\ni +pp\n\n(5.95)\nif the primal problem is convex, the converse also holds, i.e., the conditions (5.95)\nare sufficient conditions for optimality of x\u22c6, (\u03bb\u22c6, \u03bd\u22c6).\n\n "}, {"Page_number": 282, "text": "268\n\n5 duality\n\n5.9.3 perturbation and sensitivity analysis\n\nthe results of \u00a75.6 can be extended to problems involving generalized inequalities.\nwe consider the associated perturbed version of the problem,\n\nminimize\nsubject to\n\nf0(x)\nfi(x) (cid:22)ki ui,\nhi(x) = vi,\n\ni = 1, . . . , m\n\ni = 1, . . . , p,\n\nwhere ui \u2208 rki, and v \u2208 rp. we define p\u22c6(u, v) as the optimal value of the\nperturbed problem. as in the case with scalar inequalities, p\u22c6 is a convex function\nwhen the original problem is convex.\n\nnow let (\u03bb\u22c6, \u03bd\u22c6) be optimal for the dual of the original (unperturbed) problem,\n\nwhich we assume has zero duality gap. then for all u and v we have\n\np\u22c6(u, v) \u2265 p\u22c6 \u2212\n\nmxi=1\n\n\u03bb\u22c6\ni\n\nt ui \u2212 \u03bd\u22c6t v,\n\nthe analog of the global sensitivity inequality (5.57). the local sensitivity result\nholds as well: if p\u22c6(u, v) is differentiable at u = 0, v = 0, then the optimal dual\nvariables \u03bb\u22c6\n\ni satisfies\n\ni = \u2212\u2207ui p\u22c6(0, 0),\n\u03bb\u22c6\n\nthe analog of (5.58).\n\nexample 5.13 semidefinite program in inequality form. we consider a semidefinite\nprogram in inequality form, as in example 5.11. the primal problem is\n\nct x\n\nminimize\nsubject to f (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0,\n\nwith variable x \u2208 rn (and f1, . . . , fn, g \u2208 sk), and the dual problem is\n\nmaximize\nsubject to\n\ntr(gz)\ntr(fiz) + ci = 0,\nz (cid:23) 0,\n\ni = 1, . . . , n\n\nwith variable z \u2208 sk.\nsuppose that x\u22c6 and z \u22c6 are primal and dual optimal, respectively, with zero duality\ngap. the complementary slackness condition is tr(f (x\u22c6)z \u22c6) = 0. since f (x\u22c6) (cid:22) 0\nand z \u22c6 (cid:23) 0, we can conclude that f (x\u22c6)z \u22c6 = 0. thus, the complementary slackness\ncondition can be expressed as\n\nr(f (x\u22c6)) \u22a5 r(z \u22c6),\n\ni.e., the ranges of the primal and dual matrices are orthogonal.\nlet p\u22c6(u ) denote the optimal value of the perturbed sdp\n\nct x\n\nminimize\nsubject to f (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) u.\n\n "}, {"Page_number": 283, "text": "5.9 generalized inequalities\n\n269\n\nthen we have, for all u , p\u22c6(u ) \u2265 p\u22c6 \u2212 tr(z \u22c6u ). if p\u22c6(u ) is differentiable at u = 0,\nthen we have\n\nthis means that for u small, the optimal value of the perturbed sdp is very close\nto (the lower bound) p\u22c6 \u2212 tr(z \u22c6u ).\n\n\u2207p\u22c6(0) = \u2212z \u22c6.\n\n5.9.4 theorems of alternatives\n\nwe can derive theorems of alternatives for systems of generalized inequalities and\nequalities\n\nfi(x) (cid:22)ki 0,\n\n(5.96)\nwhere ki \u2286 rki are proper cones. we will also consider systems with strict in-\nequalities,\n\ni = 1, . . . , m,\n\ni = 1, . . . , p,\n\nhi(x) = 0,\n\nfi(x) \u227aki 0,\n\nwe assume that d =tm\n\nweak alternatives\n\ni=0 dom fi \u2229 tp\n\ni = 1, . . . , m,\n\nhi(x) = 0,\n\ni = 1, . . . , p.\n\n(5.97)\n\ni=1 dom hi is nonempty.\n\nwe associate with the systems (5.96) and (5.97) the dual function\n\ng(\u03bb, \u03bd) = inf\n\nx\u2208d  mxi=1\n\n\u03bbt\ni fi(x) +\n\n\u03bdihi(x)!\n\npxi=1\n\nwhere \u03bb = (\u03bb1, . . . , \u03bbm) with \u03bbi \u2208 rki and \u03bd \u2208 rp. in analogy with (5.76), we\nclaim that\n(5.98)\n\ni = 1, . . . , m,\n\ng(\u03bb, \u03bd) > 0\n\n0,\n\n\u03bbi (cid:23)k \u22c6\n\ni\n\nis a weak alternative to the system (5.96). to verify this, suppose there exists an\nx satisfying (5.96) and (\u03bb, \u03bd) satisfying (5.98). then we have a contradiction:\n\n0 < g(\u03bb, \u03bd) \u2264 \u03bbt\n\n1 f1(x) + \u00b7\u00b7\u00b7 + \u03bbt\n\nmfm(x) + \u03bd1h1(x) + \u00b7\u00b7\u00b7 + \u03bdphp(x) \u2264 0.\n\ntherefore at least one of the two systems (5.96) and (5.98) must be infeasible, i.e.,\nthe two systems are weak alternatives.\n\nin a similar way, we can prove that (5.97) and the system\n\n\u03bbi (cid:23)k \u2217\n\ni\n\n0,\n\ni = 1, . . . , m,\n\n\u03bb 6= 0,\n\ng(\u03bb, \u03bd) \u2265 0.\n\nform a pair of weak alternatives.\n\nstrong alternatives\n\nwe now assume that the functions fi are ki-convex, and the functions hi are affine.\nwe first consider a system with strict inequalities\n\nfi(x) \u227aki 0,\n\ni = 1, . . . , m,\n\nax = b,\n\n(5.99)\n\n "}, {"Page_number": 284, "text": "270\n\n5 duality\n\nand its alternative\n\n\u03bbi (cid:23)k \u22c6\n\ni\n\n0,\n\ni = 1, . . . , m,\n\n\u03bb 6= 0,\n\ng(\u03bb, \u03bd) \u2265 0.\n\n(5.100)\n\nwe have already seen that (5.99) and (5.100) are weak alternatives. they are also\nstrong alternatives provided the following constraint qualification holds: there\nexists an \u02dcx \u2208 relintd with a\u02dcx = b. to prove this, we select a set of vectors\nei \u227bki 0, and consider the problem\ns\nfi(x) (cid:22)ki sei,\nax = b\n\nminimize\nsubject to\n\ni = 1, . . . , m\n\n(5.101)\n\nwith variables x and s \u2208 r. slater\u2019s condition holds since (\u02dcx, \u02dcs) satisfies the strict\ninequalities fi(\u02dcx) \u227aki \u02dcsei provided \u02dcs is large enough.\n\nthe dual of (5.101) is\n\nmaximize\ng(\u03bb, \u03bd)\nsubject to \u03bbi (cid:23)k \u2217\ni=1 et\n\ni\n\n0,\ni \u03bbi = 1\n\npm\n\ni = 1, . . . , m\n\n(5.102)\n\nwith variables \u03bb = (\u03bb1, . . . , \u03bbm) and \u03bd.\n\nnow suppose the system (5.99) is infeasible. then the optimal value of (5.101)\nis nonnegative. since slater\u2019s condition is satisfied, we have strong duality and the\ndual optimum is attained. therefore there exist (\u02dc\u03bb, \u02dc\u03bd) that satisfy the constraints\nof (5.102) and g(\u02dc\u03bb, \u02dc\u03bd) \u2265 0, i.e., the system (5.100) has a solution.\nax = b is not sufficient for the system of nonstrict inequalities\n\nas we noted in the case of scalar inequalities, existence of an x \u2208 relintd with\n\nfi(x) (cid:22)ki 0,\n\ni = 1, . . . , m,\n\nax = b\n\nand its alternative\n\n\u03bbi (cid:23)k \u22c6\n\ni\n\n0,\n\ni = 1, . . . , m,\n\ng(\u03bb, \u03bd) > 0\n\nto be strong alternatives. an additional condition is required, e.g., that the optimal\nvalue of (5.101) is attained.\n\nexample 5.14 feasibility of a linear matrix inequality. the following systems are\nstrong alternatives:\n\nwhere fi, g \u2208 sk, and\n\nf (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g \u227a 0,\n\nz (cid:23) 0,\n\nz 6= 0,\n\ntr(gz) \u2265 0,\n\ntr(fiz) = 0,\n\ni = 1, . . . , n,\n\nwhere z \u2208 sk. this follows from the general result, if we take for k the positive\nsemidefinite cone sk\n\n+, and\n\ng(z) = inf\nx\n\n(tr(f (x)z)) =(cid:26) tr(gz)\n\n\u2212\u221e\n\ntr(fiz) = 0,\notherwise.\n\ni = 1, . . . , n\n\n "}, {"Page_number": 285, "text": "5.9 generalized inequalities\n\n271\n\nthe nonstrict inequality case is slightly more involved, and we need an extra assump-\ntion on the matrices fi to have strong alternatives. one such condition is\n\nnxi=1\n\nvifi (cid:23) 0 =\u21d2\n\nvifi = 0.\n\nnxi=1\n\nif this condition holds, the following systems are strong alternatives:\n\nf (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0\n\ntr(gz) > 0,\n\ntr(fiz) = 0,\n\ni = 1, . . . , n\n\nand\n\nz (cid:23) 0,\n\n(see exercise 5.44).\n\n "}, {"Page_number": 286, "text": "272\n\n5 duality\n\nbibliography\n\nlagrange duality is covered in detail by luenberger [lue69, chapter 8], rockafellar [roc70,\npart vi], whittle [whi71], hiriart-urruty and lemar\u00b4echal [hul93], and bertsekas, nedi\u00b4c,\nand ozdaglar [ber03]. the name is derived from lagrange\u2019s method of multipliers for\noptimization problems with equality constraints; see courant and hilbert [ch53, chapter\niv].\nthe max-min result for matrix games in \u00a75.2.5 predates linear programming duality.\nit is proved via a theorem of alternatives by von neuman and morgenstern [vnm53,\npage 153]. the strong duality result for linear programming on page 227 is due to von\nneumann [vn63] and gale, kuhn, and tucker [gkt51]. strong duality for the nonconvex\nquadratic problem (5.32) is a fundamental result in the literature on trust region methods\nfor nonlinear optimization (nocedal and wright [nw99, page 78]). it is also related to the\ns-procedure in control theory, discussed in appendix \u00a7b.1. for an extension of the proof\nof strong duality of \u00a75.3.2 to the refined slater condition (5.27), see rockafellar [roc70,\npage 277].\n\nconditions that guarantee the saddle-point property (5.47) can be found in rockafel-\nlar [roc70, part vii] and bertsekas, nedi\u00b4c, and ozdaglar [ber03, chapter 2]; see also\nexercise 5.25.\n\nthe kkt conditions are named after karush (whose unpublished 1939 master\u2019s thesis\nis summarized in kuhn [kuh76]), kuhn, and tucker [kt51]. related optimality condi-\ntions were also derived by john [joh85]. the water-filling algorithm in example 5.2 has\napplications in information theory and communications (cover and thomas [ct91, page\n252]).\n\nfarkas\u2019 lemma was published by farkas [far02].\nit is the best known theorem of al-\nternatives for systems of linear inequalities and equalities, but many variants exist; see\nmangasarian [man94, \u00a72.4]. the application of farkas\u2019 lemma to asset pricing (exam-\nple 5.10) is discussed by bertsimas and tsitsiklis [bt97, page 167] and ross [ros99].\n\nthe extension of lagrange duality to problems with generalized inequalities appears in\nisii [isi64], luenberger [lue69, chapter 8], berman [ber73], and rockafellar [roc89, page\n47].\nit is discussed in the context of cone programming in nesterov and nemirovski\n[nn94, \u00a74.2] and ben-tal and nemirovski [btn01, lecture 2]. theorems of alternatives\nfor generalized inequalities were studied by ben-israel [bi69], berman and ben-israel\n[bbi71], and craven and kohila [ck77]. bellman and fan [bf63], wolkowicz [wol81],\nand lasserre [las95] give extensions of farkas\u2019 lemma to linear matrix inequalities.\n\n "}, {"Page_number": 287, "text": "exercises\n\nexercises\n\nbasic definitions\n\n273\n\n5.1 a simple example. consider the optimization problem\n\nminimize\nsubject to\n\nx2 + 1\n(x \u2212 2)(x \u2212 4) \u2264 0,\n\nwith variable x \u2208 r.\n(a) analysis of primal problem. give the feasible set, the optimal value, and the optimal\n\nsolution.\n\n(b) lagrangian and dual function. plot the objective x2 + 1 versus x. on the same plot,\nshow the feasible set, optimal point and value, and plot the lagrangian l(x, \u03bb) versus\nx for a few positive values of \u03bb. verify the lower bound property (p\u22c6 \u2265 inf x l(x, \u03bb)\nfor \u03bb \u2265 0). derive and sketch the lagrange dual function g.\n(c) lagrange dual problem. state the dual problem, and verify that it is a concave\nmaximization problem. find the dual optimal value and dual optimal solution \u03bb\u22c6.\ndoes strong duality hold?\n\n(d) sensitivity analysis. let p\u22c6(u) denote the optimal value of the problem\n\nminimize\nsubject to\n\nx2 + 1\n(x \u2212 2)(x \u2212 4) \u2264 u,\n\nas a function of the parameter u. plot p\u22c6(u). verify that dp\u22c6(0)/du = \u2212\u03bb\u22c6.\n\n5.2 weak duality for unbounded and infeasible problems. the weak duality inequality, d\u22c6 \u2264 p\u22c6,\nclearly holds when d\u22c6 = \u2212\u221e or p\u22c6 = \u221e. show that it holds in the other two cases as\nwell: if p\u22c6 = \u2212\u221e, then we must have d\u22c6 = \u2212\u221e, and also, if d\u22c6 = \u221e, then we must have\np\u22c6 = \u221e.\n\n5.3 problems with one inequality constraint. express the dual problem of\n\nminimize\nsubject to\n\nct x\nf (x) \u2264 0,\n\nwith c 6= 0, in terms of the conjugate f \u2217. explain why the problem you give is convex.\nwe do not assume f is convex.\n\nexamples and applications\n\n5.4 interpretation of lp dual via relaxed problems. consider the inequality form lp\n\nct x\n\nminimize\nsubject to ax (cid:22) b,\n\nwith a \u2208 rm\u00d7n, b \u2208 rm. in this exercise we develop a simple geometric interpretation\nof the dual lp (5.22).\nlet w \u2208 rm\n+ . if x is feasible for the lp, i.e., satisfies ax (cid:22) b, then it also satisfies the\ninequality\n\ngeometrically, for any w (cid:23) 0, the halfspace hw = {x | wt ax \u2264 wt b} contains the feasible\nset for the lp. therefore if we minimize the objective ct x over the halfspace hw we get\na lower bound on p\u22c6.\n\nwt ax \u2264 wt b.\n\n "}, {"Page_number": 288, "text": "274\n\n5 duality\n\n(a) derive an expression for the minimum value of ct x over the halfspace hw (which\n\nwill depend on the choice of w (cid:23) 0).\n\n(b) formulate the problem of finding the best such bound, by maximizing the lower\n\nbound over w (cid:23) 0.\n\n(c) relate the results of (a) and (b) to the lagrange dual of the lp, given by (5.22).\n\n5.5 dual of general lp. find the dual function of the lp\n\nct x\n\nminimize\nsubject to gx (cid:22) h\nax = b.\n\ngive the dual problem, and make the implicit equality constraints explicit.\n\n5.6 lower bounds in chebyshev approximation from least-squares. consider the chebyshev\n\nor \u2113\u221e-norm approximation problem\n\nminimize\n\nkax \u2212 bk\u221e,\n\n(5.103)\n\nwhere a \u2208 rm\u00d7n and rank a = n. let xch denote an optimal solution (there may be\nmultiple optimal solutions; xch denotes one of them).\nthe chebyshev problem has no closed-form solution, but the corresponding least-squares\nproblem does. define\n\nxls = argminkax \u2212 bk2 = (at a)\u22121at b.\n\nwe address the following question. suppose that for a particular a and b we have com-\nputed the least-squares solution xls (but not xch). how suboptimal is xls for the chebyshev\nproblem? in other words, how much larger is kaxls \u2212 bk\u221e than kaxch \u2212 bk\u221e?\n(a) prove the lower bound\n\nkaxls \u2212 bk\u221e \u2264 \u221amkaxch \u2212 bk\u221e,\n\nusing the fact that for all z \u2208 rm,\n\n1\n\u221amkzk2 \u2264 kzk\u221e \u2264 kzk2.\n\n(b) in example 5.6 (page 254) we derived a dual for the general norm approximation\nproblem. applying the results to the \u2113\u221e-norm (and its dual norm, the \u21131-norm), we\ncan state the following dual for the chebyshev approximation problem:\n\nmaximize\nsubject to\n\nbt \u03bd\nk\u03bdk1 \u2264 1\nat \u03bd = 0.\n\n(5.104)\n\nany feasible \u03bd corresponds to a lower bound bt \u03bd on kaxch \u2212 bk\u221e.\ndenote the least-squares residual as rls = b \u2212 axls. assuming rls 6= 0, show that\n\n\u02c6\u03bd = \u2212rls/krlsk1,\n\n\u02dc\u03bd = rls/krlsk1,\n\nare both feasible in (5.104). by duality bt \u02c6\u03bd and bt \u02dc\u03bd are lower bounds on kaxch \u2212\nbk\u221e. which is the better bound? how do these bounds compare with the bound\nderived in part (a)?\n\n "}, {"Page_number": 289, "text": "exercises\n\n275\n\n5.7 piecewise-linear minimization. we consider the convex piecewise-linear minimization\n\nproblem\n\nminimize maxi=1,...,m(at\n\ni x + bi)\n\n(5.105)\n\nwith variable x \u2208 rn.\n(a) derive a dual problem, based on the lagrange dual of the equivalent problem\n\nminimize maxi=1,...,m yi\nat\ni x + bi = yi,\nsubject to\n\ni = 1, . . . , m,\n\nwith variables x \u2208 rn, y \u2208 rm.\n\n(b) formulate the piecewise-linear minimization problem (5.105) as an lp, and form the\n\ndual of the lp. relate the lp dual to the dual obtained in part (a).\n\n(c) suppose we approximate the objective function in (5.105) by the smooth function\n\nf0(x) = log  mxi=1\nlog(cid:0)pm\n\nminimize\n\nexp(at\n\ni x + bi)! ,\n\ni=1 exp(at\n\ni x + bi)(cid:1) .\n\npwl and p\u22c6\n\nand solve the unconstrained geometric program\n\n(5.106)\n\na dual of this problem is given by (5.62). let p\u22c6\nof (5.105) and (5.106), respectively. show that\n\ngp be the optimal values\n\npwl \u2264 log m.\n(d) derive similar bounds for the difference between p\u22c6\n\n0 \u2264 p\u22c6\n\ngp \u2212 p\u22c6\n\npwl and the optimal value of\n\nminimize\n\n(1/\u03b3) log(cid:0)pm\n\ni=1 exp(\u03b3(at\n\ni x + bi))(cid:1) ,\n\nwhere \u03b3 > 0 is a parameter. what happens as we increase \u03b3?\n\n5.8 relate the two dual problems derived in example 5.9 on page 257.\n\n5.9 suboptimality of a simple covering ellipsoid. recall the problem of determining the min-\nimum volume ellipsoid, centered at the origin, that contains the points a1, . . . , am \u2208 rn\n(problem (5.14), page 222):\n\nminimize\nsubject to\n\nf0(x) = log det(x \u22121)\nat\ni xai \u2264 1,\n\ni = 1, . . . , m,\n\nwith dom f0 = sn\nthe problem is bounded below).\n\n++. we assume that the vectors a1, . . . , am span rn (which implies that\n\n(a) show that the matrix\n\nis feasible. hint. show that\n\nxsim =  mxk=1\n(cid:20) pm\n\nk=1 akat\n\nat\ni\n\nk\n\nakat\n\n,\n\nk!\u22121\n1 (cid:21) (cid:23) 0,\n\nai\n\nand use schur complements (\u00a7a.5.5) to prove that at\n\ni xai \u2264 1 for i = 1, . . . , m.\n\n "}, {"Page_number": 290, "text": "276\n\n5 duality\n\n(b) now we establish a bound on how suboptimal the feasible point xsim is, via the dual\n\nproblem,\n\nmaximize\nsubject to \u03bb (cid:23) 0,\n\nlog det(cid:0)pm\n\ni=1 \u03bbiaiat\n\ni(cid:1) \u2212 1t \u03bb + n\n\ni=1 \u03bbiaiat\n\nwith the implicit constraintpm\n\ni \u227b 0. (this dual is derived on page 222.)\nto derive a bound, we restrict our attention to dual variables of the form \u03bb = t1,\nwhere t > 0. find (analytically) the optimal value of t, and evaluate the dual\nobjective at this \u03bb. use this to prove that the volume of the ellipsoid {u | ut xsimu \u2264\n1} is no more than a factor (m/n)n/2 more than the volume of the minimum volume\nellipsoid.\n\n5.10 optimal experiment design. the following problems arise in experiment design (see \u00a77.5).\n\n(a) d-optimal design.\n\nminimize\nsubject to x (cid:23) 0,\n\ni=1 xivivt\n\n1t x = 1.\n\nlog det(cid:0)pp\ntr(cid:0)pp\n\ni(cid:1)\u22121\ni(cid:1)\u22121\n\n(b) a-optimal design.\n\nminimize\nsubject to x (cid:23) 0,\n\ni=1 xivivt\n\n1t x = 1.\ni \u227b 0}. the variable is x \u2208 rp; the\nvectors v1, . . . , vp \u2208 rn are given.\nderive dual problems by first introducing a new variable x \u2208 sn and an equality con-\ni=1 xivivt\ni , and then applying lagrange duality. simplify the dual prob-\nlems as much as you can.\n5.11 derive a dual problem for\n\nthe domain of both problems is {x | pp\nstraint x =pp\n\ni=1 xivivt\n\nminimize pn\n\ni=1 kaix + bik2 + (1/2)kx \u2212 x0k2\n2.\n\nthe problem data are ai \u2208 rmi\u00d7n, bi \u2208 rmi , and x0 \u2208 rn. first introduce new variables\nyi \u2208 rmi and equality constraints yi = aix + bi.\n\n5.12 analytic centering. derive a dual problem for\n\nminimize \u2212pm\n\ni=1 log(bi \u2212 at\n\ni x)\n\nwith domain {x | at\ni x < bi, i = 1, . . . , m}. first introduce new variables yi and equality\nconstraints yi = bi \u2212 at\n(the solution of this problem is called the analytic center of the linear inequalities at\ni x \u2264\nbi, i = 1, . . . , m. analytic centers have geometric applications (see \u00a78.5.3), and play an\nimportant role in barrier methods (see chapter 11).)\n5.13 lagrangian relaxation of boolean lp. a boolean linear program is an optimization prob-\n\ni x.\n\nlem of the form\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\nxi \u2208 {0, 1},\n\ni = 1, . . . , n,\n\nand is, in general, very difficult to solve. in exercise 4.15 we studied the lp relaxation of\nthis problem,\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\n0 \u2264 xi \u2264 1,\n\ni = 1, . . . , n,\n\n(5.107)\n\nwhich is far easier to solve, and gives a lower bound on the optimal value of the boolean\nlp. in this problem we derive another lower bound for the boolean lp, and work out the\nrelation between the two lower bounds.\n\n "}, {"Page_number": 291, "text": "exercises\n\n277\n\n(a) lagrangian relaxation. the boolean lp can be reformulated as the problem\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\nxi(1 \u2212 xi) = 0,\n\ni = 1, . . . , n,\n\nwhich has quadratic equality constraints. find the lagrange dual of this problem.\nthe optimal value of the dual problem (which is convex) gives a lower bound on\nthe optimal value of the boolean lp. this method of finding a lower bound on the\noptimal value is called lagrangian relaxation.\n\n(b) show that the lower bound obtained via lagrangian relaxation, and via the lp\nrelaxation (5.107), are the same. hint. derive the dual of the lp relaxation (5.107).\n\n5.14 a penalty method for equality constraints. we consider the problem\n\nminimize\nsubject to ax = b,\n\nf0(x)\n\n(5.108)\n\nwhere f0 : rn \u2192 r is convex and differentiable, and a \u2208 rm\u00d7n with rank a = m.\nin a quadratic penalty method, we form an auxiliary function\n\n\u03c6(x) = f0(x) + \u03b1kax \u2212 bk2\n2,\n\nwhere \u03b1 > 0 is a parameter. this auxiliary function consists of the objective plus the\npenalty term \u03b1kax\u2212 bk2\n2. the idea is that a minimizer of the auxiliary function, \u02dcx, should\nbe an approximate solution of the original problem. intuition suggests that the larger the\npenalty weight \u03b1, the better the approximation \u02dcx to a solution of the original problem.\nsuppose \u02dcx is a minimizer of \u03c6. show how to find, from \u02dcx, a dual feasible point for (5.108).\nfind the corresponding lower bound on the optimal value of (5.108).\n\n5.15 consider the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\n(5.109)\n\nwhere the functions fi : rn \u2192 r are differentiable and convex. let h1, . . . , hm : r \u2192 r\nbe increasing differentiable convex functions. show that\n\n\u03c6(x) = f0(x) +\n\nhi(fi(x))\n\nmxi=1\n\nis convex. suppose \u02dcx minimizes \u03c6. show how to find from \u02dcx a feasible point for the dual\nof (5.109). find the corresponding lower bound on the optimal value of (5.109).\n\n5.16 an exact penalty method for inequality constraints. consider the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\n(5.110)\n\nwhere the functions fi : rn \u2192 r are differentiable and convex.\nmethod, we solve the auxiliary problem\n\nin an exact penalty\n\nminimize \u03c6(x) = f0(x) + \u03b1 maxi=1,...,m max{0, fi(x)},\n\n(5.111)\n\nwhere \u03b1 > 0 is a parameter. the second term in \u03c6 penalizes deviations of x from feasibility.\nthe method is called an exact penalty method if for sufficiently large \u03b1, solutions of the\nauxiliary problem (5.111) also solve the original problem (5.110).\n\n(a) show that \u03c6 is convex.\n\n "}, {"Page_number": 292, "text": "278\n\n5 duality\n\n(b) the auxiliary problem can be expressed as\n\nminimize\nsubject to\n\nf0(x) + \u03b1y\nfi(x) \u2264 y,\n0 \u2264 y\n\ni = 1, . . . , m\n\nwhere the variables are x and y \u2208 r. find the lagrange dual of this problem, and\nexpress it in terms of the lagrange dual function g of (5.110).\n(c) use the result in (b) to prove the following property. suppose \u03bb\u22c6 is an optimal\nsolution of the lagrange dual of (5.110), and that strong duality holds.\nif \u03b1 >\n1t \u03bb\u22c6, then any solution of the auxiliary problem (5.111) is also an optimal solution\nof (5.110).\n\n5.17 robust linear programming with polyhedral uncertainty. consider the robust lp\n\nminimize\nsubject to\n\nct x\nsupa\u2208pi\n\nat x \u2264 bi,\n\ni = 1, . . . , m,\n\nwith variable x \u2208 rn, where pi = {a | cia (cid:22) di}. the problem data are c \u2208 rn,\nci \u2208 rmi\u00d7n, di \u2208 rmi , and b \u2208 rm. we assume the polyhedra pi are nonempty.\nshow that this problem is equivalent to the lp\n\nminimize\nsubject to\n\nct x\ndt\ni zi \u2264 bi,\nc t\ni zi = x,\nzi (cid:23) 0,\n\ni = 1, . . . , m\ni = 1, . . . , m\n\ni = 1, . . . , m\n\nwith variables x \u2208 rn and zi \u2208 rmi , i = 1, . . . , m. hint. find the dual of the problem\nof maximizing at\n5.18 separating hyperplane between two polyhedra. formulate the following problem as an lp\nor an lp feasibility problem. find a separating hyperplane that strictly separates two\npolyhedra\n\ni x over ai \u2208 pi (with variable ai).\n\ni.e., find a vector a \u2208 rn and a scalar \u03b3 such that\n\np1 = {x | ax (cid:22) b},\n\np2 = {x | cx (cid:22) d},\n\nat x > \u03b3 for x \u2208 p1,\n\nat x < \u03b3 for x \u2208 p2.\n\nyou can assume that p1 and p2 do not intersect.\nhint. the vector a and scalar \u03b3 must satisfy\n\nuse lp duality to simplify the infimum and supremum in these conditions.\n\ninf\nx\u2208p1\n\nat x > \u03b3 > sup\nx\u2208p2\n\nat x.\n\n5.19 the sum of the largest elements of a vector. define f : rn \u2192 r as\n\nf (x) =\n\nx[i],\n\nrxi=1\n\nwhere r is an integer between 1 and n, and x[1] \u2265 x[2] \u2265 \u00b7\u00b7\u00b7 \u2265 x[r] are the components of\nx sorted in decreasing order. in other words, f (x) is the sum of the r largest elements of\nx. in this problem we study the constraint\n\nf (x) \u2264 \u03b1.\n\nas we have seen in chapter 3, page 80, this is a convex constraint, and equivalent to a set\nof n!/(r!(n \u2212 r)!) linear inequalities\n\nxi1 + \u00b7\u00b7\u00b7 + xir \u2264 \u03b1,\n\n1 \u2264 i1 < i2 < \u00b7\u00b7\u00b7 < ir \u2264 n.\n\nthe purpose of this problem is to derive a more compact representation.\n\n "}, {"Page_number": 293, "text": "exercises\n\n279\n\n(a) given a vector x \u2208 rn, show that f (x) is equal to the optimal value of the lp\n\nmaximize\nsubject to\n\nxt y\n0 (cid:22) y (cid:22) 1\n1t y = r\n\nwith y \u2208 rn as variable.\n\n(b) derive the dual of the lp in part (a). show that it can be written as\n\nminimize\nsubject to\n\nrt + 1t u\nt1 + u (cid:23) x\nu (cid:23) 0,\n\nwhere the variables are t \u2208 r, u \u2208 rn. by duality this lp has the same optimal\nvalue as the lp in (a), i.e., f (x). we therefore have the following result: x satisfies\nf (x) \u2264 \u03b1 if and only if there exist t \u2208 r, u \u2208 rn such that\n\nrt + 1t u \u2264 \u03b1,\n\nt1 + u (cid:23) x,\n\nu (cid:23) 0.\n\nthese conditions form a set of 2n + 1 linear inequalities in the 2n + 1 variables x, u, t.\n\n(c) as an application, we consider an extension of the classical markowitz portfolio\n\noptimization problem\n\nminimize\nsubject to\n\nxt \u03c3x\npt x \u2265 rmin\n1t x = 1,\n\nx (cid:23) 0\n\ndiscussed in chapter 4, page 155. the variable is the portfolio x \u2208 rn; p and \u03c3 are\nthe mean and covariance matrix of the price change vector p.\nsuppose we add a diversification constraint, requiring that no more than 80% of\nthe total budget can be invested in any 10% of the assets. this constraint can be\nexpressed as\n\n\u230a0.1n\u230bxi=1\n\nx[i] \u2264 0.8.\n\nformulate the portfolio optimization problem with diversification constraint as a\nqp.\n\n5.20 dual of channel capacity problem. derive a dual for the problem\n\nminimize \u2212ct x +pm\n\nsubject to p x = y\nx (cid:23) 0,\n\n1t x = 1,\n\ni=1 yi log yi\n\n1). the variables are x \u2208 rn, y \u2208 rm. (for cj =pm\n\nwhere p \u2208 rm\u00d7n has nonnegative elements, and its columns add up to one (i.e., p t 1 =\ni=1 pij log pij, the optimal value is,\nup to a factor log 2, the negative of the capacity of a discrete memoryless channel with\nchannel transition probability matrix p ; see exercise 4.57.)\nsimplify the dual problem as much as possible.\n\n "}, {"Page_number": 294, "text": "280\n\n5 duality\n\nstrong duality and slater\u2019s condition\n\n5.21 a convex problem in which strong duality fails. consider the optimization problem\n\nminimize\nsubject to x2/y \u2264 0\nwith variables x and y, and domain d = {(x, y) | y > 0}.\n(a) verify that this is a convex optimization problem. find the optimal value.\n(b) give the lagrange dual problem, and find the optimal solution \u03bb\u22c6 and optimal value\n\ne\u2212x\n\nd\u22c6 of the dual problem. what is the optimal duality gap?\n\n(c) does slater\u2019s condition hold for this problem?\n(d) what is the optimal value p\u22c6(u) of the perturbed problem\n\ne\u2212x\n\nminimize\nsubject to x2/y \u2264 u\n\nas a function of u? verify that the global sensitivity inequality\n\ndoes not hold.\n\np\u22c6(u) \u2265 p\u22c6(0) \u2212 \u03bb\u22c6u\n\n5.22 geometric interpretation of duality. for each of the following optimization problems,\n\ndraw a sketch of the sets\n\ng = {(u, t) | \u2203x \u2208 d, f0(x) = t, f1(x) = u},\na = {(u, t) | \u2203x \u2208 d, f0(x) \u2264 t, f1(x) \u2264 u},\n\ngive the dual problem, and solve the primal and dual problems. is the problem convex?\nis slater\u2019s condition satisfied? does strong duality hold?\nthe domain of the problem is r unless otherwise stated.\n(a) minimize x subject to x2 \u2264 1.\n(b) minimize x subject to x2 \u2264 0.\n(c) minimize x subject to |x| \u2264 0.\n(d) minimize x subject to f1(x) \u2264 0 where\n\nf1(x) =( \u2212x + 2 x \u2265 1\n\nx\n\u2212x \u2212 2 x \u2264 \u22121.\n\n\u22121 \u2264 x \u2264 1\n\n(e) minimize x3 subject to \u2212x + 1 \u2264 0.\n(f) minimize x3 subject to \u2212x + 1 \u2264 0 with domain d = r+.\n\n5.23 strong duality in linear programming. we prove that strong duality holds for the lp\n\nand its dual\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\nmaximize \u2212bt z\nsubject to at z + c = 0,\n\nz (cid:23) 0,\n\nprovided at least one of the problems is feasible. in other words, the only possible excep-\ntion to strong duality occurs when p\u22c6 = \u221e and d\u22c6 = \u2212\u221e.\n\n "}, {"Page_number": 295, "text": "exercises\n\n281\n\n(a) suppose p\u22c6 is finite and x\u22c6 is an optimal solution. (if finite, the optimal value of an\n\nlp is attained.) let i \u2286 {1, 2, . . . , m} be the set of active constraints at x\u22c6:\n\nat\ni x\u22c6 < bi,\nshow that there exists a z \u2208 rm that satisfies\n\nat\ni x\u22c6 = bi,\n\ni \u2208 i,\n\nzi \u2265 0,\n\ni \u2208 i,\n\nzi = 0,\n\ni 6\u2208 i, xi\u2208i\n\ni 6\u2208 i.\n\nziai + c = 0.\n\nshow that z is dual optimal with objective value ct x\u22c6.\n\nhint. assume there exists no such z, i.e., \u2212c 6\u2208 {pi\u2208i ziai | zi \u2265 0}. reduce\n\nthis to a contradiction by applying the strict separating hyperplane theorem of\nexample 2.20, page 49. alternatively, you can use farkas\u2019 lemma (see \u00a75.8.3).\n(b) suppose p\u22c6 = \u221e and the dual problem is feasible. show that d\u22c6 = \u221e. hint. show\nthat there exists a nonzero v \u2208 rm such that at v = 0, v (cid:23) 0, bt v < 0. if the dual\nis feasible, it is unbounded in the direction v.\n\n(c) consider the example\n\nminimize\n\nx\n\nsubject to (cid:20) 0\n\n1 (cid:21) x (cid:22)(cid:20) \u22121\n1 (cid:21) .\n\nformulate the dual lp, and solve the primal and dual problems. show that p\u22c6 = \u221e\nand d\u22c6 = \u2212\u221e.\n\n5.24 weak max-min inequality. show that the weak max-min inequality\n\nsup\nz\u2208z\n\ninf\nw\u2208w\n\nf (w, z) \u2264 inf\n\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z)\n\nalways holds, with no assumptions on f : rn \u00d7 rm \u2192 r, w \u2286 rn, or z \u2286 rm.\n\n5.25 [bl00, page 95] convex-concave functions and the saddle-point property. we derive con-\n\nditions under which the saddle-point property\n\nsup\nz\u2208z\n\ninf\nw\u2208w\n\nf (w, z) = inf\nw\u2208w\n\nsup\nz\u2208z\n\nf (w, z)\n\n(5.112)\n\nholds, where f : rn \u00d7 rm \u2192 r, w \u00d7 z \u2286 dom f , and w and z are nonempty. we will\nassume that the function\n\nis closed and convex for all z \u2208 z, and the function\n\notherwise\n\n\u221e\n\ngz(w) =(cid:26) f (w, z) w \u2208 w\nhw(z) =(cid:26) \u2212f (w, z)\n\n\u221e\n\nz \u2208 z\notherwise\n\nis closed and convex for all w \u2208 w .\n(a) the righthand side of (5.112) can be expressed as p(0), where\n\np(u) = inf\nw\u2208w\n\nsup\nz\u2208z\n\n(f (w, z) + ut z).\n\nshow that p is a convex function.\n\n "}, {"Page_number": 296, "text": "282\n\n5 duality\n\n(b) show that the conjugate of p is given by\n\np\u2217(v) =(cid:26) \u2212 inf w\u2208w f (w, v)\n\n\u221e\n\nv \u2208 z\notherwise.\n\n(c) show that the conjugate of p\u2217 is given by\n\np\u2217\u2217(u) = sup\nz\u2208z\n\ninf\nw\u2208w\n\n(f (w, z) + ut z).\n\ncombining this with (a), we can express the max-min equality (5.112) as p\u2217\u2217(0) =\np(0).\n\nconclude that this is the case if w and z are bounded.\n\n(d) from exercises 3.28 and 3.39 (d), we know that p\u2217\u2217(0) = p(0) if 0 \u2208 int dom p.\n(e) as another consequence of exercises 3.28 and 3.39, we have p\u2217\u2217(0) = p(0) if 0 \u2208\ndom p and p is closed. show that p is closed if the sublevel sets of gz are bounded.\n\noptimality conditions\n\n5.26 consider the qcqp\n\nminimize\nsubject to\n\n1 + x2\nx2\n2\n(x1 \u2212 1)2 + (x2 \u2212 1)2 \u2264 1\n(x1 \u2212 1)2 + (x2 + 1)2 \u2264 1\n\nwith variable x \u2208 r2.\n(a) sketch the feasible set and level sets of the objective. find the optimal point x\u22c6 and\noptimal value p\u22c6.\n\n(b) give the kkt conditions. do there exist lagrange multipliers \u03bb\u22c6\n\n1 and \u03bb\u22c6\n\n2 that prove\n\nthat x\u22c6 is optimal?\n\n(c) derive and solve the lagrange dual problem. does strong duality hold?\n\n5.27 equality constrained least-squares. consider the equality constrained least-squares prob-\n\nlem\n\nminimize\nsubject to gx = h\n\nkax \u2212 bk2\n\n2\n\nwhere a \u2208 rm\u00d7n with rank a = n, and g \u2208 rp\u00d7n with rank g = p.\ngive the kkt conditions, and derive expressions for the primal solution x\u22c6 and the dual\nsolution \u03bd\u22c6.\n\n5.28 prove (without using any linear programming code) that the optimal solution of the lp\n\nminimize\n\nsubject to \uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n47x1 + 93x2 + 17x3 \u2212 93x4\n\n1\n7\n\n\u22126\n\u22121\n3\n\u22122\n\u22121\n1\n3 \u221210 \u22121\n0\n\u22122\n\u22126 \u221211\n12\n\u22121 \u22123\n6\n1\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nx1\nx2\nx3\nx4\n\n\uf8ee\uf8ef\uf8f0\n\n\uf8f9\uf8fa\uf8fb (cid:22)\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n\u22123\n5\n\u22128\n\u22127\n4\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nis unique, and given by x\u22c6 = (1, 1, 1, 1).\n\n5.29 the problem\n\nminimize \u22123x2\nsubject to x2\n\n1 + x2\n\n1 + x2\n\n2 + x2\n\n2 + 2x2\n3 = 1,\n\n3 + 2(x1 + x2 + x3)\n\nis a special case of (5.32), so strong duality holds even though the problem is not convex.\nderive the kkt conditions. find all solutions x, \u03bd that satisfy the kkt conditions.\nwhich pair corresponds to the optimum?\n\n "}, {"Page_number": 297, "text": "exercises\n\n283\n\n5.30 derive the kkt conditions for the problem\n\nminimize\nsubject to xs = y,\n\ntr x \u2212 log det x\n\nwith variable x \u2208 sn and domain sn\nverify that the optimal solution is given by\n\n++. y \u2208 rn and s \u2208 rn are given, with st y = 1.\n\nx \u22c6 = i + yyt \u2212\n\n1\n\nst s\n\nsst .\n\n5.31 supporting hyperplane interpretation of kkt conditions. consider a convex problem with\n\nno equality constraints,\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m.\n\nassume that x\u22c6 \u2208 rn and \u03bb\u22c6 \u2208 rm satisfy the kkt conditions\n\n\u2207f0(x\u22c6) +pm\n\ni=1 \u03bb\u22c6\n\nshow that\n\nfi(x\u22c6) \u2264 0,\n\u03bb\u22c6\ni \u2265 0,\n\u03bb\u22c6\ni fi(x\u22c6) = 0,\ni \u2207fi(x\u22c6) = 0.\n\ni = 1, . . . , m\ni = 1, . . . , m\ni = 1, . . . , m\n\n\u2207f0(x\u22c6)t (x \u2212 x\u22c6) \u2265 0\n\nfor all feasible x. in other words the kkt conditions imply the simple optimality criterion\nof \u00a74.2.3.\n\nperturbation and sensitivity analysis\n\n5.32 optimal value of perturbed problem. let f0, f1, . . . , fm : rn \u2192 r be convex. show that\n\nthe function\n\np\u22c6(u, v) = inf{f0(x) | \u2203x \u2208 d, fi(x) \u2264 ui, i = 1, . . . , m, ax \u2212 b = v}\n\nis convex. this function is the optimal cost of the perturbed problem, as a function of\nthe perturbations u and v (see \u00a75.6.1).\n\n5.33 parametrized \u21131-norm approximation. consider the \u21131-norm minimization problem\n\nminimize\n\nkax + b + \u01ebdk1\n\nwith variable x \u2208 r3, and\n\na =\n\n,\n\nb =\n\n,\n\nd =\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n\u22122\n1\n7\n\u22125 \u22121\n3\n3 \u22125\n\u22127\n4 \u22124\n\u22121\n5\n5\n1\n2 \u22125 \u22121\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n\u22124\n3\n9\n0\n\u221211\n5\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n\u221210\n\u221213\n\u221227\n\u221210\n\u22127\n14\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n.\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\nwe denote by p\u22c6(\u01eb) the optimal value as a function of \u01eb.\n\n(a) suppose \u01eb = 0. prove that x\u22c6 = 1 is optimal. are there any other optimal points?\n(b) show that p\u22c6(\u01eb) is affine on an interval that includes \u01eb = 0.\n\n "}, {"Page_number": 298, "text": "284\n\n5 duality\n\n5.34 consider the pair of primal and dual lps\n\n(c + \u01ebd)t x\nminimize\nsubject to ax (cid:22) b + \u01ebf\n\nmaximize \u2212(b + \u01ebf )t z\nsubject to at z + c + \u01ebd = 0\n\nz (cid:23) 0\n\nand\n\nwhere\n\na =\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n\u22124\n\u221217\n1\n3\n\u221211\n\n12 \u22122\n1\n7\n12\n11\n0 \u22126\n1\n22 \u22121\n3\n2 \u22121 \u22128\n\n,\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nb =\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n8\n13\n\u22124\n27\n\u221218\n\n,\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nf =\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n6\n15\n\u221213\n48\n8\n\n,\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nc = (49,\u221234,\u221250,\u22125), d = (3, 8, 21, 25), and \u01eb is a parameter.\n(a) prove that x\u22c6 = (1, 1, 1, 1) is optimal when \u01eb = 0, by constructing a dual optimal\npoint z\u22c6 that has the same objective value as x\u22c6. are there any other primal or dual\noptimal solutions?\n\n(b) give an explicit expression for the optimal value p\u22c6(\u01eb) as a function of \u01eb on an\ninterval that contains \u01eb = 0. specify the interval on which your expression is valid.\nalso give explicit expressions for the primal solution x\u22c6(\u01eb) and the dual solution\nz\u22c6(\u01eb) as a function of \u01eb, on the same interval.\nhint. first calculate x\u22c6(\u01eb) and z\u22c6(\u01eb), assuming that the primal and dual constraints\nthat are active at the optimum for \u01eb = 0, remain active at the optimum for values\nof \u01eb around 0. then verify that this assumption is correct.\n\n5.35 sensitivity analysis for gps. consider a gp\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 1,\nhi(x) = 1,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nwhere f0, . . . , fm are posynomials, h1, . . . , hp are monomials, and the domain of the prob-\nlem is rn\n\n++. we define the perturbed gp as\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 eui ,\nhi(x) = evi ,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nand we denote the optimal value of the perturbed gp as p\u22c6(u, v). we can think of ui and\nvi as relative, or fractional, perturbations of the constraints. for example, u1 = \u22120.01\ncorresponds to tightening the first inequality constraint by (approximately) 1%.\nlet \u03bb\u22c6 and \u03bd\u22c6 be optimal dual variables for the convex form gp\n\nminimize\nsubject to\n\nlog f0(y)\nlog fi(y) \u2264 0,\nlog hi(y) = 0,\n\ni = 1, . . . , m\ni = 1, . . . , p,\n\nwith variables yi = log xi. assuming that p\u22c6(u, v) is differentiable at u = 0, v = 0, relate\n\u03bb\u22c6 and \u03bd\u22c6 to the derivatives of p\u22c6(u, v) at u = 0, v = 0. justify the statement \u201crelaxing\nthe ith constraint by \u03b1 percent will give an improvement in the objective of around \u03b1\u03bb\u22c6\ni\npercent, for \u03b1 small.\u201d\n\n "}, {"Page_number": 299, "text": "exercises\n\ntheorems of alternatives\n\n285\n\n5.36 alternatives for linear equalities. consider the linear equations ax = b, where a \u2208 rm\u00d7n.\nfrom linear algebra we know that this equation has a solution if and only b \u2208 r(a), which\noccurs if and only if b \u22a5 n (at ). in other words, ax = b has a solution if and only if\nthere exists no y \u2208 rm such that at y = 0 and bt y 6= 0.\nderive this result from the theorems of alternatives in \u00a75.8.2.\n\n5.37 [bt97] existence of equilibrium distribution in finite state markov chain. let p \u2208 rn\u00d7n\n\nbe a matrix that satisfies\n\npij \u2265 0,\n\ni, j = 1, . . . , n,\n\np t 1 = 1,\n\ni.e., the coefficients are nonnegative and the columns sum to one. use farkas\u2019 lemma to\nprove there exists a y \u2208 rn such that\np y = y,\n\n1t y = 1.\n\ny (cid:23) 0,\n\n(we can interpret y as an equilibrium distribution of the markov chain with n states and\ntransition probability matrix p .)\n\n5.38 [bt97] option pricing. we apply the results of example 5.10, page 263, to a simple\nproblem with three assets: a riskless asset with fixed return r > 1 over the investment\nperiod of interest (for example, a bond), a stock, and an option on the stock. the option\ngives us the right to purchase the stock at the end of the period, for a predetermined\nprice k.\nwe consider two scenarios.\nin the first scenario, the price of the stock goes up from\ns at the beginning of the period, to su at the end of the period, where u > r. in this\nscenario, we exercise the option only if su > k, in which case we make a profit of su\u2212 k.\notherwise, we do not exercise the option, and make zero profit. the value of the option\nat the end of the period, in the first scenario, is therefore max{0, su \u2212 k}.\nin the second scenario, the price of the stock goes down from s to sd, where d < 1. the\nvalue at the end of the period is max{0, sd \u2212 k}.\nin the notation of example 5.10,\n\nv =(cid:20) r us max{0, su \u2212 k}\nds max{0, sd \u2212 k} (cid:21) ,\n\nr\n\np1 = 1,\n\np2 = s,\n\np3 = c,\n\nwhere c is the price of the option.\nshow that for given r, s, k, u, d, the option price c is uniquely determined by the\nno-arbitrage condition. in other words, the market for the option is complete.\n\ngeneralized inequalities\n\n5.39 sdp relaxations of two-way partitioning problem. we consider the two-way partitioning\n\nproblem (5.7), described on page 219,\n\nminimize\nsubject to x2\n\nxt w x\ni = 1,\n\ni = 1, . . . , n,\n\n(5.113)\n\nwith variable x \u2208 rn. the lagrange dual of this (nonconvex) problem is given by the\nsdp\n\nmaximize \u22121t \u03bd\nsubject to w + diag(\u03bd) (cid:23) 0\n\n(5.114)\n\nwith variable \u03bd \u2208 rn. the optimal value of this sdp gives a lower bound on the optimal\nvalue of the partitioning problem (5.113). in this exercise we derive another sdp that\ngives a lower bound on the optimal value of the two-way partitioning problem, and explore\nthe connection between the two sdps.\n\n "}, {"Page_number": 300, "text": "286\n\n5 duality\n\n(a) two-way partitioning problem in matrix form. show that the two-way partitioning\n\nproblem can be cast as\n\nminimize\ntr(w x)\nsubject to x (cid:23) 0,\nxii = 1,\n\nrank x = 1\n\ni = 1, . . . , n,\n\nwith variable x \u2208 sn. hint. show that if x is feasible, then it has the form\nx = xxt , where x \u2208 rn satisfies xi \u2208 {\u22121, 1} (and vice versa).\n(b) sdp relaxation of two-way partitioning problem. using the formulation in part (a),\nwe can form the relaxation\n\ntr(w x)\n\nminimize\nsubject to x (cid:23) 0\nxii = 1,\n\ni = 1, . . . , n,\n\n(5.115)\n\nwith variable x \u2208 sn. this problem is an sdp, and therefore can be solved effi-\nciently. explain why its optimal value gives a lower bound on the optimal value of\nthe two-way partitioning problem (5.113). what can you say if an optimal point\nx \u22c6 for this sdp has rank one?\n\n(c) we now have two sdps that give a lower bound on the optimal value of the two-way\npartitioning problem (5.113): the sdp relaxation (5.115) found in part (b), and the\nlagrange dual of the two-way partitioning problem, given in (5.114). what is the\nrelation between the two sdps? what can you say about the lower bounds found\nby them? hint: relate the two sdps via duality.\n\n5.40 e-optimal experiment design. a variation on the two optimal experiment design problems\n\nof exercise 5.10 is the e-optimal design problem\n\nminimize\nsubject to x (cid:23) 0,\n\n\u03bbmax(cid:0)pp\n\ni=1 xivivt\n1t x = 1.\n\ni(cid:1)\u22121\n\n(see also \u00a77.5.) derive a dual for this problem, by first reformulating it as\n\n1/t\n\nminimize\n\nsubject to pp\n\nx (cid:23) 0,\n\ni=1 xivivt\n\ni (cid:23) ti\n1t x = 1,\n\nwith variables t \u2208 r, x \u2208 rp and domain r++ \u00d7 rp, and applying lagrange duality.\nsimplify the dual problem as much as you can.\n\n5.41 dual of fastest mixing markov chain problem. on page 174, we encountered the sdp\n\nt\n\nminimize\nsubject to \u2212ti (cid:22) p \u2212 (1/n)11t (cid:22) ti\ni, j = 1, . . . , n\n\np 1 = 1\npij \u2265 0,\npij = 0 for (i, j) 6\u2208 e,\n\nwith variables t \u2208 r, p \u2208 sn.\nshow that the dual of this problem can be expressed as\n1t z \u2212 (1/n)1t y 1\nky k2\u2217 \u2264 1\n(zi + zj) \u2264 yij for (i, j) \u2208 e\n\nmaximize\nsubject to\n\nwith variables z \u2208 rn and y \u2208 sn. the norm k \u00b7 k2\u2217 is the dual of the spectral norm\ni=1 |\u03bbi(y )|, the sum of the absolute values of the eigenvalues of y .\n(see \u00a7a.1.6, page 637.)\n\non sn: ky k2\u2217 = pn\n\n "}, {"Page_number": 301, "text": "exercises\n\n287\n\n5.42 lagrange dual of conic form problem in inequality form. find the lagrange dual problem\n\nof the conic form problem in inequality form\n\nct x\n\nminimize\nsubject to ax (cid:22)k b\n\nwhere a \u2208 rm\u00d7n, b \u2208 rm, and k is a proper cone in rm. make any implicit equality\nconstraints explicit.\n\n5.43 dual of socp. show that the dual of the socp\n\nminimize\nsubject to\n\nf t x\nkaix + bik2 \u2264 ct\n\ni x + di,\n\ni = 1, . . . , m,\n\nwith variables x \u2208 rn, can be expressed as\n\nmaximize pm\nsubject to pm\n\ni=1(bt\ni=1(at\nkuik2 \u2264 vi,\n\ni ui \u2212 divi)\ni ui \u2212 civi) + f = 0\ni = 1, . . . , m,\n\nwith variables ui \u2208 rni , vi \u2208 r, i = 1, . . . , m. the problem data are f \u2208 rn, ai \u2208 rni\u00d7n,\nbi \u2208 rni , ci \u2208 r and di \u2208 r, i = 1, . . . , m.\nderive the dual in the following two ways.\n(a) introduce new variables yi \u2208 rni and ti \u2208 r and equalities yi = aix + bi, ti =\n\nct\ni x + di, and derive the lagrange dual.\n\n(b) start from the conic formulation of the socp and use the conic dual. use the fact\n\nthat the second-order cone is self-dual.\n\n5.44 strong alternatives for nonstrict lmis.\n\nin example 5.14, page 270, we mentioned that\n\nthe system\n\ntr(gz) > 0,\n\ntr(fiz) = 0,\n\ni = 1, . . . , n,\n\n(5.116)\n\nz (cid:23) 0,\n\nis a strong alternative for the nonstrict lmi\n\nif the matrices fi satisfy\n\nf (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0,\n\n(5.117)\n\nnxi=1\n\nvifi (cid:23) 0 =\u21d2\n\nnxi=1\n\nvifi = 0.\n\n(5.118)\n\nin this exercise we prove this result, and give an example to illustrate that the systems\nare not always strong alternatives.\n\n(a) suppose (5.118) holds, and that the optimal value of the auxiliary sdp\n\ns\n\nminimize\nsubject to f (x) (cid:22) si\n\nis positive. show that the optimal value is attained. if follows from the discussion\nin \u00a75.9.4 that the systems (5.117) and (5.116) are strong alternatives.\nhint. the proof simplifies if you assume, without loss of generality, that the matrices\ni=1 vifi (cid:23) 0 \u21d2 v = 0.\n\nf1, . . . , fn are independent, so (5.118) may be replaced bypn\n1 (cid:21) .\n\nf1 =(cid:20) 0\n\ng =(cid:20) 0\n\n0 (cid:21) ,\n\n1\n\n0\n\n1\n\n0\n\nshow that (5.117) and (5.116) are both infeasible.\n\n(b) take n = 1, and\n\n "}, {"Page_number": 302, "text": " "}, {"Page_number": 303, "text": "part ii\n\napplications\n\n "}, {"Page_number": 304, "text": " "}, {"Page_number": 305, "text": "chapter 6\n\napproximation and fitting\n\n6.1 norm approximation\n\n6.1.1 basic norm approximation problem\n\nthe simplest norm approximation problem is an unconstrained problem of the form\n\nminimize\n\nkax \u2212 bk\n\n(6.1)\n\nwhere a \u2208 rm\u00d7n and b \u2208 rm are problem data, x \u2208 rn is the variable, and k\u00b7k is\na norm on rm. a solution of the norm approximation problem is sometimes called\nan approximate solution of ax \u2248 b, in the norm k \u00b7 k. the vector\n\nr = ax \u2212 b\n\nis called the residual for the problem; its components are sometimes called the\nindividual residuals associated with x.\n\nthe norm approximation problem (6.1) is a convex problem, and is solvable,\ni.e., there is always at least one optimal solution.\nits optimal value is zero if\nand only if b \u2208 r(a); the problem is more interesting and useful, however, when\nb 6\u2208 r(a). we can assume without loss of generality that the columns of a are\nindependent; in particular, that m \u2265 n. when m = n the optimal point is simply\na\u22121b, so we can assume that m > n.\n\napproximation interpretation\n\nby expressing ax as\n\nax = x1a1 + \u00b7\u00b7\u00b7 + xnan,\n\nwhere a1, . . . , an \u2208 rm are the columns of a, we see that the goal of the norm\napproximation problem is to fit or approximate the vector b by a linear combination\nof the columns of a, as closely as possible, with deviation measured in the norm\nk \u00b7 k.\nthe approximation problem is also called the regression problem. in this context\nthe vectors a1, . . . , an are called the regressors, and the vector x1a1 + \u00b7\u00b7\u00b7 + xnan,\n\n "}, {"Page_number": 306, "text": "292\n\n6 approximation and fitting\n\nwhere x is an optimal solution of the problem, is called the regression of b (onto\nthe regressors).\n\nestimation interpretation\n\na closely related interpretation of the norm approximation problem arises in the\nproblem of estimating a parameter vector on the basis of an imperfect linear vector\nmeasurement. we consider a linear measurement model\n\ny = ax + v,\n\nwhere y \u2208 rm is a vector measurement, x \u2208 rn is a vector of parameters to be\nestimated, and v \u2208 rm is some measurement error that is unknown, but presumed\nto be small (in the norm k\u00b7k). the estimation problem is to make a sensible guess\nas to what x is, given y.\nif we guess that x has the value \u02c6x, then we are implicitly making the guess that\nv has the value y \u2212 a\u02c6x. assuming that smaller values of v (measured by k \u00b7 k) are\nmore plausible than larger values, the most plausible guess for x is\n\n\u02c6x = argminzkaz \u2212 yk.\n\n(these ideas can be expressed more formally in a statistical framework; see chap-\nter 7.)\n\ngeometric interpretation\nwe consider the subspace a = r(a) \u2286 rm, and a point b \u2208 rm. a projection of\nthe point b onto the subspace a, in the norm k \u00b7 k, is any point in a that is closest\nto b, i.e., any optimal point for the problem\n\nku \u2212 bk\nminimize\nsubject to u \u2208 a.\n\nparametrizing an arbitrary element of r(a) as u = ax, we see that solving the\nnorm approximation problem (6.1) is equivalent to computing a projection of b\nonto a.\ndesign interpretation\n\nwe can interpret the norm approximation problem (6.1) as a problem of optimal\ndesign. the n variables x1, . . . , xn are design variables whose values are to be\ndetermined. the vector y = ax gives a vector of m results, which we assume to\nbe linear functions of the design variables x. the vector b is a vector of target or\ndesired results. the goal is to choose a vector of design variables that achieves, as\nclosely as possible, the desired results, i.e., ax \u2248 b. we can interpret the residual\nvector r as the deviation between the actual results (i.e., ax) and the desired\nor target results (i.e., b). if we measure the quality of a design by the norm of\nthe deviation between the actual results and the desired results, then the norm\napproximation problem (6.1) is the problem of finding the best design.\n\n "}, {"Page_number": 307, "text": "6.1 norm approximation\n\n293\n\nweighted norm approximation problems\n\nan extension of the norm approximation problem is the weighted norm approxima-\ntion problem\n\nminimize\n\nkw (ax \u2212 b)k\n\nwhere the problem data w \u2208 rm\u00d7m is called the weighting matrix. the weight-\ning matrix is often diagonal, in which case it gives different relative emphasis to\ndifferent components of the residual vector r = ax \u2212 b.\nthe weighted norm problem can be considered as a norm approximation prob-\nlem with norm k\u00b7k, and data \u02dca = w a, \u02dcb = w b, and therefore treated as a standard\nnorm approximation problem (6.1). alternatively, the weighted norm approxima-\ntion problem can be considered a norm approximation problem with data a and\nb, and the w -weighted norm defined by\n\nkzkw = kw zk\n\n(assuming here that w is nonsingular).\n\nleast-squares approximation\n\nthe most common norm approximation problem involves the euclidean or \u21132-\nnorm. by squaring the objective, we obtain an equivalent problem which is called\nthe least-squares approximation problem,\nkax \u2212 bk2\n\n2 + \u00b7\u00b7\u00b7 + r2\nm,\n\nminimize\n\n2 = r2\n\n1 + r2\n\nwhere the objective is the sum of squares of the residuals. this problem can be\nsolved analytically by expressing the objective as the convex quadratic function\n\nf (x) = xt at ax \u2212 2bt ax + bt b.\n\na point x minimizes f if and only if\n\ni.e., if and only if x satisfies the so-called normal equations\n\n\u2207f (x) = 2at ax \u2212 2at b = 0,\n\nat ax = at b,\n\nwhich always have a solution. since we assume the columns of a are independent,\nthe least-squares approximation problem has the unique solution x = (at a)\u22121at b.\n\nchebyshev or minimax approximation\n\nwhen the \u2113\u221e-norm is used, the norm approximation problem\nkax \u2212 bk\u221e = max{|r1|, . . . ,|rm|}\n\nminimize\n\nis called the chebyshev approximation problem, or minimax approximation problem,\nsince we are to minimize the maximum (absolute value) residual. the chebyshev\napproximation problem can be cast as an lp\n\nt\n\nminimize\nsubject to \u2212t1 (cid:22) ax \u2212 b (cid:22) t1,\n\nwith variables x \u2208 rn and t \u2208 r.\n\n "}, {"Page_number": 308, "text": "294\n\n6 approximation and fitting\n\nsum of absolute residuals approximation\n\nwhen the \u21131-norm is used, the norm approximation problem\n\nminimize\n\nkax \u2212 bk1 = |r1| + \u00b7\u00b7\u00b7 + |rm|\n\nis called the sum of (absolute) residuals approximation problem, or, in the context\nof estimation, a robust estimator (for reasons that will be clear soon). like the\nchebyshev approximation problem, the \u21131-norm approximation problem can be\ncast as an lp\n\n1t t\n\nminimize\nsubject to \u2212t (cid:22) ax \u2212 b (cid:22) t,\n\nwith variables x \u2208 rn and t \u2208 rm.\n\n6.1.2 penalty function approximation\n\nin \u2113p-norm approximation, for 1 \u2264 p < \u221e, the objective is\n\n(|r1|p + \u00b7\u00b7\u00b7 + |rm|p)1/p .\n\nas in least-squares problems, we can consider the equivalent problem with objective\n\n|r1|p + \u00b7\u00b7\u00b7 + |rm|p,\n\nwhich is a separable and symmetric function of the residuals. in particular, the\nobjective depends only on the amplitude distribution of the residuals, i.e., the\nresiduals in sorted order.\n\nwe will consider a useful generalization of the \u2113p-norm approximation problem,\nin which the objective depends only on the amplitude distribution of the residuals.\nthe penalty function approximation problem has the form\n\nminimize\nsubject to r = ax \u2212 b,\n\n\u03c6(r1) + \u00b7\u00b7\u00b7 + \u03c6(rm)\n\n(6.2)\n\nwhere \u03c6 : r \u2192 r is called the (residual) penalty function. we assume that \u03c6 is\nconvex, so the penalty function approximation problem is a convex optimization\nproblem. in many cases, the penalty function \u03c6 is symmetric, nonnegative, and\nsatisfies \u03c6(0) = 0, but we will not use these properties in our analysis.\n\ninterpretation\n\nwe can interpret the penalty function approximation problem (6.2) as follows. for\nthe choice x, we obtain the approximation ax of b, which has the associated resid-\nual vector r. a penalty function assesses a cost or penalty for each component\nof residual, given by \u03c6(ri); the total penalty is the sum of the penalties for each\nresidual, i.e., \u03c6(r1) + \u00b7\u00b7\u00b7 + \u03c6(rm). different choices of x lead to different resulting\nresiduals, and therefore, different total penalties. in the penalty function approxi-\nmation problem, we minimize the total penalty incurred by the residuals.\n\n "}, {"Page_number": 309, "text": "6.1 norm approximation\n\n295\n\n2\n\n1.5\n\n)\nu\n(\n\u03c6\n\n1\n\n0.5\n\nlog barrier\n\nquadratic\n\ndeadzone-linear\n\n0\n\u22121.5\n\n\u22121\n\n\u22120.5\n\n0\nu\n\n0.5\n\n1\n\n1.5\n\nfigure 6.1 some common penalty functions: the quadratic penalty function\n\u03c6(u) = u2, the deadzone-linear penalty function with deadzone width a =\n1/4, and the log barrier penalty function with limit a = 1.\n\nexample 6.1 some common penalty functions and associated approximation problems.\n\n\u2022 by taking \u03c6(u) = |u|p, where p \u2265 1, the penalty function approximation prob-\nin particular, the\nlem is equivalent to the \u2113p-norm approximation problem.\nquadratic penalty function \u03c6(u) = u2 yields least-squares or euclidean norm\napproximation, and the absolute value penalty function \u03c6(u) = |u| yields \u21131-\nnorm approximation.\n\n\u2022 the deadzone-linear penalty function (with deadzone width a > 0) is given by\n\n\u03c6(u) =(cid:26) 0\n\n|u| \u2212 a\n\n|u| \u2264 a\n|u| > a.\n\nthe deadzone-linear function assesses no penalty for residuals smaller than a.\n\n\u2022 the log barrier penalty function (with limit a > 0) has the form\n\n\u03c6(u) =(cid:26) \u2212a2 log(1 \u2212 (u/a)2)\n\n\u221e\n\n|u| < a\n|u| \u2265 a.\n\nthe log barrier penalty function assesses an infinite penalty for residuals larger\nthan a.\n\na deadzone-linear, log barrier, and quadratic penalty function are plotted in fig-\nure 6.1. note that the log barrier function is very close to the quadratic penalty for\n|u/a| \u2264 0.25 (see exercise 6.1).\n\nscaling the penalty function by a positive number does not affect the solution of\nthe penalty function approximation problem, since this merely scales the objective\n\n "}, {"Page_number": 310, "text": "296\n\n6 approximation and fitting\n\nfunction. but the shape of the penalty function has a large effect on the solution of\nthe penalty function approximation problem. roughly speaking, \u03c6(u) is a measure\nof our dislike of a residual of value u. if \u03c6 is very small (or even zero) for small\nvalues of u, it means we care very little (or not at all) if residuals have these values.\nif \u03c6(u) grows rapidly as u becomes large, it means we have a strong dislike for\nlarge residuals; if \u03c6 becomes infinite outside some interval, it means that residuals\noutside the interval are unacceptable. this simple interpretation gives insight into\nthe solution of a penalty function approximation problem, as well as guidelines for\nchoosing a penalty function.\n\nas an example, let us compare \u21131-norm and \u21132-norm approximation, associ-\nated with the penalty functions \u03c61(u) = |u| and \u03c62(u) = u2, respectively. for\n|u| = 1, the two penalty functions assign the same penalty. for small u we have\n\u03c61(u) \u226b \u03c62(u), so \u21131-norm approximation puts relatively larger emphasis on small\nresiduals compared to \u21132-norm approximation. for large u we have \u03c62(u) \u226b \u03c61(u),\nso \u21131-norm approximation puts less weight on large residuals, compared to \u21132-norm\napproximation. this difference in relative weightings for small and large residuals\nis reflected in the solutions of the associated approximation problems. the ampli-\ntude distribution of the optimal residual for the \u21131-norm approximation problem\nwill tend to have more zero and very small residuals, compared to the \u21132-norm ap-\nproximation solution. in contrast, the \u21132-norm solution will tend to have relatively\nfewer large residuals (since large residuals incur a much larger penalty in \u21132-norm\napproximation than in \u21131-norm approximation).\n\nexample\nan example will illustrate these ideas. we take a matrix a \u2208 r100\u00d730 and vector\nb \u2208 r100 (chosen at random, but the results are typical), and compute the \u21131-norm\nand \u21132-norm approximate solutions of ax \u2248 b, as well as the penalty function\napproximations with a deadzone-linear penalty (with a = 0.5) and log barrier\npenalty (with a = 1). figure 6.2 shows the four associated penalty functions,\nand the amplitude distributions of the optimal residuals for these four penalty\napproximations. from the plots of the penalty functions we note that\n\n\u2022 the \u21131-norm penalty puts the most weight on small residuals and the least\n\nweight on large residuals.\n\n\u2022 the \u21132-norm penalty puts very small weight on small residuals, but strong\n\nweight on large residuals.\n\n\u2022 the deadzone-linear penalty function puts no weight on residuals smaller\n\nthan 0.5, and relatively little weight on large residuals.\n\n\u2022 the log barrier penalty puts weight very much like the \u21132-norm penalty for\nsmall residuals, but puts very strong weight on residuals larger than around\n0.8, and infinite weight on residuals larger than 1.\n\nseveral features are clear from the amplitude distributions:\n\n\u2022 for the \u21131-optimal solution, many residuals are either zero or very small. the\n\n\u21131-optimal solution also has relatively more large residuals.\n\n "}, {"Page_number": 311, "text": "6.1 norm approximation\n\n297\n\n1\n=\np\n\n2\n=\np\n\ne\nn\no\nz\nd\na\ne\nd\n\nr\ne\ni\nr\nr\na\nb\n\ng\no\nl\n\n40\n\n0\n\u22122\n10\n\n0\n\u22122\n20\n\n0\n\u22122\n10\n\n0\n\u22122\n\n\u22121\n\n\u22121\n\n\u22121\n\n\u22121\n\n0\n\n0\n\n0\n\n0\nr\n\n1\n\n1\n\n1\n\n1\n\n2\n\n2\n\n2\n\n2\n\nfigure 6.2 histogram of residual amplitudes for four penalty functions, with\nthe (scaled) penalty functions also shown for reference. for the log barrier\nplot, the quadratic penalty is also shown, in dashed curve.\n\n "}, {"Page_number": 312, "text": "298\n\n6 approximation and fitting\n\n1.5\n\n1\n\n0.5\n\n)\nu\n(\n\u03c6\n\n0\n\u22121.5 \u22121 \u22120.5\n\n0\nu\n\n0.5\n\n1\n\n1.5\n\nfigure 6.3 a (nonconvex) penalty function that assesses a fixed penalty to\nresiduals larger than a threshold (which in this example is one): \u03c6(u) = u2\nif |u| \u2264 1 and \u03c6(u) = 1 if |u| > 1. as a result, penalty approximation with\nthis function would be relatively insensitive to outliers.\n\n\u2022 the \u21132-norm approximation has many modest residuals, and relatively few\n\nlarger ones.\n\n\u2022 for the deadzone-linear penalty, we see that many residuals have the value\n\n\u00b10.5, right at the edge of the \u2018free\u2019 zone, for which no penalty is assessed.\n\n\u2022 for the log barrier penalty, we see that no residuals have a magnitude larger\nthan 1, but otherwise the residual distribution is similar to the residual dis-\ntribution for \u21132-norm approximation.\n\nsensitivity to outliers or large errors\n\nin the estimation or regression context, an outlier is a measurement yi = at\ni x + vi\nfor which the noise vi is relatively large. this is often associated with faulty data\nor a flawed measurement. when outliers occur, any estimate of x will be associated\nwith a residual vector with some large components. ideally we would like to guess\nwhich measurements are outliers, and either remove them from the estimation\nprocess or greatly lower their weight in forming the estimate. (we cannot, however,\nassign zero penalty for very large residuals, because then the optimal point would\nlikely make all residuals large, which yields a total penalty of zero.) this could be\naccomplished using penalty function approximation, with a penalty function such\nas\n\n\u03c6(u) =(cid:26) u2\n\nm 2\n\n|u| \u2264 m\n|u| > m,\n\n(6.3)\n\nshown in figure 6.3. this penalty function agrees with least-squares for any residual\nsmaller than m , but puts a fixed weight on any residual larger than m , no matter\nhow much larger it is. in other words, residuals larger than m are ignored; they\nare assumed to be associated with outliers or bad data. unfortunately, the penalty\n\n "}, {"Page_number": 313, "text": "6.1 norm approximation\n\n299\n\n2\n\n1.5\n\n1\n\n0.5\n\n)\nu\n(\nb\nu\nh\n\u03c6\n\n0\n\u22121.5 \u22121 \u22120.5\n\n0\nu\n\n0.5\n\n1\n\n1.5\n\nfigure 6.4 the solid line is the robust least-squares or huber penalty func-\ntion \u03c6hub, with m = 1. for |u| \u2264 m it is quadratic, and for |u| > m it\ngrows linearly.\n\nfunction (6.3) is not convex, and the associated penalty function approximation\nproblem becomes a hard combinatorial optimization problem.\n\nthe sensitivity of a penalty function based estimation method to outliers de-\npends on the (relative) value of the penalty function for large residuals.\nif we\nrestrict ourselves to convex penalty functions (which result in convex optimization\nproblems), the ones that are least sensitive are those for which \u03c6(u) grows linearly,\ni.e., like |u|, for large u. penalty functions with this property are sometimes called\nrobust, since the associated penalty function approximation methods are much less\nsensitive to outliers or large errors than, for example, least-squares.\n\none obvious example of a robust penalty function is \u03c6(u) = |u|, corresponding\nto \u21131-norm approximation. another example is the robust least-squares or huber\npenalty function, given by\n\n\u03c6hub(u) =(cid:26) u2\n\nm (2|u| \u2212 m )\n\n|u| \u2264 m\n|u| > m,\n\n(6.4)\n\nshown in figure 6.4. this penalty function agrees with the least-squares penalty\nfunction for residuals smaller than m , and then reverts to \u21131-like linear growth for\nlarger residuals. the huber penalty function can be considered a convex approx-\nimation of the outlier penalty function (6.3), in the following sense: they agree\nfor |u| \u2264 m , and for |u| > m , the huber penalty function is the convex function\nclosest to the outlier penalty function (6.3).\n\nexample 6.2 robust regression. figure 6.5 shows 42 points (ti, yi) in a plane, with\ntwo obvious outliers (one at the upper left, and one at lower right). the dashed line\nshows the least-squares approximation of the points by a straight line f (t) = \u03b1 + \u03b2t.\nthe coefficients \u03b1 and \u03b2 are obtained by solving the least-squares problem\n\nminimize p42\n\ni=1(yi \u2212 \u03b1 \u2212 \u03b2ti)2,\n\n "}, {"Page_number": 314, "text": "300\n\n6 approximation and fitting\n\n20\n\n10\n\n0\n\n)\nt\n(\nf\n\n\u221210\n\n\u221220\n\n\u221210\n\n\u22125\n\n0\nt\n\n5\n\n10\n\nfigure 6.5 the 42 circles show points that can be well approximated by\nan affine function, except for the two outliers at upper left and lower right.\nthe dashed line is the least-squares fit of a straight line f (t) = \u03b1 + \u03b2t\nto the points, and is rotated away from the main locus of points, toward\nthe outliers. the solid line shows the robust least-squares fit, obtained by\nminimizing huber\u2019s penalty function with m = 1. this gives a far better fit\nto the non-outlier data.\n\nwith variables \u03b1 and \u03b2. the least-squares approximation is clearly rotated away from\nthe main locus of the points, toward the two outliers.\n\nthe solid line shows the robust least-squares approximation, obtained by minimizing\nthe huber penalty function\n\nwith m = 1. this approximation is far less affected by the outliers.\n\nminimize p42\n\ni=1 \u03c6hub(yi \u2212 \u03b1 \u2212 \u03b2ti),\n\nsince \u21131-norm approximation is among the (convex) penalty function approxi-\nmation methods that are most robust to outliers, \u21131-norm approximation is some-\ntimes called robust estimation or robust regression. the robustness property of\n\u21131-norm estimation can also be understood in a statistical framework; see page 353.\n\nsmall residuals and \u21131-norm approximation\n\nwe can also focus on small residuals. least-squares approximation puts very small\nweight on small residuals, since \u03c6(u) = u2 is very small when u is small. penalty\nfunctions such as the deadzone-linear penalty function put zero weight on small\nresiduals. for penalty functions that are very small for small residuals, we expect\nthe optimal residuals to be small, but not very small. roughly speaking, there is\nlittle or no incentive to drive small residuals smaller.\n\nin contrast, penalty functions that put relatively large weight on small residuals,\nsuch as \u03c6(u) = |u|, corresponding to \u21131-norm approximation, tend to produce\n\n "}, {"Page_number": 315, "text": "6.1 norm approximation\n\n301\n\noptimal residuals many of which are very small, or even exactly zero. this means\nthat in \u21131-norm approximation, we typically find that many of the equations are\nsatisfied exactly, i.e., we have at\ni x = bi for many i. this phenomenon can be seen\nin figure 6.2.\n\n6.1.3 approximation with constraints\n\nit is possible to add constraints to the basic norm approximation problem (6.1).\nwhen these constraints are convex, the resulting problem is convex. constraints\narise for a variety of reasons.\n\n\u2022 in an approximation problem, constraints can be used to rule out certain un-\nacceptable approximations of the vector b, or to ensure that the approximator\nax satisfies certain properties.\n\n\u2022 in an estimation problem, the constraints arise as prior knowledge of the\nvector x to be estimated, or from prior knowledge of the estimation error v.\n\n\u2022 constraints arise in a geometric setting in determining the projection of a\npoint b on a set more complicated than a subspace, for example, a cone or\npolyhedron.\n\nsome examples will make these clear.\n\nnonnegativity constraints on variables\nwe can add the constraint x (cid:23) 0 to the basic norm approximation problem:\n\nminimize\nsubject to x (cid:23) 0.\n\nkax \u2212 bk\n\nin an estimation setting, nonnegativity constraints arise when we estimate a vector\nx of parameters known to be nonnegative, e.g., powers, intensities, or rates. the\ngeometric interpretation is that we are determining the projection of a vector b onto\nthe cone generated by the columns of a. we can also interpret this problem as\napproximating b using a nonnegative linear (i.e., conic) combination of the columns\nof a.\n\nvariable bounds\nhere we add the constraint l (cid:22) x (cid:22) u, where l, u \u2208 rn are problem parameters:\n\nminimize\nsubject to\n\nkax \u2212 bk\nl (cid:22) x (cid:22) u.\n\nin an estimation setting, variable bounds arise as prior knowledge of intervals in\nwhich each variable lies. the geometric interpretation is that we are determining\nthe projection of a vector b onto the image of a box under the linear mapping\ninduced by a.\n\n "}, {"Page_number": 316, "text": "302\n\n6 approximation and fitting\n\nprobability distribution\nwe can impose the constraint that x satisfy x (cid:23) 0, 1t x = 1:\n\nminimize\nsubject to x (cid:23) 0,\n\nkax \u2212 bk\n\n1t x = 1.\n\nthis would arise in the estimation of proportions or relative frequencies, which are\nnonnegative and sum to one. it can also be interpreted as approximating b by a\nconvex combination of the columns of a. (we will have much more to say about\nestimating probabilities in \u00a77.2.)\nnorm ball constraint\n\nwe can add to the basic norm approximation problem the constraint that x lie in\na norm ball:\n\nminimize\nsubject to\n\nkax \u2212 bk\nkx \u2212 x0k \u2264 d,\n\nwhere x0 and d are problem parameters. such a constraint can be added for several\nreasons.\n\n\u2022 in an estimation setting, x0 is a prior guess of what the parameter x is, and d\nis the maximum plausible deviation of our estimate from our prior guess. our\nestimate of the parameter x is the value \u02c6x which best matches the measured\ndata (i.e., minimizes kaz \u2212 bk) among all plausible candidates (i.e., z that\nsatisfy kz \u2212 x0k \u2264 d).\n\n\u2022 the constraint kx\u2212x0k \u2264 d can denote a trust region. here the linear relation\ny = ax is only an approximation of some nonlinear relation y = f (x) that is\nvalid when x is near some point x0, specifically kx \u2212 x0k \u2264 d. the problem\nis to minimize kax \u2212 bk but only over those x for which the model y = ax is\ntrusted.\n\nthese ideas also come up in the context of regularization; see \u00a76.3.2.\n\n6.2 least-norm problems\n\nthe basic least-norm problem has the form\n\nminimize\nsubject to ax = b\n\nkxk\n\n(6.5)\n\nwhere the data are a \u2208 rm\u00d7n and b \u2208 rm, the variable is x \u2208 rn, and k \u00b7 k is a\nnorm on rn. a solution of the problem, which always exists if the linear equations\nax = b have a solution, is called a least-norm solution of ax = b. the least-norm\nproblem is, of course, a convex optimization problem.\n\nwe can assume without loss of generality that the rows of a are independent, so\nm \u2264 n. when m = n, the only feasible point is x = a\u22121b; the least-norm problem\nis interesting only when m < n, i.e., when the equation ax = b is underdetermined.\n\n "}, {"Page_number": 317, "text": "6.2 least-norm problems\n\n303\n\nreformulation as norm approximation problem\n\nthe least-norm problem (6.5) can be formulated as a norm approximation problem\nby eliminating the equality constraint. let x0 be any solution of ax = b, and let\nz \u2208 rn\u00d7k be a matrix whose columns are a basis for the nullspace of a. the\ngeneral solution of ax = b can then be expressed as x0 + zu where u \u2208 rk. the\nleast-norm problem (6.5) can be expressed as\n\nminimize\n\nkx0 + zuk,\n\nwith variable u \u2208 rk, which is a norm approximation problem.\nin particular,\nour analysis and discussion of norm approximation problems applies to least-norm\nproblems as well (when interpreted correctly).\n\ncontrol or design interpretation\n\nwe can interpret the least-norm problem (6.5) as a problem of optimal design or\noptimal control. the n variables x1, . . . , xn are design variables whose values are\nto be determined. in a control setting, the variables x1, . . . , xn represent inputs,\nwhose values we are to choose. the vector y = ax gives m attributes or results of\nthe design x, which we assume to be linear functions of the design variables x. the\nm < n equations ax = b represent m specifications or requirements on the design.\nsince m < n, the design is underspecified; there are n \u2212 m degrees of freedom in\nthe design (assuming a is rank m).\namong all the designs that satisfy the specifications, the least-norm problem\nchooses the smallest design, as measured by the norm k\u00b7k. this can be thought of\nas the most efficient design, in the sense that it achieves the specifications ax = b,\nwith the smallest possible x.\n\nestimation interpretation\n\nwe assume that x is a vector of parameters to be estimated. we have m < n\nperfect (noise free) linear measurements, given by ax = b. since we have fewer\nmeasurements than parameters to estimate, our measurements do not completely\ndetermine x. any parameter vector x that satisfies ax = b is consistent with our\nmeasurements.\n\nto make a good guess about what x is, without taking further measurements,\nwe must use prior information. suppose our prior information, or assumption, is\nthat x is more likely to be small (as measured by k \u00b7 k) than large. the least-norm\nproblem chooses as our estimate of the parameter vector x the one that is smallest\n(hence, most plausible) among all parameter vectors that are consistent with the\nmeasurements ax = b. (for a statistical interpretation of the least-norm problem,\nsee page 359.)\n\ngeometric interpretation\n\nwe can also give a simple geometric interpretation of the least-norm problem (6.5).\nthe feasible set {x | ax = b} is affine, and the objective is the distance (measured\nby the norm k \u00b7 k) between x and the point 0. the least-norm problem finds the\n\n "}, {"Page_number": 318, "text": "304\n\n6 approximation and fitting\n\npoint in the affine set with minimum distance to 0, i.e., it determines the projection\nof the point 0 on the affine set {x | ax = b}.\nleast-squares solution of linear equations\n\nthe most common least-norm problem involves the euclidean or \u21132-norm. by\nsquaring the objective we obtain the equivalent problem\n\nminimize\nsubject to ax = b,\n\nkxk2\n\n2\n\nthe unique solution of which is called the least-squares solution of the equations\nax = b. like the least-squares approximation problem, this problem can be solved\nanalytically. introducing the dual variable \u03bd \u2208 rm, the optimality conditions are\n\n2x\u22c6 + at \u03bd\u22c6 = 0,\n\nax\u22c6 = b,\n\nwhich is a pair of linear equations, and readily solved. from the first equation\nwe obtain x\u22c6 = \u2212(1/2)at \u03bd\u22c6; substituting this into the second equation we obtain\n\u2212(1/2)aat \u03bd\u22c6 = b, and conclude\n\n\u03bd\u22c6 = \u22122(aat )\u22121b,\n\nx\u22c6 = at (aat )\u22121b.\n\n(since rank a = m < n, the matrix aat is invertible.)\n\nleast-penalty problems\n\na useful variation on the least-norm problem (6.5) is the least-penalty problem\n\nminimize\nsubject to ax = b,\n\n\u03c6(x1) + \u00b7\u00b7\u00b7 + \u03c6(xn)\n\n(6.6)\n\nwhere \u03c6 : r \u2192 r is convex, nonnegative, and satisfies \u03c6(0) = 0. the penalty\nfunction value \u03c6(u) quantifies our dislike of a component of x having value u;\nthe least-penalty problem then finds x that has least total penalty, subject to the\nconstraint ax = b.\n\nall of the discussion and interpretation of penalty functions in penalty function\napproximation can be transposed to the least-penalty problem, by substituting\nthe amplitude distribution of x (in the least-penalty problem) for the amplitude\ndistribution of the residual r (in the penalty approximation problem).\n\nsparse solutions via least \u21131-norm\n\nrecall from the discussion on page 300 that \u21131-norm approximation gives relatively\nlarge weight to small residuals, and therefore results in many optimal residuals\nsmall, or even zero. a similar effect occurs in the least-norm context. the least\n\u21131-norm problem,\n\nminimize\nsubject to ax = b,\n\nkxk1\n\ntends to produce a solution x with a large number of components equal to zero.\nin other words, the least \u21131-norm problem tends to produce sparse solutions of\nax = b, often with m nonzero components.\n\n "}, {"Page_number": 319, "text": "6.3 regularized approximation\n\n305\n\nit is easy to find solutions of ax = b that have only m nonzero components.\nchoose any set of m indices (out of 1, . . . , n) which are to be the nonzero com-\nponents of x. the equation ax = b reduces to \u02dca\u02dcx = b, where \u02dca is the m \u00d7 m\nsubmatrix of a obtained by selecting only the chosen columns, and \u02dcx \u2208 rm is the\nsubvector of x containing the m selected components. if \u02dca is nonsingular, then\nwe can take \u02dcx = \u02dca\u22121b, which gives a feasible solution x with m or less nonzero\ncomponents. if \u02dca is singular and b 6\u2208 r( \u02dca), the equation \u02dca\u02dcx = b is unsolvable,\nwhich means there is no feasible x with the chosen set of nonzero components. if\n\u02dca is singular and b \u2208 r( \u02dca), there is a feasible solution with fewer than m nonzero\ncomponents.\n\nthis approach can be used to find the smallest x with m (or fewer) nonzero\nentries, but in general requires examining and comparing all n!/(m!(n\u2212m)!) choices\nof m nonzero coefficients of the n coefficients in x. solving the least \u21131-norm\nproblem, on the other hand, gives a good heuristic for finding a sparse, and small,\nsolution of ax = b.\n\n6.3 regularized approximation\n\n6.3.1 bi-criterion formulation\n\nin the basic form of regularized approximation, the goal is to find a vector x that\nis small (if possible), and also makes the residual ax \u2212 b small. this is naturally\ndescribed as a (convex) vector optimization problem with two objectives, kax\u2212 bk\nand kxk:\n\nminimize (w.r.t. r2\n\n+)\n\n(kax \u2212 bk,kxk) .\n\n(6.7)\n\nthe two norms can be different: the first, used to measure the size of the residual,\nis on rm; the second, used to measure the size of x, is on rn.\n\nthe optimal trade-off between the two objectives can be found using several\nmethods. the optimal trade-off curve of kax \u2212 bk versus kxk, which shows how\nlarge one of the objectives must be made to have the other one small, can then be\nplotted. one endpoint of the optimal trade-off curve between kax \u2212 bk and kxk\nis easy to describe. the minimum value of kxk is zero, and is achieved only when\nx = 0. for this value of x, the residual norm has the value kbk.\n\nthe other endpoint of the trade-off curve is more complicated to describe. let\nc denote the set of minimizers of kax\u2212 bk (with no constraint on kxk). then any\nminimum norm point in c is pareto optimal, corresponding to the other endpoint\nof the trade-off curve. in other words, pareto optimal points at this endpoint are\ngiven by minimum norm minimizers of kax\u2212 bk. if both norms are euclidean, this\npareto optimal point is unique, and given by x = a\u2020b, where a\u2020 is the pseudo-\ninverse of a. (see \u00a74.7.6, page 184, and \u00a7a.5.4.)\n\n "}, {"Page_number": 320, "text": "306\n\n6 approximation and fitting\n\n6.3.2 regularization\n\nregularization is a common scalarization method used to solve the bi-criterion\nproblem (6.7). one form of regularization is to minimize the weighted sum of the\nobjectives:\n\nminimize\n\n(6.8)\nwhere \u03b3 > 0 is a problem parameter. as \u03b3 varies over (0,\u221e), the solution of (6.8)\ntraces out the optimal trade-off curve.\nanother common method of regularization, especially when the euclidean norm\n\nkax \u2212 bk + \u03b3kxk,\n\nis used, is to minimize the weighted sum of squared norms, i.e.,\n\nminimize\n\nkax \u2212 bk2 + \u03b4kxk2,\n\n(6.9)\n\nfor a variety of values of \u03b4 > 0.\n\nthese regularized approximation problems each solve the bi-criterion problem\nof making both kax \u2212 bk and kxk small, by adding an extra term or penalty\nassociated with the norm of x.\n\ninterpretations\n\nregularization is used in several contexts. in an estimation setting, the extra term\npenalizing large kxk can be interpreted as our prior knowledge that kxk is not too\nlarge. in an optimal design setting, the extra term adds the cost of using large\nvalues of the design variables to the cost of missing the target specifications.\n\nthe constraint that kxk be small can also reflect a modeling issue. it might be,\nfor example, that y = ax is only a good approximation of the true relationship\ny = f (x) between x and y. in order to have f (x) \u2248 b, we want ax \u2248 b, and also\nneed x small in order to ensure that f (x) \u2248 ax.\nwe will see in \u00a76.4.1 and \u00a76.4.2 that regularization can be used to take into\naccount variation in the matrix a. roughly speaking, a large x is one for which\nvariation in a causes large variation in ax, and hence should be avoided.\n\nregularization is also used when the matrix a is square, and the goal is to\nsolve the linear equations ax = b. in cases where a is poorly conditioned, or even\nsingular, regularization gives a compromise between solving the equations (i.e.,\nmaking kax \u2212 bk zero) and keeping x of reasonable size.\n\nregularization comes up in a statistical setting; see \u00a77.1.2.\n\ntikhonov regularization\n\nthe most common form of regularization is based on (6.9), with euclidean norms,\nwhich results in a (convex) quadratic optimization problem:\n\nminimize\n\nkax \u2212 bk2\n\n2 + \u03b4kxk2\n\n2 = xt (at a + \u03b4i)x \u2212 2bt ax + bt b.\n\n(6.10)\n\nthis tikhonov regularization problem has the analytical solution\n\nx = (at a + \u03b4i)\u22121at b.\n\nsince at a + \u03b4i \u227b 0 for any \u03b4 > 0, the tikhonov regularized least-squares solution\nrequires no rank (or dimension) assumptions on the matrix a.\n\n "}, {"Page_number": 321, "text": "6.3 regularized approximation\n\n307\n\nsmoothing regularization\n\nthe idea of regularization, i.e., adding to the objective a term that penalizes large\nx, can be extended in several ways. in one useful extension we add a regularization\nterm of the form kdxk, in place of kxk.\nin many applications, the matrix d\nrepresents an approximate differentiation or second-order differentiation operator,\nso kdxk represents a measure of the variation or smoothness of x.\nfor example, suppose that the vector x \u2208 rn represents the value of some\ncontinuous physical parameter, say, temperature, along the interval [0, 1]: xi is\nthe temperature at the point i/n. a simple approximation of the gradient or\nfirst derivative of the parameter near i/n is given by n(xi+1 \u2212 xi), and a simple\napproximation of its second derivative is given by the second difference\nn (n(xi+1 \u2212 xi) \u2212 n(xi \u2212 xi\u22121)) = n2(xi+1 \u2212 2xi + xi\u22121).\n\nif \u2206 is the (tridiagonal, toeplitz) matrix\n\n\u2206 = n2\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n0 \u00b7\u00b7\u00b7\n1 \u22122\n0\n1\n0\n1 \u00b7\u00b7\u00b7\n1 \u22122\n0\n0\n0\n1 \u22122 \u00b7\u00b7\u00b7\n0\n0\n0\n0\n...\n...\n...\n...\n...\n...\n0 \u00b7\u00b7\u00b7 \u22122\n0\n0\n0\n1\n0 \u00b7\u00b7\u00b7\n1 \u22122\n0\n0\n0\n0 \u00b7\u00b7\u00b7\n0\n0\n0\n0\n\n0\n0\n0\n...\n0\n1\n1 \u22122\n\n0\n0\n0\n...\n0\n0\n1\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n\u2208 r(n\u22122)\u00d7n,\n\nthen \u2206x represents an approximation of the second derivative of the parameter, so\nk\u2206xk2\n2 represents a measure of the mean-square curvature of the parameter over\nthe interval [0, 1].\n\nthe tikhonov regularized problem\n\nminimize\n\nkax \u2212 bk2\n\n2 + \u03b4k\u2206xk2\n\n2\n\ncan be used to trade off the objective kax \u2212 bk2, which might represent a measure\nof fit, or consistency with experimental data, and the objective k\u2206xk2, which is\n(approximately) the mean-square curvature of the underlying physical parameter.\nthe parameter \u03b4 is used to control the amount of regularization required, or to\nplot the optimal trade-off curve of fit versus smoothness.\n\nwe can also add several regularization terms. for example, we can add terms\n\nassociated with smoothness and size, as in\nkax \u2212 bk2\n\nminimize\n\n2 + \u03b4k\u2206xk2\n\n2 + \u03b7kxk2\n2.\n\nhere, the parameter \u03b4 \u2265 0 is used to control the smoothness of the approximate\nsolution, and the parameter \u03b7 \u2265 0 is used to control its size.\n\nexample 6.3 optimal input design. we consider a dynamical system with scalar\ninput sequence u(0), u(1), . . . , u(n ), and scalar output sequence y(0), y(1), . . . , y(n ),\nrelated by convolution:\n\ny(t) =\n\ntx\u03c4 =0\n\nh(\u03c4 )u(t \u2212 \u03c4 ),\n\nt = 0, 1, . . . , n.\n\n "}, {"Page_number": 322, "text": "308\n\n6 approximation and fitting\n\nthe sequence h(0), h(1), . . . , h(n ) is called the convolution kernel or impulse response\nof the system.\n\nour goal is to choose the input sequence u to achieve several goals.\n\n\u2022 output tracking. the primary goal is that the output y should track, or follow,\na desired target or reference signal ydes. we measure output tracking error by\nthe quadratic function\n\njtrack =\n\n1\n\nn + 1\n\nnxt=0\n\n(y(t) \u2212 ydes(t))2.\n\n\u2022 small input. the input should not be large. we measure the magnitude of the\n\ninput by the quadratic function\n\njmag =\n\n1\n\nn + 1\n\nu(t)2.\n\nnxt=0\n\n\u2022 small input variations. the input should not vary rapidly. we measure the\n\nmagnitude of the input variations by the quadratic function\n\njder =\n\n1\nn\n\nn \u22121xt=0\n\n(u(t + 1) \u2212 u(t))2.\n\nby minimizing a weighted sum\n\njtrack + \u03b4jder + \u03b7jmag,\n\nwhere \u03b4 > 0 and \u03b7 > 0, we can trade off the three objectives.\n\nnow we consider a specific example, with n = 200, and impulse response\n\nh(t) =\n\n1\n9\n\n(0.9)t(1 \u2212 0.4 cos(2t)).\n\nfigure 6.6 shows the optimal input, and corresponding output (along with the desired\ntrajectory ydes), for three values of the regularization parameters \u03b4 and \u03b7. the top\nrow shows the optimal input and corresponding output for \u03b4 = 0, \u03b7 = 0.005. in this\ncase we have some regularization for the magnitude of the input, but no regularization\nfor its variation. while the tracking is good (i.e., we have jtrack is small), the input\nrequired is large, and rapidly varying. the second row corresponds to \u03b4 = 0, \u03b7 = 0.05.\nin this case we have more magnitude regularization, but still no regularization for\nvariation in u. the corresponding input is indeed smaller, at the cost of a larger\ntracking error. the bottom row shows the results for \u03b4 = 0.3, \u03b7 = 0.05.\nin this\ncase we have added some regularization for the variation. the input variation is\nsubstantially reduced, with not much increase in output tracking error.\n\n\u21131-norm regularization\n\nregularization with an \u21131-norm can be used as a heuristic for finding a sparse\nsolution. for example, consider the problem\n\nminimize\n\nkax \u2212 bk2 + \u03b3kxk1,\n\n(6.11)\n\n "}, {"Page_number": 323, "text": "6.3 regularized approximation\n\n309\n\n5\n\n0\n\n)\nt\n(\nu\n\n\u22125\n\n\u221210\n0\n\n4\n\n2\n\n0\n\n)\nt\n(\nu\n\n\u22122\n\n\u22124\n0\n\n4\n\n2\n\n0\n\n)\nt\n(\nu\n\n\u22122\n\n\u22124\n0\n\n1\n\n0.5\n\n)\nt\n(\ny\n\n0\n\n\u22120.5\n\n50\n\n100\n\nt\n\n150\n\n200\n\n\u22121\n0\n\n1\n\n0.5\n\n)\nt\n(\ny\n\n0\n\n\u22120.5\n\n50\n\n100\n\nt\n\n150\n\n200\n\n\u22121\n0\n\n1\n\n0.5\n\n)\nt\n(\ny\n\n0\n\n\u22120.5\n\n50\n\n100\n\nt\n\n150\n\n200\n\n50\n\n100\n\nt\n\n150\n\n200\n\n50\n\n100\n\nt\n\n150\n\n200\n\n\u22121\n0\n\n50\n\n100\n\nt\n\n150\n\n200\n\nfigure 6.6 optimal inputs (left) and resulting outputs (right) for three values\nof the regularization parameters \u03b4 (which corresponds to input variation) and\n\u03b7 (which corresponds to input magnitude). the dashed line in the righthand\nplots shows the desired output ydes. top row: \u03b4 = 0, \u03b7 = 0.005; middle row:\n\u03b4 = 0, \u03b7 = 0.05; bottom row: \u03b4 = 0.3, \u03b7 = 0.05.\n\n "}, {"Page_number": 324, "text": "310\n\n6 approximation and fitting\n\nin which the residual is measured with the euclidean norm and the regularization is\ndone with an \u21131-norm. by varying the parameter \u03b3 we can sweep out the optimal\ntrade-off curve between kax \u2212 bk2 and kxk1, which serves as an approximation\nof the optimal trade-off curve between kax \u2212 bk2 and the sparsity or cardinality\ncard(x) of the vector x, i.e., the number of nonzero elements. the problem (6.11)\ncan be recast and solved as an socp.\n\nexample 6.4 regressor selection problem. we are given a matrix a \u2208 rm\u00d7n,\nwhose columns are potential regressors, and a vector b \u2208 rm that is to be fit by a\nlinear combination of k < n columns of a. the problem is to choose the subset of k\nregressors to be used, and the associated coefficients. we can express this problem\nas\n\nin general, this is a hard combinatorial problem.\n\nminimize\nsubject to\n\nkax \u2212 bk2\ncard(x) \u2264 k.\n\none straightforward approach is to check every possible sparsity pattern in x with k\nnonzero entries. for a fixed sparsity pattern, we can find the optimal x by solving\na least-squares problem, i.e., minimizing k \u02dca\u02dcx \u2212 bk2, where \u02dca denotes the submatrix\nof a obtained by keeping the columns corresponding to the sparsity pattern, and\n\u02dcx is the subvector with the nonzero components of x. this is done for each of the\nn!/(k!(n \u2212 k)!) sparsity patterns with k nonzeros.\na good heuristic approach is to solve the problem (6.11) for different values of \u03b3,\nfinding the smallest value of \u03b3 that results in a solution with card(x) = k. we then\nfix this sparsity pattern and find the value of x that minimizes kax \u2212 bk2.\nfigure 6.7 illustrates a numerical example with a \u2208 r10\u00d720, x \u2208 r20, b \u2208 r10. the\ncircles on the dashed curve are the (globally) pareto optimal values for the trade-off\nbetween card(x) (vertical axis) and the residual kax \u2212 bk2 (horizontal axis). for\neach k, the pareto optimal point was obtained by enumerating all possible sparsity\npatterns with k nonzero entries, as described above. the circles on the solid curve\nwere obtained with the heuristic approach, by using the sparsity patterns of the\nsolutions of problem (6.11) for different values of \u03b3. note that for card(x) = 1, the\nheuristic method actually finds the global optimum.\nthis idea will come up again in basis pursuit (\u00a76.5.4).\n\n6.3.3 reconstruction, smoothing, and de-noising\n\nin this section we describe an important special case of the bi-criterion approxi-\nmation problem described above, and give some examples showing how different\nregularization methods perform. in reconstruction problems, we start with a signal\nrepresented by a vector x \u2208 rn. the coefficients xi correspond to the value of\nsome function of time, evaluated (or sampled, in the language of signal processing)\nat evenly spaced points. it is usually assumed that the signal does not vary too\nrapidly, which means that usually, we have xi \u2248 xi+1. (in this section we consider\nsignals in one dimension, e.g., audio signals, but the same ideas can be applied to\nsignals in two or more dimensions, e.g., images or video.)\n\n "}, {"Page_number": 325, "text": "6.3 regularized approximation\n\n311\n\n)\nx\n(\nd\nr\na\nc\n\n10\n\n8\n\n6\n\n4\n\n2\n\n0\n0\n\n1\n\n2\nkax \u2212 bk2\n\n3\n\n4\n\nfigure 6.7 sparse regressor selection with a matrix a \u2208 r10\u00d720. the circles\non the dashed line are the pareto optimal values for the trade-off between\nthe residual kax \u2212 bk2 and the number of nonzero elements card(x). the\npoints indicated by circles on the solid line are obtained via the \u21131-norm\nregularized heuristic.\n\nthe signal x is corrupted by an additive noise v:\n\nxcor = x + v.\n\nthe noise can be modeled in many different ways, but here we simply assume that\nit is unknown, small, and, unlike the signal, rapidly varying. the goal is to form an\nestimate \u02c6x of the original signal x, given the corrupted signal xcor. this process is\ncalled signal reconstruction (since we are trying to reconstruct the original signal\nfrom the corrupted version) or de-noising (since we are trying to remove the noise\nfrom the corrupted signal). most reconstruction methods end up performing some\nsort of smoothing operation on xcor to produce \u02c6x, so the process is also called\nsmoothing.\n\none simple formulation of the reconstruction problem is the bi-criterion problem\n\nminimize (w.r.t. r2\n\n+)\n\n(k\u02c6x \u2212 xcork2, \u03c6(\u02c6x)) ,\n\n(6.12)\n\nwhere \u02c6x is the variable and xcor is a problem parameter. the function \u03c6 : rn \u2192 r\nit is\nis convex, and is called the regularization function or smoothing objective.\nmeant to measure the roughness, or lack of smoothness, of the estimate \u02c6x. the\nreconstruction problem (6.12) seeks signals that are close (in \u21132-norm) to the cor-\nrupted signal, and that are smooth, i.e., for which \u03c6(\u02c6x) is small. the reconstruction\nproblem (6.12) is a convex bi-criterion problem. we can find the pareto optimal\npoints by scalarization, and solving a (scalar) convex optimization problem.\n\n "}, {"Page_number": 326, "text": "312\n\n6 approximation and fitting\n\nquadratic smoothing\n\nthe simplest reconstruction method uses the quadratic smoothing function\n\n\u03c6quad(x) =\n\nn\u22121xi=1\n\n(xi+1 \u2212 xi)2 = kdxk2\n2,\n\nwhere d \u2208 r(n\u22121)\u00d7n is the bidiagonal matrix\n0 \u00b7\u00b7\u00b7\n0\n1 \u00b7\u00b7\u00b7\n0\n...\n...\n0 \u00b7\u00b7\u00b7 \u22121\n0 \u00b7\u00b7\u00b7\n\n\u22121\n1\n0 \u22121\n...\n...\n0\n0\n0\n0\n\nd =\n\n0\n0\n...\n1\n0 \u22121\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n0\n0\n...\n0\n1\n\n.\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\nwe can obtain the optimal trade-off between k\u02c6x\u2212 xcork2 and kd\u02c6xk2 by minimizing\n\nk\u02c6x \u2212 xcork2\n\n2 + \u03b4kd\u02c6xk2\n2,\n\nwhere \u03b4 > 0 parametrizes the optimal trade-off curve. the solution of this quadratic\nproblem,\n\n\u02c6x = (i + \u03b4dt d)\u22121xcor,\n\ncan be computed very efficiently since i + \u03b4dt d is tridiagonal; see appendix c.\n\nquadratic smoothing example\nfigure 6.8 shows a signal x \u2208 r4000 (top) and the corrupted signal xcor (bottom).\nthe optimal trade-off curve between the objectives k\u02c6x\u2212xcork2 and kd\u02c6xk2 is shown\nin figure 6.9. the extreme point on the left of the trade-off curve corresponds to\n\u02c6x = xcor, and has objective value kdxcork2 = 4.4. the extreme point on the right\ncorresponds to \u02c6x = 0, for which k\u02c6x \u2212 xcork2 = kxcork2 = 16.2. note the clear knee\nin the trade-off curve near k\u02c6x \u2212 xcork2 \u2248 3.\nfigure 6.10 shows three smoothed signals on the optimal trade-off curve, cor-\nresponding to k\u02c6x \u2212 xcork2 = 8 (top), 3 (middle), and 1 (bottom). comparing the\nreconstructed signals with the original signal x, we see that the best reconstruction\nis obtained for k\u02c6x \u2212 xcork2 = 3, which corresponds to the knee of the trade-off\ncurve. for higher values of k\u02c6x \u2212 xcork2, there is too much smoothing; for smaller\nvalues there is too little smoothing.\n\ntotal variation reconstruction\n\nsimple quadratic smoothing works well as a reconstruction method when the orig-\ninal signal is very smooth, and the noise is rapidly varying. but any rapid varia-\ntions in the original signal will, obviously, be attenuated or removed by quadratic\nsmoothing. in this section we describe a reconstruction method that can remove\nmuch of the noise, while still preserving occasional rapid variations in the original\nsignal. the method is based on the smoothing function\n\n\u03c6tv(\u02c6x) =\n\nn\u22121xi=1\n\n|\u02c6xi+1 \u2212 \u02c6xi| = kd\u02c6xk1,\n\n "}, {"Page_number": 327, "text": "6.3 regularized approximation\n\n313\n\n0.5\n\nx\n\n0\n\n\u22120.5\n0\n\n0.5\n\nr\no\nc\nx\n\n0\n\n\u22120.5\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n1000\n\n2000\n\ni\n\n3000\n\n4000\n\nfigure 6.8 top: the original signal x \u2208 r4000. bottom: the corrupted signal\nxcor.\n\n4\n\n3\n\n2\n\nk\n\u02c6x\nd\nk\n\n2\n\n1\n\n0\n0\n\n5\n\n10\n\n15\n\n20\n\nk\u02c6x \u2212 xcork2\nfigure 6.9 optimal trade-off curve between kd\u02c6xk2 and k\u02c6x \u2212 xcork2. the\ncurve has a clear knee near k\u02c6x \u2212 xcork \u2248 3.\n\n "}, {"Page_number": 328, "text": "314\n\n6 approximation and fitting\n\n0.5\n\n\u02c6x\n\n0\n\n\u22120.5\n0\n\n0.5\n\n\u02c6x\n\n0\n\n\u22120.5\n0\n\n0.5\n\n\u02c6x\n\n0\n\n\u22120.5\n0\n\n1000\n\n2000\n\n3000\n\n4000\n\n1000\n\n2000\n\n3000\n\n4000\n\n1000\n\n2000\n\ni\n\n3000\n\n4000\n\nfigure 6.10 three smoothed or reconstructed signals \u02c6x. the top one cor-\nresponds to k\u02c6x \u2212 xcork2 = 8, the middle one to k\u02c6x \u2212 xcork2 = 3, and the\nbottom one to k\u02c6x \u2212 xcork2 = 1.\n\nwhich is called the total variation of x \u2208 rn. like the quadratic smoothness\nmeasure \u03c6quad, the total variation function assigns large values to rapidly varying\n\u02c6x. the total variation measure, however, assigns relatively less penalty to large\nvalues of |xi+1 \u2212 xi|.\n\ntotal variation reconstruction example\n\nfigure 6.11 shows a signal x \u2208 r2000 (in the top plot), and the signal corrupted\nwith noise xcor. the signal is mostly smooth, but has several rapid variations or\njumps in value; the noise is rapidly varying.\n\nwe first use quadratic smoothing. figure 6.12 shows three smoothed signals on\nthe optimal trade-off curve between kd\u02c6xk2 and k\u02c6x\u2212xcork2. in the first two signals,\nthe rapid variations in the original signal are also smoothed. in the third signal\nthe steep edges in the signal are better preserved, but there is still a significant\namount of noise left.\n\nnow we demonstrate total variation reconstruction. figure 6.13 shows the\noptimal trade-off curve between kd\u02c6xk1 and k\u02c6x\u2212 xcorrk2. figure 6.14 shows the re-\nconstructed signals on the optimal trade-off curve, for kd\u02c6xk1 = 5 (top), kd\u02c6xk1 = 8\n(middle), and kd\u02c6xk1 = 10 (bottom). we observe that, unlike quadratic smoothing,\ntotal variation reconstruction preserves the sharp transitions in the signal.\n\n "}, {"Page_number": 329, "text": "6.3 regularized approximation\n\n315\n\n2\n\n1\n\n0\n\nx\n\n\u22121\n\u22122\n0\n\n2\n\n1\n\n0\n\nr\no\nc\nx\n\n\u22121\n\u22122\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n500\n\n1000\n\ni\n\n1500\n\n2000\n\nfigure 6.11 a signal x \u2208 r2000, and the corrupted signal xcor \u2208 r2000. the\nnoise is rapidly varying, and the signal is mostly smooth, with a few rapid\nvariations.\n\n "}, {"Page_number": 330, "text": "316\n\n6 approximation and fitting\n\n2\n\n0\n\n\u02c6x\n\n\u22122\n0\n2\n\n\u02c6x\n\n0\n\n\u22122\n0\n2\n\n\u02c6x\n\n0\n\n\u22122\n0\n\n500\n\n1000\n\n1500\n\n2000\n\n500\n\n1000\n\n1500\n\n2000\n\n500\n\n1000\n\ni\n\n1500\n\n2000\n\nfigure 6.12 three quadratically smoothed signals \u02c6x. the top one corre-\nsponds to k\u02c6x \u2212 xcork2 = 10, the middle one to k\u02c6x \u2212 xcork2 = 7, and the\nbottom one to k\u02c6x \u2212 xcork2 = 4. the top one greatly reduces the noise, but\nalso excessively smooths out the rapid variations in the signal. the bottom\nsmoothed signal does not give enough noise reduction, and still smooths out\nthe rapid variations in the original signal. the middle smoothed signal gives\nthe best compromise, but still smooths out the rapid variations.\n\n250\n\n200\n\n150\n\n1\n\nk\n\u02c6x\nd\nk\n\n100\n\n50\n\n0\n0\n\n10\n\nfigure 6.13 optimal trade-off curve between kd\u02c6xk1 and k\u02c6x \u2212 xcork2.\n\n30\n20\nk\u02c6x \u2212 xcork2\n\n40\n\n50\n\n "}, {"Page_number": 331, "text": "6.3 regularized approximation\n\n317\n\n2\n\n0\n\n\u02c6x\n\n\u22122\n0\n2\n\n\u02c6x\n\n0\n\n\u22122\n0\n2\n\n\u02c6x\n\n0\n\n\u22122\n0\n\n500\n\n1000\n\ni\n\n1500\n\n2000\n\n500\n\n1000\n\n1500\n\n2000\n\n500\n\n1000\n\n1500\n\n2000\n\nfigure 6.14 three reconstructed signals \u02c6x, using total variation reconstruc-\ntion. the top one corresponds to kd\u02c6xk1 = 5, the middle one to kd\u02c6xk1 = 8,\nand the bottom one to kd\u02c6xk1 = 10. the bottom one does not give quite\nenough noise reduction, while the top one eliminates some of the slowly vary-\ning parts of the signal. note that in total variation reconstruction, unlike\nquadratic smoothing, the sharp changes in the signal are preserved.\n\n "}, {"Page_number": 332, "text": "318\n\n6 approximation and fitting\n\n6.4 robust approximation\n\n6.4.1 stochastic robust approximation\n\nwe consider an approximation problem with basic objective kax\u2212bk, but also wish\nto take into account some uncertainty or possible variation in the data matrix a.\n(the same ideas can be extended to handle the case where there is uncertainty in\nboth a and b.) in this section we consider some statistical models for the variation\nin a.\n\nwe assume that a is a random variable taking values in rm\u00d7n, with mean \u00afa,\n\nso we can describe a as\n\na = \u00afa + u,\n\nwhere u is a random matrix with zero mean. here, the constant matrix \u00afa gives\nthe average value of a, and u describes its statistical variation.\n\nit is natural to use the expected value of kax \u2212 bk as the objective:\n\nminimize ekax \u2212 bk.\n\n(6.13)\n\nwe refer to this problem as the stochastic robust approximation problem.\nit is\nalways a convex optimization problem, but usually not tractable since in most\ncases it is very difficult to evaluate the objective or its derivatives.\n\none simple case in which the stochastic robust approximation problem (6.13)\n\ncan be solved occurs when a assumes only a finite number of values, i.e.,\n\nprob(a = ai) = pi,\n\ni = 1, . . . , k,\n\nwhere ai \u2208 rm\u00d7n, 1t p = 1, p (cid:23) 0. in this case the problem (6.13) has the form\n\nminimize p1ka1x \u2212 bk + \u00b7\u00b7\u00b7 + pkkakx \u2212 bk,\n\nwhich is often called a sum-of-norms problem. it can be expressed as\n\nminimize\nsubject to\n\npt t\nkaix \u2212 bk \u2264 ti,\n\ni = 1, . . . , k,\n\nwhere the variables are x \u2208 rn and t \u2208 rk. if the norm is the euclidean norm,\nthis sum-of-norms problem is an socp. if the norm is the \u21131- or \u2113\u221e-norm, the\nsum-of-norms problem can be expressed as an lp; see exercise 6.8.\n\nsome variations on the statistical robust approximation problem (6.13) are\n\ntractable. as an example, consider the statistical robust least-squares problem\n\nwhere the norm is the euclidean norm. we can express the objective as\n\nminimize ekax \u2212 bk2\n2,\n\nekax \u2212 bk2\n\n2 = e( \u00afax \u2212 b + u x)t ( \u00afax \u2212 b + u x)\n= ( \u00afax \u2212 b)t ( \u00afax \u2212 b) + e xt u t u x\n= k \u00afax \u2212 bk2\n\n2 + xt p x,\n\n "}, {"Page_number": 333, "text": "6.4 robust approximation\n\n319\n\nwhere p = e u t u . therefore the statistical robust approximation problem has\nthe form of a regularized least-squares problem\nk \u00afax \u2212 bk2\n\n2 + kp 1/2xk2\n2,\n\nminimize\n\nwith solution\n\nx = ( \u00afat \u00afa + p )\u22121 \u00afat b.\n\nthis makes perfect sense: when the matrix a is subject to variation, the vector\nax will have more variation the larger x is, and jensen\u2019s inequality tells us that\nvariation in ax will increase the average value of kax\u2212 bk2. so we need to balance\nmaking \u00afax \u2212 b small with the desire for a small x (to keep the variation in ax\nsmall), which is the essential idea of regularization.\nthis observation gives us another interpretation of the tikhonov regularized\nleast-squares problem (6.10), as a robust least-squares problem, taking into account\npossible variation in the matrix a. the solution of the tikhonov regularized least-\nsquares problem (6.10) minimizes ek(a + u )x \u2212 bk2, where uij are zero mean,\nuncorrelated random variables, with variance \u03b4/m (and here, a is deterministic).\n\n6.4.2 worst-case robust approximation\n\nit is also possible to model the variation in the matrix a using a set-based, worst-\ncase approach. we describe the uncertainty by a set of possible values for a:\n\na \u2208 a \u2286 rm\u00d7n,\n\nwhich we assume is nonempty and bounded. we define the associated worst-case\nerror of a candidate approximate solution x \u2208 rn as\n\newc(x) = sup{kax \u2212 bk | a \u2208 a},\n\nwhich is always a convex function of x. the (worst-case) robust approximation\nproblem is to minimize the worst-case error:\n\nminimize\n\newc(x) = sup{kax \u2212 bk | a \u2208 a},\n\n(6.14)\n\nwhere the variable is x, and the problem data are b and the set a. when a is the\nsingleton a = {a}, the robust approximation problem (6.14) reduces to the basic\nnorm approximation problem (6.1). the robust approximation problem is always\na convex optimization problem, but its tractability depends on the norm used and\nthe description of the uncertainty set a.\n\nexample 6.5 comparison of stochastic and worst-case robust approximation. to\nillustrate the difference between the stochastic and worst-case formulations of the\nrobust approximation problem, we consider the least-squares problem\n\nminimize\n\nka(u)x \u2212 bk2\n2,\n\nwhere u \u2208 r is an uncertain parameter and a(u) = a0 + ua1. we consider a\nspecific instance of the problem, with a(u) \u2208 r20\u00d710, ka0k = 10, ka1k = 1, and u\n\n "}, {"Page_number": 334, "text": "320\n\n6 approximation and fitting\n\n12\n\n10\n\n8\n\n6\n\n4\n\n2\n\n)\nu\n(\nr\n\nxnom\n\nxstoch\n\nxwc\n\n0\n\u22122\n\n\u22121\n\n0\nu\n\n1\n\n2\n\nfigure 6.15 the residual r(u) = ka(u)x \u2212 bk2 as a function of the un-\ncertain parameter u for three approximate solutions x: (1) the nominal\nleast-squares solution xnom; (2) the solution of the stochastic robust approx-\nimation problem xstoch (assuming u is uniformly distributed on [\u22121, 1]); and\n(3) the solution of the worst-case robust approximation problem xwc, as-\nsuming the parameter u lies in the interval [\u22121, 1]. the nominal solution\nachieves the smallest residual when u = 0, but gives much larger residuals\nas u approaches \u22121 or 1. the worst-case solution has a larger residual when\nu = 0, but its residuals do not rise much as the parameter u varies over the\ninterval [\u22121, 1].\n\nin the interval [\u22121, 1]. (so, roughly speaking, the variation in the matrix a is around\n\u00b110%.)\nwe find three approximate solutions:\n\n\u2022 nominal optimal. the optimal solution xnom is found, assuming a(u) has its\n\nnominal value a0.\n\nbk2\n\n\u2022 stochastic robust approximation. we find xstoch, which minimizes eka(u)x \u2212\n\n2, assuming the parameter u is uniformly distributed on [\u22121, 1].\n\u2022 worst-case robust approximation. we find xwc, which minimizes\n\n\u22121\u2264u\u22641ka(u)x \u2212 bk2 = max{k(a0 \u2212 a1)x \u2212 bk2,k(a0 + a1)x \u2212 bk2}.\nsup\n\nfor each of these three values of x, we plot the residual r(u) = ka(u)x \u2212 bk2 as a\nfunction of the uncertain parameter u, in figure 6.15. these plots show how sensitive\nan approximate solution can be to variation in the parameter u. the nominal solu-\ntion achieves the smallest residual when u = 0, but is quite sensitive to parameter\nvariation: it gives much larger residuals as u deviates from 0, and approaches \u22121 or\n1. the worst-case solution has a larger residual when u = 0, but its residuals do not\nrise much as u varies over the interval [\u22121, 1]. the stochastic robust approximate\nsolution is in between.\n\n "}, {"Page_number": 335, "text": "6.4 robust approximation\n\n321\n\nthe robust approximation problem (6.14) arises in many contexts and applica-\ntions. in an estimation setting, the set a gives our uncertainty in the linear relation\nbetween the vector to be estimated and our measurement vector. sometimes the\nnoise term v in the model y = ax + v is called additive noise or additive error,\nsince it is added to the \u2018ideal\u2019 measurement ax. in contrast, the variation in a is\ncalled multiplicative error, since it multiplies the variable x.\n\nin an optimal design setting, the variation can represent uncertainty (arising in\nmanufacture, say) of the linear equations that relate the design variables x to the\nresults vector ax. the robust approximation problem (6.14) is then interpreted as\nthe robust design problem: find design variables x that minimize the worst possible\nmismatch between ax and b, over all possible values of a.\n\nfinite set\nhere we have a = {a1, . . . , ak}, and the robust approximation problem is\n\nminimize maxi=1,...,k kaix \u2212 bk.\n\nthis problem is equivalent to the robust approximation problem with the polyhe-\ndral set a = conv{a1, . . . , ak}:\n\nminimize\n\nsup{kax \u2212 bk | a \u2208 conv{a1, . . . , ak}} .\n\nwe can cast the problem in epigraph form as\n\nminimize\nsubject to\n\nt\nkaix \u2212 bk \u2264 t,\n\ni = 1, . . . , k,\n\nwhich can be solved in a variety of ways, depending on the norm used. if the norm\nis the euclidean norm, this is an socp. if the norm is the \u21131- or \u2113\u221e-norm, we can\nexpress it as an lp.\n\nnorm bound error\nhere the uncertainty set a is a norm ball, a = { \u00afa + u | kuk \u2264 a}, where k \u00b7 k is a\nnorm on rm\u00d7n. in this case we have\n\newc(x) = sup{k \u00afax \u2212 b + u xk | kuk \u2264 a},\n\nwhich must be carefully interpreted since the first norm appearing is on rm (and\nis used to measure the size of the residual) and the second one appearing is on\nrm\u00d7n (used to define the norm ball a).\nthis expression for ewc(x) can be simplified in several cases. as an example,\nlet us take the euclidean norm on rn and the associated induced norm on rm\u00d7n,\ni.e., the maximum singular value. if \u00afax \u2212 b 6= 0 and x 6= 0, the supremum in the\nexpression for ewc(x) is attained for u = auvt , with\n\nu =\n\n\u00afax \u2212 b\nk \u00afax \u2212 bk2\n\n,\n\nv =\n\n,\n\nx\nkxk2\n\nand the resulting worst-case error is\n\newc(x) = k \u00afax \u2212 bk2 + akxk2.\n\n "}, {"Page_number": 336, "text": "322\n\n6 approximation and fitting\n\n(it is easily verified that this expression is also valid if x or \u00afax \u2212 b is zero.) the\nrobust approximation problem (6.14) then becomes\n\nwhich is a regularized norm problem, solvable as the socp\n\nminimize\n\nk \u00afax \u2212 bk2 + akxk2,\n\nminimize\nsubject to\n\nt1 + at2\nk \u00afax \u2212 bk2 \u2264 t1,\n\nkxk2 \u2264 t2.\n\nsince the solution of this problem is the same as the solution of the regularized\n\nleast-squares problem\n\nminimize\n\nk \u00afax \u2212 bk2\n\n2 + \u03b4kxk2\n\n2\n\nfor some value of the regularization parameter \u03b4, we have another interpretation of\nthe regularized least-squares problem as a worst-case robust approximation prob-\nlem.\n\nuncertainty ellipsoids\n\nwe can also describe the variation in a by giving an ellipsoid of possible values for\neach row:\n\na = {[a1 \u00b7\u00b7\u00b7 am]t | ai \u2208 ei, i = 1, . . . , m},\n\nwhere\n\nei = {\u00afai + piu | kuk2 \u2264 1}.\n\nthe matrix pi \u2208 rn\u00d7n describes the variation in ai. we allow pi to have a nontriv-\nial nullspace, in order to model the situation when the variation in ai is restricted\nto a subspace. as an extreme case, we take pi = 0 if there is no uncertainty in ai.\nwith this ellipsoidal uncertainty description, we can give an explicit expression\n\nfor the worst-case magnitude of each residual:\n\nai\u2208ei |at\nsup\n\ni x \u2212 bi| = sup{|\u00afat\n\ni x \u2212 bi + (piu)t x| | kuk2 \u2264 1}\n\n= |\u00afat\n\ni x \u2212 bi| + kp t\n\ni xk2.\n\nusing this result we can solve several robust approximation problems. for\n\nexample, the robust \u21132-norm approximation problem\n\nminimize\n\newc(x) = sup{kax \u2212 bk2 | ai \u2208 ei, i = 1, . . . , m}\n\ncan be reduced to an socp, as follows. an explicit expression for the worst-case\nerror is given by\n\newc(x) =  mxi=1(cid:18) sup\n\nai\u2208ei |at\n\ni x \u2212 bi|(cid:19)2!1/2\n\n=  mxi=1\n\n(|\u00afat\n\ni x \u2212 bi| + kp t\n\ni xk2)2!1/2\n\n.\n\nto minimize ewc(x) we can solve\n\nminimize\nsubject to\n\nktk2\n|\u00afat\ni x \u2212 bi| + kp t\n\ni xk2 \u2264 ti,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 337, "text": "6.4 robust approximation\n\n323\n\nwhere we introduced new variables t1, . . . , tm. this problem can be formulated as\n\nminimize\nsubject to\n\ni xk2 \u2264 ti,\ni xk2 \u2264 ti,\nwhich becomes an socp when put in epigraph form.\n\nktk2\ni x \u2212 bi + kp t\n\u00afat\n\u2212\u00afat\ni x + bi + kp t\n\ni = 1, . . . , m\n\ni = 1, . . . , m,\n\nnorm bounded error with linear structure\nas a generalization of the norm bound description a = { \u00afa + u | kuk \u2264 a}, we can\ndefine a as the image of a norm ball under an affine transformation:\n\na = { \u00afa + u1a1 + u2a2 + \u00b7\u00b7\u00b7 + upap | kuk \u2264 1},\n\nwhere k \u00b7 k is a norm on rp, and the p + 1 matrices \u00afa, a1, . . . , ap \u2208 rm\u00d7n are\ngiven. the worst-case error can be expressed as\n\newc(x) = sup\n\nkuk\u22641k( \u00afa + u1a1 + \u00b7\u00b7\u00b7 + upap)x \u2212 bk\nkuk\u22641kp (x)u + q(x)k,\n\n= sup\n\nwhere p and q are defined as\n\np (x) =(cid:2) a1x a2x \u00b7\u00b7\u00b7 apx (cid:3) \u2208 rm\u00d7p,\n\nq(x) = \u00afax \u2212 b \u2208 rm.\n\nas a first example, we consider the robust chebyshev approximation problem\n\nminimize\n\newc(x) = supkuk\u221e\u22641 k( \u00afa + u1a1 + \u00b7\u00b7\u00b7 + upap)x \u2212 bk\u221e.\n\nin this case we can derive an explicit expression for the worst-case error. let pi(x)t\ndenote the ith row of p (x). we have\n\newc(x) =\n\nkuk\u221e\u22641kp (x)u + q(x)k\u221e\nsup\n\n= max\n\ni=1,...,m\n\n= max\n\ni=1,...,m\n\nkuk\u221e\u22641|pi(x)t u + qi(x)|\nsup\n(kpi(x)k1 + |qi(x)|).\n\nthe robust chebyshev approximation problem can therefore be cast as an lp\n\nt\n\nminimize\nsubject to \u2212y0 (cid:22) \u00afax \u2212 b (cid:22) y0\n\u2212yk (cid:22) akx (cid:22) yk,\nk=1 yk (cid:22) t1,\n\ny0 +pp\nwith variables x \u2208 rn, yk \u2208 rm, t \u2208 r.\n\nk = 1, . . . , p\n\nas another example, we consider the robust least-squares problem\n\nminimize\n\newc(x) = supkuk2\u22641 k( \u00afa + u1a1 + \u00b7\u00b7\u00b7 + upap)x \u2212 bk2.\n\n "}, {"Page_number": 338, "text": "324\n\n6 approximation and fitting\n\nhere we use lagrange duality to evaluate ewc. the worst-case error ewc(x) is the\nsquareroot of the optimal value of the (nonconvex) quadratic optimization problem\n\nmaximize\nsubject to ut u \u2264 1,\n\nkp (x)u + q(x)k2\n\n2\n\nwith u as variable. the lagrange dual of this problem can be expressed as the\nsdp\n\nt + \u03bb\n\nminimize\n\nsubject to \uf8ee\uf8f0\n\ni\n\np (x)\n\np (x)t\nq(x)t\n\n\u03bbi\n0\n\nq(x)\n\n0\n\nt \uf8f9\uf8fb (cid:23) 0\n\n(6.15)\n\nwith variables t, \u03bb \u2208 r. moreover, as mentioned in \u00a75.2 and \u00a7b.1 (and proved\nin \u00a7b.4), strong duality holds for this pair of primal and dual problems. in other\nwords, for fixed x, we can compute ewc(x)2 by solving the sdp (6.15) with variables\nt and \u03bb. optimizing jointly over t, \u03bb, and x is equivalent to minimizing ewc(x)2.\nwe conclude that the robust least-squares problem is equivalent to the sdp (6.15)\nwith x, \u03bb, t as variables.\n\nexample 6.6 comparison of worst-case robust, tikhonov regularized, and nominal\nleast-squares solutions. we consider an instance of the robust approximation problem\n\nminimize\n\nsupkuk2\u22641 k( \u00afa + u1a1 + u2a2)x \u2212 bk2,\n\n(6.16)\nwith dimensions m = 50, n = 20. the matrix \u00afa has norm 10, and the two matrices\na1 and a2 have norm 1, so the variation in the matrix a is, roughly speaking, around\n10%. the uncertainty parameters u1 and u2 lie in the unit disk in r2.\nwe compute the optimal solution of the robust least-squares problem (6.16) xrls, as\nwell as the solution of the nominal least-squares problem xls (i.e., assuming u = 0),\nand also the tikhonov regularized solution xtik, with \u03b4 = 1.\n\nto illustrate the sensitivity of each of these approximate solutions to the parameter\nu, we generate 105 parameter vectors, uniformly distributed on the unit disk, and\nevaluate the residual\n\nfor each parameter value. the distributions of the residuals are shown in figure 6.16.\n\nk(a0 + u1a1 + u2a2)x \u2212 bk2\n\nwe can make several observations. first, the residuals of the nominal least-squares\nsolution are widely spread, from a smallest value around 0.52 to a largest value\naround 4.9. in particular, the least-squares solution is very sensitive to parameter\nvariation. in contrast, both the robust least-squares and tikhonov regularized so-\nlutions exhibit far smaller variation in residual as the uncertainty parameter varies\nover the unit disk. the robust least-squares solution, for example, achieves a residual\nbetween 2.0 and 2.6 for all parameters in the unit disk.\n\n6.5 function fitting and interpolation\n\nin function fitting problems, we select a member of a finite-dimensional subspace\nof functions that best fits some given data or requirements. for simplicity we\n\n "}, {"Page_number": 339, "text": "6.5 function fitting and interpolation\n\n325\n\ny\nc\nn\ne\nu\nq\ne\nr\nf\n\n0.25\n\n0.2\n\n0.15\n\n0.1\n\n0.05\n\n0\n0\n\nxrls\n\nxtik\n\nxls\n\n1\n\n2\n\n3\n\n4\n\n5\n\nk(a0 + u1a1 + u2a2)x \u2212 bk2\n\nfigure 6.16 distribution of the residuals for the three solutions of a least-\nsquares problem (6.16): xls, the least-squares solution assuming u = 0; xtik,\nthe tikhonov regularized solution with \u03b4 = 1; and xrls, the robust least-\nsquares solution. the histograms were obtained by generating 105 values of\nthe uncertain parameter vector u from a uniform distribution on the unit\ndisk in r2. the bins have width 0.1.\n\n "}, {"Page_number": 340, "text": "326\n\n6 approximation and fitting\n\nconsider real-valued functions; the ideas are readily extended to handle vector-\nvalued functions as well.\n\n6.5.1 function families\n\nf (u) = x1f1(u) + \u00b7\u00b7\u00b7 + xnfn(u)\n\nwe consider a family of functions f1, . . . , fn : rk \u2192 r, with common domain\ndom fi = d. with each x \u2208 rn we associate the function f : rk \u2192 r given by\n(6.17)\nwith dom f = d. the family {f1, . . . , fn} is sometimes called the set of basis\nfunctions (for the fitting problem) even when the functions are not independent.\nthe vector x \u2208 rn, which parametrizes the subspace of functions, is our optimiza-\ntion variable, and is sometimes called the coefficient vector. the basis functions\ngenerate a subspace f of functions on d.\nin many applications the basis functions are specially chosen, using prior knowl-\nedge or experience, in order to reasonably model functions of interest with the\nfinite-dimensional subspace of functions.\nin other cases, more generic function\nfamilies are used. we describe a few of these below.\n\npolynomials\n\none common subspace of functions on r consists of polynomials of degree less\nthan n. the simplest basis consists of the powers, i.e., fi(t) = ti\u22121, i = 1, . . . , n.\nin many applications, the same subspace is described using a different basis, for\nexample, a set of polynomials f1, . . . , fn, of degree less than n, that are orthonormal\nwith respect to some positive function (or measure) \u03c6 : rn \u2192 r+, i.e.,\n\nz fi(t)fj(t)\u03c6(t) dt =(cid:26) 1\n\n0\n\ni = j\ni 6= j.\n\nanother common basis for polynomials is the lagrange basis f1, . . . , fn associated\nwith distinct points t1, . . . , tn, which satisfy\n\nfi(tj) =(cid:26) 1\n\n0\n\ni = j\ni 6= j.\n\nwe can also consider polynomials on rk, with a maximum total degree, or a\nmaximum degree for each variable.\n\nas a related example, we have trigonometric polynomials of degree less than n,\n\nwith basis\n\nsin kt,\n\nk = 1, . . . , n \u2212 1,\n\ncos kt,\n\nk = 0, . . . , n \u2212 1.\n\npiecewise-linear functions\n\nwe start with a triangularization of the domain d, which means the following. we\nhave a set of mesh or grid points g1, . . . , gn \u2208 rk, and a partition of d into a set\nof simplexes:\n\nd = s1 \u222a \u00b7\u00b7\u00b7 \u222a sm,\n\nint(si \u2229 sj) = \u2205 for i 6= j.\n\n "}, {"Page_number": 341, "text": "6.5 function fitting and interpolation\n\n327\n\n)\n2\nu\n\n,\n1\nu\n(\nf\n\n1\n\n0\n0\n\n0\n\nu1\n\n1\n\n1\n\nu2\n\nfigure 6.17 a piecewise-linear function of two variables, on the unit square.\nthe triangulation consists of 98 simplexes, and a uniform grid of 64 points\nin the unit square.\n\neach simplex is the convex hull of k + 1 grid points, and we require that each grid\npoint is a vertex of any simplex it lies in.\n\ngiven a triangularization, we can construct a piecewise-linear (or more precisely,\npiecewise-affine) function f by assigning function values f (gi) = xi to the grid\npoints, and then extending the function affinely on each simplex. the function f\ncan be expressed as (6.17) where the basis functions fi are affine on each simplex\nand are defined by the conditions\n\nfi(gj) =(cid:26) 1 i = j\n\n0 i 6= j.\n\nby construction, such a function is continuous.\n\nfigure 6.17 shows an example for k = 2.\n\npiecewise polynomials and splines\n\nthe idea of piecewise-affine functions on a triangulated domain is readily extended\nto piecewise polynomials and other functions.\n\npiecewise polynomials are defined as polynomials (of some maximum degree)\non each simplex of the triangulation, which are continuous, i.e., the polynomials\nagree at the boundaries between simplexes. by further restricting the piecewise\npolynomials to have continuous derivatives up to a certain order, we can define\nvarious classes of spline functions. figure 6.18 shows an example of a cubic spline,\ni.e., a piecewise polynomial of degree 3 on r, with continuous first and second\nderivatives.\n\n "}, {"Page_number": 342, "text": "328\n\n6 approximation and fitting\n\np2(u)\n\np3(u)\n\n)\nu\n(\nf\n\np1(u)\n\nu0\n\nu1\n\nu2\n\nu\n\nu3\n\nfigure 6.18 cubic spline. a cubic spline is a piecewise polynomial, with\ncontinuous first and second derivatives. in this example, the cubic spline f\nis formed from the three cubic polynomials p1 (on [u0, u1]), p2 (on [u1, u2]),\nand p3 (on [u2, u3]). adjacent polynomials have the same function value,\nand equal first and second derivatives, at the boundary points u1 and u2.\nin this example, the dimension of the family of functions is n = 6, since\nwe have 12 polynomial coefficients (4 per cubic polynomial), and 6 equality\nconstraints (3 each at u1 and u2).\n\n "}, {"Page_number": 343, "text": "6.5 function fitting and interpolation\n\n329\n\n6.5.2 constraints\n\nin this section we describe some constraints that can be imposed on the function\nf , and therefore, on the variable x \u2208 rn.\nfunction value interpolation and inequalities\n\nlet v be a point in d. the value of f at v,\n\nf (v) =\n\nnxi=1\n\nxifi(v),\n\nis a linear function of x. therefore interpolation conditions\n\nf (vj) = zj,\n\nj = 1, . . . , m,\n\nwhich require the function f to have the values zj \u2208 r at specified points vj \u2208 d,\nform a set of linear equalities in x. more generally, inequalities on the function\nvalue at a given point, as in l \u2264 f (v) \u2264 u, are linear inequalities on the variable x.\nthere are many other interesting convex constraints on f (hence, x) that involve\nthe function values at a finite set of points v1, . . . , vn . for example, the lipschitz\nconstraint\n\n|f (vj) \u2212 f (vk)| \u2264 lkvj \u2212 vkk,\n\nj, k = 1, . . . , m,\n\nforms a set of linear inequalities in x.\n\nwe can also impose inequalities on the function values at an infinite number of\n\npoints. as an example, consider the nonnegativity constraint\n\nf (u) \u2265 0 for all u \u2208 d.\n\nthis is a convex constraint on x (since it is the intersection of an infinite number\nof halfspaces), but may not lead to a tractable problem except in special cases\nthat exploit the particular structure of the functions. one simple example occurs\nwhen the functions are piecewise-linear.\nin this case, if the function values are\nnonnegative at the grid points, the function is nonnegative everywhere, so we obtain\na simple (finite) set of linear inequalities.\n\nas a less trivial example, consider the case when the functions are polynomials\non r, with even maximum degree 2k (i.e., n = 2k + 1), and d = r. as shown in\nexercise 2.37, page 65, the nonnegativity constraint\n\np(u) = x1 + x2u + \u00b7\u00b7\u00b7 + x2k+1u2k \u2265 0 for all u \u2208 r,\n\nis equivalent to\n\nxi = xm+n=i+1\n\nymn,\n\ni = 1, . . . , 2k + 1,\n\ny (cid:23) 0,\n\nwhere y \u2208 sk+1 is an auxiliary variable.\n\n "}, {"Page_number": 344, "text": "330\n\n6 approximation and fitting\n\nderivative constraints\nsuppose the basis functions fi are differentiable at a point v \u2208 d. the gradient\n\n\u2207f (v) =\n\nnxi=1\n\nxi\u2207fi(v),\n\nis a linear function of x, so interpolation conditions on the derivative of f at v\nreduce to linear equality constraints on x. requiring that the norm of the gradient\nat v not exceed a given limit,\n\nk\u2207f (v)k =(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\nnxi=1\n\nxi\u2207fi(v)(cid:13)(cid:13)(cid:13)(cid:13)(cid:13) \u2264 m,\n\nis a convex constraint on x. the same idea extends to higher derivatives. for\nexample, if f is twice differentiable at v, the requirement that\n\nli (cid:22) \u22072f (v) (cid:22) ui\nis a linear matrix inequality in x, hence convex.\n\nwe can also impose constraints on the derivatives at an infinite number of\n\npoints. for example, we can require that f is monotone:\n\nf (u) \u2265 f (v) for all u, v \u2208 d, u (cid:23) v.\n\nthis is a convex constraint in x, but may not lead to a tractable problem except in\nspecial cases. when f is piecewise affine, for example, the monotonicity constraint\nis equivalent to the condition \u2207f (v) (cid:23) 0 inside each of the simplexes. since the\ngradient is a linear function of the grid point values, this leads to a simple (finite)\nset of linear inequalities.\n\nas another example, we can require that the function be convex, i.e., satisfy\n\nf ((u + v)/2) \u2264 (f (u) + f (v))/2 for all u, v \u2208 d\n\n(which is enough to ensure convexity when f is continuous). this is a convex con-\nstraint, which has a tractable representation in some cases. one obvious example\nis when f is quadratic, in which case the convexity constraint reduces to the re-\nquirement that the quadratic part of f be nonnegative, which is an lmi. another\nexample in which a convexity constraint leads to a tractable problem is described\nin more detail in \u00a76.5.5.\nintegral constraints\nany linear functional l on the subspace of functions can be expressed as a linear\nfunction of x, i.e., we have l(f ) = ct x. evaluation of f (or a derivative) at a point\nis just a special case. as another example, the linear functional\n\nl(f ) =zd\n\n\u03c6(u)f (u) du,\n\n "}, {"Page_number": 345, "text": "6.5 function fitting and interpolation\n\n331\n\nwhere \u03c6 : rk \u2192 r, can be expressed as l(f ) = ct x, where\n\nci =zd\n\n\u03c6(u)fi(u) du.\n\nthus, a constraint of the form l(f ) = a is a linear equality constraint on x. one\nexample of such a constraint is the moment constraint\n\nzd\n\ntmf (t) dt = a\n\n(where f : r \u2192 r).\n\n6.5.3 fitting and interpolation problems\n\nminimum norm function fitting\n\nin a fitting problem, we are given data\n\n(u1, y1),\n\n. . . ,\n\n(um, ym)\n\nwith ui \u2208 d and yi \u2208 r, and seek a function f \u2208 f that matches this data as\nclosely as possible. for example in least-squares fitting we consider the problem\n\nminimize pm\n\ni=1(f (ui) \u2212 yi)2,\n\nwhich is a simple least-squares problem in the variable x. we can add a variety of\nconstraints, for example linear inequalities that must be satisfied by f at various\npoints, constraints on the derivatives of f , monotonicity constraints, or moment\nconstraints.\n\nexample 6.7 polynomial fitting. we are given data u1, . . . , um \u2208 r and v1, . . . , vm \u2208\nr, and hope to approximately fit a polynomial of the form\n\np(u) = x1 + x2u + \u00b7\u00b7\u00b7 + xnun\u22121\n\nto the data. for each x we form the vector of errors,\n\ne = (p(u1) \u2212 v1, . . . , p(um) \u2212 vm) .\n\nto find the polynomial that minimizes the norm of the error, we solve the norm\napproximation problem\n\nminimize\n\nkek = kax \u2212 vk\n, i = 1, . . . , m, j = 1, . . . , n.\n\nwith variable x \u2208 rn, where aij = uj\u22121\nfigure 6.19 shows an example with m = 40 data points and n = 6 (i.e., polynomials\nof maximum degree 5), for the \u21132- and \u2113\u221e-norms.\n\ni\n\n "}, {"Page_number": 346, "text": "332\n\n6 approximation and fitting\n\n0.2\n\n0.1\n\n)\nu\n(\np\n\n0\n\n\u22120.1\n\n\u22121\n\n\u22120.5\n\n0\nu\n\n0.5\n\n1\n\nfigure 6.19 two polynomials of degree 5 that approximate the 40 data\npoints shown as circles. the polynomial shown as a solid line minimizes the\n\u21132-norm of the error; the polynomial shown as a dashed line minimizes the\n\u2113\u221e-norm.\n\n0.2\n\n0.1\n\n)\nu\n(\nf\n\n0\n\n\u22120.1\n\n\u22121\n\n\u22120.5\n\n0\nu\n\n0.5\n\n1\n\nfigure 6.20 two cubic splines that approximate the 40 data points shown as\ncircles (which are the same as the data in figure 6.19). the spline shown as\na solid line minimizes the \u21132-norm of the error; the spline shown as a dashed\nline minimizes the \u2113\u221e-norm. as in the polynomial approximation shown in\nfigure 6.19, the dimension of the subspace of fitting functions is 6.\n\n "}, {"Page_number": 347, "text": "6.5 function fitting and interpolation\n\n333\n\nexample 6.8 spline fitting. figure 6.20 shows the same data as in example 6.7,\nand two optimal fits with cubic splines. the interval [\u22121, 1] is divided into three\nequal intervals, and we consider piecewise polynomials, with maximum degree 3, with\ncontinuous first and second derivatives. the dimension of this subspace of functions\nis 6, the same as the dimension of polynomials with maximum degree 5, considered\nin example 6.7.\n\nin the simplest forms of function fitting, we have m \u226b n, i.e., the number\nof data points is much larger than the dimension of the subspace of functions.\nsmoothing is accomplished automatically, since all members of the subspace are\nsmooth.\n\nleast-norm interpolation\n\nin another variation of function fitting, we have fewer data points than the dimen-\nsion of the subspace of functions. in the simplest case, we require that the function\nwe choose must satisfy the interpolation conditions\n\nf (ui) = yi,\n\ni = 1, . . . , m,\n\nwhich are linear equality constraints on x. among the functions that satisfy these\ninterpolation conditions, we might seek one that is smoothest, or smallest. these\nlead to least-norm problems.\n\nin the most general function fitting problem, we can optimize an objective\n(such as some measure of the error e), subject to a variety of convex constraints\nthat represent our prior knowledge of the underlying function.\n\ninterpolation, extrapolation, and bounding\nby evaluating the optimal function fit \u02c6f at a point v not in the original data set,\nwe obtain a guess of what the value of the underlying function is, at the point v.\nthis is called interpolation when v is between or near the given data points (e.g.,\nv \u2208 conv{v1, . . . , vm}), and extrapolation otherwise.\nwe can also produce an interval in which the value f (v) can lie, by maximizing\nand minimizing (the linear function) f (v), subject to the constraints. we can use\nthe function fit to help identify faulty data or outliers. here we might use, for\nexample, an \u21131-norm fit, and look for data points with large errors.\n\n6.5.4 sparse descriptions and basis pursuit\n\nin basis pursuit, there is a very large number of basis functions, and the goal is to\nfind a good fit of the given data as a linear combination of a small number of the\nbasis functions. (in this context the function family is linearly dependent, and is\nsometimes referred to as an over-complete basis or dictionary.) this is called basis\npursuit since we are selecting a much smaller basis, from the given over-complete\nbasis, to model the data.\n\n "}, {"Page_number": 348, "text": "334\n\n6 approximation and fitting\n\nthus we seek a function f \u2208 f that fits the data well,\n\nf (ui) \u2248 yi,\n\ni = 1, . . . , m,\n\nwith a sparse coefficient vector x, i.e., card(x) small. in this case we refer to\n\nf = x1f1 + \u00b7\u00b7\u00b7 + xnfn =xi\u2208b\n\nxifi,\n\nwhere b = {i | xi 6= 0} is the set of indices of the chosen basis elements, as a sparse\ndescription of the data. mathematically, basis pursuit is the same as the regressor\nselection problem (see \u00a76.4), but the interpretation (and scale) of the optimization\nproblem are different.\nsparse descriptions and basis pursuit have many uses. they can be used for\nde-noising or smoothing, or data compression for efficient transmission or storage\nof a signal. in data compression, the sender and receiver both know the dictionary,\nor basis elements. to send a signal to the receiver, the sender first finds a sparse\nrepresentation of the signal, and then sends to the receiver only the nonzero coef-\nficients (to some precision). using these coefficients, the receiver can reconstruct\n(an approximation of) the original signal.\n\none common approach to basis pursuit is the same as the method for regressor\nselection described in \u00a76.4, and based on \u21131-norm regularization as a heuristic for\nfinding sparse descriptions. we first solve the convex problem\ni=1(f (ui) \u2212 yi)2 + \u03b3kxk1,\n\n(6.18)\n\nwhere \u03b3 > 0 is a parameter used to trade off the quality of the fit to the data,\nand the sparsity of the coefficient vector. the solution of this problem can be used\ndirectly, or followed by a refinement step, in which the best fit is found, using the\nsparsity pattern of the solution of (6.18). in other words, we first solve (6.18), to\nobtain \u02c6x. we then set b = {i | \u02c6xi 6= 0}, i.e., the set of indices corresponding to\nnonzero coefficients. then we solve the least-squares problem\n\nminimize pm\n\nminimize pm\n\ni=1(f (ui) \u2212 yi)2\n\nwith variables xi, i \u2208 b, and xi = 0 for i 6\u2208 b.\nin basis pursuit and sparse description applications it is not uncommon to have\na very large dictionary, with n on the order of 104 or much more. to be effective,\nalgorithms for solving (6.18) must exploit problem structure, which derives from\nthe structure of the dictionary signals.\n\ntime-frequency analysis via basis pursuit\n\nin this section we illustrate basis pursuit and sparse representation with a simple\nexample. we consider functions (or signals) on r, with the range of interest [0, 1].\nwe think of the independent variable as time, so we use t (instead of u) to denote\nit.\n\nwe first describe the basis functions in the dictionary. each basis function is a\n\ngaussian sinusoidal pulse, or gabor function, with form\n\ne\u2212(t\u2212\u03c4 )2/\u03c32\n\ncos(\u03c9t + \u03c6),\n\n "}, {"Page_number": 349, "text": "6.5 function fitting and interpolation\n\n335\n\n1\n\n0\n\nc\n,\n0\n,\n5\n.\n0\nf\n\n\u22121\n0\n1\n\nc\n,\n5\n7\n,\n5\n.\n0\nf\n\n0\n\n\u22121\n0\n1\n\n0\n\n\u22121\n0\n\nc\n,\n0\n5\n1\n,\n5\n.\n0\nf\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\nt\n\n1\n\n1\n\n1\n\nfigure 6.21 three of the basis elements in the dictionary, all with center time\n\u03c4 = 0.5 and cosine phase. the top signal has frequency \u03c9 = 0, the middle\none has frequency \u03c9 = 75, and the bottom one has frequency \u03c9 = 150.\n\nwhere \u03c3 > 0 gives the width of the pulse, \u03c4 is the time of (the center of) the pulse,\n\u03c9 \u2265 0 is the frequency, and \u03c6 is the phase angle. all of the basis functions have\nwidth \u03c3 = 0.05. the pulse times and frequencies are\n\n\u03c4 = 0.002k,\n\nk = 0, . . . , 500,\n\n\u03c9 = 5k,\n\nk = 0, . . . , 30.\n\nfor each time \u03c4 , there is one basis element with frequency zero (and phase \u03c6 = 0),\nand 2 basis elements (cosine and sine, i.e., phase \u03c6 = 0 and \u03c6 = \u03c0/2) for each of 30\nremaining frequencies, so all together there are 501 \u00d7 61 = 30561 basis elements.\nthe basis elements are naturally indexed by time, frequency, and phase (cosine or\nsine), so we denote them as\n\nf\u03c4,\u03c9,c,\nf\u03c4,\u03c9,s,\n\n\u03c4 = 0, 0.002, . . . , 1,\n\u03c4 = 0, 0.002, . . . , 1,\n\n\u03c9 = 0, 5, . . . , 150,\n\u03c9 = 5, . . . , 150.\n\nthree of these basis functions (all with time \u03c4 = 0.5) are shown in figure 6.21.\n\nbasis pursuit with this dictionary can be thought of as a time-frequency analysis\nof the data. if a basis element f\u03c4,\u03c9,c or f\u03c4,\u03c9,s appears in the sparse representation\nof a signal (i.e., with a nonzero coefficient), we can interpret this as meaning that\nthe data contains the frequency \u03c9 at time \u03c4 .\n\nwe will use basis pursuit to find a sparse approximation of the signal\n\ny(t) = a(t) sin \u03b8(t)\n\n "}, {"Page_number": 350, "text": "336\n\n6 approximation and fitting\n\n)\nt\n(\ny\n\n,\n)\nt\n(\n\u02c6y\n\n1.5\n\n0.5\n\n\u22120.5\n\n\u22121.5\n0\n\n0.05\n\n)\nt\n(\n\u02c6y\n\u2212\n\n)\nt\n(\ny\n\n0\n\n\u22120.05\n0\n\n0.2\n\n0.4\n\n0.2\n\n0.4\n\nt\n\nt\n\n0.6\n\n0.8\n\n1\n\n0.6\n\n0.8\n\n1\n\nfigure 6.22 top. the original signal (solid line) and approximation \u02c6y ob-\ntained by basis pursuit (dashed line) are almost indistinguishable. bottom.\nthe approximation error y(t) \u2212 \u02c6y(t), with different vertical scale.\n\nwhere\n\na(t) = 1 + 0.5 sin(11t),\n\n\u03b8(t) = 30 sin(5t).\n\n(this signal is chosen only because it is simple to describe, and exhibits noticeable\nchanges in its spectral content over time.) we can interpret a(t) as the signal\namplitude, and \u03b8(t) as its total phase. we can also interpret\n\n\u03c9(t) =(cid:12)(cid:12)(cid:12)(cid:12)\n\nd\u03b8\n\ndt(cid:12)(cid:12)(cid:12)(cid:12) = 150| cos(5t)|\n\nas the instantaneous frequency of the signal at time t. the data are given as 501\nuniformly spaced samples over the interval [0, 1], i.e., we are given 501 pairs (tk, yk)\nwith\n\ntk = 0.005k,\n\nyk = y(tk),\n\nk = 0, . . . , 500.\n\nwe first solve the \u21131-norm regularized least-squares problem (6.18), with \u03b3 =\n1. the resulting optimal coefficient vector is very sparse, with only 42 nonzero\ncoefficients out of 30561. we then find the least-squares fit of the original signal\nusing these 42 basis vectors. the result \u02c6y is compared with the original signal\ny in figure 6.22. the top figure shows the approximated signal (in dashed line)\nand, almost indistinguishable, the original signal y(t) (in solid line). the bottom\nfigure shows the error y(t) \u2212 \u02c6y(t). as is clear from the figure, we have obtained an\n\n "}, {"Page_number": 351, "text": "6.5 function fitting and interpolation\n\n337\n\n)\nt\n(\ny\n\n)\nt\n(\n\u03c9\n\n1.5\n\n0.5\n\n\u22120.5\n\n\u22121.5\n0\n\n150\n\n100\n\n50\n\n0\n0\n\n0.2\n\n0.4\n\n0.2\n\n0.4\n\nt\n\n\u03c4\n\n0.6\n\n0.8\n\n1\n\n0.6\n\n0.8\n\n1\n\nfigure 6.23 top: original signal. bottom: time-frequency plot. the dashed\ncurve shows the instantaneous frequency \u03c9(t) = 150| cos(5t)| of the original\nsignal. each circle corresponds to a chosen basis element in the approxima-\ntion obtained by basis pursuit. the horizontal axis shows the time index \u03c4 ,\nand the vertical axis shows the frequency index \u03c9 of the basis element.\n\napproximation \u02c6y with a very good relative fit. the relative error is\n\n(1/501)p501\n\n(1/501)p501\n\ni=1(y(ti) \u2212 \u02c6y(ti))2\n\ni=1 y(ti)2\n\n= 2.6 \u00b7 10\u22124.\n\nby plotting the pattern of nonzero coefficients versus time and frequency, we\nobtain a time-frequency analysis of the original data. such a plot is shown in fig-\nure 6.23, along with the instantaneous frequency. the plot shows that the nonzero\ncomponents closely track the instantaneous frequency.\n\n6.5.5 interpolation with convex functions\n\nin some special cases we can solve interpolation problems involving an infinite-\ndimensional set of functions, using finite-dimensional convex optimization. in this\nsection we describe an example.\n\nwe start with the following question: when does there exist a convex function\n\nf : rk \u2192 r, with dom f = rk, that satisfies the interpolation conditions\n\nf (ui) = yi,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 352, "text": "338\n\n6 approximation and fitting\n\nat given points ui \u2208 rk? (here we do not restrict f to lie in any finite-dimensional\nsubspace of functions.) the answer is:\nif and only if there exist g1, . . . , gm such\nthat\n\n(6.19)\nto see this, first suppose that f is convex, dom f = rk, and f (ui) = yi,\n\ni (uj \u2212 ui),\n\ni, j = 1, . . . , m.\n\nyj \u2265 yi + gt\n\ni = 1, . . . , m. at each ui we can find a vector gi such that\n\nf (z) \u2265 f (ui) + gt\n\ni (z \u2212 ui)\n\n(6.20)\n\nfor all z. if f is differentiable, we can take gi = \u2207f (ui); in the more general case,\nwe can construct gi by finding a supporting hyperplane to epi f at (ui, yi). (the\nvectors gi are called subgradients.) by applying (6.20) to z = uj, we obtain (6.19).\n\nconversely, suppose g1, . . . , gm satisfy (6.19). define f as\n\nf (z) = max\n\ni=1,...,m\n\n(yi + gt\n\ni (z \u2212 ui))\n\nfor all z \u2208 rk. clearly, f is a (piecewise-linear) convex function. the inequali-\nties (6.19) imply that f (ui) = yi, for i = 1, . . . , m.\nwe can use this result to solve several problems involving interpolation, approx-\n\nimation, or bounding, with convex functions.\n\nfitting a convex function to given data\n\nperhaps the simplest application is to compute the least-squares fit of a convex\nfunction to given data (ui, yi), i = 1, . . . , m:\n\nminimize pm\n\nsubject to\n\ni=1(yi \u2212 f (ui))2\n\nf : rk \u2192 r is convex, dom f = rk.\n\nthis is an infinite-dimensional problem, since the variable is f , which is in the\nspace of continuous real-valued functions on rk. using the result above, we can\nformulate this problem as\n\nminimize pm\n\nsubject to\n\ni=1(yi \u2212 \u02c6yi)2\n\n\u02c6yj \u2265 \u02c6yi + gt\n\ni (uj \u2212 ui),\n\ni, j = 1, . . . , m,\n\nwhich is a qp with variables \u02c6y \u2208 rm and g1, . . . , gm \u2208 rk. the optimal value of\nthis problem is zero if and only if the given data can be interpolated by a convex\nfunction, i.e., if there is a convex function that satisfies f (ui) = yi. an example is\nshown in figure 6.24.\n\nbounding values of an interpolating convex function\n\nas another simple example, suppose that we are given data (ui, yi), i = 1, . . . , m,\nwhich can be interpolated by a convex function. we would like to determine the\nrange of possible values of f (u0), where u0 is another point in rk, and f is any\nconvex function that interpolates the given data. to find the smallest possible\nvalue of f (u0) we solve the lp\n\nminimize\nsubject to\n\ny0\nyj \u2265 yi + gt\n\ni (uj \u2212 ui),\n\ni, j = 0, . . . , m,\n\n "}, {"Page_number": 353, "text": "6.5 function fitting and interpolation\n\n339\n\nfigure 6.24 least-squares fit of a convex function to data, shown as circles.\nthe (piecewise-linear) function shown minimizes the sum of squared fitting\nerror, over all convex functions.\n\nwhich is an lp with variables y0 \u2208 r, g0, . . . , gm \u2208 rk. by maximizing y0 (which\nis also an lp) we find the largest possible value of f (u0) for a convex function that\ninterpolates the given data.\n\ninterpolation with monotone convex functions\n\nas an extension of convex interpolation, we can consider interpolation with a convex\nand monotone nondecreasing function. it can be shown that there exists a convex\nfunction f : rk \u2192 r, with dom f = rk, that satisfies the interpolation conditions\n\nf (ui) = yi,\n\ni = 1, . . . , m,\n\nand is monotone nondecreasing (i.e., f (u) \u2265 f (v) whenever u (cid:23) v), if and only if\nthere exist g1, . . . , gm \u2208 rk, such that\n\ngi (cid:23) 0,\n\ni = 1, . . . , m,\n\nyj \u2265 yi + gt\n\ni (uj \u2212 ui),\n\ni, j = 1, . . . , m.\n\n(6.21)\n\nin other words, we add to the convex interpolation conditions (6.19), the condition\nthat the subgradients gi are all nonnegative. (see exercise 6.12.)\n\nbounding consumer preference\n\nas an application, we consider a problem of predicting consumer preferences. we\nconsider different baskets of goods, consisting of different amounts of n consumer\ngoods. a goods basket is specified by a vector x \u2208 [0, 1]n where xi denotes the\namount of consumer good i. we assume the amounts are normalized so that\n0 \u2264 xi \u2264 1, i.e., xi = 0 is the minimum and xi = 1 is the maximum possible\namount of good i. given two baskets of goods x and \u02dcx, a consumer can either\nprefer x to \u02dcx, or prefer \u02dcx to x, or consider x and \u02dcx equally attractive. we consider\none model consumer, whose choices are repeatable.\n\n "}, {"Page_number": 354, "text": "340\n\n6 approximation and fitting\n\nwe model consumer preference in the following way. we assume there is an\nunderlying utility function u : rn \u2192 r, with domain [0, 1]n; u(x) gives a measure\nof the utility derived by the consumer from the goods basket x. given a choice\nbetween two baskets of goods, the consumer chooses the one that has larger utility,\nand will be ambivalent when the two baskets have equal utility. it is reasonable to\nassume that u is monotone nondecreasing. this means that the consumer always\nprefers to have more of any good, with the amounts of all other goods the same. it\nis also reasonable to assume that u is concave. this models satiation, or decreasing\nmarginal utility as we increase the amount of goods.\n\nnow suppose we are given some consumer preference data, but we do not know\nthe underlying utility function u. specifically, we have a set of goods baskets\na1, . . . , am \u2208 [0, 1]n, and some information about preferences among them:\n\nu(ai) > u(aj) for (i, j) \u2208 p,\n\nu(ai) \u2265 u(aj) for (i, j) \u2208 pweak,\n\n(6.22)\n\nwhere p, pweak \u2286 {1, . . . , m}\u00d7{1, . . . , m} are given. here p gives the set of known\npreferences: (i, j) \u2208 p means that basket ai is known to be preferred to basket aj.\nthe set pweak gives the set of known weak preferences: (i, j) \u2208 pweak means that\nbasket ai is preferred to basket aj, or that the two baskets are equally attractive.\nwe first consider the following question: how can we determine if the given data\nare consistent, i.e., whether or not there exists a concave nondecreasing utility\nfunction u for which (6.22) holds? this is equivalent to solving the feasibility\nproblem\n\nu\n\nfind\nsubject to u : rn \u2192 r concave and nondecreasing\n\nu(ai) > u(aj),\nu(ai) \u2265 u(aj),\n\n(i, j) \u2208 p\n(i, j) \u2208 pweak,\n\n(6.23)\n\nwith the function u as the (infinite-dimensional) optimization variable. since the\nconstraints in (6.23) are all homogeneous, we can express the problem in the equiv-\nalent form\n\nu\n\nfind\nsubject to u : rn \u2192 r concave and nondecreasing\n\nu(ai) \u2265 u(aj) + 1,\nu(ai) \u2265 u(aj),\n\n(i, j) \u2208 p\n(i, j) \u2208 pweak,\n\n(6.24)\n\nwhich uses only nonstrict inequalities. (it is clear that if u satisfies (6.24), then\nit must satisfy (6.23); conversely, if u satisfies (6.23), then it can be scaled to\nsatisfy (6.24).) this problem, in turn, can be cast as a (finite-dimensional) linear\nprogramming feasibility problem, using the interpolation result on page 339:\n\nfind\nsubject to\n\nu1, . . . , um, g1, . . . , gm\ngi (cid:23) 0,\ni = 1, . . . , m\nuj \u2264 ui + gt\ni (aj \u2212 ai),\n(i, j) \u2208 p\nui \u2265 uj + 1,\n(i, j) \u2208 pweak.\nui \u2265 uj,\n\ni, j = 1, . . . , m\n\n(6.25)\n\nby solving this linear programming feasibility problem, we can determine whether\nthere exists a concave, nondecreasing utility function that is consistent with the\n\n "}, {"Page_number": 355, "text": "6.5 function fitting and interpolation\n\n341\n\ngiven sets of strict and nonstrict preferences. if (6.25) is feasible, there is at least\none such utility function (and indeed, we can construct one that is piecewise-linear,\nfrom a feasible u1, . . . , um, g1, . . . , gm). if (6.25) is not feasible, we can conclude\nthat there is no concave increasing utility function that is consistent with the given\nsets of strict and nonstrict preferences.\n\nas an example, suppose that p and pweak are consumer preferences that are\nknown to be consistent with at least one concave increasing utility function. con-\nsider a pair (k, l) that is not in p or pweak, i.e., consumer preference between\nbaskets k and l is not known. in some cases we can conclude that a preference\nholds between basket k and l, even without knowing the underlying preference\nfunction. to do this we augment the known preferences (6.22) with the inequality\nu(ak) \u2264 u(al), which means that basket l is preferred to basket k, or they are\nequally attractive. we then solve the feasibility linear program (6.25), including\nthe extra weak preference u(ak) \u2264 u(al). if the augmented set of preferences is in-\nfeasible, it means that any concave nondecreasing utility function that is consistent\nwith the original given consumer preference data must also satisfy u(ak) > u(al).\nin other words, we can conclude that basket k is preferred to basket l, without\nknowing the underlying utility function.\n\nexample 6.9 here we give a simple numerical example that illustrates the discussion\nabove. we consider baskets of two goods (so we can easily plot the goods baskets).\nto generate the consumer preference data p, we compute 40 random points in [0, 1]2,\nand then compare them using the utility function\n\nu(x1, x2) = (1.1x1/2\n\n1 + 0.8x1/2\n\n2\n\n)/1.9.\n\nthese goods baskets, and a few level curves of the utility function u, are shown in\nfigure 6.25.\n\nwe now use the consumer preference data (but not, of course, the true utility function\nu) to compare each of these 40 goods baskets to the basket a0 = (0.5, 0.5). for each\noriginal basket ai, we solve the linear programming feasibility problem described\nabove, to see if we can conclude that basket a0 is preferred to basket ai. similarly,\nwe check whether we can conclude that basket ai is preferred to basket a0. for each\nbasket ai, there are three possible outcomes: we can conclude that a0 is definitely\npreferred to ai, that ai is definitely preferred to a0, or (if both lp feasibility problems\nare feasible) that no conclusion is possible. (here, definitely preferred means that the\npreference holds for any concave nondecreasing utility function that is consistent with\nthe original given data.)\n\nwe find that 21 of the baskets are definitely rejected in favor of (0.5, 0.5), and 14\nof the baskets are definitely preferred. we cannot make any conclusion, from the\nconsumer preference data, about the remaining 5 baskets. these results are shown in\nfigure 6.26. note that goods baskets below and to the left of (0.5, 0.5) will definitely\nbe rejected in favor of (0.5, 0.5), using only the monotonicity property of the utility\nfunction, and similarly, those points that are above and to the right of (0.5, 0.5) must\nbe preferred. so for these 17 points, there is no need to solve the feasibility lp (6.25).\nclassifying the 23 points in the other two quadrants, however, requires the concavity\nassumption, and solving the feasibility lp (6.25).\n\n "}, {"Page_number": 356, "text": "342\n\n6 approximation and fitting\n\n1\n\n2\nx\n\n0.5\n\n0\n0\n\n0.5\nx1\n\n1\n\nfigure 6.25 forty goods baskets a1, . . . , a40, shown as circles.\nthe\n0.1, 0.2, . . . , 0.9 level curves of the true utility function u are shown as dashed\nlines. this utility function is used to find the consumer preference data p\namong the 40 baskets.\n\n1\n\n2\nx\n\n0.5\n\n0\n0\n\n0.5\nx1\n\n1\n\nfigure 6.26 results of consumer preference analysis using the lp (6.25), for a\nnew goods basket a0 = (0.5, 0.5). the original baskets are displayed as open\ncircles if they are definitely rejected (u(ak) < u(a0)), as solid black circles\nif they are definitely preferred (u(ak) > u(a0)), and as squares when no\nconclusion can be made. the level curve of the underlying utility function,\nthat passes through (0.5, 0.5), is shown as a dashed curve. the vertical and\nhorizontal lines passing through (0.5, 0.5) divide [0, 1]2 into four quadrants.\npoints in the upper right quadrant must be preferred to (0.5, 0.5), by the\nmonotonicity assumption on u. similarly, (0.5, 0.5) must be preferred to the\npoints in the lower left quadrant. for the points in the other two quadrants,\nthe results are not obvious.\n\n "}, {"Page_number": 357, "text": "bibliography\n\nbibliography\n\n343\n\nthe robustness properties of approximations with different penalty functions were an-\nalyzed by huber [hub64, hub81], who also proposed the penalty function (6.4). the\nlog-barrier penalty function arises in control theory, where it is applied to the system\nclosed-loop frequency response, and has several names, e.g., central h\u221e, or risk-averse\ncontrol; see boyd and barratt [bb91] and the references therein.\n\nregularized approximation is covered in many books, including tikhonov and arsenin\n[ta77] and hansen [han98]. tikhonov regularization is sometimes called ridge regression\n(golub and van loan [gl89, page 564]). least-squares approximation with \u21131-norm\nregularization is also known under the name lasso (tibshirani [tib96]). other least-\nsquares regularization and regressor selection techniques are discussed and compared in\nhastie, tibshirani, and friedman [htf01, \u00a73.4].\ntotal variation denoising was introduced for image reconstruction by rudin, osher, and\nfatemi [rof92].\n\nthe robust least-squares problem with norm bounded uncertainty (page 321) was in-\ntroduced by el ghaoui and lebret [el97], and chandrasekaran, golub, gu, and sayed\n[cggs98]. el ghaoui and lebret also give the sdp formulation of the robust least-squares\nproblem with structured uncertainty (page 323).\n\nchen, donoho, and saunders [cds01] discuss basis pursuit via linear programming. they\nrefer to the \u21131-norm regularized problem (6.18) as basis pursuit denoising. meyer and\npratt [mp68] is an early paper on the problem of bounding utility functions.\n\n "}, {"Page_number": 358, "text": "344\n\n6 approximation and fitting\n\nexercises\n\nnorm approximation and least-norm problems\n\n6.1 quadratic bounds for log barrier penalty. let \u03c6 : r \u2192 r be the log barrier penalty\n\nfunction with limit a > 0:\n\n\u03c6(u) =(cid:26) \u2212a2 log(1 \u2212 (u/a)2)\n\n\u221e\n\n|u| < a\notherwise.\n\nshow that if u \u2208 rm satisfies kuk\u221e < a, then\n\nthis means thatpm\n\na. for example, if kuk\u221e/a = 0.25, then\n\ni=1 \u03c6(ui) is well approximated by kuk2\n\n2 if kuk\u221e is small compared to\n\nkuk2\n\n2 \u2264\n\nmxi=1\n\n\u03c6(ui) \u2264\n\n\u03c6(kuk\u221e)\nkuk2\n\n\u221e kuk2\n2.\n\nkuk2\n\n2 \u2264\n\nmxi=1\n\n\u03c6(ui) \u2264 1.033 \u00b7 kuk2\n2.\n\n6.2 \u21131-, \u21132-, and \u2113\u221e-norm approximation by a constant vector. what is the solution of the\n\nnorm approximation problem with one scalar variable x \u2208 r,\n\nfor the \u21131-, \u21132-, and \u2113\u221e-norms?\n\nminimize\n\nkx1 \u2212 bk,\n\n6.3 formulate the following approximation problems as lps, qps, socps, or sdps. the\n\nproblem data are a \u2208 rm\u00d7n and b \u2208 rm. the rows of a are denoted at\ni .\n\n(a) deadzone-linear penalty approximation: minimizepm\n\ni=1 \u03c6(at\n\ni x \u2212 bi), where\n\n\u03c6(u) =(cid:26) 0\n\n|u| \u2212 a\n\n|u| \u2264 a\n|u| > a,\n\nwhere a > 0.\n\n(b) log-barrier penalty approximation: minimizepm\n\u03c6(u) =(cid:26) \u2212a2 log(1 \u2212 (u/a)2)\n\n\u221e\n\ni=1 \u03c6(at\n\ni x \u2212 bi), where\n|u| < a\n|u| \u2265 a,\n\nwith a > 0.\n\n(c) huber penalty approximation: minimizepm\n\ni=1 \u03c6(at\n\n\u03c6(u) =(cid:26) u2\n\nm (2|u| \u2212 m )\n\ni x \u2212 bi), where\n|u| \u2264 m\n|u| > m,\n\nwith m > 0.\n\n(d) log-chebyshev approximation: minimize maxi=1,...,m | log(at\n\ni x)\u2212 log bi|. we assume\n\nb \u227b 0. an equivalent convex form is\n\nminimize\nsubject to\n\nt\n1/t \u2264 at\n\ni x/bi \u2264 t,\n\ni = 1, . . . , m,\n\nwith variables x \u2208 rn and t \u2208 r, and domain rn \u00d7 r++.\n\n "}, {"Page_number": 359, "text": "exercises\n\n345\n\n(e) minimizing the sum of the largest k residuals:\n\nminimize pk\n\nsubject to\n\ni=1 |r|[i]\nr = ax \u2212 b,\n\nwhere |r|[1] \u2265 |r|[2] \u2265 \u00b7\u00b7\u00b7 \u2265 |r|[m] are the numbers |r1|, |r2|, . . . , |rm| sorted in\ndecreasing order. (for k = 1, this reduces to \u2113\u221e-norm approximation; for k = m, it\nreduces to \u21131-norm approximation.) hint. see exercise 5.19.\n\n6.4 a differentiable approximation of \u21131-norm approximation. the function \u03c6(u) = (u2+\u01eb)1/2,\nwith parameter \u01eb > 0, is sometimes used as a differentiable approximation of the absolute\nvalue function |u|. to approximately solve the \u21131-norm approximation problem\n\n(6.26)\n\n(6.27)\n\nwhere a \u2208 rm\u00d7n, we solve instead the problem\n\nminimize\n\nkax \u2212 bk1,\n\nminimize pm\n\ni=1 \u03c6(at\n\ni x \u2212 bi),\n\nis the ith row of a. we assume rank a = n.\n\nwhere at\ni\nlet p\u22c6 denote the optimal value of the \u21131-norm approximation problem (6.26). let \u02c6x\ndenote the optimal solution of the approximate problem (6.27), and let \u02c6r denote the\nassociated residual, \u02c6r = a\u02c6x \u2212 b.\ni=1 \u02c6r2\n\ni + \u01eb)1/2.\n\ni /(\u02c6r2\n\n(a) show that p\u22c6 \u2265pm\n\n(b) show that\n\nka\u02c6x \u2212 bk1 \u2264 p\u22c6 +\n\n|\u02c6ri|(cid:18)1 \u2212\n\n|\u02c6ri|\n\ni + \u01eb)1/2(cid:19) .\n\n(\u02c6r2\n\nmxi=1\n\n(by evaluating the righthand side after computing \u02c6x, we obtain a bound on how subop-\ntimal \u02c6x is for the \u21131-norm approximation problem.)\n\n6.5 minimum length approximation. consider the problem\n\nminimize\nsubject to\n\nlength(x)\nkax \u2212 bk \u2264 \u01eb,\n\nwhere length(x) = min{k | xi = 0 for i > k}. the problem variable is x \u2208 rn; the\nproblem parameters are a \u2208 rm\u00d7n, b \u2208 rm, and \u01eb > 0. in a regression context, we are\nasked to find the minimum number of columns of a, taken in order, that can approximate\nthe vector b within \u01eb.\nshow that this is a quasiconvex optimization problem.\n\n6.6 duals of some penalty function approximation problems. derive a lagrange dual for the\n\nproblem\n\nminimize pm\n\nsubject to\n\ni=1 \u03c6(ri)\nr = ax \u2212 b,\n\nfor the following penalty functions \u03c6 : r \u2192 r. the variables are x \u2208 rn, r \u2208 rm.\n(a) deadzone-linear penalty (with deadzone width a = 1),\n\n(b) huber penalty (with m = 1),\n\n\u03c6(u) =(cid:26) 0\n\u03c6(u) =(cid:26) u2\n\n|u| \u2212 1\n\n2|u| \u2212 1\n\n|u| \u2264 1\n|u| > 1.\n\n|u| \u2264 1\n|u| > 1.\n\n "}, {"Page_number": 360, "text": "346\n\n6 approximation and fitting\n\n(c) log-barrier (with limit a = 1),\n\n\u03c6(u) = \u2212 log(1 \u2212 u2),\n\ndom \u03c6 = (\u22121, 1).\n\n(d) relative deviation from one,\n\n\u03c6(u) = max{u, 1/u} =(cid:26) u\n\nu \u2265 1\n1/u u \u2264 1,\n\nwith dom \u03c6 = r++.\n\nregularization and robust approximation\n\n6.7 bi-criterion optimization with euclidean norms. we consider the bi-criterion optimization\n\nproblem\n\nminimize (w.r.t. r2\n\n+)\n\n(kax \u2212 bk2\n\n2,kxk2\n2),\n\nwhere a \u2208 rm\u00d7n has rank r, and b \u2208 rm. show how to find the solution of each of the\nfollowing problems from the singular value decomposition of a,\n\na = u diag(\u03c3)v t =\n\n\u03c3iuivt\ni\n\nrxi=1\n\n(see \u00a7a.5.4).\n(a) tikhonov regularization: minimize kax \u2212 bk2\n(b) minimize kax \u2212 bk2\n(c) maximize kax \u2212 bk2\nhere \u03b4 and \u03b3 are positive parameters.\nyour results provide efficient methods for computing the optimal trade-off curve and the\nset of achievable values of the bi-criterion problem.\n\n2 subject to kxk2\n2 subject to kxk2\n\n2 + \u03b4kxk2\n2.\n\n2 = \u03b3.\n2 = \u03b3.\n\n6.8 formulate the following robust approximation problems as lps, qps, socps, or sdps.\n\nfor each subproblem, consider the \u21131-, \u21132-, and the \u2113\u221e-norms.\n\n(a) stochastic robust approximation with a finite set of parameter values, i.e., the sum-\n\nof-norms problem\n\nwhere p (cid:23) 0 and 1t p = 1. (see \u00a76.4.1.)\n\n(b) worst-case robust approximation with coefficient bounds:\n\nminimize pk\n\ni=1 pikaix \u2212 bk\n\nminimize\n\nsupa\u2208a kax \u2212 bk\n\nwhere\n\na = {a \u2208 rm\u00d7n | lij \u2264 aij \u2264 uij, i = 1, . . . , m, j = 1, . . . , n}.\n\nhere the uncertainty set is described by giving upper and lower bounds for the\ncomponents of a. we assume lij < uij.\n\n(c) worst-case robust approximation with polyhedral uncertainty:\n\nminimize\n\nsupa\u2208a kax \u2212 bk\n\nwhere\n\na = {[a1 \u00b7\u00b7\u00b7 am]t | ciai (cid:22) di, i = 1, . . . , m}.\n\nthe uncertainty is described by giving a polyhedron pi = {ai | ciai (cid:22) di} of possible\nvalues for each row. the parameters ci \u2208 rpi\u00d7n, di \u2208 rpi , i = 1, . . . , m, are given.\nwe assume that the polyhedra pi are nonempty and bounded.\n\n "}, {"Page_number": 361, "text": "exercises\n\n347\n\nfunction fitting and interpolation\n\n6.9 minimax rational function fitting. show that the following problem is quasiconvex:\n\nwhere\n\nminimize\n\nmax\n\ni=1,...,k(cid:12)(cid:12)(cid:12)(cid:12)\n\np(ti)\n\nq(ti) \u2212 yi(cid:12)(cid:12)(cid:12)(cid:12)\n\np(t) = a0 + a1t + a2t2 + \u00b7\u00b7\u00b7 + amtm,\n\nq(t) = 1 + b1t + \u00b7\u00b7\u00b7 + bntn,\n\nand the domain of the objective function is defined as\n\nd = {(a, b) \u2208 rm+1 \u00d7 rn | q(t) > 0, \u03b1 \u2264 t \u2264 \u03b2}.\n\nin this problem we fit a rational function p(t)/q(t) to given data, while constraining the\ndenominator polynomial to be positive on the interval [\u03b1, \u03b2]. the optimization variables\nare the numerator and denominator coefficients ai, bi. the interpolation points ti \u2208 [\u03b1, \u03b2],\nand desired function values yi, i = 1, . . . , k, are given.\n\n6.10 fitting data with a concave nonnegative nondecreasing quadratic function. we are given\n\nthe data\n\nand wish to fit a quadratic function of the form\n\nx1, . . . , xn \u2208 rn,\n\ny1, . . . , yn \u2208 r,\n\nf (x) = (1/2)xt p x + qt x + r,\n\nwhere p \u2208 sn, q \u2208 rn, and r \u2208 r are the parameters in the model (and, therefore, the\nvariables in the fitting problem).\nour model will be used only on the box b = {x \u2208 rn | l (cid:22) x (cid:22) u}. you can assume that\nl \u227a u, and that the given data points xi are in this box.\nwe will use the simple sum of squared errors objective,\n\nnxi=1\n\n(f (xi) \u2212 yi)2,\n\nas the criterion for the fit. we also impose several constraints on the function f . first,\nit must be concave. second, it must be nonnegative on b, i.e., f (z) \u2265 0 for all z \u2208 b.\nthird, f must be nondecreasing on b, i.e., whenever z, \u02dcz \u2208 b satisfy z (cid:22) \u02dcz, we have\nf (z) \u2264 f (\u02dcz).\nshow how to formulate this fitting problem as a convex problem. simplify your formula-\ntion as much as you can.\n\n6.11 least-squares direction interpolation. suppose f1, . . . , fn : rk \u2192 rp, and we form the\n\nlinear combination f : rk \u2192 rp,\n\nf (u) = x1f1(u) + \u00b7\u00b7\u00b7 + xnfn(u),\n\nwhere x is the variable in the interpolation problem.\nin this problem we require that 6 (f (vj), qj) = 0, j = 1, . . . , m, where qj are given vectors\nin rp, which we assume satisfy kqjk2 = 1. in other words, we require the direction of\nf to take on specified values at the points vj. to ensure that f (vj) is not zero (which\nmakes the angle undefined), we impose the minimum length constraints kf (vj)k2 \u2265 \u01eb,\nj = 1, . . . , m, where \u01eb > 0 is given.\nshow how to find x that minimizes kxk2, and satisfies the direction (and minimum length)\nconditions above, using convex optimization.\n6.12 interpolation with monotone functions. a function f : rk \u2192 r is monotone nondecreas-\n\ning (with respect to rk\n\n+) if f (u) \u2265 f (v) whenever u (cid:23) v.\n\n "}, {"Page_number": 362, "text": "348\n\n6 approximation and fitting\n\n(a) show that there exists a monotone nondecreasing function f : rk \u2192 r, that satisfies\n\nf (ui) = yi for i = 1, . . . , m, if and only if\n\nyi \u2265 yj whenever ui (cid:23) uj,\n\ni, j = 1, . . . , m.\n\n(b) show that there exists a convex monotone nondecreasing function f : rk \u2192 r, with\ndom f = rk, that satisfies f (ui) = yi for i = 1, . . . , m, if and only if there exist\ngi \u2208 rk, i = 1, . . . , m, such that\ni = 1, . . . , m,\n\ni, j = 1, . . . , m.\n\nyj \u2265 yi + gt\n\ni (uj \u2212 ui),\n\ngi (cid:23) 0,\n\n6.13 interpolation with quasiconvex functions. show that there exists a quasiconvex function\nf : rk \u2192 r, that satisfies f (ui) = yi for i = 1, . . . , m, if and only if there exist gi \u2208 rk,\ni = 1, . . . , m, such that\n\ngt\ni (uj \u2212 ui) \u2264 \u22121 whenever yj < yi,\n\ni, j = 1, . . . , m.\n\n6.14 [nes00] interpolation with positive-real functions. suppose z1, . . . , zn \u2208 c are n distinct\npoints with |zi| > 1. we define knp as the set of vectors y \u2208 cn for which there exists a\nfunction f : c \u2192 c that satisfies the following conditions.\n\n\u2022 f is positive-real, which means it is analytic outside the unit circle (i.e., for |z| > 1),\n\nand its real part is nonnegative outside the unit circle (\u211cf (z) \u2265 0 for |z| > 1).\n\n\u2022 f satisfies the interpolation conditions\n\nf (z1) = y1,\n\nf (z2) = y2,\n\n. . . ,\n\nf (zn) = yn.\n\nif we denote the set of positive-real functions as f , then we can express knp as\n\nknp = {y \u2208 cn | \u2203f \u2208 f , yk = f (zk), k = 1, . . . , n}.\n\n(a) it can be shown that f is positive-real if and only if there exists a nondecreasing\n\nfunction \u03c1 such that for all z with |z| > 1,\n\nf (z) = i\u2111f (\u221e) +z 2\u03c0\n\n0\n\nei\u03b8 + z\u22121\n\nei\u03b8 \u2212 z\u22121 d\u03c1(\u03b8),\n\nis a closed convex cone.\n\nwhere i = \u221a\u22121 (see [kn77, page 389]). use this representation to show that knp\n(b) we will use the inner product \u211c(xh y) between vectors x, y \u2208 cn, where xh denotes\nthe complex conjugate transpose of x. show that the dual cone of knp is given by\n\nl ! \u2265 0 \u2200\u03b8 \u2208 [0, 2\u03c0]) .\n\nl\n\ne\u2212i\u03b8 + \u00afz\u22121\ne\u2212i\u03b8 \u2212 \u00afz\u22121\n\nqkl\n1 \u2212 z\u22121\nk \u00afz\u22121\n\nl\n\n, l = 1, . . . , n)\n\n(c) show that\n\nk \u2217\n\nxl\n\nk \u2217\n\nnp =(x \u2208 cn (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) \u2111(1t x) = 0, \u211c  nxl=1\nnp =(x \u2208 cn (cid:12)(cid:12)(cid:12)(cid:12)(cid:12) \u2203q \u2208 hn\nnxk=1\nnxk=0\n\n+, xl =\n\n(yke\u2212ik\u03b8 + \u00afykeik\u03b8)\n\nwhere hn\n+ denotes the set of positive semidefinite hermitian matrices of size n \u00d7 n.\nuse the following result (known as riesz-fej\u00b4er theorem; see [kn77, page 60]). a\nfunction of the form\n\n "}, {"Page_number": 363, "text": "exercises\n\n349\n\nis nonnegative for all \u03b8 if and only if there exist a0, . . . , an \u2208 c such that\n\nnxk=0\n\n(yke\u2212ik\u03b8 + \u00afykeik\u03b8) =(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n\nnxk=0\n\n2\n\n.\n\nakeik\u03b8(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n\n(d) show that knp = {y \u2208 cn | p (y) (cid:23) 0} where p (y) \u2208 hn is defined as\n\np (y)kl =\n\nyk + yl\n1 \u2212 z\u22121\n\nk \u00afz\u22121\n\nl\n\n,\n\nl, k = 1, . . . , n.\n\nthe matrix p (y) is called the nevanlinna-pick matrix associated with the points\nzk, yk.\nhint. as we noted in part (a), knp is a closed convex cone, so knp = k \u2217\u2217\nnp.\n\n(e) as an application, pose the following problem as a convex optimization problem:\n\nminimize pn\n\nsubject to\n\nf \u2208 f .\n\nk=1 |f (zk) \u2212 wk|2\n\nthe problem data are n points zk with |zk| > 1 and n complex numbers w1, . . . ,\nwn. we optimize over all positive-real functions f .\n\n "}, {"Page_number": 364, "text": " "}, {"Page_number": 365, "text": "chapter 7\n\nstatistical estimation\n\n7.1 parametric distribution estimation\n\n7.1.1 maximum likelihood estimation\n\nwe consider a family of probability distributions on rm, indexed by a vector\nx \u2208 rn, with densities px(\u00b7). when considered as a function of x, for fixed y \u2208 rm,\nthe function px(y) is called the likelihood function. it is more convenient to work\nwith its logarithm, which is called the log-likelihood function, and denoted l:\n\nl(x) = log px(y).\n\nthere are often constraints on the values of the parameter x, which can repre-\nsent prior knowledge about x, or the domain of the likelihood function. these\nconstraints can be explicitly given, or incorporated into the likelihood function by\nassigning px(y) = 0 (for all y) whenever x does not satisfy the prior information\nconstraints. (thus, the log-likelihood function can be assigned the value \u2212\u221e for\nparameters x that violate the prior information constraints.)\nnow consider the problem of estimating the value of the parameter x, based\non observing one sample y from the distribution. a widely used method, called\nmaximum likelihood (ml) estimation, is to estimate x as\n\n\u02c6xml = argmaxxpx(y) = argmaxxl(x),\n\ni.e., to choose as our estimate a value of the parameter that maximizes the like-\nlihood (or log-likelihood) function for the observed value of y.\nif we have prior\ninformation about x, such as x \u2208 c \u2286 rn, we can add the constraint x \u2208 c\nexplicitly, or impose it implicitly, by redefining px(y) to be zero for x 6\u2208 c.\nthe problem of finding a maximum likelihood estimate of the parameter vector\nx can be expressed as\n\nl(x) = log px(y)\n\nmaximize\nsubject to x \u2208 c,\n\n(7.1)\n\nwhere x \u2208 c gives the prior information or other constraints on the parameter\nvector x. in this optimization problem, the vector x \u2208 rn (which is the parameter\n\n "}, {"Page_number": 366, "text": "352\n\n7 statistical estimation\n\nin the probability density) is the variable, and the vector y \u2208 rm (which is the\nobserved sample) is a problem parameter.\nthe maximum likelihood estimation problem (7.1) is a convex optimization\nproblem if the log-likelihood function l is concave for each value of y, and the set\nc can be described by a set of linear equality and convex inequality constraints, a\nsituation which occurs in many estimation problems. for these problems we can\ncompute an ml estimate using convex optimization.\n\nlinear measurements with iid noise\n\nwe consider a linear measurement model,\n\nyi = at\n\ni x + vi,\n\ni = 1, . . . , m,\n\nwhere x \u2208 rn is a vector of parameters to be estimated, yi \u2208 r are the measured\nor observed quantities, and vi are the measurement errors or noise. we assume\nthat vi are independent, identically distributed (iid), with density p on r. the\nlikelihood function is then\n\npx(y) =\n\nmyi=1\n\np(yi \u2212 at\n\ni x),\n\nso the log-likelihood function is\n\nl(x) = log px(y) =\n\nmxi=1\n\nlog p(yi \u2212 at\n\ni x).\n\nthe ml estimate is any optimal point for the problem\ni=1 log p(yi \u2212 at\n\ni x),\n\nmaximize pm\n\nwith variable x. if the density p is log-concave, this problem is convex, and has the\nform of a penalty approximation problem ((6.2), page 294), with penalty function\n\u2212 log p.\n\n(7.2)\n\nexample 7.1 ml estimation for some common noise densities.\n\n\u2022 gaussian noise. when vi are gaussian with zero mean and variance \u03c32, the\n\ndensity is p(z) = (2\u03c0\u03c32)\u22121/2e\u2212z2/2\u03c32\n\n, and the log-likelihood function is\n\nl(x) = \u2212(m/2) log(2\u03c0\u03c32) \u2212\n1 , . . . , at\n\n1\n2\u03c32 kax \u2212 yk2\n2,\nm. therefore the ml estimate of\n2, the solution of a least-squares approximation\n\nwhere a is the matrix with rows at\nx is xml = argminx kax \u2212 yk2\nproblem.\n\n\u2022 laplacian noise. when vi are laplacian, i.e., have density p(z) = (1/2a)e\u2212|z|/a\n(where a > 0), the ml estimate is \u02c6x = argminx kax \u2212 yk1, the solution of the\n\u21131-norm approximation problem.\n\n\u2022 uniform noise. when vi are uniformly distributed on [\u2212a, a], we have p(z) =\n\n1/(2a) on [\u2212a, a], and an ml estimate is any x satisfying kax \u2212 yk\u221e \u2264 a.\n\n "}, {"Page_number": 367, "text": "7.1 parametric distribution estimation\n\n353\n\nml interpretation of penalty function approximation\n\nconversely, we can interpret any penalty function approximation problem\n\nas a maximum likelihood estimation problem, with noise density\n\nminimize pm\n\ni=1 \u03c6(bi \u2212 at\n\ni x)\n\np(z) =\n\n,\n\ne\u2212\u03c6(z)\n\nr e\u2212\u03c6(u) du\n\nand measurements b. this observation gives a statistical interpretation of the\npenalty function approximation problem. suppose, for example, that the penalty\nfunction \u03c6 grows very rapidly for large values, which means that we attach a very\nlarge cost or penalty to large residuals. the corresponding noise density function\np will have very small tails, and the ml estimator will avoid (if possible) estimates\nwith any large residuals because these correspond to very unlikely events.\n\nwe can also understand the robustness of \u21131-norm approximation to large errors\nin terms of maximum likelihood estimation. we interpret \u21131-norm approximation\nas maximum likelihood estimation with a noise density that is laplacian; \u21132-norm\napproximation is maximum likelihood estimation with a gaussian noise density.\nthe laplacian density has larger tails than the gaussian, i.e., the probability of a\nvery large vi is far larger with a laplacian than a gaussian density. as a result,\nthe associated maximum likelihood method expects to see greater numbers of large\nresiduals.\n\ncounting problems with poisson distribution\n\nin a wide variety of problems the random variable y is nonnegative integer valued,\nwith a poisson distribution with mean \u00b5 > 0:\n\nprob(y = k) =\n\ne\u2212\u00b5\u00b5k\n\nk!\n\n.\n\noften y represents the count or number of events (such as photon arrivals, traffic\naccidents, etc.) of a poisson process over some period of time.\n\nin a simple statistical model, the mean \u00b5 is modeled as an affine function of a\n\nvector u \u2208 rn:\n\n\u00b5 = at u + b.\n\nhere u is called the vector of explanatory variables, and the vector a \u2208 rn and\nnumber b \u2208 r are called the model parameters. for example, if y is the number\nof traffic accidents in some region over some period, u1 might be the total traffic\nflow through the region during the period, u2 the rainfall in the region during the\nperiod, and so on.\n\nwe are given a number of observations which consist of pairs (ui, yi), i =\n1, . . . , m, where yi is the observed value of y for which the value of the explanatory\nvariable is ui \u2208 rn. our job is to find a maximum likelihood estimate of the model\nparameters a \u2208 rn and b \u2208 r from these data.\n\n "}, {"Page_number": 368, "text": "354\n\n7 statistical estimation\n\nthe likelihood function has the form\n\n(at ui + b)yi exp(\u2212(at ui + b))\n\nyi!\n\n,\n\nmyi=1\n\nso the log-likelihood function is\n\nl(a, b) =\n\nmxi=1\n\n(yi log(at ui + b) \u2212 (at ui + b) \u2212 log(yi!)).\n\nwe can find an ml estimate of a and b by solving the convex optimization problem\n\nmaximize pm\n\nwhere the variables are a and b.\n\ni=1(yi log(at ui + b) \u2212 (at ui + b)),\n\nlogistic regression\nwe consider a random variable y \u2208 {0, 1}, with\n\nprob(y = 1) = p,\n\nprob(y = 0) = 1 \u2212 p,\n\nwhere p \u2208 [0, 1], and is assumed to depend on a vector of explanatory variables\nu \u2208 rn. for example, y = 1 might mean that an individual in a population acquires\na certain disease. the probability of acquiring the disease is p, which is modeled\nas a function of some explanatory variables u, which might represent weight, age,\nheight, blood pressure, and other medically relevant variables.\n\nthe logistic model has the form\n\np =\n\nexp(at u + b)\n\n1 + exp(at u + b)\n\n,\n\n(7.3)\n\nwhere a \u2208 rn and b \u2208 r are the model parameters that determine how the\nprobability p varies as a function of the explanatory variable u.\nnow suppose we are given some data consisting of a set of values of the explana-\ntory variables u1, . . . , um \u2208 rn along with the corresponding outcomes y1, . . . , ym \u2208\n{0, 1}. our job is to find a maximum likelihood estimate of the model parameters\na \u2208 rn and b \u2208 r. finding an ml estimate of a and b is sometimes called logistic\nregression.\nwe can re-order the data so for u1, . . . , uq, the outcome is y = 1, and for\n\nuq+1, . . . , um the outcome is y = 0. the likelihood function then has the form\n\npi\n\nqyi=1\n\nmyi=q+1\n\n(1 \u2212 pi),\n\nwhere pi is given by the logistic model with explanatory variable ui. the log-\nlikelihood function has the form\n\nl(a, b) =\n\nlog pi +\n\nqxi=1\n\nmxi=q+1\n\nlog(1 \u2212 pi)\n\n "}, {"Page_number": 369, "text": "7.1 parametric distribution estimation\n\n355\n\n)\n1\n=\ny\n(\nb\no\nr\np\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n\n0\n\n2\n\n4\n\n6\n\nu\n\n8\n\n10\n\nfigure 7.1 logistic regression. the circles show 50 points (ui, yi), where\nui \u2208 r is the explanatory variable, and yi \u2208 {0, 1} is the outcome. the\ndata suggest that for u < 5 or so, the outcome is more likely to be y = 0,\nwhile for u > 5 or so, the outcome is more likely to be y = 1. the data\nalso suggest that for u < 2 or so, the outcome is very likely to be y = 0,\nand for u > 8 or so, the outcome is very likely to be y = 1. the solid\ncurve shows prob(y = 1) = exp(au + b)/(1 + exp(au + b)) for the maximum\nlikelihood parameters a, b. this maximum likelihood model is consistent\nwith our informal observations about the data set.\n\nlog\n\nexp(at ui + b)\n\n1 + exp(at ui + b)\n\n+\n\nmxi=q+1\n\nlog\n\n1\n\n1 + exp(at ui + b)\n\nlog(1 + exp(at ui + b)).\n\n=\n\n=\n\nqxi=1\nqxi=1\n\n(at ui + b) \u2212\n\nmxi=1\n\nsince l is a concave function of a and b, the logistic regression problem can be solved\nas a convex optimization problem. figure 7.1 shows an example with u \u2208 r.\ncovariance estimation for gaussian variables\nsuppose y \u2208 rn is a gaussian random variable with zero mean and covariance\nmatrix r = e yyt , so its density is\n\npr(y) = (2\u03c0)\u2212n/2 det(r)\u22121/2 exp(\u2212yt r\u22121y/2),\n\nwhere r \u2208 sn\n++. we want to estimate the covariance matrix r based on n in-\ndependent samples y1, . . . , yn \u2208 rn drawn from the distribution, and using prior\nknowledge about r.\n\nthe log-likelihood function has the form\n\nl(r) = log pr(y1, . . . , yn )\n\n "}, {"Page_number": 370, "text": "356\n\n7 statistical estimation\n\n= \u2212(n n/2) log(2\u03c0) \u2212 (n/2) log det r \u2212 (1/2)\n= \u2212(n n/2) log(2\u03c0) \u2212 (n/2) log det r \u2212 (n/2) tr(r\u22121y ),\n\nyt\nk r\u22121yk\n\nnxk=1\n\nwhere\n\ny =\n\n1\nn\n\nnxk=1\n\nykyt\nk\n\nis the sample covariance of y1, . . . , yn . this log-likelihood function is not a concave\nfunction of r (although it is concave on a subset of its domain sn\n++; see exercise 7.4),\nbut a change of variable yields a concave log-likelihood function. let s denote the\ninverse of the covariance matrix, s = r\u22121 (which is called the information matrix ).\nusing s in place of r as a new parameter, the log-likelihood function has the form\n\nl(s) = \u2212(n n/2) log(2\u03c0) + (n/2) log det s \u2212 (n/2) tr(sy ),\n\nwhich is a concave function of s.\n\ntherefore the ml estimate of s (hence, r) is found by solving the problem\n\nmaximize\nsubject to s \u2208 s\n\nlog det s \u2212 tr(sy )\n\n(7.4)\n\nwhere s is our prior knowledge of s = r\u22121. (we also have the implicit constraint\nthat s \u2208 sn\n++.) since the objective function is concave, this is a convex problem\nif the set s can be described by a set of linear equality and convex inequality\nconstraints.\nfirst we examine the case in which no prior assumptions are made on r (hence,\ns), other than r \u227b 0. in this case the problem (7.4) can be solved analytically. the\ngradient of the objective is s\u22121\u2212y , so the optimal s satisfies s\u22121 = y if y \u2208 sn\n++.\n(if y 6\u2208 sn\n++, the log-likelihood function is unbounded above.) therefore, when\nwe have no prior assumptions about r, the maximum likelihood estimate of the\ncovariance is, simply, the sample covariance: \u02c6rml = y .\n\nnow we consider some examples of constraints on r that can be expressed as\nconvex constraints on the information matrix s. we can handle lower and upper\n(matrix) bounds on r, of the form\n\nl (cid:22) r (cid:22) u,\n\nwhere l and u are symmetric and positive definite, as\n\na condition number constraint on r,\n\nu \u22121 (cid:22) r\u22121 (cid:22) l\u22121.\n\ncan be expressed as\n\n\u03bbmax(r) \u2264 \u03bamax\u03bbmin(r),\n\n\u03bbmax(s) \u2264 \u03bamax\u03bbmin(s).\n\n "}, {"Page_number": 371, "text": "7.1 parametric distribution estimation\n\n357\n\nthis is equivalent to the existence of u > 0 such that ui (cid:22) s (cid:22) \u03bamaxui. we can\ntherefore solve the ml problem, with the condition number constraint on r, by\nsolving the convex problem\n\nlog det s \u2212 tr(sy )\nmaximize\nsubject to ui (cid:22) s (cid:22) \u03bamaxui\n\n(7.5)\n\nwhere the variables are s \u2208 sn and u \u2208 r.\nfunctions of the underlying random vector y,\n\nas another example, suppose we are given bounds on the variance of some linear\n\nthese prior assumptions can be expressed as\n\ne(ct\n\ni y)2 \u2264 \u03b1i,\n\ni = 1, . . . , k.\n\ne(ct\n\ni y)2 = ct\n\ni rci = ct\n\ni s\u22121ci \u2264 \u03b1i,\n\ni = 1, . . . , k.\n\nsince ct\nbounds can be imposed in the ml problem.\n\ni s\u22121ci is a convex function of s (provided s \u227b 0, which holds here), these\n\n7.1.2 maximum a posteriori probability estimation\n\nmaximum a posteriori probability (map) estimation can be considered a bayesian\nversion of maximum likelihood estimation, with a prior probability density on the\nunderlying parameter x. we assume that x (the vector to be estimated) and y (the\nobservation) are random variables with a joint probability density p(x, y). this\nis in contrast to the statistical estimation setup, where x is a parameter, not a\nrandom variable.\n\nthe prior density of x is given by\n\npx(x) =z p(x, y) dy.\n\nthis density represents our prior information about what the values of the vector x\nmight be, before we observe the vector y. similarly, the prior density of y is given\nby\n\npy(y) =z p(x, y) dx.\n\nthis density represents the prior information about what the measurement or ob-\nservation vector y will be.\n\nthe conditional density of y, given x, is given by\n\npy|x(x, y) =\n\np(x, y)\npx(x)\n\n.\n\nin the map estimation method, py|x plays the role of the parameter dependent\ndensity px in the maximum likelihood estimation setup. the conditional density\nof x, given y, is given by\n\npx|y(x, y) =\n\np(x, y)\npy(y)\n\n= py|x(x, y)\n\npx(x)\npy(y)\n\n.\n\n "}, {"Page_number": 372, "text": "358\n\n7 statistical estimation\n\nwhen we substitute the observed value y into px|y, we obtain the posterior density\nof x. it represents our knowledge of x after the observation.\n\nin the map estimation method, our estimate of x, given the observation y, is\n\ngiven by\n\n\u02c6xmap = argmaxxpx|y(x, y)\n\n= argmaxxpy|x(x, y)px(x)\n= argmaxxp(x, y).\n\nin other words, we take as estimate of x the value that maximizes the conditional\ndensity of x, given the observed value of y. the only difference between this\nestimate and the maximum likelihood estimate is the second term, px(x), appearing\nhere. this term can be interpreted as taking our prior knowledge of x into account.\nnote that if the prior density of x is uniform over a set c, then finding the map\nestimate is the same as maximizing the likelihood function subject to x \u2208 c, which\nis the ml estimation problem (7.1).\n\ntaking logarithms, we can express the map estimate as\n\n\u02c6xmap = argmaxx(log py|x(x, y) + log px(x)).\n\n(7.6)\n\nthe first term is essentially the same as the log-likelihood function; the second\nterm penalizes choices of x that are unlikely, according to the prior density (i.e., x\nwith px(x) small).\n\nbrushing aside the philosophical differences in setup, the only difference between\nfinding the map estimate (via (7.6)) and the ml estimate (via (7.1)) is the presence\nof an extra term in the optimization problem, associated with the prior density of\nx. therefore, for any maximum likelihood estimation problem with concave log-\nlikelihood function, we can add a prior density for x that is log-concave, and the\nresulting map estimation problem will be convex.\n\nlinear measurements with iid noise\nsuppose that x \u2208 rn and y \u2208 rm are related by\n\nyi = at\n\ni x + vi,\n\ni = 1, . . . , m,\n\nwhere vi are iid with density pv on r, and x has prior density px on rn. the\njoint density of x and y is then\n\np(x, y) = px(x)\n\npv(yi \u2212 at\n\ni x),\n\nmyi=1\nlog px(x) +pm\n\nand the map estimate can be found by solving the optimization problem\n\nmaximize\n\ni=1 log pv(yi \u2212 at\n\ni x).\n\n(7.7)\n\nif px and pv are log-concave, this problem is convex. the only difference between\nthe map estimation problem (7.7) and the associated ml estimation problem (7.2)\nis the extra term log px(x).\n\n "}, {"Page_number": 373, "text": "7.2 nonparametric distribution estimation\n\n359\n\nfor example, if vi are uniform on [\u2212a, a], and the prior distribution of x is\ngaussian with mean \u00afx and covariance \u03c3, the map estimate is found by solving\nthe qp\n\nminimize\nsubject to\n\n(x \u2212 \u00afx)t \u03c3\u22121(x \u2212 \u00afx)\nkax \u2212 yk\u221e \u2264 a,\n\nwith variable x.\n\nmap with perfect linear measurements\nsuppose x \u2208 rn is a vector of parameters to be estimated, with prior density\npx. we have m perfect (noise free, deterministic) linear measurements, given by\ny = ax. in other words, the conditional distribution of y, given x, is a point mass\nwith value one at the point ax. the map estimate can be found by solving the\nproblem\n\nmaximize\nlog px(x)\nsubject to ax = y.\n\nif px is log-concave, this is a convex problem.\n\nif under the prior distribution, the parameters xi are iid with density p on r,\n\nthen the map estimation problem has the form\n\nmaximize pn\n\nsubject to ax = y,\n\ni=1 log p(xi)\n\nwhich is a least-penalty problem ((6.6), page 304), with penalty function \u03c6(u) =\n\u2212 log p(u).\n\nconversely, we can interpret any least-penalty problem,\n\nminimize\nsubject to ax = b\n\n\u03c6(x1) + \u00b7\u00b7\u00b7 + \u03c6(xn)\n\nas a map estimation problem, with m perfect linear measurements (i.e., ax = b)\nand xi iid with density\n\np(z) =\n\n.\n\ne\u2212\u03c6(z)\n\nr e\u2212\u03c6(u) du\n\n7.2 nonparametric distribution estimation\n\nwe consider a random variable x with values in the finite set {\u03b11, . . . , \u03b1n} \u2286 r.\n(we take the values to be in r for simplicity; the same ideas can be applied when\nthe values are in rk, for example.) the distribution of x is characterized by\np \u2208 rn, with prob(x = \u03b1k) = pk. clearly, p satisfies p (cid:23) 0, 1t p = 1. conversely,\nif p \u2208 rn satisfies p (cid:23) 0, 1t p = 1, then it defines a probability distribution for a\nrandom variable x, defined as prob(x = \u03b1k) = pk. thus, the probability simplex\n\n{p \u2208 rn | p (cid:23) 0, 1t p = 1}\n\n "}, {"Page_number": 374, "text": "360\n\n7 statistical estimation\n\nis in one-to-one correspondence with all possible probability distributions for a\nrandom variable x taking values in {\u03b11, . . . , \u03b1n}.\nin this section we discuss methods used to estimate the distribution p based on\na combination of prior information and, possibly, observations and measurements.\n\nprior information\n\nmany types of prior information about p can be expressed in terms of linear equality\nconstraints or inequalities. if f : r \u2192 r is any function, then\n\ne f (x) =\n\npif (\u03b1i)\n\nnxi=1\n\nis a linear function of p. as a special case, if c \u2286 r, then prob(x \u2208 c) is a linear\nfunction of p:\n\nprob(x \u2208 c) = ct p,\n\nci =(cid:26) 1 \u03b1i \u2208 c\n\n0 \u03b1i 6\u2208 c.\n\nit follows that known expected values of certain functions (e.g., moments) or known\nprobabilities of certain sets can be incorporated as linear equality constraints on\np \u2208 rn. inequalities on expected values or probabilities can be expressed as linear\ninequalities on p \u2208 rn.\nfor example, suppose we know that x has mean e x = \u03b1, second moment\ne x 2 = \u03b2, and prob(x \u2265 0) \u2264 0.3. this prior information can be expressed as\n\ne x =\n\nnxi=1\n\n\u03b1ipi = \u03b1,\n\ne x 2 =\n\nnxi=1\n\n\u03b12\n\ni pi = \u03b2, x\u03b1i\u22650\n\npi \u2264 0.3,\n\nwhich are two linear equalities and one linear inequality in p.\n\nwe can also include some prior constraints that involve nonlinear functions of\n\np. as an example, the variance of x is given by\n\nvar(x) = e x 2 \u2212 (e x)2 =\n\n\u03b12\n\ni pi \u2212  nxi=1\n\nnxi=1\n\n\u03b1ipi!2\n\n.\n\nthe first term is a linear function of p and the second term is concave quadratic\nin p, so the variance of x is a concave function of p. it follows that a lower bound\non the variance of x can be expressed as a convex quadratic inequality on p.\n\nas another example, suppose a and b are subsets of r, and consider the\n\nconditional probability of a given b:\n\nprob(x \u2208 a|x \u2208 b) =\n\nprob(x \u2208 a \u2229 b)\n\nprob(x \u2208 b)\n\n.\n\nthis function is linear-fractional in p \u2208 rn: it can be expressed as\n\nwhere\n\nprob(x \u2208 a|x \u2208 b) = ct p/dt p,\n\nci =(cid:26) 1 \u03b1i \u2208 a \u2229 b\n\n0 \u03b1i 6\u2208 a \u2229 b\n\n,\n\ndi =(cid:26) 1 \u03b1i \u2208 b\n\n0 \u03b1i 6\u2208 b.\n\n "}, {"Page_number": 375, "text": "7.2 nonparametric distribution estimation\n\n361\n\ntherefore we can express the prior constraints\n\nl \u2264 prob(x \u2208 a|x \u2208 b) \u2264 u\n\nas the linear inequality constraints on p\n\nldt p \u2264 ct p \u2264 udt p.\n\nseveral other types of prior information can be expressed in terms of nonlinear\n\nconvex inequalities. for example, the entropy of x, given by\n\n\u2212\n\nnxi=1\n\npi log pi,\n\nis a concave function of p, so we can impose a minimum value of entropy as a convex\ninequality on p. if q represents another distribution, i.e., q (cid:23) 0, 1t q = 1, then\nthe kullback-leibler divergence between the distribution q and the distribution p\nis given by\n\npi log(pi/qi),\n\nnxi=1\n\nwhich is convex in p (and q as well; see example 3.19, page 90). it follows that\nwe can impose a maximum kullback-leibler divergence between p and a given\ndistribution q, as a convex inequality on p.\n\nin the next few paragraphs we express the prior information about the distribu-\ntion p as p \u2208 p. we assume that p can be described by a set of linear equalities and\nconvex inequalities. we include in the prior information p the basic constraints\np (cid:23) 0, 1t p = 1.\nbounding probabilities and expected values\ngiven prior information about the distribution, say p \u2208 p, we can compute upper\nor lower bounds on the expected value of a function, or probability of a set. for\nexample to determine a lower bound on e f (x) over all distributions that satisfy\nthe prior information p \u2208 p, we solve the convex problem\n\nminimize pn\n\nsubject to p \u2208 p.\n\ni=1 f (\u03b1i)pi\n\nmaximum likelihood estimation\n\nwe can use maximum likelihood estimation to estimate p based on observations\nfrom the distribution. suppose we observe n independent samples x1, . . . , xn from\nthe distribution. let ki denote the number of these samples with value \u03b1i, so that\nk1 + \u00b7\u00b7\u00b7 + kn = n , the total number of observed samples. the log-likelihood\nfunction is then\n\nl(p) =\n\nki log pi,\n\nnxi=1\n\n "}, {"Page_number": 376, "text": "362\n\n7 statistical estimation\n\nwhich is a concave function of p. the maximum likelihood estimate of p can be\nfound by solving the convex problem\n\nmaximize\nsubject to p \u2208 p,\n\nl(p) =pn\n\ni=1 ki log pi\n\nwith variable p.\n\nmaximum entropy\n\nthe maximum entropy distribution consistent with the prior assumptions can be\nfound by solving the convex problem\n\nminimize pn\n\nsubject to p \u2208 p.\n\ni=1 pi log pi\n\nenthusiasts describe the maximum entropy distribution as the most equivocal or\nmost random, among those consistent with the prior information.\n\nminimum kullback-leibler divergence\n\nwe can find the distribution p that has minimum kullback-leibler divergence from\na given prior distribution q, among those consistent with prior information, by\nsolving the convex problem\n\nminimize pn\n\nsubject to p \u2208 p,\n\ni=1 pi log(pi/qi)\n\nnote that when the prior distribution is the uniform distribution, i.e., q = (1/n)1,\nthis problem reduces to the maximum entropy problem.\n\nexample 7.2 we consider a probability distribution on 100 equidistant points \u03b1i in\nthe interval [\u22121, 1]. we impose the following prior assumptions:\n\ne x \u2208 [\u22120.1, 0.1]\ne x 2 \u2208 [0.5, 0.6]\ne(3x 3 \u2212 2x) \u2208 [\u22120.3, \u22120.2]\nprob(x < 0) \u2208 [0.3, 0.4].\n\n(7.8)\n\nalong with the constraints 1t p = 1, p (cid:23) 0, these constraints describe a polyhedron\nof probability distributions.\n\nfigure 7.2 shows the maximum entropy distribution that satisfies these constraints.\nthe maximum entropy distribution satisfies\n\ne x = 0.056\ne x 2 = 0.5\ne(3x 3 \u2212 2x) = \u22120.2\nprob(x < 0) = 0.4.\n\nto illustrate bounding probabilities, we compute upper and lower bounds on the\ncumulative distribution prob(x \u2264 \u03b1i), for i = 1, . . . , 100. for each value of i,\n\n "}, {"Page_number": 377, "text": "7.2 nonparametric distribution estimation\n\n363\n\n0.04\n\n0.03\n\n0.02\n\n0.01\n\n)\ni\n\n\u03b1\n=\nx\n(\nb\no\nr\np\n=\n\ni\np\n\n0\n\u22121\n\n\u22120.5\n\n0\n\u03b1i\n\n0.5\n\n1\n\nfigure 7.2 maximum entropy distribution that satisfies the constraints (7.8).\n\nwe solve two lps: one that maximizes prob(x \u2264 \u03b1i), and one that minimizes\nprob(x \u2264 \u03b1i), over all distributions consistent with the prior assumptions (7.8).\nthe results are shown in figure 7.3. the upper and lower curves show the upper and\nlower bounds, respectively; the middle curve shows the cumulative distribution of the\nmaximum entropy distribution.\n\nexample 7.3 bounding risk probability with known marginal distributions. suppose x\nand y are two random variables that give the return on two investments. we assume\nthat x takes values in {\u03b11, . . . , \u03b1n} \u2286 r and y takes values in {\u03b21, . . . , \u03b2m} \u2286 r,\nwith pij = prob(x = \u03b1i, y = \u03b2j). the marginal distributions of the two returns x\nand y are known, i.e.,\n\npij = ri,\n\ni = 1, . . . , n,\n\nmxj=1\n\nnxi=1\n\npij = qj,\n\nj = 1, . . . , m,\n\n(7.9)\n\nbut otherwise nothing is known about the joint distribution p. this defines a poly-\nhedron of joint distributions consistent with the given marginals.\n\nnow suppose we make both investments, so our total return is the random variable\nx + y . we are interested in computing an upper bound on the probability of some\nlevel of loss, or low return, i.e., prob(x + y < \u03b3). we can compute a tight upper\nbound on this probability by solving the lp\n\nmaximize p{pij | \u03b1i + \u03b2j < \u03b3}\n\npij \u2265 0,\n\nsubject to\n\n(7.9),\n\ni = 1, . . . n,\n\nj = 1, . . . , m.\n\nthe optimal value of this lp is the maximum probability of loss. the optimal\nsolution p\u22c6 is the joint distribution, consistent with the given marginal distributions,\nthat maximizes the probability of the loss.\n\nthe same method can be applied to a derivative of the two investments. let r(x, y )\nbe the return of the derivative, where r : r2 \u2192 r. we can compute sharp lower\n\n "}, {"Page_number": 378, "text": "364\n\n7 statistical estimation\n\n)\ni\n\n\u03b1\n\u2264\nx\n(\nb\no\nr\np\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n\n\u22121\n\n\u22120.5\n\n0\n\u03b1i\n\n0.5\n\n1\n\nfigure 7.3 the top and bottom curves show the maximum and minimum\npossible values of the cumulative distribution function, prob(x \u2264 \u03b1i), over\nall distributions that satisfy (7.8). the middle curve is the cumulative dis-\ntribution of the maximum entropy distribution that satisfies (7.8).\n\nand upper bounds on prob(r < \u03b3) by solving a similar lp, with objective function\n\nwhich we can minimize and maximize.\n\nx{pij | r(\u03b1i, \u03b2j) < \u03b3} ,\n\n7.3 optimal detector design and hypothesis testing\n\nsuppose x is a random variable with values in {1, . . . , n}, with a distribution that\ndepends on a parameter \u03b8 \u2208 {1, . . . , m}. the distributions of x, for the m possible\nvalues of \u03b8, can be represented by a matrix p \u2208 rn\u00d7m, with elements\n\npkj = prob(x = k | \u03b8 = j).\n\nthe jth column of p gives the probability distribution associated with the param-\neter value \u03b8 = j.\n\nwe consider the problem of estimating \u03b8, based on an observed sample of x. in\nother words, the sample x is generated from one of the m possible distributions,\nand we are to guess which one. the m values of \u03b8 are called hypotheses, and guessing\nwhich hypothesis is correct (i.e., which distribution generated the observed sample\nx) is called hypothesis testing. in many cases one of the hypotheses corresponds\nto some normal situation, and each of the other hypotheses corresponds to some\nabnormal event. in this case hypothesis testing can be interpreted as observing a\n\n "}, {"Page_number": 379, "text": "7.3 optimal detector design and hypothesis testing\n\n365\n\nvalue of x, and then guessing whether or not an abnormal event has occurred, and\nif so, which one. for this reason hypothesis testing is also called detection.\n\nin most cases there is no significance to the ordering of the hypotheses; they are\nsimply m different hypotheses, arbitrarily labeled \u03b8 = 1, . . . , m. if \u02c6\u03b8 = \u03b8, where \u02c6\u03b8\ndenotes the estimate of \u03b8, then we have correctly guessed the parameter value \u03b8. if\n\u02c6\u03b8 6= \u03b8, then we have (incorrectly) guessed the parameter value \u03b8; we have mistaken\n\u02c6\u03b8 for \u03b8. in other cases, there is significance in the ordering of the hypotheses. in this\ncase, an event such as \u02c6\u03b8 > \u03b8, i.e., the event that we overestimate \u03b8, is meaningful.\nit is also possible to parametrize \u03b8 by values other than {1, . . . , m}, say as \u03b8 \u2208\n{\u03b81, . . . , \u03b8m}, where \u03b8i are (distinct) values. these values could be real numbers, or\nvectors, for example, specifying the mean and variance of the kth distribution. in\nthis case, a quantity such as k\u02c6\u03b8\u2212 \u03b8k, which is the norm of the parameter estimation\nerror, is meaningful.\n\n7.3.1 deterministic and randomized detectors\n\na (deterministic) estimator or detector is a function \u03c8 from {1, . . . , n} (the set of\npossible observed values) into {1, . . . , m} (the set of hypotheses). if x is observed\nto have value k, then our guess for the value of \u03b8 is \u02c6\u03b8 = \u03c8(k). one obvious\ndeterministic detector is the maximum likelihood detector, given by\n\n\u02c6\u03b8 = \u03c8ml(k) = argmax\n\nj\n\npkj.\n\n(7.10)\n\nwhen we observe the value x = k, the maximum likelihood estimate of \u03b8 is a\nvalue that maximizes the probability of observing x = k, over the set of possible\ndistributions.\n\nwe will consider a generalization of the deterministic detector, in which the\nestimate of \u03b8, given an observed value of x, is random. a randomized detector\nof \u03b8 is a random variable \u02c6\u03b8 \u2208 {1, . . . , m}, with a distribution that depends on the\nobserved value of x. a randomized detector can be defined in terms of a matrix\nt \u2208 rm\u00d7n with elements\n\ntik = prob(\u02c6\u03b8 = i | x = k).\n\nthe interpretation is as follows: if we observe x = k, then the detector gives \u02c6\u03b8 = i\nwith probability tik. the kth column of t , which we will denote tk, gives the\nprobability distribution of \u02c6\u03b8, when we observe x = k. if each column of t is a\nunit vector, then the randomized detector is a deterministic detector, i.e., \u02c6\u03b8 is a\n(deterministic) function of the observed value of x.\n\nat first glance, it seems that intentionally introducing additional randomiza-\ntion into the estimation or detection process can only make the estimator worse.\nbut we will see below examples in which a randomized detector outperforms all\ndeterministic estimators.\n\nwe are interested in designing the matrix t that defines the randomized detec-\ntor. obviously the columns tk of t must satisfy the (linear equality and inequality)\nconstraints\n\ntk (cid:23) 0,\n\n1t tk = 1.\n\n(7.11)\n\n "}, {"Page_number": 380, "text": "366\n\n7 statistical estimation\n\n7.3.2 detection probability matrix\n\nfor the randomized detector defined by the matrix t , we define the detection\nprobability matrix as d = t p . we have\n\ndij = (t p )ij = prob(\u02c6\u03b8 = i | \u03b8 = j),\n\nso dij is the probability of guessing \u02c6\u03b8 = i, when in fact \u03b8 = j. the m \u00d7 m\ndetection probability matrix d characterizes the performance of the randomized\ndetector defined by t . the diagonal entry dii is the probability of guessing \u02c6\u03b8 = i\nwhen \u03b8 = i, i.e., the probability of correctly detecting that \u03b8 = i. the off-diagonal\nentry dij (with i 6= j) is the probability of mistaking \u03b8 = i for \u03b8 = j, i.e., the\nprobability that our guess is \u02c6\u03b8 = i, when in fact \u03b8 = j. if d = i, the detector is\nperfect: no matter what the parameter \u03b8 is, we correctly guess \u02c6\u03b8 = \u03b8.\n\nthe diagonal entries of d, arranged in a vector, are called the detection proba-\n\nbilities, and denoted p d:\n\ni = dii = prob(\u02c6\u03b8 = i | \u03b8 = i).\np d\n\nthe error probabilities are the complements, and are denoted p e:\n\ni = 1 \u2212 dii = prob(\u02c6\u03b8 6= i | \u03b8 = i).\np e\n\nsince the columns of the detection probability matrix d add up to one, we can\nexpress the error probabilities as\n\np e\n\ni =xj6=i\n\ndji.\n\n7.3.3 optimal detector design\n\nin this section we show that a wide variety of objectives for detector design are\nlinear, affine, or convex piecewise-linear functions of d, and therefore also of t\n(which is the optimization variable). similarly, a variety of constraints for detector\ndesign can be expressed in terms of linear inequalities in d. it follows that a wide\nvariety of optimal detector design problems can be expressed as lps. we will see\nin \u00a77.3.4 that some of these lps have simple solutions; in this section we simply\nformulate the problem.\n\nlimits on errors and detection probabilities\n\nwe can impose a lower bound on the probability of correctly detecting the jth\nhypothesis,\n\np d\nj = djj \u2265 lj,\n\nwhich is a linear inequality in d (hence, t ). similarly, we can impose a maximum\nallowable probability for mistaking \u03b8 = i for \u03b8 = j:\n\ndij \u2264 uij,\n\n "}, {"Page_number": 381, "text": "7.3 optimal detector design and hypothesis testing\n\n367\n\nwhich are also linear constraints on t . we can take any of the detection prob-\nabilities as an objective to be maximized, or any of the error probabilities as an\nobjective to be minimized.\n\nminimax detector design\n\nwe can take as objective (to be minimized) the minimax error probability, maxj p e\nj ,\nwhich is a piecewise-linear convex function of d (hence, also of t ). with this as\nthe only objective, we have the problem of minimizing the maximum probability\nof detection error,\n\nminimize maxj p e\nj\ntk (cid:23) 0,\nsubject to\n\n1t tk = 1,\n\nk = 1, . . . , n,\n\nwhere the variables are t1, . . . , tn \u2208 rm. this can be reformulated as an lp. the\nminimax detector minimizes the worst-case (largest) probability of error over all m\nhypotheses.\n\nwe can, of course, add further constraints to the minimax detector design prob-\n\nlem.\n\nbayes detector design\n\nin bayes detector design, we have a prior distribution for the hypotheses, given by\nq \u2208 rm, where\n\nqi = prob(\u03b8 = i).\n\nin this case, the probabilities pij are interpreted as conditional probabilities of x,\ngiven \u03b8. the probability of error for the detector is then given by qt p e, which is\nan affine function of t . the bayes optimal detector is the solution of the lp\n\nminimize\nsubject to\n\nqt p e\ntk (cid:23) 0,\n\n1t tk = 1,\n\nk = 1, . . . , n.\n\nwe will see in \u00a77.3.4 that this problem has a simple analytical solution.\none special case is when q = (1/m)1. in this case the bayes optimal detector\nminimizes the average probability of error, where the (unweighted) average is over\nthe hypotheses. in \u00a77.3.4 we will see that the maximum likelihood detector (7.10)\nis optimal for this problem.\n\nbias, mean-square error, and other quantities\n\nin this section we assume that the ordering of the values of \u03b8 have some significance,\ni.e., that the value \u03b8 = i can be interpreted as a larger value of the parameter than\n\u03b8 = j, when i > j. this might be the case, for example, when \u03b8 = i corresponds to\nthe hypothesis that i events have occurred. here we may be interested in quantities\nsuch as\n\nwhich is the probability that we overestimate \u03b8 when \u03b8 = i. this is an affine\nfunction of d:\n\nprob(\u02c6\u03b8 > \u03b8 | \u03b8 = i),\nprob(\u02c6\u03b8 > \u03b8 | \u03b8 = i) =xj>i\n\ndji,\n\n "}, {"Page_number": 382, "text": "368\n\n7 statistical estimation\n\nso a maximum allowable value for this probability can be expressed as a linear\ninequality on d (hence, t ). as another example, the probability of misclassifying\n\u03b8 by more than one, when \u03b8 = i,\n\nprob(|\u02c6\u03b8 \u2212 \u03b8| > 1 | \u03b8 = i) = x|j\u2212i|>1\n\ndji,\n\nis also a linear function of d.\n\nwe now suppose that the parameters have values {\u03b81, . . . , \u03b8m} \u2286 r. the es-\ntimation or detection (parameter) error is then given by \u02c6\u03b8 \u2212 \u03b8, and a number of\nquantities of interest are given by linear functions of d. examples include:\n\n\u2022 bias. the bias of the detector, when \u03b8 = \u03b8i, is given by the linear function\n\ne\ni\n\n(\u02c6\u03b8 \u2212 \u03b8) =\n\nmxj=1\n\n(\u03b8j \u2212 \u03b8i)dji,\n\nwhere the subscript on e means the expectation is with respect to the dis-\ntribution of the hypothesis \u03b8 = \u03b8i.\n\n\u2022 mean square error. the mean square error of the detector, when \u03b8 = \u03b8i, is\n\ngiven by the linear function\n\ne\ni\n\n(\u02c6\u03b8 \u2212 \u03b8)2 =\n\nmxj=1\n\n(\u03b8j \u2212 \u03b8i)2dji.\n\n\u2022 average absolute error. the average absolute error of the detector, when\n\n\u03b8 = \u03b8i, is given by the linear function\n\ne\n\ni |\u02c6\u03b8 \u2212 \u03b8| =\n\nmxj=1\n\n|\u03b8j \u2212 \u03b8i|dji.\n\n7.3.4 multicriterion formulation and scalarization\n\nthe optimal detector design problem can be considered a multicriterion problem,\nwith the constraints (7.11), and the m(m \u2212 1) objectives given by the off-diagonal\nentries of d, which are the probabilities of the different types of detection error:\n\nminimize (w.r.t. rm(m\u22121)\nsubject to\n\n+\n\n) dij,\n\ntk (cid:23) 0,\n\ni, j = 1, . . . , m,\n\ni 6= j\n\n1t tk = 1,\n\nk = 1, . . . , n,\n\n(7.12)\n\nwith variables t1, . . . , tn \u2208 rm. since each objective dij is a linear function of the\nvariables, this is a multicriterion linear program.\nwe can scalarize this multicriterion problem by forming the weighted sum ob-\n\njective\n\nwijdij = tr(w t d)\n\nmxi,j=1\n\n "}, {"Page_number": 383, "text": "7.3 optimal detector design and hypothesis testing\n\n369\n\nwhere the weight matrix w \u2208 rm\u00d7m satisfies\nwij > 0,\n\ni = 1, . . . , m,\n\nwii = 0,\n\ni, j = 1, . . . , m,\n\ni 6= j.\n\nthis objective is a weighted sum of the m(m \u2212 1) error probabilities, with weight\nwij associated with the error of guessing \u02c6\u03b8 = i when in fact \u03b8 = j. the weight\nmatrix is sometimes called the loss matrix.\n\nto find a pareto optimal point for the multicriterion problem (7.12), we form\n\nthe scalar optimization problem\n\nminimize\nsubject to\n\ntr(w t d)\ntk (cid:23) 0,\n\n1t tk = 1,\n\nk = 1, . . . , n,\n\n(7.13)\n\nwhich is an lp. this lp is separable in the variables t1, . . . , tn. the objective can\nbe expressed as a sum of (linear) functions of tk:\n\ntr(w t d) = tr(w t t p ) = tr(p w t t ) =\n\nct\nk tk,\n\nnxk=1\n\nwhere ck is the kth column of w p t . the constraints are separable (i.e., we have\nseparate constraints on each ti). therefore we can solve the lp (7.13) by separately\nsolving\n\nminimize\nsubject to\n\nct\nk tk\ntk (cid:23) 0,\n\n1t tk = 1,\n\nfor k = 1, . . . , n. each of these lps has a simple analytical solution (see exer-\ncise 4.8). we first find an index q such that ckq = minj ckj. then we take t\u22c6\nk = eq.\nthis optimal point corresponds to a deterministic detector: when x = k is ob-\nserved, our estimate is\n\n\u02c6\u03b8 = argmin\n\nj\n\n(w p t )jk.\n\n(7.14)\n\nthus, for every weight matrix w with positive off-diagonal elements we can find\na deterministic detector that minimizes the weighted sum objective. this seems\nto suggest that randomized detectors are not needed, but we will see this is not\nthe case. the pareto optimal trade-off surface for the multicriterion lp (7.12) is\npiecewise-linear; the deterministic detectors of the form (7.14) correspond to the\nvertices on the pareto optimal surface.\n\nmap and ml detectors\n\nconsider a bayes detector design with prior distribution q. the mean probability\nof error is\n\nqt p e =\n\nmxj=1\n\nqjxi6=j\n\ndij =\n\nmxi,j=1\n\nwijdij,\n\nif we define the weight matrix w as\n\nwij = qj,\n\ni, j = 1, . . . , m,\n\ni 6= j,\n\nwii = 0,\n\ni = 1, . . . , m.\n\n "}, {"Page_number": 384, "text": "370\n\n7 statistical estimation\n\nthus, a bayes optimal detector is given by the deterministic detector (7.14), with\n\n(w p t )jk =xi6=j\n\nqipki =\n\nmxi=1\n\nqipki \u2212 qjpkj.\n\nthe first term is independent of j, so the optimal detector is simply\n\n\u02c6\u03b8 = argmax\n\nj\n\n(pkjqj),\n\nwhen x = k is observed. the solution has a simple interpretation: since pkjqj\ngives the probability that \u03b8 = j and x = k, this detector is a maximum a posteriori\nprobability (map) detector.\n\nfor the special case q = (1/m)1, i.e., a uniform prior distribution on \u03b8, this\n\nmap detector reduces to a maximum likelihood (ml) detector:\n\n\u02c6\u03b8 = argmax\n\nj\n\npkj.\n\nthus, a maximum likelihood detector minimizes the (unweighted) average or mean\nprobability of error.\n\n7.3.5 binary hypothesis testing\n\nas an illustration, we consider the special case m = 2, which is called binary\nhypothesis testing. the random variable x is generated from one of two distribu-\ntions, which we denote p \u2208 rn and q \u2208 rn, to simplify the notation. often the\nhypothesis \u03b8 = 1 corresponds to some normal situation, and the hypothesis \u03b8 = 2\ncorresponds to some abnormal event that we are trying to detect. if \u02c6\u03b8 = 1, we say\nthe test is negative (i.e., we guess that the event did not occur); if \u02c6\u03b8 = 2, we say\nthe test is positive (i.e., we guess that the event did occur).\n\nthe detection probability matrix d \u2208 r2\u00d72 is traditionally expressed as\n\nd =(cid:20) 1 \u2212 pfp\n\npfp\n\npfn\n\n1 \u2212 pfn (cid:21) .\n\nhere pfn is the probability of a false negative (i.e., the test is negative when in fact\nthe event has occurred) and pfp is the probability of a false positive (i.e., the test\nis positive when in fact the event has not occurred), which is also called the false\nalarm probability. the optimal detector design problem is a bi-criterion problem,\nwith objectives pfn and pfp.\n\nthe optimal trade-off curve between pfn and pfp is called the receiver operating\ncharacteristic (roc), and is determined by the distributions p and q. the roc\ncan be found by scalarizing the bi-criterion problem, as described in \u00a77.3.4. for\nthe weight matrix w , an optimal detector (7.14) is\n\n\u02c6\u03b8 =(cid:26) 1 w21pk > w12qk\n\n2 w21pk \u2264 w12qk\n\n "}, {"Page_number": 385, "text": "7.3 optimal detector design and hypothesis testing\n\n371\n\nn\nf\np\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n0\n\n1\n\n2\n\n4\n\n3\n\n0.2\n\n0.4\n\npfp\n\n0.6\n\n0.8\n\n1\n\nfigure 7.4 optimal trade-off curve between probability of a false negative,\nand probability of a false positive test result, for the matrix p given in (7.15).\nthe vertices of the trade-off curve, labeled 1\u20133, correspond to deterministic\ndetectors; the point labeled 4, which is a randomized detector, is the mini-\nmax detector. the dashed line shows pfn = pfp, the points where the error\nprobabilities are equal.\n\nwhen x = k is observed. this is called a likelihood ratio threshold test:\nif the\nratio pk/qk is more than the threshold w12/w21, the test is negative (i.e., \u02c6\u03b8 =\n1); otherwise the test is positive. by choosing different values of the threshold,\nwe obtain (deterministic) pareto optimal detectors that give different levels of\nfalse positive versus false negative error probabilities. this result is known as\nthe neyman-pearson lemma.\n\nthe likelihood ratio detectors do not give all the pareto optimal detectors; they\n\nare the vertices of the optimal trade-off curve, which is piecewise-linear.\n\nexample 7.4 we consider a binary hypothesis testing example with n = 4, and\n\n(7.15)\n\nthe optimal trade-off curve between pfn and pfp, i.e., the receiver operating curve,\nis shown in figure 7.4. the left endpoint corresponds to the detector which is always\nnegative, independent of the observed value of x; the right endpoint corresponds to\nthe detector that is always positive. the vertices labeled 1, 2, and 3 correspond to\nthe deterministic detectors\n\np =\uf8ee\uf8ef\uf8f0\n\n0.70\n0.20\n0.05\n0.05\n\n0.10\n0.10\n0.70\n0.10\n\n\uf8f9\uf8fa\uf8fb .\n\nt (1) = (cid:20) 1\nt (2) = (cid:20) 1\n\n0\n\n0\n\n1\n0\n\n1\n0\n\n0\n1\n\n0\n1\n\n1\n\n0 (cid:21) ,\n1 (cid:21) ,\n\n0\n\n "}, {"Page_number": 386, "text": "372\n\n7 statistical estimation\n\nrespectively. the point labeled 4 corresponds to the nondeterministic detector\n\n0\n\nt (3) = (cid:20) 1\nt (4) =(cid:20) 1\n\n0\n\n0\n1\n\n0\n1\n\n2/3\n1/3\n\n0\n1\n\n0\n\n1 (cid:21) ,\n1 (cid:21) ,\n\n0\n\nwhich is the minimax detector. this minimax detector yields equal probability of\na false positive and false negative, which in this case is 1/6. every deterministic\ndetector has either a false positive or false negative probability that exceeds 1/6,\nso this is an example where a randomized detector outperforms every deterministic\ndetector.\n\n7.3.6 robust detectors\n\nso far we have assumed that p , which gives the distribution of the observed variable\nx, for each value of the parameter \u03b8, is known. in this section we consider the case\nwhere these distributions are not known, but certain prior information about them\nis given. we assume that p \u2208 p, where p is the set of possible distributions. with\na randomized detector characterized by t , the detection probability matrix d now\ndepends on the particular value of p . we will judge the error probabilities by\ntheir worst-case values, over p \u2208 p. we define the worst-case detection probability\nmatrix dwc as\n\nand\n\ndwc\n\nij = sup\np \u2208p\n\ndij,\n\ni, j = 1, . . . , m,\n\ni 6= j\n\ndwc\n\nii = inf\np \u2208p\n\ndii,\n\ni = 1, . . . , m.\n\nthe off-diagonal entries give the largest possible probability of errors, and the\ndiagonal entries give the smallest possible probability of detection, over p \u2208 p.\n6= 1 in general, i.e., the columns of a worst-case detection\nprobability matrix do not necessarily add up to one.\n\ni=1 dwc\nij\n\nnote that pn\n\nwe define the worst-case probability of error as\n\np wce\ni = 1 \u2212 dwc\nii .\n\ni\n\nis the largest probability of error, when \u03b8 = i, over all possible distri-\n\nthus, p wce\nbutions in p.\nusing the worst-case detection probability matrix, or the worst-case probability\nof error vector, we can develop various robust versions of detector design problems.\nin the rest of this section we concentrate on the robust minimax detector design\nproblem, as a generic example that illustrates the ideas.\n\nwe define the robust minimax detector as the detector that minimizes the worst-\n\ncase probability of error, over all hypotheses, i.e., minimizes the objective\n\nmax\n\ni\n\np wce\n\ni = max\n\ni=1,...,m\n\nsup\np \u2208p\n\n(1 \u2212 (t p )ii) = 1 \u2212 min\n\ni=1,...,m\n\ninf\np \u2208p\n\n(t p )ii.\n\nthe robust minimax detector minimizes the worst possible probability of error,\nover all m hypotheses, and over all p \u2208 p.\n\n "}, {"Page_number": 387, "text": "7.3 optimal detector design and hypothesis testing\n\n373\n\nrobust minimax detector for finite p\nwhen the set of possible distributions is finite, the robust minimax detector design\nproblem is readily formulated as an lp. with p = {p1, . . . , pk}, we can find the\nrobust minimax detector by solving\n\nmaximize mini=1,...,m inf p \u2208p (t p )ii = mini=1,...,m minj=1,...,k(t pj)ii\nsubject to\n\ni = 1, . . . , n,\n\n1t ti = 1,\n\nti (cid:23) 0,\n\nthe objective is piecewise-linear and concave, so this problem can be expressed as\nan lp. note that we can just as well consider p to be the polyhedron conv p;\nthe associated worst-case detection matrix, and robust minimax detector, are the\nsame.\n\nrobust minimax detector for polyhedral p\nit is also possible to efficiently formulate the robust minimax detector problem as an\nlp when p is a polyhedron described by linear equality and inequality constraints.\nthis formulation is less obvious, and relies on a dual representation of p.\n\nto simplify the discussion, we assume that p has the form\n\np =(cid:8)p = [p1 \u00b7\u00b7\u00b7 pm] (cid:12)(cid:12) akpk = bk, 1t pk = 1, pk (cid:23) 0(cid:9) .\n\nin other words, for each distribution pk, we are given some expected values akpk =\nbk. (these might represent known moments, probabilities, etc.) the extension to\nthe case where we are given inequalities on expected values is straightforward.\n\n(7.16)\n\nthe robust minimax design problem is\n\nmaximize\nsubject to\n\n\u03b3\ninf{\u02dctt\nti (cid:23) 0,\n\ni p | aip = bi, 1t p = 1, p (cid:23) 0} \u2265 \u03b3,\n\ni = 1, . . . , n,\n\n1t ti = 1,\n\ni = 1, . . . , m\n\nwhere \u02dctt\n\ni denotes the ith row of t (so that (t p )ii = \u02dctt\ninf{\u02dctt\n\ni p | aip = bi, 1t p = 1, p (cid:23) 0} = sup{\u03bdt bi + \u00b5 | at\n\ni pi). by lp duality,\ni \u03bd + \u00b51 (cid:22) \u02dcti}.\n\nusing this, the robust minimax detector design problem can be expressed as the\nlp\n\nmaximize\nsubject to\n\n\u03b3\n\u03bdt\ni bi + \u00b5i \u2265 \u03b3,\ni \u03bdi + \u00b5i1 (cid:22) \u02dcti,\nat\n1t ti = 1,\nti (cid:23) 0,\n\ni = 1, . . . , m\n\ni = 1, . . . , m\n\ni = 1, . . . , n,\n\nwith variables \u03bd1, . . . , \u03bdm, \u00b51, . . . , \u00b5n, and t (which has columns ti and rows \u02dctt\n\ni ).\n\nexample 7.5 robust binary hypothesis testing. suppose m = 2 and the set p in (7.16)\nis defined by\n\na1 = a2 = a =(cid:20) a1\n\na2\n1\n\na2\na2\n2\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\nan\na2\n\nn (cid:21) ,\n\nb1 =(cid:20) \u03b11\n\u03b12 (cid:21) ,\n\nb2 =(cid:20) \u03b21\n\u03b22 (cid:21) .\n\ndesigning a robust minimax detector for this set p can be interpreted as a binary\nhypothesis testing problem: based on an observation of a random variable x \u2208\n{a1, . . . , an}, choose between the following two hypotheses:\n\n "}, {"Page_number": 388, "text": "374\n\n7 statistical estimation\n\n1. e x = \u03b11, e x 2 = \u03b12\n2. e x = \u03b21, e x 2 = \u03b22.\n\nlet \u02dctt denote the first row of t (and so, (1\u2212 \u02dct)t is the second row). for given \u02dct, the\nworst-case probabilities of correct detection are\n\naipi = \u03b11,\n\ndwc\n\ndwc\n\n11 = inf(\u02dctt p (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\nnxi=1\n22 = inf((1 \u2212 \u02dct)t p (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\n\nnxi=1\n\na2\n\nnxi=1\n\ni pi = \u03b12, 1t p = 1, p (cid:23) 0)\nnxi=1\n\ni pi = \u03b22, 1t p = 1, p (cid:23) 0) .\n\na2\n\naipi = \u03b21,\n\nusing lp duality we can express dwc\n\n11 as the optimal value of the lp\n\nmaximize\nsubject to\n\nz0 + z1\u03b11 + z2\u03b12\nz0 + aiz1 + a2\nwith variables z0, z1, z2 \u2208 r. similarly dwc\nmaximize w0 + w1\u03b21 + w2\u03b22\nsubject to w0 + aiw1 + a2\n\ni = 1, . . . , n,\n\ni z2 \u2264 \u02dcti,\n22 is the optimal value of the lp\n\ni w2 \u2264 1 \u2212 \u02dcti,\n\ni = 1, . . . , n,\n\nwith variables w0, w1, w2 \u2208 r. to obtain the minimax detector, we have to maximize\nthe minimum of dwc\n\n22 , i.e., solve the lp\n\n11 and dwc\n\nmaximize\nsubject to\n\n\u03b3\nz0 + z1\u03b12 + z2\u03b12 \u2265 \u03b3\nw0 + \u03b21w1 + \u03b22w2 \u2265 \u03b3\ni \u2264 \u02dcti,\nz0 + z1ai + z2a2\ni \u2264 1 \u2212 \u02dcti,\nw0 + w1ai + w2a2\n0 (cid:22) \u02dct (cid:22) 1.\n\ni = 1, . . . , n\n\ni = 1, . . . , n\n\nthe variables are z0, z1, z2, w0, w1, w2 and \u02dct.\n\n7.4 chebyshev and chernoff bounds\n\nin this section we consider two types of classical bounds on the probability of a set,\nand show that generalizations of each can be cast as convex optimization problems.\nthe original classical bounds correspond to simple convex optimization problems\nwith analytical solutions; the convex optimization formulation of the general cases\nallow us to compute better bounds, or bounds for more complex situations.\n\n7.4.1 chebyshev bounds\n\nchebyshev bounds give an upper bound on the probability of a set based on known\nexpected values of certain functions (e.g., mean and variance). the simplest ex-\nample is markov\u2019s inequality: if x is a random variable on r+ with e x = \u00b5,\n\n "}, {"Page_number": 389, "text": "7.4 chebyshev and chernoff bounds\n\n375\n\nthen we have prob(x \u2265 1) \u2264 \u00b5, no matter what the distribution of x is. an-\nother simple example is chebyshev\u2019s bound: if x is a random variable on r with\ne x = \u00b5 and e(x \u2212 \u00b5)2 = \u03c32, then we have prob(|x \u2212 \u00b5| \u2265 1) \u2264 \u03c32, again no\nmatter what the distribution of x is. the idea behind these simple bounds can be\ngeneralized to a setting in which convex optimization is used to compute a bound\non the probability.\n\nlet x be a random variable on s \u2286 rm, and c \u2286 s be the set for which we\nwant to bound prob(x \u2208 c). let 1c denote the 0-1 indicator function of the set\nc, i.e., 1c(z) = 1 if z \u2208 c and 1c(z) = 0 if z 6\u2208 c.\nour prior knowledge of the distribution consists of known expected values of\nsome functions:\n\ne fi(x) = ai,\n\ni = 1, . . . , n,\n\nwhere fi : rm \u2192 r. we take f0 to be the constant function with value one, for\nwhich we always have e f0(x) = a0 = 1. consider a linear combination of the\nfunctions fi, given by\n\nf (z) =\n\nxifi(z),\n\nnxi=0\n\nwhere xi \u2208 r, i = 0, . . . , n. from our knowledge of e fi(x), we have e f (x) =\nat x.\nnow suppose that f satisfies the condition f (z) \u2265 1c(z) for all z \u2208 s, i.e., f\nis pointwise greater than or equal to the indicator function of c (on s). then we\nhave\n\ne f (x) = at x \u2265 e 1c(x) = prob(x \u2208 c).\n\nin other words, at x is an upper bound on prob(x \u2208 c), valid for all distributions\nsupported on s, with e fi(x) = ai.\nwe can search for the best such upper bound on prob(x \u2208 c), by solving the\n\nproblem\n\nminimize\nsubject to\n\nx0 + a1x1 + \u00b7\u00b7\u00b7 + anxn\n\nf (z) =pn\nf (z) =pn\n\ni=0 xifi(z) \u2265 1 for z \u2208 c\ni=0 xifi(z) \u2265 0 for z \u2208 s, z /\u2208 c,\n\n(7.17)\n\nwith variable x \u2208 rn+1. this problem is always convex, since the constraints can\nbe expressed as\n\ng1(x) = 1 \u2212 inf\n\nz\u2208c\n\nf (z) \u2264 0,\n\ng2(x) = \u2212 inf\n\nz\u2208s\\c\n\nf (z) \u2264 0\n\n(g1 and g2 are convex). the problem (7.17) can also be thought of as a semi-infinite\nlinear program, i.e., an optimization problem with a linear objective and an infinite\nnumber of linear inequalities, one for each z \u2208 s.\nin simple cases we can solve the problem (7.17) analytically. as an example, we\ntake s = r+, c = [1,\u221e), f0(z) = 1, and f1(z) = z, with e f1(x) = e x = \u00b5 \u2264 1\nas our prior information. the constraint f (z) \u2265 0 for z \u2208 s reduces to x0 \u2265 0,\nx1 \u2265 0. the constraint f (z) \u2265 1 for z \u2208 c, i.e., x0 + x1z \u2265 1 for all z \u2265 1, reduces\nto x0 + x1 \u2265 1. the problem (7.17) is then\n\nminimize\nx0 + \u00b5x1\nsubject to x0 \u2265 0,\n\nx1 \u2265 0\n\nx0 + x1 \u2265 1.\n\n "}, {"Page_number": 390, "text": "376\n\n7 statistical estimation\n\nsince 0 \u2264 \u00b5 \u2264 1, the optimal point for this simple lp is x0 = 0, x1 = 1. this gives\nthe classical markov bound prob(x \u2265 1) \u2264 \u00b5.\n\nin other cases we can solve the problem (7.17) using convex optimization.\n\nremark 7.1 duality and the chebyshev bound problem. the chebyshev bound prob-\nlem (7.17) determines a bound on prob(x \u2208 c) for all probability measures that\nsatisfy the given expected value constraints. thus we can think of the chebyshev\nbound problem (7.17) as producing a bound on the optimal value of the infinite-\ndimensional problem\n\nmaximize\nsubject to\n\n\u03c0(dz)\nfi(z)\u03c0(dz) = ai,\n\u03c0(dz) = 1\n\ni = 1, . . . , n\n\n(7.18)\n\nrc\nrs\nrs\n\n\u03c0 \u2265 0,\n\nwhere the variable is the measure \u03c0, and \u03c0 \u2265 0 means that the measure is nonnegative.\nsince the chebyshev problem (7.17) produces a bound on the problem (7.18), it\nshould not be a surprise that they are related by duality. while semi-infinite and\ninfinite-dimensional problems are beyond the scope of this book, we can still formally\nconstruct a dual of the problem (7.17), introducing a lagrange multiplier function\np : s \u2192 r, with p(z) the lagrange multiplier associated with the inequality f (z) \u2265 1\n(for z \u2208 c) or f (z) \u2265 0 (for z \u2208 s\\c). using an integral over z where we would have\na sum in the finite-dimensional case, we arrive at the formal dual\n\nmaximize\nsubject to\n\np(z) dz\nfi(z)p(z) dz = ai,\np(z) dz = 1\n\ni = 1, . . . , n\n\np(z) \u2265 0 for all z \u2208 s,\n\nrc\nrs\nrs\n\nwhere the optimization variable is the function p. this is, essentially, the same\nas (7.18).\n\nprobability bounds with known first and second moments\nas an example, suppose that s = rm, and that we are given the first and second\nmoments of the random variable x:\ne x = a \u2208 rm,\n\ne xx t = \u03c3 \u2208 sm.\n\nin other words, we are given the expected value of the m functions zi, i = 1, . . . , m,\nand the m(m + 1)/2 functions zizj, i, j = 1, . . . , m, but no other information about\nthe distribution.\n\nin this case we can express f as the general quadratic function\n\nf (z) = zt p z + 2qt z + r,\n\nwhere the variables (i.e., the vector x in the discussion above) are p \u2208 sm, q \u2208 rm,\nand r \u2208 r. from our knowledge of the first and second moments, we find that\n\ne f (x) = e(x t p x + 2qt x + r)\n\n= e tr(p xx t ) + 2 e qt x + r\n= tr(\u03c3p ) + 2qt a + r.\n\n "}, {"Page_number": 391, "text": "7.4 chebyshev and chernoff bounds\n\n377\n\nthe constraint that f (z) \u2265 0 for all z can be expressed as the linear matrix in-\nequality\n\n(cid:20) p\n\nqt\n\nq\n\nr (cid:21) (cid:23) 0.\n\nin particular, we have p (cid:23) 0.\n\nnow suppose that the set c is the complement of an open polyhedron,\n\nc = rm \\ p,\n\np = {z | at\n\ni z < bi, i = 1, . . . , k}.\n\nthe condition that f (z) \u2265 1 for all z \u2208 c is the same as requiring that\n\nat\ni z \u2265 bi =\u21d2 zt p z + 2qt z + r \u2265 1\n\nfor i = 1, . . . , k. this, in turn, can be expressed as: there exist \u03c41, . . . , \u03c4k \u2265 0 such\nthat\n\n(cid:20) p\n\nqt\n\nq\n\nr \u2212 1 (cid:21) (cid:23) \u03c4i(cid:20)\n\n0\nat\n\nai/2\n\ni /2 \u2212bi (cid:21) ,\n\ni = 1, . . . , k.\n\n(see \u00a7b.2.)\nas\n\nputting it all together, the chebyshev bound problem (7.17) can be expressed\n\ntr(\u03c3p ) + 2qt a + r\n\nminimize\n\nsubject to (cid:20) p\n(cid:20) p\n\nqt\n\nqt\n\n\u03c4i \u2265 0,\n\nq\n\nr \u2212 1 (cid:21) (cid:23) \u03c4i(cid:20)\nr (cid:21) (cid:23) 0,\n\ni = 1, . . . , k\n\nq\n\n0\nat\n\nai/2\n\ni /2 \u2212bi (cid:21) ,\n\ni = 1, . . . , k\n\n(7.19)\n\nwhich is a semidefinite program in the variables p , q, r, and \u03c41, . . . , \u03c4k. the\noptimal value, say \u03b1, is an upper bound on prob(x \u2208 c) over all distributions\nwith mean a and second moment \u03c3. or, turning it around, 1 \u2212 \u03b1 is a lower bound\non prob(x \u2208 p).\n\nremark 7.2 duality and the chebyshev bound problem. the dual sdp associated\nwith (7.19) can be expressed as\n\nsubject to\n\nmaximize pk\ni=1(cid:20) zi\npk\n(cid:20) zi\n\ni=1 \u03bbi\nat\ni zi \u2265 b\u03bbi,\nzt\ni\nzi\n\nzt\ni\n\n\u03bbi (cid:21) (cid:23) 0,\n\ni = 1, . . . , k\nzi\n\n1 (cid:21)\n\u03bbi (cid:21) (cid:22)(cid:20) \u03c3 a\n\nat\n\ni = 1, . . . , k.\n\nthe variables are zi \u2208 sm, zi \u2208 rm, and \u03bbi \u2208 r, for i = 1, . . . , k. since the\nsdp (7.19) is strictly feasible, strong duality holds and the dual optimum is attained.\n\nwe can give an interesting probability interpretation to the dual problem. suppose\nzi, zi, \u03bbi are dual feasible and that the first r components of \u03bb are positive, and the\n\n "}, {"Page_number": 392, "text": "378\n\n7 statistical estimation\n\ni=1 \u03bbi. with these definitions the dual feasibility constraints can be\n\ni=1 \u03bbi < 1. we define\n\nxi = (1/\u03bbi)zi,\n\nrest are zero. for simplicity we also assume thatpk\n\u03bbixi! ,\nrxi=1\ni! ,\nrxi=1\n\n\u00b5 a \u2212\n\u00b5 \u03c3 \u2212\n\n\u03bbixixt\n\nw0 =\n\ni = 1, . . . , r,\n\nw =\n\n1\n\n1\n\nwhere \u00b5 = 1\u2212pk\n\nexpressed as\n\nand\n\nmoreover, from dual feasibility,\n\nat\ni xi \u2265 bi,\n\ni = 1, . . . , r\n\nxi\n\nwt\n0\n\ni\nxt\ni\n\n\u03bbi(cid:20) xixt\nrxi=1\n\u00b5(cid:20) w w0\n1 (cid:21) = (cid:20) \u03c3 a\n= (cid:20) \u03c3 a\n(cid:23) (cid:20) \u03c3 a\n\n1 (cid:21) + \u00b5(cid:20) w w0\n1 (cid:21) \u2212\n1 (cid:21) \u2212\n1 (cid:21) \u2212\n\nwt\n0\n\nat\n\nat\n\nat\n\n(cid:23) 0.\n\nxi\n\nat\n\ni\nxt\ni\n\n1 (cid:21) =(cid:20) \u03c3 a\n1 (cid:21) .\n1 (cid:21)\n\u03bbi(cid:20) xixt\nrxi=1\nrxi=1(cid:20) (1/\u03bbi)zizt\n\u03bbi (cid:21)\nrxi=1(cid:20) zi\n\u03bbi (cid:21)\n0 = ps\n\nzt\ni\n\nzt\ni\n\nzi\n\nzi\n\ni\n\ntherefore, w (cid:23) w0wt\ni . now\nconsider a discrete random variable x with the following distribution. if s \u2265 1, we\ntake\n\n0 , so it can be factored as w \u2212 w0wt\n\ni=1 wiwt\n\nwith probability \u03bbi,\n\nx = xi\nx = w0 + \u221as wi with probability \u00b5/(2s),\nx = w0 \u2212 \u221as wi with probability \u00b5/(2s),\n\ni = 1, . . . , r\n\ni = 1, . . . , s\ni = 1, . . . , s.\n\nif s = 0, we take\n\nx = xi with probability \u03bbi,\nx = w0 with probability \u00b5.\n\ni = 1, . . . , r\n\nit is easily verified that e x = a and e xx t = \u03c3, i.e., the distribution matches the\ngiven moments. furthermore, since xi \u2208 c,\n\nprob(x \u2208 c) \u2265\n\n\u03bbi.\n\nrxi=1\n\nin particular, by applying this interpretation to the dual optimal solution, we can\nconstruct a distribution that satisfies the chebyshev bound from (7.19) with equality,\nwhich shows that the chebyshev bound is sharp for this case.\n\n "}, {"Page_number": 393, "text": "7.4 chebyshev and chernoff bounds\n\n379\n\n7.4.2 chernoff bounds\n\nlet x be a random variable on r. the chernoff bound states that\n\nprob(x \u2265 u) \u2264 inf\n\n\u03bb\u22650\n\ne e\u03bb(x\u2212u),\n\nwhich can be expressed as\n\nlog prob(x \u2265 u) \u2264 inf\n\n\u03bb\u22650{\u2212\u03bbu + log e e\u03bbx}.\n\n(7.20)\n\nrecall (from example 3.41, page 106) that the righthand term, log e e\u03bbx , is called\nthe cumulant generating function of the distribution, and is always convex, so the\nfunction to be minimized is convex. the bound (7.20) is most useful in cases when\nthe cumulant generating function has an analytical expression, and the minimiza-\ntion over \u03bb can be carried out analytically.\n\nfor example, if x is gaussian with zero mean and unit variance, the cumulant\n\ngenerating function is\n\nlog e e\u03bbx = \u03bb2/2,\n\nand the infimum over \u03bb \u2265 0 of \u2212\u03bbu + \u03bb2/2 occurs with \u03bb = u (if u \u2265 0), so the\nchernoff bound is (for u \u2265 0)\n\nprob(x \u2265 u) \u2264 e\u2212u2/2.\n\nthe idea behind the chernoff bound can be extended to a more general setting,\nin which convex optimization is used to compute a bound on the probability of a\nset in rm. let c \u2286 rm, and as in the description of chebyshev bounds above,\nlet 1c denote the 0-1 indicator function of c. we will derive an upper bound on\nprob(x \u2208 c). (in principle we can compute prob(x \u2208 c), for example by monte\ncarlo simulation, or numerical integration, but either of these can be a daunting\ncomputational task, and neither method produces guaranteed bounds.)\n\nlet \u03bb \u2208 rm and \u00b5 \u2208 r, and consider the function f : rm \u2192 r given by\n\nf (z) = e\u03bbt z+\u00b5.\n\nas in the development of chebyshev bounds, if f satisfies f (z) \u2265 1c(z) for all z,\nthen we can conclude that\n\nprob(x \u2208 c) = e 1c(x) \u2264 e f (x).\n\nclearly we have f (z) \u2265 0 for all z; to have f (z) \u2265 1 for z \u2208 c is the same as\n\u03bbt z + \u00b5 \u2265 0 for all z \u2208 c, i.e., \u2212\u03bbt z \u2264 \u00b5 for all z \u2208 c. thus, if \u2212\u03bbt z \u2264 \u00b5 for all\nz \u2208 c, we have the bound\n\nprob(x \u2208 c) \u2264 e exp(\u03bbt x + \u00b5),\n\nor, taking logarithms,\n\nlog prob(x \u2208 c) \u2264 \u00b5 + log e exp(\u03bbt x).\n\n "}, {"Page_number": 394, "text": "380\n\n7 statistical estimation\n\nfrom this we obtain a general form of chernoff\u2019s bound:\n\nlog prob(x \u2208 c) \u2264 inf{\u00b5 + log e exp(\u03bbt x) | \u2212 \u03bbt z \u2264 \u00b5 for all z \u2208 c}\n\n= inf\n\n\u03bb (cid:18)sup\n\n(\u2212\u03bbt z) + log e exp(\u03bbt x)(cid:19)\n= inf(cid:0)sc(\u2212\u03bb) + log e exp(\u03bbt x)(cid:1) ,\n\nz\u2208c\n\nwhere sc is the support function of c. note that the second term, log e exp(\u03bbt x),\nis the cumulant generating function of the distribution, and is always convex (see\nexample 3.41, page 106). evaluating this bound is, in general, a convex optimiza-\ntion problem.\n\nchernoff bound for a gaussian variable on a polyhedron\nas a specific example, suppose that x is a gaussian random vector on rm with\nzero mean and covariance i, so its cumulant generating function is\n\nlog e exp(\u03bbt x) = \u03bbt \u03bb/2.\n\nwe take c to be a polyhedron described by inequalities:\n\nc = {x | ax (cid:22) b},\n\nwhich we assume is nonempty.\n\nfor use in the chernoff bound, we use a dual characterization of the support\n\nfunction sc:\n\nsc(y) = sup{yt x | ax (cid:22) b}\n\n= \u2212 inf{\u2212yt x | ax (cid:22) b}\n= \u2212 sup{\u2212bt u | at u = y, u (cid:23) 0}\n= inf{bt u | at u = y, u (cid:23) 0}\n\nwhere in the third line we use lp duality:\n\ninf{ct x | ax (cid:22) b} = sup{\u2212bt u | at u + c = 0, u (cid:23) 0}\n\nwith c = \u2212y. using this expression for sc in the chernoff bound we obtain\n\nlog prob(x \u2208 c) \u2264 inf\n= inf\n\u03bb\n\n\u03bb (cid:0)sc(\u2212\u03bb) + log e exp(\u03bbt x)(cid:1)\nu {bt u + \u03bbt \u03bb/2 (cid:12)(cid:12) u (cid:23) 0, at u + \u03bb = 0}.\n\ninf\n\nthus, the chernoff bound on prob(x \u2208 c) is the exponential of the optimal value\nof the qp\n\nbt u + \u03bbt \u03bb/2\n\nminimize\nsubject to u (cid:23) 0, at u + \u03bb = 0,\n\n(7.21)\n\nwhere the variables are u and \u03bb.\n\n "}, {"Page_number": 395, "text": "7.4 chebyshev and chernoff bounds\n\n381\n\nthis problem has an interesting geometric interpretation. it is equivalent to\n\nminimize\nsubject to u (cid:23) 0,\n\nbt u + (1/2)kat uk2\n\n2\n\nwhich is the dual of\n\nin other words, the chernoff bound is\n\nmaximize \u2212(1/2)kxk2\nsubject to ax (cid:22) b.\n\n2\n\nprob(x \u2208 c) \u2264 exp(\u2212 dist(0, c)2/2),\nwhere dist(0, c) is the euclidean distance of the origin to c.\n\n(7.22)\n\nremark 7.3 the bound (7.22) can also be derived without using chernoff\u2019s inequality.\nif the distance between 0 and c is d, then there is a halfspace h = {z | at z \u2265 d},\nwith kak2 = 1, that contains c. the random variable at x is n (0, 1), so\n\nprob(x \u2208 c) \u2264 prob(x \u2208 h) = \u03c6(\u2212d),\n\nwhere \u03c6 is the cumulative distribution function of a zero mean, unit variance gaus-\n\nsian. since \u03c6(\u2212d) \u2264 e\u2212d2/2 for d \u2265 0, this bound is at least as sharp as the chernoff\n\nbound (7.22).\n\n7.4.3 example\n\nin this section we illustrate the chebyshev and chernoff probability bounding\nmethods with a detection example. we have a set of m possible symbols or signals\ns \u2208 {s1, s2, . . . , sm} \u2286 rn, which is called the signal constellation. one of these\nsignals is transmitted over a noisy channel. the received signal is x = s + v,\nwhere v is a noise, modeled as a random variable. we assume that e v = 0 and\ne vvt = \u03c32i, i.e., the noise components v1, . . . , vn are zero mean, uncorrelated,\nand have variance \u03c32. the receiver must estimate which signal was sent on the\nbasis of the received signal x = s + v. the minimum distance detector chooses as\nestimate the symbol sk closest (in euclidean norm) to x. (if the noise v is gaussian,\nthen minimum distance decoding is the same as maximum likelihood decoding.)\n\nif the signal sk is transmitted, correct detection occurs if sk is the estimate,\ngiven x. this occurs when the signal sk is closer to x than the other signals, i.e.,\n\nkx \u2212 skk2 < kx \u2212 sjk2,\n\nj 6= k.\n\nthus, correct detection of symbol sk occurs if the random variable v satisfies the\nlinear inequalities\n\n2(sj \u2212 sk)t (sk + v) < ksjk2\n\n2 \u2212 kskk2\n2,\n\nj 6= k.\n\nthese inequalities define the voronoi region vk of sk in the signal constellation,\ni.e., the set of points closer to sk than any other signal in the constellation. the\nprobability of correct detection of sk is prob(sk + v \u2208 vk).\n\nfigure 7.5 shows a simple example with m = 7 signals, with dimension n = 2.\n\n "}, {"Page_number": 396, "text": "382\n\n7 statistical estimation\n\ns3\n\ns2\n\ns4\n\ns1\n\ns5\n\ns7\n\ns6\n\nfigure 7.5 a constellation of 7 signals s1, . . . , s7 \u2208 r2, shown as small circles.\nthe line segments show the boundaries of the corresponding voronoi regions.\nthe minimum distance detector selects symbol sk when the received signal\nlies closer to sk than to any of the other points, i.e., if the received signal is\nin the interior of the voronoi region around symbol sk. the circles around\neach point have radius one, to show the scale.\n\nchebyshev bounds\n\nthe sdp bound (7.19) provides a lower bound on the probability of correct detec-\ntion, and is plotted in figure 7.6, as a function of the noise standard deviation \u03c3,\nfor the three symbols s1, s2, and s3. these bounds hold for any noise distribution\nwith zero mean and covariance \u03c32i. they are tight in the sense that there exists\na noise distribution with zero mean and covariance \u03c3 = \u03c32i, for which the proba-\nbility of error is equal to the lower bound. this is illustrated in figure 7.7, for the\nfirst voronoi set, and \u03c3 = 1.\n\nchernoff bounds\n\nwe use the same example to illustrate the chernoff bound. here we assume that the\nnoise is gaussian, i.e., v \u223c n (0, \u03c32i). if symbol sk is transmitted, the probability\nof correct detection is the probability that sk + v \u2208 vk. to find a lower bound for\nthis probability, we use the qp (7.21) to compute upper bounds on the probability\nthat the ml detector selects symbol i, i = 1, . . . , m, i 6= k. (each of these upper\nbounds is related to the distance of sk to the voronoi set vi.) adding these upper\nbounds on the probabilities of mistaking sk for si, we obtain an upper bound on\nthe probability of error, and therefore, a lower bound on the probability of correct\ndetection of symbol sk. the resulting lower bound, for s1, is shown in figure 7.8,\nalong with an estimate of the probability of correct detection obtained using monte\ncarlo analysis.\n\n "}, {"Page_number": 397, "text": "7.4 chebyshev and chernoff bounds\n\n383\n\n1\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\nn\no\ni\nt\nc\ne\nt\ne\nd\n\nt\nc\ne\nr\nr\no\nc\n\nf\no\n\ny\nt\ni\nl\ni\n\nb\na\nb\no\nr\np\n\n0\n0\n\n0.5\n\n1\n\n3\n\n2\n\n1\n\n\u03c3\n\n1.5\n\n2\n\n2.5\n\nfigure 7.6 chebyshev lower bounds on the probability of correct detection\nfor symbols s1, s2, and s3. these bounds are valid for any noise distribution\nthat has zero mean and covariance \u03c32i.\n\ns3\n\ns2\n\ns4\n\ns1\n\ns5\n\ns7\n\ns6\n\nfigure 7.7 the chebyshev lower bound on the probability of correct detec-\ntion of symbol 1 is equal to 0.2048 when \u03c3 = 1. this bound is achieved by\nthe discrete distribution illustrated in the figure. the solid circles are the\npossible values of the received signal s1 + v. the point in the center of the\nellipse has probability 0.2048. the five points on the boundary have a total\nprobability 0.7952. the ellipse is defined by xt p x + 2qt x + r = 1, where\np , q, and r are the optimal solution of the sdp (7.19).\n\n "}, {"Page_number": 398, "text": "384\n\n7 statistical estimation\n\n1\n\n0.95\n\nn\no\ni\nt\nc\ne\nt\ne\nd\n\nt\nc\ne\nr\nr\no\nc\n\nf\no\n\ny\nt\ni\nl\ni\n\nb\na\nb\no\nr\np\n\n0.9\n\n0.2\n\n0.3\n\n\u03c3\n\n0.4\n\n0.5\n\nfigure 7.8 the chernoff lower bound (solid line) and a monte carlo esti-\nmate (dashed line) of the probability of correct detection of symbol s1, as\na function of \u03c3. in this example the noise is gaussian with zero mean and\ncovariance \u03c32i.\n\n7.5 experiment design\n\nwe consider the problem of estimating a vector x \u2208 rn from measurements or\nexperiments\n\nyi = at\n\ni x + wi,\n\ni = 1, . . . , m,\n\nwhere wi is measurement noise. we assume that wi are independent gaussian\nrandom variables with zero mean and unit variance, and that the measurement\nvectors a1, . . . , am span rn. the maximum likelihood estimate of x, which is the\nsame as the minimum variance estimate, is given by the least-squares solution\n\nthe associated estimation error e = \u02c6x \u2212 x has zero mean and covariance matrix\n\nyiai.\n\naiat\n\n\u02c6x =  mxi=1\ni!\u22121 mxi=1\ne = e eet =  mxi=1\ni!\u22121\n\naiat\n\n.\n\nthe matrix e characterizes the accuracy of the estimation, or the informativeness\nof the experiments. for example the \u03b1-confidence level ellipsoid for x is given by\n\ne = {z | (z \u2212 \u02c6x)t e\u22121(z \u2212 \u02c6x) \u2264 \u03b2},\n\nwhere \u03b2 is a constant that depends on n and \u03b1.\n\nwe suppose that the vectors a1, . . . , am, which characterize the measurements,\ncan be chosen among p possible test vectors v1, . . . , vp \u2208 rn, i.e., each ai is one of\n\n "}, {"Page_number": 399, "text": "7.5 experiment design\n\n385\n\nthe vj. the goal of experiment design is to choose the vectors ai, from among the\npossible choices, so that the error covariance e is small (in some sense). in other\nwords, each of m experiments or measurements can be chosen from a fixed menu\nof p possible experiments; our job is to find a set of measurements that (together)\nare maximally informative.\n\nlet mj denote the number of experiments for which ai is chosen to have the\n\nvalue vj, so we have\n\nwe can express the error covariance matrix as\n\nm1 + \u00b7\u00b7\u00b7 + mp = m.\n\ne =  mxi=1\n\ni!\u22121\n\naiat\n\n=\uf8eb\uf8ed\npxj=1\n\nmjvjvt\n\n\u22121\n\n.\n\nj\uf8f6\uf8f8\n\nthis shows that the error covariance depends only on the numbers of each type of\nexperiment chosen (i.e., m1, . . . , mp).\n\nthe basic experiment design problem is as follows. given the menu of possible\nchoices for experiments, i.e., v1, . . . , vp, and the total number m of experiments to\nbe carried out, choose the numbers of each type of experiment, i.e., m1, . . . , mp,\nto make the error covariance e small (in some sense). the variables m1, . . . , mp\nmust, of course, be integers and sum to m, the given total number of experiments.\nthis leads to the optimization problem\n\nminimize (w.r.t. sn\nsubject to\n\n+) e =(cid:16)pp\n\nj=1 mjvjvt\n\nj(cid:17)\u22121\n\nmi \u2265 0, m1 + \u00b7\u00b7\u00b7 + mp = m\nmi \u2208 z,\n\n(7.23)\n\nwhere the variables are the integers m1, . . . , mp.\n\nthe basic experiment design problem (7.23) is a vector optimization problem\nover the positive semidefinite cone.\nif one experiment design results in e, and\nanother in \u02dce, with e (cid:22) \u02dce, then certainly the first experiment design is as good\nas or better than the second. for example, the confidence ellipsoid for the first\nexperiment design (translated to the origin for comparison) is contained in the\nconfidence ellipsoid of the second. we can also say that the first experiment design\nallows us to estimate qt x better (i.e., with lower variance) than the second experi-\nment design, for any vector q, since the variance of our estimate of qt x is given by\nqt eq for the first experiment design and qt \u02dceq for the second. we will see below\nseveral common scalarizations for the problem.\n\n7.5.1 the relaxed experiment design problem\n\nthe basic experiment design problem (7.23) can be a hard combinatorial problem\nwhen m, the total number of experiments, is comparable to n, since in this case\nthe mi are all small integers. in the case when m is large compared to n, however,\na good approximate solution of (7.23) can be found by ignoring, or relaxing, the\nconstraint that the mi are integers. let \u03bbi = mi/m, which is the fraction of\n\n "}, {"Page_number": 400, "text": "386\n\n7 statistical estimation\n\nthe total number of experiments for which aj = vi, or the relative frequency of\nexperiment i. we can express the error covariance in terms of \u03bbi as\n\ne =\n\n1\n\nm  pxi=1\n\n\u03bbivivt\n\ni !\u22121\n\n.\n\n(7.24)\n\nthe vector \u03bb \u2208 rp satisfies \u03bb (cid:23) 0, 1t \u03bb = 1, and also, each \u03bbi is an integer multiple\nof 1/m. by ignoring this last constraint, we arrive at the problem\n\nminimize (w.r.t. sn\nsubject to\n\n+) e = (1/m)(cid:0)pp\n\n\u03bb (cid:23) 0,\n\n1t \u03bb = 1,\n\ni=1 \u03bbivivt\n\ni (cid:1)\u22121\n\n(7.25)\n\nwith variable \u03bb \u2208 rp. to distinguish this from the original combinatorial experi-\nment design problem (7.23), we refer to it as the relaxed experiment design problem.\nthe relaxed experiment design problem (7.25) is a convex optimization problem,\nsince the objective e is an sn\n\n+-convex function of \u03bb.\n\nseveral statements can be made about the relation between the (combinato-\nrial) experiment design problem (7.23) and the relaxed problem (7.25). clearly\nthe optimal value of the relaxed problem provides a lower bound on the optimal\nvalue of the combinatorial one, since the combinatorial problem has an additional\nconstraint. from a solution of the relaxed problem (7.25) we can construct a sub-\noptimal solution of the combinatorial problem (7.23) as follows. first, we apply\nsimple rounding to get\n\nmi = round(m\u03bbi),\n\ni = 1, . . . , p.\n\ncorresponding to this choice of m1, . . . , mp is the vector \u02dc\u03bb,\n\n\u02dc\u03bbi = (1/m)round(m\u03bbi),\n\ni = 1, . . . , p.\n\nthe vector \u02dc\u03bb satisfies the constraint that each entry is an integer multiple of 1/m.\nclearly we have |\u03bbi \u2212 \u02dc\u03bbi| \u2264 1/(2m), so for m large, we have \u03bb \u2248 \u02dc\u03bb. this implies\nthat the constraint 1t \u02dc\u03bb = 1 is nearly satisfied, for large m, and also that the error\ncovariance matrices associated with \u02dc\u03bb and \u03bb are close.\n\nwe can also give an alternative interpretation of the relaxed experiment design\nproblem (7.25). we can interpret the vector \u03bb \u2208 rp as defining a probability\ndistribution on the experiments v1, . . . , vp. our choice of \u03bb corresponds to a random\nexperiment: each experiment ai takes the form vj with probability \u03bbj.\n\nin the rest of this section, we consider only the relaxed experiment design\n\nproblem, so we drop the qualifier \u2018relaxed\u2019 in our discussion.\n\n7.5.2 scalarizations\n\nseveral scalarizations have been proposed for the experiment design problem (7.25),\nwhich is a vector optimization problem over the positive semidefinite cone.\n\n "}, {"Page_number": 401, "text": "7.5 experiment design\n\nd-optimal design\n\n387\n\nthe most widely used scalarization is called d-optimal design, in which we minimize\nthe determinant of the error covariance matrix e. this corresponds to designing\nthe experiment to minimize the volume of the resulting confidence ellipsoid (for\na fixed confidence level). ignoring the constant factor 1/m in e, and taking the\nlogarithm of the objective, we can pose this problem as\n\nminimize\nsubject to \u03bb (cid:23) 0,\nwhich is a convex optimization problem.\n\nlog det(cid:0)pp\n\ni=1 \u03bbivivt\n1t \u03bb = 1,\n\ni (cid:1)\u22121\n\n(7.26)\n\ne-optimal design\n\nof the confidence ellipsoid e is proportional to kek1/2\n\nin e-optimal design, we minimize the norm of the error covariance matrix, i.e.,\nthe maximum eigenvalue of e. since the diameter (twice the longest semi-axis)\n, minimizing kek2 can be\ninterpreted geometrically as minimizing the diameter of the confidence ellipsoid.\ne-optimal design can also be interpreted as minimizing the maximum variance of\nqt e, over all q with kqk2 = 1.\n\nthe e-optimal experiment design problem is\n\n2\n\nminimize\nsubject to \u03bb (cid:23) 0,\n\n(cid:13)(cid:13)(cid:13)(cid:0)pp\n\ni=1 \u03bbivivt\n\ni (cid:1)\u22121(cid:13)(cid:13)(cid:13)2\n\n1t \u03bb = 1.\n\nthe objective is a convex function of \u03bb, so this is a convex problem.\n\nthe e-optimal experiment design problem can be cast as an sdp\n\nt\n\nmaximize\n\nsubject to pp\n\n\u03bb (cid:23) 0,\n\ni=1 \u03bbivivt\n\ni (cid:23) ti\n1t \u03bb = 1,\n\nwith variables \u03bb \u2208 rp and t \u2208 r.\na-optimal design\n\n(7.27)\n\nin a-optimal experiment design, we minimize tr e, the trace of the covariance\nmatrix. this objective is simply the mean of the norm of the error squared:\n\nthe a-optimal experiment design problem is\n\nekek2\n\n2 = e tr(eet ) = tr e.\n\nminimize\nsubject to \u03bb (cid:23) 0,\n\ntr(cid:0)pp\n\ni=1 \u03bbivivt\n\n1t \u03bb = 1.\n\ni (cid:1)\u22121\n\n(7.28)\n\nthis, too, is a convex problem. like the e-optimal experiment design problem, it\ncan be cast as an sdp:\n\n1t u\n\nminimize\n\nsubject to (cid:20) pp\n\n\u03bb (cid:23) 0,\n\ni=1 \u03bbivivt\ni\n\net\nk\n1t \u03bb = 1,\n\nek\n\nuk (cid:21) (cid:23) 0,\n\nk = 1, . . . , n\n\n "}, {"Page_number": 402, "text": "388\n\n7 statistical estimation\n\nwhere the variables are u \u2208 rn and \u03bb \u2208 rp, and here, ek is the kth unit vector.\noptimal experiment design and duality\n\nthe lagrange duals of the three scalarizations have an interesting geometric mean-\ning.\n\nthe dual of the d-optimal experiment design problem (7.26) can be expressed\n\nas\n\nmaximize\nsubject to\n\nlog det w + n log n\nvt\ni w vi \u2264 1,\n\ni = 1, . . . , p,\n\nwith variable w \u2208 sn and domain sn\n++ (see exercise 5.10). this dual problem\nhas a simple interpretation: the optimal solution w \u22c6 determines the minimum\nvolume ellipsoid, centered at the origin, given by {x | xt w \u22c6x \u2264 1}, that contains\nthe points v1, . . . , vp. (see also the discussion of problem (5.14) on page 222.) by\ncomplementary slackness,\n\n\u03bb\u22c6\ni (1 \u2212 vt\n\ni w \u22c6vi) = 0,\n\ni = 1, . . . , p,\n\n(7.29)\n\ni.e., the optimal experiment design only uses the experiments vi which lie on the\nsurface of the minimum volume ellipsoid.\n\nthe duals of the e-optimal and a-optimal design problems can be given a\nsimilar interpretation. the duals of problems (7.27) and (7.28) can be expressed\nas\n\nand\n\nmaximize\nsubject to\n\ntr w\nvt\ni w vi \u2264 1,\nw (cid:23) 0,\n\nmaximize\nsubject to\n\n(tr w 1/2)2\nvt\ni w vi \u2264 1,\n\ni = 1, . . . , p\n\n(7.30)\n\ni = 1, . . . , p,\n\n(7.31)\n\nrespectively. the variable in both problems is w \u2208 sn. in the second problem\nthere is an implicit constraint w \u2208 sn\nas for the d-optimal design, the optimal solution w \u22c6 determines a minimal\nellipsoid {x | xt w \u22c6x \u2264 1} that contains the points v1, . . . , vp. moreover w \u22c6 and\n\u03bb\u22c6 satisfy the complementary slackness conditions (7.29), i.e., the optimal design\nonly uses experiments vi that lie on the surface of the ellipsoid defined by w \u22c6.\n\n+. (see exercises 5.40 and 5.10.)\n\nexperiment design example\nwe consider a problem with x \u2208 r2, and p = 20. the 20 candidate measurement\nvectors ai are shown as circles in figure 7.9. the origin is indicated with a cross.\nthe d-optimal experiment has only two nonzero \u03bbi, indicated as solid circles in\nfigure 7.9. the e-optimal experiment has two nonzero \u03bbi, indicated as solid circles\nin figure 7.10. the a-optimal experiment has three nonzero \u03bbi, indicated as solid\ncircles in figure 7.11. we also show the three ellipsoids {x | xt w \u22c6x \u2264 1} associated\nwith the dual optimal solutions w \u22c6. the resulting 90% confidence ellipsoids are\nshown in figure 7.12, along with the confidence ellipsoid for the \u2018uniform\u2019 design,\nwith equal weight \u03bbi = 1/p on all experiments.\n\n "}, {"Page_number": 403, "text": "7.5 experiment design\n\n389\n\n\u03bb1 = 0.5\n\n\u03bb2 = 0.5\n\nfigure 7.9 experiment design example. the 20 candidate measurement vec-\ntors are indicated with circles. the d-optimal design uses the two measure-\nment vectors indicated with solid circles, and puts an equal weight \u03bbi = 0.5\non each of them. the ellipsoid is the minimum volume ellipsoid centered at\nthe origin, that contains the points vi.\n\n\u03bb2 = 0.2\n\n\u03bb3 = 0.8\n\nfigure 7.10 the e-optimal design uses two measurement vectors. the\ndashed lines are (part of) the boundary of the ellipsoid {x | xt w \u22c6x \u2264 1}\nwhere w \u22c6 is the solution of the dual problem (7.30).\n\n\u03bb1 = 0.30\n\n\u03bb2 = 0.38\n\n\u03bb3 = 0.32\n\nfigure 7.11 the a-optimal design uses three measurement vectors. the\ndashed line shows the ellipsoid {x | xt w \u22c6x \u2264 1} associated with the solution\nof the dual problem (7.31).\n\n "}, {"Page_number": 404, "text": "390\n\n7 statistical estimation\n\nd\n\na\n\nuniform\n\ne\n\nfigure 7.12 shape of the 90% confidence ellipsoids for d-optimal, a-optimal,\ne-optimal, and uniform designs.\n\n7.5.3 extensions\n\nresource limits\n\nsuppose that associated with each experiment is a cost ci, which could represent\nthe economic cost, or time required, to carry out an experiment with vi. the total\ncost, or time required (if the experiments are carried out sequentially) is then\n\nm1c1 + \u00b7\u00b7\u00b7 + mpcp = mct \u03bb.\n\nwe can add a limit on total cost by adding the linear inequality mct \u03bb \u2264 b, where\nb is a budget, to the basic experiment design problem. we can add multiple linear\ninequalities, representing limits on multiple resources.\n\nmultiple measurements per experiment\n\nwe can also consider a generalization in which each experiment yields multiple\nmeasurements. in other words, when we carry out an experiment using one of the\npossible choices, we obtain several measurements. to model this situation we can\nuse the same notation as before, with vi as matrices in rn\u00d7ki:\n\nvi =(cid:2) ui1\n\n\u00b7\u00b7\u00b7 uiki (cid:3) ,\n\nwhere ki is the number of (scalar) measurements obtained when the experiment vi\nis carried out. the error covariance matrix, in this more complicated setup, has\nthe exact same form.\n\nin conjunction with additional linear inequalities representing limits on cost or\ntime, we can model discounts or time savings associated with performing groups\nof measurements simultaneously. suppose, for example, that the cost of simulta-\nneously making (scalar) measurements v1 and v2 is less than the sum of the costs\n\n "}, {"Page_number": 405, "text": "7.5 experiment design\n\n391\n\nof making them separately. we can take v3 to be the matrix\n\nand assign costs c1, c2, and c3 associated with making the first measurement alone,\nthe second measurement alone, and the two simultaneously, respectively.\n\nv3 =(cid:2) v1\n\nv2 (cid:3)\n\nwhen we solve the experiment design problem, \u03bb1 will give us the fraction of\ntimes we should carry out the first experiment alone, \u03bb2 will give us the fraction\nof times we should carry out the second experiment alone, and \u03bb3 will give us\nthe fraction of times we should carry out the two experiments simultaneously.\n(normally we would expect a choice to be made here; we would not expect to have\n\u03bb1 > 0, \u03bb2 > 0, and \u03bb3 > 0.)\n\n "}, {"Page_number": 406, "text": "392\n\n7 statistical estimation\n\nbibliography\n\nml and map estimation, hypothesis testing, and detection are covered in books on\nstatistics, pattern recognition, statistical signal processing, or communications; see, for\nexample, bickel and doksum [bd77], duda, hart, and stork [dhs99], scharf [sch91], or\nproakis [pro01].\nlogistic regression is discussed in hastie, tibshirani, and friedman [htf01, \u00a74.4]. for\nthe covariance estimation problem of page 355, see anderson [and70].\n\ngeneralizations of chebyshev\u2019s inequality were studied extensively in the sixties, by isii\n[isi64], marshall and olkin [mo60], karlin and studden [ks66, chapter 12], and others.\nthe connection with semidefinite programming was made more recently by bertsimas and\nsethuraman [bs00] and lasserre [las02].\nthe terminology in \u00a77.5 (a-, d-, and e-optimality) is standard in the literature on optimal\nexperiment design (see, for example, pukelsheim [puk93]). the geometric interpretation\nof the dual d-optimal design problem is discussed by titterington [tit75].\n\n "}, {"Page_number": 407, "text": "exercises\n\nexercises\n\nestimation\n\n393\n\n7.1 linear measurements with exponentially distributed noise. show how to solve the ml\n\nestimation problem (7.2) when the noise is exponentially distributed, with density\n\np(z) =(cid:26) (1/a)e\u2212z/a\n\n0\n\nz \u2265 0\nz < 0,\n\nwhere a > 0.\n\n7.2 ml estimation and \u2113\u221e-norm approximation. we consider the linear measurement model\n\ny = ax + v of page 352, with a uniform noise distribution of the form\n\np(z) =(cid:26) 1/(2\u03b1)\n\n0\n\n|z| \u2264 \u03b1\n|z| > \u03b1.\n\nas mentioned in example 7.1, page 352, any x that satisfies kax \u2212 yk\u221e \u2264 \u03b1 is a ml\nestimate.\nnow assume that the parameter \u03b1 is not known, and we wish to estimate \u03b1, along with\nthe parameters x. show that the ml estimates of x and \u03b1 are found by solving the\n\u2113\u221e-norm approximation problem\n\nwhere at\n\ni are the rows of a.\n\nminimize\n\nkax \u2212 yk\u221e,\n\n7.3 probit model. suppose y \u2208 {0, 1} is random variable given by\n\ny =(cid:26) 1\n\n0\n\nat u + b + v \u2264 0\nat u + b + v > 0,\n\nwhere the vector u \u2208 rn is a vector of explanatory variables (as in the logistic model\ndescribed on page 354), and v is a zero mean unit variance gaussian variable.\nformulate the ml estimation problem of estimating a and b, given data consisting of\npairs (ui, yi), i = 1, . . . , n , as a convex optimization problem.\n\n7.4 estimation of covariance and mean of a multivariate normal distribution. we consider the\nproblem of estimating the covariance matrix r and the mean a of a gaussian probability\ndensity function\n\npr,a(y) = (2\u03c0)\u2212n/2 det(r)\u22121/2 exp(\u2212(y \u2212 a)t r\u22121(y \u2212 a)/2),\n\nbased on n independent samples y1, y2, . . . , yn \u2208 rn.\n(a) we first consider the estimation problem when there are no additional constraints\n\non r and a. let \u00b5 and y be the sample mean and covariance, defined as\n\n\u00b5 =\n\n1\nn\n\nnxk=1\n\nyk,\n\ny =\n\n1\nn\n\nnxk=1\n\n(yk \u2212 \u00b5)(yk \u2212 \u00b5)t .\n\nshow that the log-likelihood function\n\nl(r, a) = \u2212(n n/2) log(2\u03c0) \u2212 (n/2) log det r \u2212 (1/2)\n\nnxk=1\n\n(yk \u2212 a)t r\u22121(yk \u2212 a)\n\n "}, {"Page_number": 408, "text": "394\n\n7 statistical estimation\n\ncan be expressed as\n\nl(r, a) =\n\nn\n\n2 (cid:0)\u2212n log(2\u03c0) \u2212 log det r \u2212 tr(r\u22121y ) \u2212 (a \u2212 \u00b5)t r\u22121(a \u2212 \u00b5)(cid:1) .\n\nuse this expression to show that if y \u227b 0, the ml estimates of r and a are unique,\nand given by\n\naml = \u00b5,\n\nrml = y.\n\n(b) the log-likelihood function includes a convex term (\u2212 log det r), so it is not obvi-\nously concave. show that l is concave, jointly in r and a, in the region defined\nby\n\nthis means we can use convex optimization to compute simultaneous ml estimates\nof r and a, subject to convex constraints, as long as the constraints include r (cid:22) 2y ,\ni.e., the estimate r must not exceed twice the unconstrained ml estimate.\n\nr (cid:22) 2y.\n\n7.5 markov chain estimation. consider a markov chain with n states, and transition proba-\n\nbility matrix p \u2208 rn\u00d7n defined as\n\npij = prob(y(t + 1) = i | y(t) = j).\n\nthe transition probabilities must satisfy pij \u2265 0 and pn\n\ni=1 pij = 1, j = 1, . . . , n. we\nconsider the problem of estimating the transition probabilities, given an observed sample\nsequence y(1) = k1, y(2) = k2, . . . , y(n ) = kn.\n\n(a) show that if there are no other prior constraints on pij, then the ml estimates are\nthe empirical transition frequencies: \u02c6pij is the ratio of the number of times the state\ntransitioned from j into i, divided by the number of times it was j, in the observed\nsample.\n\n(b) suppose that an equilibrium distribution p of the markov chain is known, i.e., a\n+ satisfying 1t q = 1 and p q = q. show that the problem of computing\nvector q \u2208 rn\nthe ml estimate of p , given the observed sequence and knowledge of q, can be\nexpressed as a convex optimization problem.\n\n7.6 estimation of mean and variance. consider a random variable x \u2208 r with density p,\nwhich is normalized, i.e., has zero mean and unit variance. consider a random variable\ny = (x+b)/a obtained by an affine transformation of x, where a > 0. the random variable\ny has mean b and variance 1/a2. as a and b vary over r+ and r, respectively, we generate\na family of densities obtained from p by scaling and shifting, uniquely parametrized by\nmean and variance.\nshow that if p is log-concave, then finding the ml estimate of a and b, given samples\ny1, . . . , yn of y, is a convex problem.\nas an example, work out an analytical solution for the ml estimates of a and b, assuming\np is a normalized laplacian density, p(x) = e\u22122|x|.\n\n7.7 ml estimation of poisson distributions. suppose xi, i = 1, . . . , n, are independent random\n\nvariables with poisson distributions\n\nprob(xi = k) =\n\ne\u2212\u00b5i \u00b5k\ni\n\nk!\n\n,\n\nwith unknown means \u00b5i. the variables xi represent the number of times that one of n\npossible independent events occurs during a certain period. in emission tomography, for\nexample, they might represent the number of photons emitted by n sources.\nwe consider an experiment designed to determine the means \u00b5i. the experiment involves\nm detectors. if event i occurs, it is detected by detector j with probability pji. we assume\n\n "}, {"Page_number": 409, "text": "exercises\n\n395\n\nthe probabilities pji are given (with pji \u2265 0,pm\n\nrecorded by detector j is denoted yj,\n\nj=1 pji \u2264 1). the total number of events\n\nyj =\n\nnxi=1\n\nyji,\n\nj = 1, . . . , m.\n\nformulate the ml estimation problem of estimating the means \u00b5i, based on observed\nvalues of yj, j = 1, . . . , m, as a convex optimization problem.\nhint. the variables yji have poisson distributions with means pji\u00b5i, i.e.,\n\nprob(yji = k) =\n\ne\u2212pji\u00b5i (pji\u00b5i)k\n\nk!\n\n.\n\nthe sum of n independent poisson variables with means \u03bb1, . . . , \u03bbn has a poisson distri-\nbution with mean \u03bb1 + \u00b7\u00b7\u00b7 + \u03bbn.\n\n7.8 estimation using sign measurements. we consider the measurement setup\n\nyi = sign(at\n\ni x + bi + vi),\n\ni = 1, . . . , m,\n\nwhere x \u2208 rn is the vector to be estimated, and yi \u2208 {\u22121, 1} are the measurements. the\nvectors ai \u2208 rn and scalars bi \u2208 r are known, and vi are iid noises with a log-concave\nprobability density. (you can assume that at\ni x + bi + vi = 0 does not occur.) show that\nmaximum likelihood estimation of x is a convex optimization problem.\n\n7.9 estimation with unknown sensor nonlinearity. we consider the measurement setup\n\nyi = f (at\n\ni x + bi + vi),\n\ni = 1, . . . , m,\n\nwhere x \u2208 rn is the vector to be estimated, yi \u2208 r are the measurements, ai \u2208 rn,\nbi \u2208 r are known, and vi are iid noises with log-concave probability density. the function\nf : r \u2192 r, which represents a measurement nonlinearity, is not known. however, it is\nknown that f \u2032(t) \u2208 [l, u] for all t, where 0 < l < u are given.\nexplain how to use convex optimization to find a maximum likelihood estimate of x, as\nwell as the function f . (this is an infinite-dimensional ml estimation problem, but you\ncan be informal in your approach and explanation.)\n\n7.10 nonparametric distributions on rk. we consider a random variable x \u2208 rk with values\n\nin a finite set {\u03b11, . . . , \u03b1n}, and with distribution\n\npi = prob(x = \u03b1i),\n\ni = 1, . . . , n.\n\nshow that a lower bound on the covariance of x,\n\ns (cid:22) e(x \u2212 e x)(x \u2212 e x)t ,\n\nis a convex constraint in p.\n\noptimal detector design\n\n7.11 randomized detectors. show that every randomized detector can be expressed as a convex\n\ncombination of a set of deterministic detectors: if\n\nt =(cid:2) t1\n\nt2\n\n\u00b7\u00b7\u00b7\n\ntn (cid:3) \u2208 rm\u00d7n\n\nsatisfies tk (cid:23) 0 and 1t tk = 1, then t can be expressed as\nt = \u03b81t1 + \u00b7\u00b7\u00b7 + \u03b8n tn ,\n\n "}, {"Page_number": 410, "text": "396\n\n7 statistical estimation\n\n\u03b8i \u2265 0,pn\n\nwhere ti is a zero-one matrix with exactly one element equal to one per column, and\ni=1 \u03b8i = 1. what is the maximum number of deterministic detectors n we may\n\nneed?\nwe can interpret this convex decomposition as follows. the randomized detector can be\nrealized as a bank of n deterministic detectors. when we observe x = k, the estimator\nchooses a random index from the set {1, . . . , n}, with probability prob(j = i) = \u03b8i, and\nthen uses deterministic detector tj.\n7.12 optimal action. in detector design, we are given a matrix p \u2208 rn\u00d7m (whose columns\nare probability distributions), and then design a matrix t \u2208 rm\u00d7n (whose columns are\nprobability distributions), so that d = t p has large diagonal elements (and small off-\ndiagonal elements). in this problem we study the dual problem: given p , find a matrix\ns \u2208 rm\u00d7n (whose columns are probability distributions), so that \u02dcd = p s \u2208 rn\u00d7n has\nlarge diagonal elements (and small off-diagonal elements). to make the problem specific,\nwe take the objective to be maximizing the minimum element of \u02dcd on the diagonal.\nwe can interpret this problem as follows. there are n outcomes, which depend (stochas-\ntically) on which of m inputs or actions we take: pij is the probability that outcome i\noccurs, given action j. our goal is find a (randomized) strategy that, to the extent pos-\nsible, causes any specified outcome to occur. the strategy is given by the matrix s: sji\nis the probability that we take action j, when we want outcome i to occur. the matrix\n\u02dcd gives the action error probability matrix: \u02dcdij is the probability that outcome i occurs,\nwhen we want outcome j to occur. in particular, \u02dcdii is the probability that outcome i\noccurs, when we want it to occur.\nshow that this problem has a simple analytical solution. show that (unlike the corre-\nsponding detector problem) there is always an optimal solution that is deterministic.\nhint. show that the problem is separable in the columns of s.\n\nchebyshev and chernoff bounds\n\n7.13 chebyshev-type inequalities on a finite set. assume x is a random variable taking values\nin the set {\u03b11, \u03b12, . . . , \u03b1m}, and let s be a subset of {\u03b11, . . . , \u03b1m}. the distribution of x\nis unknown, but we are given the expected values of n functions fi:\n\ne fi(x) = bi,\n\ni = 1, . . . , n.\n\n(7.32)\n\nshow that the optimal value of the lp\n\nminimize\n\nx0 +pn\nsubject to x0 +pn\nx0 +pn\n\ni=1 bixi\ni=1 fi(\u03b1)xi \u2265 1, \u03b1 \u2208 s\ni=1 fi(\u03b1)xi \u2265 0, \u03b1 6\u2208 s,\n\nwith variables x0, . . . , xn, is an upper bound on prob(x \u2208 s), valid for all distributions\nthat satisfy (7.32). show that there always exists a distribution that achieves the upper\nbound.\n\n "}, {"Page_number": 411, "text": "chapter 8\n\ngeometric problems\n\n8.1 projection on a set\n\nthe distance of a point x0 \u2208 rn to a closed set c \u2286 rn, in the norm k \u00b7 k, is\ndefined as\n\ndist(x0, c) = inf{kx0 \u2212 xk | x \u2208 c}.\n\nthe infimum here is always achieved. we refer to any point z \u2208 c which is closest\nto x0, i.e., satisfies kz \u2212 x0k = dist(x0, c), as a projection of x0 on c. in general\nthere can be more than one projection of x0 on c, i.e., several points in c closest\nto x0.\n\nin some special cases we can establish that the projection of a point on a set\nis unique. for example, if c is closed and convex, and the norm is strictly convex\n(e.g., the euclidean norm), then for any x0 there is always exactly one z \u2208 c which\nis closest to x0. as an interesting converse, we have the following result: if for every\nx0 there is a unique euclidean projection of x0 on c, then c is closed and convex\n(see exercise 8.2).\n\nwe use the notation pc : rn \u2192 rn to denote any function for which pc(x0)\n\nis a projection of x0 on c, i.e., for all x0,\n\npc(x0) \u2208 c,\n\nkx0 \u2212 pc(x0)k = dist(x0, c).\n\nin other words, we have\n\npc(x0) = argmin{kx \u2212 x0k | x \u2208 c}.\n\nwe refer to pc as projection on c.\n\nexample 8.1 projection on the unit square in r2. consider the (boundary of the)\nunit square in r2, i.e., c = {x \u2208 r2 | kxk\u221e = 1}. we take x0 = 0.\nin the \u21131-norm, the four points (1, 0), (0,\u22121), (\u22121, 0), and (0, 1) are closest to x0 = 0,\nwith distance 1, so we have dist(x0, c) = 1 in the \u21131-norm. the same statement holds\nfor the \u21132-norm.\n\nin the \u2113\u221e-norm, all points in c lie at a distance 1 from x0, and dist(x0, c) = 1.\n\n "}, {"Page_number": 412, "text": "398\n\n8 geometric problems\n\nexample 8.2 projection onto rank-k matrices. consider the set of m \u00d7 n matrices\nwith rank less than or equal to k,\n\nc = {x \u2208 rm\u00d7n | rank x \u2264 k},\n\nwith k \u2264 min{m, n}, and let x0 \u2208 rm\u00d7n. we can find a projection of x0 on\nc, in the (spectral or maximum singular value) norm k \u00b7 k2, via the singular value\ndecomposition. let\n\nx0 =\n\n\u03c3iuivt\ni\n\nrxi=1\n\nbe the singular value decomposition of x0, where r = rank x0. then the matrix\n\n\u03c3iuivt\ni\n\nis a projection of x0 on c.\n\ny =pmin{k,r}\n\ni=1\n\n8.1.1 projecting a point on a convex set\n\nif c is convex, then we can compute the projection pc(x0) and the distance\ndist(x0, c) by solving a convex optimization problem. we represent the set c\nby a set of linear equalities and convex inequalities\n\nax = b,\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\n(8.1)\n\nand find the projection of x0 on c by solving the problem\n\nminimize\nsubject to\n\nkx \u2212 x0k\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m\n\n(8.2)\n\nwith variable x. this problem is feasible if and only if c is nonempty; when it is\nfeasible, its optimal value is dist(x0, c), and any optimal point is a projection of\nx0 on c.\n\neuclidean projection on a polyhedron\nthe projection of x0 on a polyhedron described by linear inequalities ax (cid:22) b can\nbe computed by solving the qp\n\nkx \u2212 x0k2\nminimize\nsubject to ax (cid:22) b.\nsome special cases have simple analytical solutions.\n\n2\n\n\u2022 the euclidean projection of x0 on a hyperplane c = {x | at x = b} is given\n\nby\n\npc(x0) = x0 + (b \u2212 at x0)a/kak2\n2.\n\n\u2022 the euclidean projection of x0 on a halfspace c = {x | at x \u2264 b} is given by\n\npc(x0) =(cid:26) x0 + (b \u2212 at x0)a/kak2\n\nx0\n\n2 at x0 > b\nat x0 \u2264 b.\n\n "}, {"Page_number": 413, "text": "8.1 projection on a set\n\n399\n\n\u2022 the euclidean projection of x0 on a rectangle c = {x | l (cid:22) x (cid:22) u} (where\n\nl \u227a u) is given by\n\npc(x0)k =\uf8f1\uf8f2\uf8f3\n\nlk\nx0k\nuk\n\nx0k \u2264 lk\nlk \u2264 x0k \u2264 uk\nx0k \u2265 uk.\n\neuclidean projection on a proper cone\n\nlet x = pk(x0) denote the euclidean projection of a point x0 on a proper cone k.\nthe kkt conditions of\n\nminimize\nsubject to x (cid:23)k 0\n\nkx \u2212 x0k2\n\n2\n\nare given by\n\nx (cid:23)k 0,\n\nx \u2212 x0 = z,\n\nz (cid:23)k \u2217 0,\n\nzt x = 0.\n\nintroducing the notation x+ = x and x\u2212 = z, we can express these conditions as\n\nx0 = x+ \u2212 x\u2212,\n\nx+ (cid:23)k 0,\n\nx\u2212 (cid:23)k \u2217 0,\n\nxt\n+x\u2212 = 0.\n\nin other words, by projecting x0 on the cone k, we decompose it into the difference\nof two orthogonal elements: one nonnegative with respect to k (and which is the\nprojection of x0 on k), and the other nonnegative with respect to k \u2217.\n\nsome specific examples:\n\u2022 for k = rn\n\n+, we have pk(x0)k = max{x0k, 0}. the euclidean projection\nof a vector onto the nonnegative orthant is found by replacing each negative\ncomponent with 0.\n\n\u2022 for k = sn\npn\ni=1 max{0, \u03bbi}vivt\n\n+, and the euclidean (or frobenius) norm k\u00b7kf , we have pk(x0) =\nis the eigenvalue decomposi-\ntion of x0. to project a symmetric matrix onto the positive semidefinite cone,\nwe form its eigenvalue expansion and drop terms associated with negative\neigenvalues. this matrix is also the projection onto the positive semidefinite\ncone in the \u21132-, or spectral norm.\n\ni , where x0 =pn\n\ni=1 \u03bbivivt\ni\n\n8.1.2 separating a point and a convex set\n\nsuppose c is a closed convex set described by the equalities and inequalities (8.1).\nif x0 \u2208 c, then dist(x0, c) = 0, and the optimal point for the problem (8.2) is\nx0. if x0 6\u2208 c then dist(x0, c) > 0, and the optimal value of the problem (8.2) is\npositive. in this case we will see that any dual optimal point provides a separating\nhyperplane between the point x0 and the set c.\n\nthe link between projecting a point on a convex set and finding a hyperplane\nthat separates them (when the point is not in the set) should not be surprising.\nindeed, our proof of the separating hyperplane theorem, given in \u00a72.5.1, relies on\n\n "}, {"Page_number": 414, "text": "400\n\n8 geometric problems\n\nx0\n\npc(x0)\n\nc\n\nfigure 8.1 a point x0 and its euclidean projection pc (x0) on a convex set c.\nthe hyperplane midway between the two, with normal vector pc (x0) \u2212 x0,\nstrictly separates the point and the set. this property does not hold for\ngeneral norms; see exercise 8.4.\n\nfinding the euclidean distance between the sets. if pc(x0) denotes the euclidean\nprojection of x0 on c, where x0 6\u2208 c, then the hyperplane\n\n(pc(x0) \u2212 x0)t (x \u2212 (1/2)(x0 + pc(x0))) = 0\n\n(strictly) separates x0 from c, as illustrated in figure 8.1. in other norms, however,\nthe clearest link between the projection problem and the separating hyperplane\nproblem is via lagrange duality.\n\nwe first express (8.2) as\n\nminimize\nsubject to\n\nkyk\nfi(x) \u2264 0,\nax = b\nx0 \u2212 x = y\n\ni = 1, . . . , m\n\nwith variables x and y. the lagrangian of this problem is\n\nl(x, y, \u03bb, \u00b5, \u03bd) = kyk +\n\nmxi=1\n\nand the dual function is\n\n\u03bbifi(x) + \u03bdt (ax \u2212 b) + \u00b5t (x0 \u2212 x \u2212 y)\n\ng(\u03bb, \u00b5, \u03bd) =(cid:26) inf x(cid:0)pm\n\n\u2212\u221e\n\nso we obtain the dual problem\n\ni=1 \u03bbifi(x) + \u03bdt (ax \u2212 b) + \u00b5t (x0 \u2212 x)(cid:1)\n\u00b5t x0 + inf x(cid:0)pm\n\ni=1 \u03bbifi(x) + \u03bdt (ax \u2212 b) \u2212 \u00b5t x(cid:1)\n\nk\u00b5k\u2217 \u2264 1\notherwise,\n\nmaximize\nsubject to \u03bb (cid:23) 0\n\nk\u00b5k\u2217 \u2264 1,\n\nwith variables \u03bb, \u00b5, \u03bd. we can interpret the dual problem as follows. suppose \u03bb,\n\u00b5, \u03bd are dual feasible with a positive dual objective value, i.e., \u03bb (cid:23) 0, k\u00b5k\u2217 \u2264 1,\n\n "}, {"Page_number": 415, "text": "8.1 projection on a set\n\n401\n\nand\n\n\u00b5t x0 \u2212 \u00b5t x +\n\nmxi=1\n\n\u03bbifi(x) + \u03bdt (ax \u2212 b) > 0\n\nfor all x. this implies that \u00b5t x0 > \u00b5t x for x \u2208 c, and therefore \u00b5 defines a\nstrictly separating hyperplane. in particular, suppose (8.2) is strictly feasible, so\nstrong duality holds. if x0 6\u2208 c, the optimal value is positive, and any dual optimal\nsolution defines a strictly separating hyperplane.\nnote that this construction of a separating hyperplane, via duality, works for\nany norm. in contrast, the simple construction described above only works for the\neuclidean norm.\n\nseparating a point from a polyhedron\n\nthe dual problem of\n\nis\n\nminimize\nsubject to ax (cid:22) b\n\nkyk\nx0 \u2212 x = y\n\u00b5t x0 \u2212 bt \u03bb\nmaximize\nsubject to at \u03bb = \u00b5\nk\u00b5k\u2217 \u2264 1\n\u03bb (cid:23) 0\n\nwhich can be further simplified as\n\n(ax0 \u2212 b)t \u03bb\nmaximize\nsubject to kat \u03bbk\u2217 \u2264 1\n\u03bb (cid:23) 0.\n\nit is easily verified that if the dual objective is positive, then at \u03bb is the normal\nvector to a separating hyperplane: if ax (cid:22) b, then\n\n(at \u03bb)t x = \u03bbt (ax) \u2264 \u03bbt b < \u03bbt ax0,\n\nso \u00b5 = at \u03bb defines a separating hyperplane.\n\n8.1.3 projection and separation via indicator and support functions\n\nthe ideas described above in \u00a78.1.1 and \u00a78.1.2 can be expressed in a compact form\nin terms of the indicator function ic and the support function sc of the set c,\ndefined as\n\nsc(x) = sup\ny\u2208c\n\nxt y,\n\nic(x) =(cid:26) 0\n\nx \u2208 c\n+\u221e x 6\u2208 c.\n\nthe problem of projecting x0 on a closed convex set c can be expressed compactly\nas\n\nminimize\nsubject to\n\nkx \u2212 x0k\nic(x) \u2264 0,\n\n "}, {"Page_number": 416, "text": "402\n\n8 geometric problems\n\nor, equivalently, as\n\nminimize\nsubject to\n\nkyk\nic(x) \u2264 0\nx0 \u2212 x = y\n\nwhere the variables are x and y. the dual function of this problem is\n\ng(z, \u03bb) = inf\n\nx,y(cid:0)kyk + \u03bbic(x) + zt (x0 \u2212 x \u2212 y)(cid:1)\n\n= (cid:26) zt x0 + inf x(cid:0)\u2212zt x + ic(x)(cid:1)\n= (cid:26) zt x0 \u2212 sc(z)\n\nkzk\u2217 \u2264 1,\notherwise\n\n\u03bb \u2265 0\n\n\u2212\u221e\n\n\u2212\u221e\n\nkzk\u2217 \u2264 1,\notherwise\n\n\u03bb \u2265 0\n\nso we obtain the dual problem\n\nmaximize\nsubject to\n\nzt x0 \u2212 sc(z)\nkzk\u2217 \u2264 1.\n\nif z is dual optimal with a positive objective value, then zt x0 > zt x for all x \u2208 c,\ni.e., z defines a separating hyperplane.\n\n8.2 distance between sets\n\nthe distance between two sets c and d, in a norm k \u00b7 k, is defined as\n\ndist(c, d) = inf{kx \u2212 yk | x \u2208 c, y \u2208 d}.\n\nthe two sets c and d do not intersect if dist(c, d) > 0. they intersect if\ndist(c, d) = 0 and the infimum in the definition is attained (which is the case, for\nexample, if the sets are closed and one of the sets is bounded).\n\nthe distance between sets can be expressed in terms of the distance between a\n\npoint and a set,\n\ndist(c, d) = dist(0, d \u2212 c),\n\nso the results of the previous section can be applied. in this section, however, we\nderive results specifically for problems involving distance between sets. this allows\nus to exploit the structure of the set c \u2212 d, and makes the interpretation easier.\n\n8.2.1 computing the distance between convex sets\n\nsuppose c and d are described by two sets of convex inequalities\n\nc = {x | fi(x) \u2264 0, i = 1, . . . , m},\n\nd = {x | gi(x) \u2264 0, i = 1, . . . , p}.\n\n "}, {"Page_number": 417, "text": "8.2 distance between sets\n\n403\n\nd\n\nc\n\nfigure 8.2 euclidean distance between polyhedra c and d. the dashed line\nconnects the two points in c and d, respectively, that are closest to each\nother in euclidean norm. these points can be found by solving a qp.\n\n(we can include linear equalities, but exclude them here for simplicity.) we can\nfind dist(c, d) by solving the convex optimization problem\n\nminimize\nsubject to\n\nkx \u2212 yk\nfi(x) \u2264 0,\ngi(y) \u2264 0,\n\ni = 1, . . . , m\ni = 1, . . . , p.\n\n(8.3)\n\neuclidean distance between polyhedra\nlet c and d be two polyhedra described by the sets of linear inequalities a1x (cid:22) b1\nand a2x (cid:22) b2, respectively. the distance between c and d is the distance between\nthe closest pair of points, one in c and the other in d, as illustrated in figure 8.2.\nthe distance between them is the optimal value of the problem\n\nkx \u2212 yk2\nminimize\nsubject to a1x (cid:22) b1\na2y (cid:22) b2.\n\n(8.4)\n\nwe can square the objective to obtain an equivalent qp.\n\n8.2.2 separating convex sets\n\nthe dual of the problem (8.3) of finding the distance between two convex sets has\nan interesting geometric interpretation in terms of separating hyperplanes between\nthe sets. we first express the problem in the following equivalent form:\n\nminimize\nsubject to\n\nkwk\nfi(x) \u2264 0,\ngi(y) \u2264 0,\nx \u2212 y = w.\n\ni = 1, . . . , m\ni = 1, . . . , p\n\n(8.5)\n\nthe dual function is\n\ng(\u03bb, z, \u00b5) = inf\n\nx,y,w kwk +\n\n\u03bbifi(x) +\n\nmxi=1\n\n\u00b5igi(y) + zt (x \u2212 y \u2212 w)!\n\npxi=1\n\n "}, {"Page_number": 418, "text": "404\n\n8 geometric problems\n\nwhich results in the dual problem\n\n= (cid:26) inf x(cid:0)pm\n\n\u2212\u221e\n\nmaximize\nsubject to\n\ni=1 \u03bbifi(x) + zt x(cid:1) + inf y(cid:0)pp\ninf x(cid:0)pm\n\ni=1 \u03bbifi(x) + zt x(cid:1) + inf y(cid:0)pp\n\nkzk\u2217 \u2264 1\n\u03bb (cid:23) 0, \u00b5 (cid:23) 0.\n\ni=1 \u00b5igi(y) \u2212 zt y(cid:1)\n\nkzk\u2217 \u2264 1\notherwise,\n\ni=1 \u00b5igi(y) \u2212 zt y(cid:1)\n\n(8.6)\n\nwe can interpret this geometrically as follows.\npositive objective value, then\n\nif \u03bb, \u00b5 are dual feasible with a\n\n\u03bbifi(x) + zt x +\n\nmxi=1\n\npxi=1\n\n\u00b5igi(y) \u2212 zt y > 0\n\nfor all x and y. in particular, for x \u2208 c and y \u2208 d, we have zt x \u2212 zt y > 0, so we\nsee that z defines a hyperplane that strictly separates c and d.\ntherefore, if strong duality holds between the two problems (8.5) and (8.6)\n(which is the case when (8.5) is strictly feasible), we can make the following con-\nclusion. if the distance between the two sets is positive, then they can be strictly\nseparated by a hyperplane.\n\nseparating polyhedra\napplying these duality results to sets defined by linear inequalities a1x (cid:22) b1 and\na2x (cid:22) b2, we find the dual problem\n\n1 \u03bb \u2212 bt\nmaximize \u2212bt\n2 \u00b5\nsubject to at\n1 \u03bb + z = 0\nat\n2 \u00b5 \u2212 z = 0\nkzk\u2217 \u2264 1\n\u03bb (cid:23) 0, \u00b5 (cid:23) 0.\n\nif \u03bb, \u00b5, and z are dual feasible, then for all x \u2208 c, y \u2208 d,\n\nzt x = \u2212\u03bbt a1x \u2265 \u2212\u03bbt b1,\nand, if the dual objective value is positive,\n\nzt y = \u00b5t a2x \u2264 \u00b5t b2,\n\ni.e., z defines a separating hyperplane.\n\nzt x \u2212 zt y \u2265 \u2212\u03bbt b1 \u2212 \u00b5t b2 > 0,\n\n8.2.3 distance and separation via indicator and support functions\n\nthe ideas described above in \u00a78.2.1 and \u00a78.2.2 can be expressed in a compact form\nusing indicator and support functions. the problem of finding the distance between\ntwo convex sets can be posed as the convex problem\n\nminimize\nsubject to\n\nkx \u2212 yk\nic(x) \u2264 0\nid(y) \u2264 0,\n\n "}, {"Page_number": 419, "text": "8.3 euclidean distance and angle problems\n\n405\n\nwhich is equivalent to\n\nthe dual of this problem is\n\nminimize\nsubject to\n\nkwk\nic(x) \u2264 0\nid(y) \u2264 0\nx \u2212 y = w.\n\nmaximize\nsubject to\n\n\u2212sc(\u2212z) \u2212 sd(z)\nkzk\u2217 \u2264 1.\n\nif z is dual feasible with a positive objective value, then sd(z) < \u2212sc(\u2212z), i.e.,\n\nsup\nx\u2208d\n\nzt x < inf\nx\u2208c\n\nzt x.\n\nin other words, z defines a hyperplane that strictly separates c and d.\n\n8.3 euclidean distance and angle problems\n\nsuppose a1, . . . , an is a set of vectors in rn, which we assume (for now) have known\neuclidean lengths\n\nl1 = ka1k2,\n\n. . . ,\n\nln = kank2.\n\nwe will refer to the set of vectors as a configuration, or, when they are indepen-\ndent, a basis. in this section we consider optimization problems involving various\ngeometric properties of the configuration, such as the euclidean distances between\npairs of the vectors, the angles between pairs of the vectors, and various geometric\nmeasures of the conditioning of the basis.\n\n8.3.1 gram matrix and realizability\n\nthe lengths, distances, and angles can be expressed in terms of the gram matrix\nassociated with the vectors a1, . . . , an, given by\n\nso that gij = at\n\ni aj. the diagonal entries of g are given by\n\ng = at a,\n\na =(cid:2) a1\n\n\u00b7\u00b7\u00b7 an (cid:3) ,\n\ngii = l2\ni ,\n\ni = 1, . . . , n,\n\nwhich (for now) we assume are known and fixed. the distance dij between ai and\naj is\n\ndij = kai \u2212 ajk2\n\n= (l2\n= (l2\n\ni + l2\ni + l2\n\ni aj)1/2\nj \u2212 2at\nj \u2212 2gij)1/2.\n\n "}, {"Page_number": 420, "text": "406\n\n8 geometric problems\n\nconversely, we can express gij in terms of dij as\n\ngij =\n\ni + l2\nj \u2212 d2\nl2\n2\n\nij\n\n,\n\nwhich we note, for future reference, is an affine function of d2\nij.\n\nthe correlation coefficient \u03c1ij between (nonzero) ai and aj is given by\n\n\u03c1ij =\n\nat\ni aj\n\nkaik2kajk2\n\n=\n\ngij\nlilj\n\n,\n\nso that gij = lilj\u03c1ij is a linear function of \u03c1ij. the angle \u03b8ij between (nonzero) ai\nand aj is given by\n\n\u03b8ij = cos\u22121 \u03c1ij = cos\u22121(gij/(lilj)),\n\nwhere we take cos\u22121 \u03c1 \u2208 [0, \u03c0]. thus, we have gij = lilj cos \u03b8ij.\nthe lengths, distances, and angles are invariant under orthogonal transforma-\ntions: if q \u2208 rn\u00d7n is orthogonal, then the set of vectors qai, . . . , qan has the\nsame gram matrix, and therefore the same lengths, distances, and angles.\n\nrealizability\n\nthe gram matrix g = at a is, of course, symmetric and positive semidefinite. the\nconverse is a basic result of linear algebra: a matrix g \u2208 sn is the gram matrix\nof a set of vectors a1, . . . , an if and only if g (cid:23) 0. when g (cid:23) 0, we can construct\na configuration with gram matrix g by finding a matrix a with at a = g. one\nsolution of this equation is the symmetric squareroot a = g1/2. when g \u227b 0, we\ncan find a solution via the cholesky factorization of g: if llt = g, then we can\ntake a = lt . moreover, we can construct all configurations with the given gram\nmatrix g, given any one solution a, by orthogonal transformation: if \u02dcat \u02dca = g is\nany solution, then \u02dca = qa for some orthogonal matrix q.\n\nthus, a set of lengths, distances, and angles (or correlation coefficients) is real-\nizable, i.e., those of some configuration, if and only if the associated gram matrix\ng is positive semidefinite, and has diagonal elements l2\n\n1, . . . , l2\nn.\n\nwe can use this fact to express several geometric problems as convex optimiza-\ntion problems, with g \u2208 sn as the optimization variable. realizability imposes\nthe constraint g (cid:23) 0 and gii = l2\ni , i = 1, . . . , n; we list below several other convex\nconstraints and objectives.\n\nangle and distance constraints\n\nwe can fix an angle to have a certain value, \u03b8ij = \u03b1, via the linear equality\nconstraint gij = lilj cos \u03b1. more generally, we can impose a lower and upper\nbound on an angle, \u03b1 \u2264 \u03b8ij \u2264 \u03b2, by the constraint\n\nlilj cos \u03b1 \u2265 gij \u2265 lilj cos \u03b2,\n\nwhich is a pair of linear inequalities on g. (here we use the fact that cos\u22121 is\nmonotone decreasing.) we can maximize or minimize a particular angle \u03b8ij, by\nminimizing or maximizing gij (again using monotonicity of cos\u22121).\n\n "}, {"Page_number": 421, "text": "8.3 euclidean distance and angle problems\n\n407\n\nin a similar way we can impose constraints on the distances. to require that\n\ndij lies in an interval, we use\n\ndmin \u2264 dij \u2264 dmax \u21d0\u21d2 d2\n\u21d0\u21d2 d2\n\nmin \u2264 d2\nmin \u2264 l2\n\nij \u2264 d2\ni + l2\n\nmax\n\nj \u2212 2gij \u2264 d2\n\nmax,\n\nwhich is a pair of linear inequalities on g. we can minimize or maximize a distance,\nby minimizing or maximizing its square, which is an affine function of g.\n\nas a simple example, suppose we are given ranges (i.e., an interval of possible\nvalues) for some of the angles and some of the distances. we can then find the\nminimum and maximum possible value of some other angle, or some other distance,\nover all configurations, by solving two sdps. we can reconstruct the two extreme\nconfigurations by factoring the resulting optimal gram matrices.\n\nsingular value and condition number constraints\nthe singular values of a, \u03c31 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03c3n, are the squareroots of the eigenvalues\n\u03bb1 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn of g. therefore \u03c32\nn is a concave\nfunction of g. thus we can impose an upper bound on the maximum singular value\nof a, or minimize it; we can impose a lower bound on the minimum singular value,\nor maximize it. the condition number of a, \u03c31/\u03c3n, is a quasiconvex function of g,\nso we can impose a maximum allowable value, or minimize it over all configurations\nthat satisfy the other geometric constraints, by quasiconvex optimization.\n\n1 is a convex function of g, and \u03c32\n\nroughly speaking, the constraints we can impose as convex constraints on g\n\nare those that require a1, . . . , an to be a well conditioned basis.\n\ndual basis\nwhen g \u227b 0, a1, . . . , an form a basis for rn. the associated dual basis is b1, . . . , bn,\nwhere\n\nbt\n\ni aj =(cid:26) 1 i = j\n\n0 i 6= j.\n\nthe dual basis vectors b1, . . . , bn are simply the rows of the matrix a\u22121. as a\nresult, the gram matrix associated with the dual basis is g\u22121.\n\nwe can express several geometric conditions on the dual basis as convex con-\n\nstraints on g. the (squared) lengths of the dual basis vectors,\n\nkbik2\n\n2 = et\n\ni g\u22121ei,\n\nare convex functions of g, and so can be minimized. the trace of g\u22121, another\nconvex function of g, gives the sum of the squares of the lengths of the dual basis\nvectors (and is another measure of a well conditioned basis).\n\nellipsoid and simplex volume\nthe volume of the ellipsoid {au | kuk2 \u2264 1}, which gives another measure of how\nwell conditioned the basis is, is given by\n\n\u03b3(det(at a))1/2 = \u03b3(det g)1/2,\n\n "}, {"Page_number": 422, "text": "408\n\n8 geometric problems\n\nwhere \u03b3 is the volume of the unit ball in rn. the log volume is therefore log \u03b3 +\n(1/2) log det g, which is a concave function of g. we can therefore maximize the\nvolume of the image ellipsoid, over a convex set of configurations, by maximizing\nlog det g.\n\nthe same holds for any set in rn. the volume of the image under a is its\nvolume, multiplied by the factor (det g)1/2. for example, consider the image under\na of the unit simplex conv{0, e1, . . . , en}, i.e., the simplex conv{0, a1, . . . , an}.\nthe volume of this simplex is given by \u03b3(det g)1/2, where \u03b3 is the volume of the\nunit simplex in rn. we can maximize the volume of this simplex by maximizing\nlog det g.\n\n8.3.2 problems involving angles only\n\nsuppose we only care about the angles (or correlation coefficients) between the\nvectors, and do not specify the lengths or distances between them. in this case it is\nintuitively clear that we can simply assume the vectors ai have length li = 1. this\nis easily verified: the gram matrix has the form g = diag(l)c diag(l), where l\nis the vector of lengths, and c is the correlation matrix, i.e., cij = cos \u03b8ij.\nit\nfollows that if g (cid:23) 0 for any set of positive lengths, then g (cid:23) 0 for all sets of\npositive lengths, and in particular, this occurs if and only if c (cid:23) 0 (which is the\nsame as assuming that all lengths are one). thus, a set of angles \u03b8ij \u2208 [0, \u03c0],\ni, j = 1, . . . , n is realizable if and only if c (cid:23) 0, which is a linear matrix inequality\nin the correlation coefficients.\nas an example, suppose we are given lower and upper bounds on some of the\nangles (which is equivalent to imposing lower and upper bounds on the correlation\ncoefficients). we can then find the minimum and maximum possible value of some\nother angle, over all configurations, by solving two sdps.\n\nexample 8.3 bounding correlation coefficients. we consider an example in r4, where\nwe are given\n\n0.6 \u2264 \u03c112 \u2264 0.9,\n0.5 \u2264 \u03c124 \u2264 0.7, \u22120.8 \u2264 \u03c134 \u2264 \u22120.4.\n\n0.8 \u2264 \u03c113 \u2264 0.9,\n\n(8.7)\n\nto find the minimum and maximum possible values of \u03c114, we solve the two sdps\n\nminimize/maximize\nsubject to\n\n\u03c112\n1\n\u03c123\n\u03c124\n\n\u03c113\n\u03c123\n1\n\u03c134\n\n\u03c114\n\u03c124\n\u03c134\n1\n\n\uf8f9\uf8fa\uf8fb (cid:23) 0,\n\nwith variables \u03c112, \u03c113, \u03c114, \u03c123, \u03c124, \u03c134. the minimum and maximum values (to two\nsignificant digits) are \u22120.39 and 0.23, with corresponding correlation matrices\n\n\uf8ee\uf8ef\uf8f0\n\n1.00\n0.60\n0.87\n\u22120.39\n\n0.60\n1.00\n0.33\n0.50 \u22120.55\n\n0.87 \u22120.39\n0.50\n0.33\n1.00 \u22120.55\n1.00\n\n\uf8ee\uf8ef\uf8f0\n\n1.00\n0.71\n0.80\n0.23\n\n0.71\n1.00\n0.31\n0.59 \u22120.40\n\n0.80\n0.23\n0.31\n0.59\n1.00 \u22120.40\n1.00\n\n\uf8f9\uf8fa\uf8fb .\n\n\u03c114\n(8.7)\n1\n\u03c112\n\u03c113\n\u03c114\n\n\uf8ee\uf8ef\uf8f0\n\uf8f9\uf8fa\uf8fb ,\n\n "}, {"Page_number": 423, "text": "8.3 euclidean distance and angle problems\n\n409\n\n8.3.3 euclidean distance problems\n\nin a euclidean distance problem, we are concerned only with the distances between\nthe vectors, dij, and do not care about the lengths of the vectors, or about the angles\nbetween them. these distances, of course, are invariant not only under orthogonal\ntransformations, but also translation: the configuration \u02dca1 = a1+b, . . . , \u02dcan = an+b\nhas the same distances as the original configuration, for any b \u2208 rn. in particular,\nfor the choice\n\nb = \u2212(1/n)\n\nai = \u2212(1/n)a1,\n\nnxi=1\n\ni=1 \u02dcai = 0.\n\nwe see that \u02dcai have the same distances as the original configuration, and also satisfy\nit follows that in a euclidean distance problem, we can assume,\nwithout any loss of generality, that the average of the vectors a1, . . . , an is zero,\ni.e., a1 = 0.\n\npn\n\nwe can solve euclidean distance problems by considering the lengths (which\ncannot occur in the objective or constraints of a euclidean distance problem) as\nfree variables in the optimization problem. here we rely on the fact that there is\na configuration with distances dij \u2265 0 if and only if there are lengths l1, . . . , ln for\nwhich g (cid:23) 0, where gij = (l2\nij (with, of course,\ndii = 0). the condition that g (cid:23) 0 for some choice of lengths can be expressed as\n(8.8)\n\ni + l2\nwe define z \u2208 rn as zi = l2\n\nj \u2212 d2\ni , and d \u2208 sn by dij = d2\n\ng = (z1t + 1zt \u2212 d)/2 (cid:23) 0 for some z (cid:23) 0,\n\nij)/2.\n\nwhich is an lmi in d and z. a matrix d \u2208 sn, with nonnegative elements,\nzero diagonal, and which satisfies (8.8), is called a euclidean distance matrix. a\nmatrix is a euclidean distance matrix if and only if its entries are the squares\nof the euclidean distances between the vectors of some configuration. (given a\neuclidean distance matrix d and the associated length squared vector z, we can\nreconstruct one, or all, configurations with the given pairwise distances using the\nmethod described above.)\n\nthe condition (8.8) turns out to be equivalent to the simpler condition that d\n\nis negative semidefinite on 1\u22a5, i.e.,\n\n(8.8) \u21d0\u21d2 ut du \u2264 0 for all u with 1t u = 0\n\n\u21d0\u21d2 (i \u2212 (1/n)11t )d(i \u2212 (1/n)11t ) (cid:22) 0.\n\nthis simple matrix inequality, along with dij \u2265 0, dii = 0, is the classical char-\nacterization of a euclidean distance matrix. to see the equivalence, recall that we\ncan assume a1 = 0, which implies that 1t g1 = 1t at a1 = 0. it follows that\ng (cid:23) 0 if and only if g is positive semidefinite on 1\u22a5, i.e.,\n\n0 (cid:22) (i \u2212 (1/n)11t )g(i \u2212 (1/n)11t )\n\n= (1/2)(i \u2212 (1/n)11t )(z1t + 1zt \u2212 d)(i \u2212 (1/n)11t )\n= \u2212(1/2)(i \u2212 (1/n)11t )d(i \u2212 (1/n)11t ),\n\nwhich is the simplified condition.\n\n "}, {"Page_number": 424, "text": "410\n\n8 geometric problems\n\nin summary, a matrix d \u2208 sn is a euclidean distance matrix, i.e., gives the\n\nsquared distances between a set of n vectors in rn, if and only if\n\ndii = 0,\n\ni = 1, . . . , n,\n\ndij \u2265 0,\n\ni, j = 1, . . . , n,\n\n(i \u2212 (1/n)11t )d(i \u2212 (1/n)11t ) (cid:22) 0,\n\nwhich is a set of linear equalities, linear inequalities, and a matrix inequality in\nd. therefore we can express any euclidean distance problem that is convex in the\nsquared distances as a convex problem with variable d \u2208 sn.\n\n8.4 extremal volume ellipsoids\n\nsuppose c \u2286 rn is bounded and has nonempty interior. in this section we consider\nthe problems of finding the maximum volume ellipsoid that lies inside c, and the\nminimum volume ellipsoid that covers c. both problems can be formulated as\nconvex programming problems, but are tractable only in special cases.\n\n8.4.1 the l\u00a8owner-john ellipsoid\n\nthe minimum volume ellipsoid that contains a set c is called the l\u00a8owner-john\nellipsoid of the set c, and is denoted elj. to characterize elj, it will be convenient\nto parametrize a general ellipsoid as\n\ne = {v | kav + bk2 \u2264 1} ,\n\n(8.9)\n\ni.e., the inverse image of the euclidean unit ball under an affine mapping. we can\nassume without loss of generality that a \u2208 sn\n++, in which case the volume of e is\nproportional to det a\u22121. the problem of computing the minimum volume ellipsoid\ncontaining c can be expressed as\n\nminimize\nsubject to\n\nlog det a\u22121\nsupv\u2208c kav + bk2 \u2264 1,\n\n(8.10)\n\nwhere the variables are a \u2208 sn and b \u2208 rn, and there is an implicit constraint\na \u227b 0. the objective and constraint functions are both convex in a and b, so the\nproblem (8.10) is convex. evaluating the constraint function in (8.10), however,\ninvolves solving a convex maximization problem, and is tractable only in certain\nspecial cases.\n\nminimum volume ellipsoid covering a finite set\n\nwe consider the problem of finding the minimum volume ellipsoid that contains\nthe finite set c = {x1, . . . , xm} \u2286 rn. an ellipsoid covers c if and only if it\ncovers its convex hull, so finding the minimum volume ellipsoid that covers c\n\n "}, {"Page_number": 425, "text": "8.4 extremal volume ellipsoids\n\n411\n\nis the same as finding the minimum volume ellipsoid containing the polyhedron\nconv{x1, . . . , xm}. applying (8.10), we can write this problem as\n\nminimize\nsubject to\n\nlog det a\u22121\nkaxi + bk2 \u2264 1,\n\ni = 1, . . . , m\n\n(8.11)\n\nwhere the variables are a \u2208 sn and b \u2208 rn, and we have the implicit constraint a \u227b\n0. the norm constraints kaxi +bk2 \u2264 1, i = 1, . . . , m, are convex inequalities in the\nvariables a and b. they can be replaced with the squared versions, kaxi + bk2\n2 \u2264 1,\nwhich are convex quadratic inequalities in a and b.\n\nminimum volume ellipsoid covering union of ellipsoids\n\nminimum volume covering ellipsoids can also be computed efficiently for certain\nsets c that are defined by quadratic inequalities. in particular, it is possible to\ncompute the l\u00a8owner-john ellipsoid for a union or sum of ellipsoids.\n\nas an example, consider the problem of finding the minimum volume ellip-\nsoid elj, that contains the ellipsoids e1, . . . ,em (and therefore, the convex hull of\ntheir union). the ellipsoids e1, . . . , em will be described by (convex) quadratic\ninequalities:\n\nei = {x | xt aix + 2bt\n\ni x + ci \u2264 0},\n\ni = 1, . . . , m,\n\nwhere ai \u2208 sn\n\n++. we parametrize the ellipsoid elj as\n\nelj = {x | kax + bk2 \u2264 1}\n\n= {x | xt at ax + 2(at b)t x + bt b \u2212 1 \u2264 0}\n\nwhere a \u2208 sn and b \u2208 rn. now we use a result from \u00a7b.2, that ei \u2286 elj if and\nonly if there exists a \u03c4 \u2265 0 such that\n\n(cid:20) a2 \u2212 \u03c4 ai\n(ab \u2212 \u03c4 bi)t\n\nab \u2212 \u03c4 bi\n\nbt b \u2212 1 \u2212 \u03c4 ci (cid:21) (cid:22) 0.\n\nthe volume of elj is proportional to det a\u22121, so we can find the minimum volume\nellipsoid that contains e1, . . . ,em by solving\n\nminimize\nsubject to\n\nlog det a\u22121\n\u03c41 \u2265 0, . . . , \u03c4m \u2265 0\n\n(cid:20) a2 \u2212 \u03c4iai\n(ab \u2212 \u03c4ibi)t\n\nab \u2212 \u03c4ibi\n\nbt b \u2212 1 \u2212 \u03c4ici (cid:21) (cid:22) 0,\n\nor, replacing the variable b by \u02dcb = ab,\n\nminimize\nsubject to\n\nlog det a\u22121\n\u03c41 \u2265 0, . . . , \u03c4m \u2265 0\n\n\u02dcb \u2212 \u03c4ibi\na2 \u2212 \u03c4iai\n(\u02dcb \u2212 \u03c4ibi)t \u22121 \u2212 \u03c4ici\n\n\u02dcb\n\n0\n\n\uf8ee\uf8f0\n\n0\n\u02dcbt\n\n\u2212a2 \uf8f9\uf8fb (cid:22) 0,\n\nwhich is convex in the variables a2 \u2208 sn, \u02dcb, \u03c41, . . . , \u03c4m.\n\ni = 1, . . . , m,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 426, "text": "412\n\n8 geometric problems\n\nfigure 8.3 the outer ellipse is the boundary of the l\u00a8owner-john ellipsoid,\ni.e., the minimum volume ellipsoid that encloses the points x1, . . . , x6 (shown\nas dots), and therefore the polyhedron p = conv{x1, . . . , x6}. the smaller\nellipse is the boundary of the l\u00a8owner-john ellipsoid, shrunk by a factor of\nn = 2 about its center. this ellipsoid is guaranteed to lie inside p.\n\nefficiency of l\u00a8owner-john ellipsoidal approximation\nlet elj be the l\u00a8owner-john ellipsoid of the convex set c \u2286 rn, which is bounded\nand has nonempty interior, and let x0 be its center. if we shrink the l\u00a8owner-john\nellipsoid by a factor of n, about its center, we obtain an ellipsoid that lies inside\nthe set c:\n\nx0 + (1/n)(elj \u2212 x0) \u2286 c \u2286 elj.\n\nin other words, the l\u00a8owner-john ellipsoid approximates an arbitrary convex set,\nwithin a factor that depends only on the dimension n. figure 8.3 shows a simple\nexample.\n\nthe factor 1/n cannot be improved without additional assumptions on c. any\nsimplex in rn, for example, has the property that its l\u00a8owner-john ellipsoid must\nbe shrunk by a factor n to fit inside it (see exercise 8.13).\n\nwe will prove this efficiency result for the special case c = conv{x1, . . . , xm}.\nwe square the norm constraints in (8.11) and introduce variables \u02dca = a2 and\n\u02dcb = ab, to obtain the problem\n\nminimize\nsubject to xi\n\nlog det \u02dca\u22121\nt \u02dcaxi \u2212 2\u02dcbt xi + \u02dcbt \u02dca\u22121\u02dcb \u2264 1,\n\ni = 1, . . . , m.\n\n(8.12)\n\nthe kkt conditions for this problem are\n\npm\n\ni=1 \u03bbi(xixi\n\u03bbi \u2265 0,\n\nt \u2212 \u02dca\u22121\u02dcb\u02dcbt \u02dca\u22121) = \u02dca\u22121,\n\npm\ni=1 \u03bbi(xi \u2212 \u02dca\u22121\u02dcb) = 0,\nt \u02dcaxi \u2212 2\u02dcbt xi + \u02dcbt \u02dca\u22121\u02dcb \u2264 1,\nxi\nt \u02dcaxi + 2\u02dcbt xi \u2212 \u02dcbt \u02dca\u22121\u02dcb) = 0,\n\u03bbi(1 \u2212 xi\n\ni = 1, . . . , m.\n\ni = 1, . . . , m,\n\nby a suitable affine change of coordinates, we can assume that \u02dca = i and \u02dcb = 0,\ni.e., the minimum volume ellipsoid is the unit ball centered at the origin. the kkt\n\n "}, {"Page_number": 427, "text": "8.4 extremal volume ellipsoids\n\n413\n\nconditions then simplify to\n\n\u03bbixixi\n\nt = i,\n\nmxi=1\n\nmxi=1\n\n\u03bbixi = 0,\n\n\u03bbi(1 \u2212 xi\n\nt xi) = 0,\n\ni = 1, . . . , m,\n\nplus the feasibility conditions kxik2 \u2264 1 and \u03bbi \u2265 0. by taking the trace of\nboth sides of the first equation, and using complementary slackness, we also have\n\ni=1 \u03bbi = n.\nin the new coordinates the shrunk ellipsoid is a ball with radius 1/n, centered\n\npm\n\nat the origin. we need to show that\n\nkxk2 \u2264 1/n =\u21d2 x \u2208 c = conv{x1, . . . , xm}.\n\nsuppose kxk2 \u2264 1/n. from the kkt conditions, we see that\n\nx =\n\nmxi=1\n\n\u03bbi(xt xi)xi =\n\nmxi=1\n\n\u03bbi(xt xi + 1/n)xi =\n\nmxi=1\n\n\u00b5ixi,\n\n(8.13)\n\nwhere \u00b5i = \u03bbi(xt xi + 1/n). from the cauchy-schwartz inequality, we note that\n\n\u00b5i = \u03bbi(xt xi + 1/n) \u2265 \u03bbi(\u2212kxk2kxik2 + 1/n) \u2265 \u03bbi(\u22121/n + 1/n) = 0.\n\nfurthermore\n\n\u00b5i =\n\n\u03bbi(xt xi + 1/n) =\n\n\u03bbi/n = 1.\n\nmxi=1\n\nmxi=1\n\nmxi=1\n\nthis, along with (8.13), shows that x is a convex combination of x1, . . . , xm, hence\nx \u2208 c.\nefficiency of l\u00a8owner-john ellipsoidal approximation for symmetric sets\n\nif the set c is symmetric about a point x0, then the factor 1/n can be tightened\nto 1/\u221an:\n\nagain, the factor 1/\u221an is tight. the l\u00a8owner-john ellipsoid of the cube\n\nx0 + (1/\u221an)(elj \u2212 x0) \u2286 c \u2286 elj.\n\nc = {x \u2208 rn | \u2212 1 (cid:22) x (cid:22) 1}\n\nis the ball with radius \u221an. scaling down by 1/\u221an yields a ball enclosed in c, and\ntouching the boundary at x = \u00b1ei.\napproximating a norm by a quadratic norm\nlet k \u00b7 k be any norm on rn, and let c = {x | kxk \u2264 1} be its unit ball. let\nelj = {x | xt ax \u2264 1}, with a \u2208 sn\n++, be the l\u00a8owner-john ellipsoid of c. since c\nis symmetric about the origin, the result above tells us that (1/\u221an)elj \u2286 c \u2286 elj.\nlet k \u00b7 klj denote the quadratic norm\n\nkzklj = (zt az)1/2,\n\n "}, {"Page_number": 428, "text": "414\n\n8 geometric problems\n\nwhose unit ball is elj. the inclusions (1/\u221an)elj \u2286 c \u2286 elj are equivalent to the\n\ninequalities\n\nkzklj \u2264 kzk \u2264 \u221ankzklj\n\nfor all z \u2208 rn. in other words, the quadratic norm k \u00b7 klj approximates the norm\nk \u00b7 k within a factor of \u221an. in particular, we see that any norm on rn can be\napproximated within a factor of \u221an by a quadratic norm.\n\n8.4.2 maximum volume inscribed ellipsoid\n\nwe now consider the problem of finding the ellipsoid of maximum volume that lies\ninside a convex set c, which we assume is bounded and has nonempty interior. to\nformulate this problem, we parametrize the ellipsoid as the image of the unit ball\nunder an affine transformation, i.e., as\n\ne = {bu + d | kuk2 \u2264 1} .\n\nagain it can be assumed that b \u2208 sn\n++, so the volume is proportional to det b. we\ncan find the maximum volume ellipsoid inside c by solving the convex optimization\nproblem\n\nmaximize\nsubject to\n\nlog det b\nsupkuk2\u22641 ic(bu + d) \u2264 0\n\n(8.14)\n\nin the variables b \u2208 sn and d \u2208 rn, with implicit constraint b \u227b 0.\nmaximum volume ellipsoid in a polyhedron\n\nwe consider the case where c is a polyhedron described by a set of linear inequal-\nities:\n\nto apply (8.14) we first express the constraint in a more convenient form:\n\nc = {x | at\n\ni x \u2264 bi, i = 1, . . . , m}.\n\nsup\n\nkuk2\u22641\n\nic(bu + d) \u2264 0 \u21d0\u21d2 sup\n\nkuk2\u22641\n\nat\ni (bu + d) \u2264 bi,\n\ni = 1, . . . , m\n\n\u21d0\u21d2 kbaik2 + at\n\ni d \u2264 bi,\n\ni = 1, . . . , m.\n\nwe can therefore formulate (8.14) as a convex optimization problem in the variables\nb and d:\n\nminimize\nsubject to\n\nlog det b\u22121\nkbaik2 + at\n\ni d \u2264 bi,\n\ni = 1, . . . , m.\n\n(8.15)\n\nmaximum volume ellipsoid in an intersection of ellipsoids\nwe can also find the maximum volume ellipsoid e that lies in the intersection of\nm ellipsoids e1, . . . ,em. we will describe e as e = {bu + d | kuk2 \u2264 1} with\nb \u2208 sn\n\n++, and the other ellipsoids via convex quadratic inequalities,\n\nei = {x | xt aix + 2bt\n\ni x + ci \u2264 0},\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 429, "text": "8.4 extremal volume ellipsoids\n\n415\n\nwhere ai \u2208 sn\nif and only if\n\n++. we first work out the condition under which e \u2286 ei. this occurs\n\nsup\n\nkuk2\u22641(cid:0)(d + bu)t ai(d + bu) + 2bt\n\ni (d + bu) + ci(cid:1)\n\n= dt aid + 2bt\n\ni d + ci + sup\n\nkuk2\u22641(cid:0)ut baibu + 2(aid + bi)t bu(cid:1)\n\n\u2264 0.\n\nfrom \u00a7b.1,\n\nsup\n\nkuk2\u22641(cid:0)ut baibu + 2(aid + bi)t bu(cid:1) \u2264 \u2212(dt aid + 2bt\n\u03bbii \u2212 baib (cid:21) (cid:23) 0.\n\nif and only if there exists a \u03bbi \u2265 0 such that\ni d \u2212 ci\n\n(cid:20) \u2212\u03bbi \u2212 dt aid \u2212 2bt\n\n(aid + bi)t b\n\nb(aid + bi)\n\ni d + ci)\n\nthe maximum volume ellipsoid contained in e1, . . . ,em can therefore be found by\nsolving the problem\n\nminimize\n\nlog det b\u22121\n\nsubject to (cid:20) \u2212\u03bbi \u2212 dt aid \u2212 2bt\n\u03bbii \u2212 baib (cid:21) (cid:23) 0,\nwith variables b \u2208 sn, d \u2208 rn, and \u03bb \u2208 rm, or, equivalently,\nminimize\n\n(aid + bi)t b\n\nb(aid + bi)\n\nlog det b\u22121\n\ni d \u2212 ci\n\nsubject to \uf8ee\uf8f0\n\ni a\u22121\n\ni bi\n\n\u2212\u03bbi \u2212 ci + bt\nd + a\u22121\ni bi\n\n0\n\n0\n\u03bbii\nb\n\n(d + a\u22121\n\ni bi)t\nb\na\u22121\n\ni\n\n\uf8f9\uf8fb (cid:23) 0,\n\ni = 1, . . . , m,\n\ni = 1, . . . , m.\n\nefficiency of ellipsoidal inner approximations\n\napproximation efficiency results, similar to the ones for the l\u00a8owner-john ellipsoid,\nhold for the maximum volume inscribed ellipsoid. if c \u2286 rn is convex, bounded,\nwith nonempty interior, then the maximum volume inscribed ellipsoid, expanded\nby a factor of n about its center, covers the set c. the factor n can be tightened\nto \u221an if the set c is symmetric about a point. an example is shown in figure 8.4.\n\n8.4.3 affine invariance of extremal volume ellipsoids\n\nthe l\u00a8owner-john ellipsoid and the maximum volume inscribed ellipsoid are both\nif elj is the l\u00a8owner-john ellipsoid of c, and t \u2208 rn\u00d7n is\naffinely invariant.\nnonsingular, then the l\u00a8owner-john ellipsoid of t c is telj. a similar result holds\nfor the maximum volume inscribed ellipsoid.\nto establish this result, let e be any ellipsoid that covers c. then the ellipsoid\nte covers t c. the converse is also true: every ellipsoid that covers t c has\n\n "}, {"Page_number": 430, "text": "416\n\n8 geometric problems\n\nfigure 8.4 the maximum volume ellipsoid (shown shaded) inscribed in a\npolyhedron p. the outer ellipse is the boundary of the inner ellipsoid,\nexpanded by a factor n = 2 about its center. the expanded ellipsoid is\nguaranteed to cover p.\n\nthe form te, where e is an ellipsoid that covers c. in other words, the relation\n\u02dce = te gives a one-to-one correspondence between the ellipsoids covering t c and\nthe ellipsoids covering c. moreover, the volumes of the corresponding ellipsoids are\nall related by the ratio | det t|, so in particular, if e has minimum volume among\nellipsoids covering c, then te has minimum volume among ellipsoids covering t c.\n\n8.5 centering\n\n8.5.1 chebyshev center\n\nlet c \u2286 rn be bounded and have nonempty interior, and x \u2208 c. the depth of a\npoint x \u2208 c is defined as\n\ndepth(x, c) = dist(x, rn \\ c),\n\ni.e., the distance to the closest point in the exterior of c. the depth gives the\nradius of the largest ball, centered at x, that lies in c. a chebyshev center of the\nset c is defined as any point of maximum depth in c:\n\nxcheb(c) = argmax depth(x, c) = argmax dist(x, rn \\ c).\n\na chebyshev center is a point inside c that is farthest from the exterior of c; it is\nalso the center of the largest ball that lies inside c. figure 8.5 shows an example,\nin which c is a polyhedron, and the norm is euclidean.\n\n "}, {"Page_number": 431, "text": "8.5 centering\n\n417\n\nxchebxcheb\n\nfigure 8.5 chebyshev center of a polyhedron c, in the euclidean norm. the\ncenter xcheb is the deepest point inside c, in the sense that it is farthest from\nthe exterior, or complement, of c. the center xcheb is also the center of the\nlargest euclidean ball (shown lightly shaded) that lies inside c.\n\nchebyshev center of a convex set\n\nwhen the set c is convex, the depth is a concave function for x \u2208 c, so computing\nthe chebyshev center is a convex optimization problem (see exercise 8.5). more\nspecifically, suppose c \u2286 rn is defined by a set of convex inequalities:\n\nc = {x | f1(x) \u2264 0, . . . , fm(x) \u2264 0}.\n\nwe can find a chebyshev center by solving the problem\n\nmaximize r\nsubject to\n\ngi(x, r) \u2264 0,\n\ni = 1, . . . , m,\n\n(8.16)\n\nwhere gi is defined as\n\ngi(x, r) = sup\nkuk\u22641\n\nfi(x + ru).\n\nproblem (8.16) is a convex optimization problem, since each function gi is the\npointwise maximum of a family of convex functions of x and r, hence convex.\nhowever, evaluating gi involves solving a convex maximization problem (either\nnumerically or analytically), which may be very hard. in practice, we can find the\nchebyshev center only in cases where the functions gi are easy to evaluate.\n\nchebyshev center of a polyhedron\n\nsuppose c is defined by a set of linear inequalities at\nhave\n\ni x \u2264 bi, i = 1, . . . , m. we\n\ngi(x, r) = sup\nkuk\u22641\n\ni (x + ru) \u2212 bi = at\nat\n\ni x + rkaik\u2217 \u2212 bi\n\n "}, {"Page_number": 432, "text": "418\n\n8 geometric problems\n\nif r \u2265 0, so the chebyshev center can be found by solving the lp\n\nmaximize r\nsubject to at\n\ni x + rkaik\u2217 \u2264 bi,\nr \u2265 0\n\ni = 1, . . . , m\n\nwith variables x and r.\n\neuclidean chebyshev center of intersection of ellipsoids\n\nlet c be an intersection of m ellipsoids, defined by quadratic inequalities,\n\nc = {x | xt aix + 2bt\n\ni x + ci \u2264 0, i = 1, . . . , m},\n\n++. we have\n\nwhere ai \u2208 sn\ngi(x, r) =\n\nsup\n\nkuk2\u22641(cid:0)(x + ru)t ai(x + ru) + 2bt\n\ni (x + ru) + ci(cid:1)\n\n= xt aix + 2bt\n\ni x + ci + sup\n\nkuk2\u22641(cid:0)r2ut aiu + 2r(aix + bi)t u(cid:1) .\n\nfrom \u00a7b.1, gi(x, r) \u2264 0 if and only if there exists a \u03bbi such that the matrix\ninequality\n\n(cid:20) \u2212xt aixi \u2212 2bt\n\nr(aix + bi)\n\ni x \u2212 ci \u2212 \u03bbi r(aix + bi)t\n\n\u03bbii \u2212 r2ai (cid:21) (cid:23) 0\n\n(8.17)\n\nholds. using this result, we can express the chebyshev centering problem as\n\nmaximize r\n\nsubject to \uf8ee\uf8f0\n\ni a\u22121\n\ni bi\n\n\u2212\u03bbi \u2212 ci + bt\nx + a\u22121\ni bi\n\n0\n\n0\n\u03bbii\nri\n\ni bi)t\n\n(x + a\u22121\nri\na\u22121\n\ni\n\n\uf8f9\uf8fb (cid:23) 0,\n\ni = 1, . . . , m,\n\nwhich is an sdp with variables r, \u03bb, and x. note that the schur complement of\na\u22121\n\nin the lmi constraint is equal to the lefthand side of (8.17).\n\ni\n\n8.5.2 maximum volume ellipsoid center\n\nthe chebyshev center xcheb of a set c \u2286 rn is the center of the largest ball that\nlies in c. as an extension of this idea, we define the maximum volume ellipsoid\ncenter of c, denoted xmve, as the center of the maximum volume ellipsoid that lies\nin c. figure 8.6 shows an example, where c is a polyhedron.\n\nthe maximum volume ellipsoid center is readily computed when c is defined\nby a set of linear inequalities, by solving the problem (8.15). (the optimal value\nof the variable d \u2208 rn is xmve.) since the maximum volume ellipsoid inside c is\naffine invariant, so is the maximum volume ellipsoid center.\n\n "}, {"Page_number": 433, "text": "8.5 centering\n\n419\n\nxmve\n\nfigure 8.6 the lightly shaded ellipsoid shows the maximum volume ellipsoid\ncontained in the set c, which is the same polyhedron as in figure 8.5. its\ncenter xmve is the maximum volume ellipsoid center of c.\n\n8.5.3 analytic center of a set of inequalities\n\nthe analytic center xac of a set of convex inequalities and linear equalities,\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nf x = g\n\nis defined as an optimal point for the (convex) problem\n\nminimize \u2212pm\n\nsubject to f x = g,\n\ni=1 log(\u2212fi(x))\n\n(8.18)\n\nwith variable x \u2208 rn and implicit constraints fi(x) < 0, i = 1, . . . , m. the objec-\ntive in (8.18) is called the logarithmic barrier associated with the set of inequalities.\nwe assume here that the domain of the logarithmic barrier intersects the affine set\ndefined by the equalities, i.e., the strict inequality system\n\nfi(x) < 0,\n\ni = 1, . . . , m,\n\nf x = g\n\nis feasible. the logarithmic barrier is bounded below on the feasible set\n\nc = {x | fi(x) < 0, i = 1, . . . , m, f x = g},\n\nif c is bounded.\n\nwhen x is strictly feasible, i.e., f x = g and fi(x) < 0 for i = 1, . . . , m, we can\ninterpret \u2212fi(x) as the margin or slack in the ith inequality. the analytic center\nxac is the point that maximizes the product (or geometric mean) of these slacks or\nmargins, subject to the equality constraints f x = g, and the implicit constraints\nfi(x) < 0.\n\nthe analytic center is not a function of the set c described by the inequalities\nand equalities; two sets of inequalities and equalities can define the same set, but\nhave different analytic centers. still, it is not uncommon to informally use the\n\n "}, {"Page_number": 434, "text": "420\n\n8 geometric problems\n\nterm \u2018analytic center of a set c\u2019 to mean the analytic center of a particular set of\nequalities and inequalities that define it.\n\nthe analytic center is, however, independent of affine changes of coordinates.\nit is also invariant under (positive) scalings of the inequality functions, and any\nreparametrization of the equality constraints. in other words, if \u02dcf and \u02dcg are such\nthat \u02dcf x = \u02dcg if and only if f x = g, and \u03b11, . . . , \u03b1m > 0, then the analytic center of\n\n\u03b1ifi(x) \u2264 0,\n\ni = 1, . . . , m,\n\n\u02dcf x = \u02dcg,\n\nis the same as the analytic center of\n\n(see exercise 8.17).\n\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nf x = g\n\nanalytic center of a set of linear inequalities\n\nthe analytic center of a set of linear inequalities\n\nis the solution of the unconstrained minimization problem\n\nat\ni x \u2264 bi,\n\ni = 1, . . . , m,\n\n(8.19)\n\nminimize \u2212pm\n\ni=1 log(bi \u2212 at\n\ni x),\n\nwith implicit constraint bi \u2212 at\ni x > 0, i = 1, . . . , m. if the polyhedron defined by\nthe linear inequalities is bounded, then the logarithmic barrier is bounded below\nand strictly convex, so the analytic center is unique. (see exercise 4.2.)\n\nwe can give a geometric interpretation of the analytic center of a set of linear\ninequalities. since the analytic center is independent of positive scaling of the\nconstraint functions, we can assume without loss of generality that kaik2 = 1. in\nthis case, the slack bi \u2212 at\ni x =\nbi}. therefore the analytic center xac is the point that maximizes the product of\ndistances to the defining hyperplanes.\n\ni x is the distance to the hyperplane hi = {x | at\n\ninner and outer ellipsoids from analytic center of linear inequalities\n\nthe analytic center of a set of linear inequalities implicitly defines an inscribed and\na covering ellipsoid, defined by the hessian of the logarithmic barrier function\n\n\u2212\n\nmxi=1\n\nevaluated at the analytic center, i.e.,\n\nlog(bi \u2212 at\n\ni x),\n\nh =\n\ni aiat\nd2\ni ,\n\nmxi=1\nwe have einner \u2286 p \u2286 eouter, where\np = {x | at\n\ndi =\n\n1\nbi \u2212 at\n\ni xac\n\n,\n\ni = 1, . . . , m.\n\ni x \u2264 bi, i = 1, . . . , m},\n\neinner = {x | (x \u2212 xac)t h(x \u2212 xac) \u2264 1},\neouter = {x | x \u2212 xac)t h(x \u2212 xac) \u2264 m(m \u2212 1)}.\n\n "}, {"Page_number": 435, "text": "8.5 centering\n\n421\n\nxac\n\nfigure 8.7 the dashed lines show five level curves of the logarithmic barrier\nfunction for the inequalities defining the polyhedron c in figure 8.5. the\nminimizer of the logarithmic barrier function, labeled xac, is the analytic\ncenter of the inequalities. the inner ellipsoid einner = {x | (x \u2212 xac)h(x \u2212\nxac) \u2264 1}, where h is the hessian of the logarithmic barrier function at xac,\nis shaded.\n\nthis is a weaker result than the one for the maximum volume inscribed ellipsoid,\nwhich when scaled up by a factor of n covers the polyhedron. the inner and outer\nellipsoids defined by the hessian of the logarithmic barrier, in contrast, are related\nby the scale factor (m(m \u2212 1))1/2, which is always at least n.\n\nto show that einner \u2286 p, suppose x \u2208 einner, i.e.,\n\n(x \u2212 xac)t h(x \u2212 xac) =\n\nmxi=1\n\n(diat\n\ni (x \u2212 xac))2 \u2264 1.\n\nthis implies that\n\nat\ni (x \u2212 xac) \u2264 1/di = bi \u2212 at\n\ni xac,\n\ni = 1, . . . , m,\n\nand therefore at\ni x \u2264 bi for i = 1, . . . , m. (we have not used the fact that xac is\nthe analytic center, so this result is valid if we replace xac with any strictly feasible\npoint.)\n\nto establish that p \u2286 eouter, we will need the fact that xac is the analytic\n\ncenter, and therefore the gradient of the logarithmic barrier vanishes:\n\ndiai = 0.\n\nmxi=1\n\nnow assume x \u2208 p. then\n\n(x \u2212 xac)t h(x \u2212 xac)\n\n=\n\n(diat\n\ni (x \u2212 xac))2\n\nmxi=1\n\n "}, {"Page_number": 436, "text": "422\n\n8 geometric problems\n\ni (1/di \u2212 at\nd2\n\ni (x \u2212 xac))2 \u2212 m\n\n=\n\n=\n\nmxi=1\nmxi=1\n\u2264   mxi=1\n=   mxi=1\n\n= m2 \u2212 m,\n\nd2\ni (bi \u2212 at\n\ni x)2 \u2212 m\ni x)!2\n\ndi(bi \u2212 at\n\n\u2212 m\n\ndi(bi \u2212 at\n\ni xac) +\n\ni (xac \u2212 x)!2\n\ndiat\n\n\u2212 m\n\nmxi=1\n\n(the second equality follows from the fact that\n\nwhich shows that x \u2208 eouter.\n\npm\ni=1 diai = 0. the inequality follows frompm\nlast equality follows frompm\n\nanalytic center of a linear matrix inequality\n\ni=1 y2\n\ni \u2264 (pm\n\ni=1 diai = 0, and the definition of di.)\n\ni=1 yi)2 for y (cid:23) 0. the\n\nthe definition of analytic center can be extended to sets described by generalized\ninequalities with respect to a cone k, if we define a logarithm on k. for example,\nthe analytic center of a linear matrix inequality\n\nx1a1 + x2a2 + \u00b7\u00b7\u00b7 + xnan (cid:22) b\n\nis defined as the solution of\n\nminimize \u2212 log det(b \u2212 x1a1 \u2212 \u00b7\u00b7\u00b7 \u2212 xnan).\n\n8.6 classification\n\nin pattern recognition and classification problems we are given two sets of points\nin rn, {x1, . . . , xn} and {y1, . . . , ym}, and wish to find a function f : rn \u2192 r\n(within a given family of functions) that is positive on the first set and negative on\nthe second, i.e.,\n\nf (xi) > 0,\n\ni = 1, . . . , n,\n\nf (yi) < 0,\n\ni = 1, . . . , m.\n\nif these inequalities hold, we say that f , or its 0-level set {x | f (x) = 0}, separates,\nclassifies, or discriminates the two sets of points. we sometimes also consider weak\nseparation, in which the weak versions of the inequalities hold.\n\n "}, {"Page_number": 437, "text": "8.6 classification\n\n423\n\nfigure 8.8 the points x1, . . . , xn are shown as open circles, and the points\ny1, . . . , ym are shown as filled circles. these two sets are classified by an\naffine function f , whose 0-level set (a line) separates them.\n\n8.6.1 linear discrimination\n\nin linear discrimination, we seek an affine function f (x) = at x \u2212 b that classifies\nthe points, i.e.,\n\nat xi \u2212 b > 0,\n\ni = 1, . . . , n,\n\nat yi \u2212 b < 0,\n\ni = 1, . . . , m.\n\n(8.20)\n\ngeometrically, we seek a hyperplane that separates the two sets of points. since\nthe strict inequalities (8.20) are homogeneous in a and b, they are feasible if and\nonly if the set of nonstrict linear inequalities\n\nat xi \u2212 b \u2265 1,\n\ni = 1, . . . , n,\n\nat yi \u2212 b \u2264 \u22121,\n\ni = 1, . . . , m\n\n(8.21)\n\n(in the variables a, b) is feasible. figure 8.8 shows a simple example of two sets of\npoints and a linear discriminating function.\n\nlinear discrimination alternative\n\nthe strong alternative of the set of strict inequalities (8.20) is the existence of \u03bb,\n\u02dc\u03bb such that\n\n\u03bb (cid:23) 0,\n\n\u02dc\u03bb (cid:23) 0,\n\n(\u03bb, \u02dc\u03bb) 6= 0,\n\n\u03bbixi =\n\nnxi=1\n\nmxi=1\n\n\u02dc\u03bbiyi,\n\n1t \u03bb = 1t \u02dc\u03bb (8.22)\n\n(see \u00a75.8.3). using the third and last conditions, we can express these alternative\nconditions as\n\n\u03bb (cid:23) 0,\n\n1t \u03bb = 1,\n\n\u02dc\u03bb (cid:23) 0,\n\n1t \u02dc\u03bb = 1,\n\n\u03bbixi =\n\nnxi=1\n\n\u02dc\u03bbiyi\n\nmxi=1\n\n "}, {"Page_number": 438, "text": "424\n\n8 geometric problems\n\n(by dividing by 1t \u03bb, which is positive, and using the same symbols for the normal-\nized \u03bb and \u02dc\u03bb). these conditions have a simple geometric interpretation: they state\nthat there is a point in the convex hull of both {x1, . . . , xn} and {y1, . . . , ym}. in\nother words: the two sets of points can be linearly discriminated (i.e., discrimi-\nnated by an affine function) if and only if their convex hulls do not intersect. we\nhave seen this result several times before.\n\nrobust linear discrimination\nthe existence of an affine classifying function f (x) = at x \u2212 b is equivalent to a\nset of linear inequalities in the variables a and b that define f .\nif the two sets\ncan be linearly discriminated, then there is a polyhedron of affine functions that\ndiscriminate them, and we can choose one that optimizes some measure of robust-\nness. we might, for example, seek the function that gives the maximum possible\n\u2018gap\u2019 between the (positive) values at the points xi and the (negative) values at the\npoints yi. to do this we have to normalize a and b, since otherwise we can scale a\nand b by a positive constant and make the gap in the values arbitrarily large. this\nleads to the problem\n\nt\n\nmaximize\nsubject to at xi \u2212 b \u2265 t,\nat yi \u2212 b \u2264 \u2212t,\nkak2 \u2264 1,\n\ni = 1, . . . , n\n\ni = 1, . . . , m\n\n(8.23)\n\nwith variables a, b, and t. the optimal value t\u22c6 of this convex problem (with\nlinear objective, linear inequalities, and one quadratic inequality) is positive if\nand only if the two sets of points can be linearly discriminated. in this case the\ninequality kak2 \u2264 1 is always tight at the optimum, i.e., we have ka\u22c6k2 = 1. (see\nexercise 8.23.)\nwe can give a simple geometric interpretation of the robust linear discrimination\nproblem (8.23). if kak2 = 1 (as is the case at any optimal point), at xi \u2212 b is the\neuclidean distance from the point xi to the separating hyperplane h = {z | at z =\nb}. similarly, b\u2212at yi is the distance from the point yi to the hyperplane. therefore\nthe problem (8.23) finds the hyperplane that separates the two sets of points, and\nhas maximal distance to the sets. in other words, it finds the thickest slab that\nseparates the two sets.\n\nas suggested by the example shown in figure 8.9, the optimal value t\u22c6 (which is\nhalf the slab thickness) turns out to be half the distance between the convex hulls\nof the two sets of points. this can be seen clearly from the dual of the robust linear\ndiscrimination problem (8.23). the lagrangian (for the problem of minimizing \u2212t)\nis\n\n\u2212t +\n\nui(t + b \u2212 at xi) +\n\nvi(t \u2212 b + at yi) + \u03bb(kak2 \u2212 1).\n\nnxi=1\n\nmxi=1\n\nminimizing over b and t yields the conditions 1t u = 1/2, 1t v = 1/2. when these\nhold, we have\n\ng(u, v, \u03bb) = inf\n\na  at (\nmxi=1\n\nviyi \u2212\n\nnxi=1\n\nuixi) + \u03bbkak2 \u2212 \u03bb!\n\n "}, {"Page_number": 439, "text": "8.6 classification\n\n425\n\nfigure 8.9 by solving the robust linear discrimination problem (8.23) we\nfind an affine function that gives the largest gap in values between the two\nsets (with a normalization bound on the linear part of the function). ge-\nometrically, we are finding the thickest slab that separates the two sets of\npoints.\n\nthe dual problem can then be written as\n\n\u2212\u221e otherwise.\n\n(cid:13)(cid:13)(cid:13)pm\n= ( \u2212\u03bb\ni=1 viyi \u2212pn\nmaximize \u2212(cid:13)(cid:13)(cid:13)pm\ni=1 viyi \u2212pn\n\nsubject to u (cid:23) 0,\nv (cid:23) 0,\n\n1t u = 1/2\n1t v = 1/2.\n\ni=1 uixi(cid:13)(cid:13)(cid:13)2 \u2264 \u03bb\ni=1 uixi(cid:13)(cid:13)(cid:13)2\n\nwe can interpret 2pn\n2pm\n\ni=1 uixi as a point in the convex hull of {x1, . . . , xn} and\ni=1 viyi as a point in the convex hull of {y1, . . . , ym}. the dual objective is to\nminimize (half) the distance between these two points, i.e., find (half) the distance\nbetween the convex hulls of the two sets.\n\nsupport vector classifier\n\nwhen the two sets of points cannot be linearly separated, we might seek an affine\nfunction that approximately classifies the points, for example, one that minimizes\nthe number of points misclassified. unfortunately, this is in general a difficult\ncombinatorial optimization problem. one heuristic for approximate linear discrim-\nination is based on support vector classifiers, which we describe in this section.\n\nwe start with the feasibility problem (8.21). we first relax the constraints\nby introducing nonnegative variables u1, . . . , un and v1, . . . , um , and forming the\ninequalities\nat xi \u2212 b \u2265 1\u2212 ui,\n\nat yi \u2212 b \u2264 \u2212(1\u2212 vi),\n\ni = 1, . . . , m. (8.24)\n\ni = 1, . . . , n,\n\n "}, {"Page_number": 440, "text": "426\n\n8 geometric problems\n\nfigure 8.10 approximate linear discrimination via linear programming. the\npoints x1, . . . , x50, shown as open circles, cannot be linearly separated from\nthe points y1, . . . , y50, shown as filled circles. the classifier shown as a solid\nline was obtained by solving the lp (8.25). this classifier misclassifies one\npoint. the dashed lines are the hyperplanes at z \u2212 b = \u00b11. four points are\ncorrectly classified, but lie in the slab defined by the dashed lines.\n\nwhen u = v = 0, we recover the original constraints; by making u and v large\nenough, these inequalities can always be made feasible. we can think of ui as\na measure of how much the constraint at xi \u2212 b \u2265 1 is violated, and similarly\nfor vi. our goal is to find a, b, and sparse nonnegative u and v that satisfy the\ninequalities (8.24). as a heuristic for this, we can minimize the sum of the variables\nui and vi, by solving the lp\n\n1t u + 1t v\n\nminimize\nsubject to at xi \u2212 b \u2265 1 \u2212 ui,\n\nat yi \u2212 b \u2264 \u2212(1 \u2212 vi),\nu (cid:23) 0,\n\nv (cid:23) 0.\n\ni = 1, . . . , n\n\ni = 1, . . . , m\n\n(8.25)\n\nfigure 8.10 shows an example. in this example, the affine function at z \u2212 b mis-\nclassifies 1 out of 100 points. note however that when 0 < ui < 1, the point xi\nis correctly classified by the affine function at z \u2212 b, but violates the inequality\nat xi \u2212 b \u2265 1, and similarly for yi. the objective function in the lp (8.25) can be\ninterpreted as a relaxation of the number of points xi that violate at xi\u2212 b \u2265 1 plus\nthe number of points yi that violate at yi\u2212b \u2264 \u22121. in other words, it is a relaxation\nof the number of points misclassified by the function at z \u2212 b, plus the number of\npoints that are correctly classified but lie in the slab defined by \u22121 < at z \u2212 b < 1.\nmore generally, we can consider the trade-off between the number of misclas-\nsified points, and the width of the slab {z | \u2212 1 \u2264 at z \u2212 b \u2264 1}, which is\ngiven by 2/kak2. the standard support vector classifier for the sets {x1, . . . , xn},\n\n "}, {"Page_number": 441, "text": "8.6 classification\n\n427\n\nfigure 8.11 approximate linear discrimination via support vector classifier,\nwith \u03b3 = 0.1. the support vector classifier, shown as the solid line, misclas-\nsifies three points. fifteen points are correctly classified but lie in the slab\ndefined by \u22121 < at z \u2212 b < 1, bounded by the dashed lines.\n\n{y1, . . . , ym} is defined as the solution of\n\nminimize\nsubject to at xi \u2212 b \u2265 1 \u2212 ui,\n\nkak2 + \u03b3(1t u + 1t v)\nat yi \u2212 b \u2264 \u2212(1 \u2212 vi),\nu (cid:23) 0,\n\nv (cid:23) 0,\n\ni = 1, . . . , n\n\ni = 1, . . . , m\n\nthe first term is proportional to the inverse of the width of the slab defined by\n\u22121 \u2264 at z \u2212 b \u2264 1. the second term has the same interpretation as above, i.e., it\nis a convex relaxation for the number of misclassified points (including the points\nin the slab). the parameter \u03b3, which is positive, gives the relative weight of the\nnumber of misclassified points (which we want to minimize), compared to the width\nof the slab (which we want to maximize). figure 8.11 shows an example.\n\napproximate linear discrimination via logistic modeling\n\nanother approach to finding an affine function that approximately classifies two\nsets of points that cannot be linearly separated is based on the logistic model\ndescribed in \u00a77.1.1. we start by fitting the two sets of points with a logistic model.\nsuppose z is a random variable with values 0 or 1, with a distribution that depends\non some (deterministic) explanatory variable u \u2208 rn, via a logistic model of the\nform\n\nprob(z = 1) = (exp(at u \u2212 b))/(1 + exp(at u \u2212 b))\nprob(z = 0) = 1/(1 + exp(at u \u2212 b)).\n\n(8.26)\n\nnow we assume that the given sets of points, {x1, . . . , xn} and {y1, . . . , ym},\narise as samples from the logistic model. specifically, {x1, . . . , xn} are the values\n\n "}, {"Page_number": 442, "text": "428\n\n8 geometric problems\n\nof u for the n samples for which z = 1, and {y1, . . . , ym} are the values of u for\nthe m samples for which z = 0. (this allows us to have xi = yj, which would rule\nout discrimination between the two sets. in a logistic model, it simply means that\nwe have two samples, with the same value of explanatory variable but different\noutcomes.)\n\nwe can determine a and b by maximum likelihood estimation from the observed\n\nsamples, by solving the convex optimization problem\n\nwith variables a, b, where l is the log-likelihood function\n\nminimize \u2212l(a, b)\n\n(8.27)\n\nl(a, b) =pn\n\u2212pn\n\ni=1(at xi \u2212 b)\n\ni=1 log(1 + exp(at xi \u2212 b)) \u2212pm\n\ni=1 log(1 + exp(at yi \u2212 b))\n\n(see \u00a77.1.1). if the two sets of points can be linearly separated, i.e., if there exist a,\nb with at xi > b and at yi < b, then the optimization problem (8.27) is unbounded\nbelow.\n\nonce we find the maximum likelihood values of a and b, we can form a linear\nclassifier f (x) = at x\u2212 b for the two sets of points. this classifier has the following\nproperty: assuming the data points are in fact generated from a logistic model\nwith parameters a and b, it has the smallest probability of misclassification, over\nall linear classifiers. the hyperplane at u = b corresponds to the points where\nprob(z = 1) = 1/2, i.e., the two outcomes are equally likely. an example is shown\nin figure 8.12.\n\nremark 8.1 bayesian interpretation. let x and z be two random variables, taking\nvalues in rn and in {0, 1}, respectively. we assume that\n\nprob(z = 1) = prob(z = 0) = 1/2,\n\nand we denote by p0(x) and p1(x) the conditional probability densities of x, given\nz = 0 and given z = 1, respectively. we assume that p0 and p1 satisfy\n\np1(x)\np0(x)\n\n= eat x\u2212b\n\nfor some a and b. many common distributions satisfy this property. for example,\np0 and p1 could be two normal densities on rn with equal covariance matrices and\ndifferent means, or they could be two exponential densities on rn\n+.\n\nit follows from bayes\u2019 rule that\n\nprob(z = 1 | x = u) =\n\nprob(z = 0 | x = u) =\n\np1(u)\n\np1(u) + p0(u)\n\np0(u)\n\np1(u) + p0(u)\n\n,\n\nfrom which we obtain\n\nprob(z = 1 | x = u) =\n\nprob(z = 0 | x = u) =\n\nexp(at u \u2212 b)\n1 + exp(at u \u2212 b)\n\n1\n\n1 + exp(at u \u2212 b)\n\n.\n\n "}, {"Page_number": 443, "text": "8.6 classification\n\n429\n\nfigure 8.12 approximate linear discrimination via logistic modeling. the\npoints x1, . . . , x50, shown as open circles, cannot be linearly separated from\nthe points y1, . . . , y50, shown as filled circles. the maximum likelihood lo-\ngistic model yields the hyperplane shown as a dark line, which misclassifies\nonly two points. the two dashed lines show at u\u2212 b = \u00b11, where the proba-\nbility of each outcome, according to the logistic model, is 73%. three points\nare correctly classified, but lie in between the dashed lines.\n\nthe logistic model (8.26) can therefore be interpreted as the posterior distribution of\nz, given that x = u.\n\n8.6.2 nonlinear discrimination\n\nwe can just as well seek a nonlinear function f , from a given subspace of functions,\nthat is positive on one set and negative on another:\n\nf (xi) > 0,\n\ni = 1, . . . , n,\n\nf (yi) < 0,\n\ni = 1, . . . , m.\n\nprovided f is linear (or affine) in the parameters that define it, these inequalities\ncan be solved in exactly the same way as in linear discrimination. in this section\nwe examine some interesting special cases.\n\nquadratic discrimination\n\nsuppose we take f to be quadratic: f (x) = xt p x + qt x + r. the parameters\np \u2208 sn, q \u2208 rn, r \u2208 r must satisfy the inequalities\n\nxt\ni p xi + qt xi + r > 0,\nyt\ni p yi + qt yi + r < 0,\n\ni = 1, . . . , n\ni = 1, . . . , m,\n\n "}, {"Page_number": 444, "text": "430\n\n8 geometric problems\n\nwhich is a set of strict linear inequalities in the variables p , q, r. as in linear\ndiscrimination, we note that f is homogeneous in p , q, and r, so we can find a\nsolution to the strict inequalities by solving the nonstrict feasibility problem\n\nxt\ni p xi + qt xi + r \u2265 1,\nyt\ni p yi + qt yi + r \u2264 \u22121,\n\ni = 1, . . . , n\n\ni = 1, . . . , m.\n\nthe separating surface {z | zt p z + qt z + r = 0} is a quadratic surface, and\n\nthe two classification regions\n\n{z | zt p z + qt z + r \u2264 0},\n\n{z | zt p z + qt z + r \u2265 0},\n\nare defined by quadratic inequalities. solving the quadratic discrimination problem,\nthen, is the same as determining whether the two sets of points can be separated\nby a quadratic surface.\n\nwe can impose conditions on the shape of the separating surface or classification\nregions by adding constraints on p , q, and r. for example, we can require that\np \u227a 0, which means the separating surface is ellipsoidal. more specifically, it means\nthat we seek an ellipsoid that contains all the points x1, . . . , xn , but none of the\npoints y1, . . . , ym . this quadratic discrimination problem can be solved as an sdp\nfeasibility problem\n\np, q, r\nfind\nsubject to xt\ni p xi + qt xi + r \u2265 1,\ni p yi + qt yi + r \u2264 \u22121,\nyt\np (cid:22) \u2212i,\n\ni = 1, . . . , n\n\ni = 1, . . . , m\n\nwith variables p \u2208 sn, q \u2208 rn, and r \u2208 r. (here we use homogeneity in p , q, r\nto express the constraint p \u227a 0 as p (cid:22) \u2212i.) figure 8.13 shows an example.\npolynomial discrimination\n\nwe consider the set of polynomials on rn with degree less than or equal to d:\n\nf (x) = xi1+\u00b7\u00b7\u00b7+in\u2264d\n\nai1\u00b7\u00b7\u00b7idxi1\n\n1 \u00b7\u00b7\u00b7 xin\nn .\n\nwe can determine whether or not two sets {x1, . . . , xn} and {y1, . . . , ym} can be\nseparated by such a polynomial by solving a set of linear inequalities in the variables\nai1\u00b7\u00b7\u00b7id. geometrically, we are checking whether the two sets can be separated by\nan algebraic surface (defined by a polynomial of degree less than or equal to d).\n\nas an extension, the problem of determining the minimum degree polynomial on\nrn that separates two sets of points can be solved via quasiconvex programming,\nsince the degree of a polynomial is a quasiconvex function of the coefficients. this\ncan be carried out by bisection on d, solving a feasibility linear program at each\nstep. an example is shown in figure 8.14.\n\n "}, {"Page_number": 445, "text": "8.6 classification\n\n431\n\nfigure 8.13 quadratic discrimination, with the condition that p \u227a 0. this\nmeans that we seek an ellipsoid containing all of xi (shown as open circles)\nand none of the yi (shown as filled circles). this can be solved as an sdp\nfeasibility problem.\n\nfigure 8.14 minimum degree polynomial discrimination in r2. in this ex-\nample, there exists no cubic polynomial that separates the points x1, . . . , xn\n(shown as open circles) from the points y1, . . . , ym (shown as filled circles),\nbut they can be separated by fourth-degree polynomial, the zero level set of\nwhich is shown.\n\n "}, {"Page_number": 446, "text": "432\n\n8 geometric problems\n\n8.7 placement and location\n\nin this section we discuss a few variations on the following problem. we have\nn points in r2 or r3, and a list of pairs of points that must be connected by\nlinks. the positions of some of the n points are fixed; our task is to determine the\npositions of the remaining points, i.e., to place the remaining points. the objective\nis to place the points so that some measure of the total interconnection length of\nthe links is minimized, subject to some additional constraints on the positions.\nas an example application, we can think of the points as locations of plants or\nwarehouses of a company, and the links as the routes over which goods must be\nshipped. the goal is to find locations that minimize the total transportation cost.\nin another application, the points represent the position of modules or cells on an\nintegrated circuit, and the links represent wires that connect pairs of cells. here\nthe goal might be to place the cells in such a way that the total length of wire used\nto interconnect the cells is minimized.\n\nthe problem can be described in terms of an undirected graph with n nodes,\nrepresenting the n points. with each node we associate a variable xi \u2208 rk, where\nk = 2 or k = 3, which represents its location or position. the problem is to\nminimize\n\nx(i,j)\u2208a\n\nfij(xi, xj)\n\nwhere a is the set of all links in the graph, and fij : rk \u00d7 rk \u2192 r is a cost\nfunction associated with arc (i, j). (alternatively, we can sum over all i and j, or\nover i < j, and simply set fij = 0 when links i and j are not connected.) some of\nthe coordinate vectors xi are given. the optimization variables are the remaining\ncoordinates. provided the functions fij are convex, this is a convex optimization\nproblem.\n\n8.7.1 linear facility location problems\n\nin the simplest version of the problem the cost associated with arc (i, j) is the\ndistance between nodes i and j: fij(xi, xj) = kxi \u2212 xjk, i.e., we minimize\n\nx(i,j)\u2208a\n\nkxi \u2212 xjk.\n\nwe can use any norm, but the most common applications involve the euclidean\nnorm or the \u21131-norm. for example, in circuit design it is common to route the wires\nbetween cells along piecewise-linear paths, with each segment either horizontal or\nvertical. (this is called manhattan routing, since paths along the streets in a city\nwith a rectangular grid are also piecewise-linear, with each street aligned with one\nof two orthogonal axes.) in this case, the length of wire required to connect cell i\nand cell j is given by kxi \u2212 xjk1.\n\nwe can include nonnegative weights that reflect differences in the cost per unit\n\n "}, {"Page_number": 447, "text": "8.7 placement and location\n\n433\n\ndistance along different arcs:\n\nx(i,j)\u2208a\n\nwijkxi \u2212 xjk.\n\nby assigning a weight wij = 0 to pairs of nodes that are not connected, we can\nexpress this problem more simply using the objective\n\nxi<j\n\nwijkxi \u2212 xjk.\n\n(8.28)\n\nthis placement problem is convex.\n\nexample 8.4 one free point. consider the case where only one point (u, v) \u2208 r2 is\nfree, and we minimize the sum of the distances to fixed points (u1, v1), . . . , (uk , vk ).\n\n\u2022 \u21131-norm. we can find a point that minimizes\n\nkxi=1\n\n(|u \u2212 ui| + |v \u2212 vi|)\n\nanalytically. an optimal point is any median of the fixed points. in other words,\nu can be taken to be any median of the points {u1, . . . , uk}, and v can be taken\nto be any median of the points {v1, . . . , vk}. (if k is odd, the minimizer is\nunique; if k is even, there can be a rectangle of optimal points.)\n\n\u2022 euclidean norm. the point (u, v) that minimizes the sum of the euclidean\n\ndistances,\n\nkxi=1(cid:0)(u \u2212 ui)2 + (v \u2212 vi)2(cid:1)1/2\n\nis called the weber point of the given fixed points.\n\n,\n\n8.7.2 placement constraints\n\nwe now list some interesting constraints that can be added to the basic placement\nproblem, preserving convexity. we can require some positions xi to lie in a specified\nconvex set, e.g., a particular line, interval, square, or ellipsoid. we can constrain\nthe relative position of one point with respect to one or more other points, for\nexample, by limiting the distance between a pair of points. we can impose relative\nposition constraints, e.g., that one point must lie to the left of another point.\n\nthe bounding box of a group of points is the smallest rectangle that contains\nthe points. we can impose a constraint that limits the points x1, . . . , xp (say) to lie\nin a bounding box with perimeter not exceeding pmax, by adding the constraints\n\nu (cid:22) xi (cid:22) v,\n\ni = 1, . . . , p,\n\n21t (v \u2212 u) \u2264 pmax,\n\nwhere u, v are additional variables.\n\n "}, {"Page_number": 448, "text": "434\n\n8 geometric problems\n\n8.7.3 nonlinear facility location problems\n\nmore generally, we can associate a cost with each arc that is a nonlinear increasing\nfunction of the length, i.e.,\n\nminimize pi<j wijh(kxi \u2212 xjk)\n\nwhere h is an increasing (on r+) and convex function, and wij \u2265 0. we call this\na nonlinear placement or nonlinear facility location problem.\none common example uses the euclidean norm, and the function h(z) = z2,\n\ni.e., we minimize\n\nxi<j\n\nwijkxi \u2212 xjk2\n2.\n\nthis is called a quadratic placement problem. the quadratic placement problem\ncan be solved analytically when the only constraints are linear equalities; it can be\nsolved as a qp if the constraints are linear equalities and inequalities.\n\nexample 8.5 one free point. consider the case where only one point x is free, and we\nminimize the sum of the squares of the euclidean distances to fixed points x1, . . . , xk ,\n\nkx \u2212 x1k2\n\n2 + kx \u2212 x2k2\n\n2 + \u00b7\u00b7\u00b7 + kx \u2212 xkk2\n2.\n\ntaking derivatives, we see that the optimal x is given by\n\n1\nk\n\n(x1 + x2 + \u00b7\u00b7\u00b7 + xk ),\n\ni.e., the average of the fixed points.\n\nsome other interesting possibilities are the \u2018deadzone\u2019 function h with deadzone\n\nwidth 2\u03b3, defined as\n\nand the \u2018quadratic-linear\u2019 function h, defined as\n\nh(z) =(cid:26) 0\nh(z) =(cid:26) z2\n\n|z \u2212 \u03b3|\n\n|z| \u2264 \u03b3\n|z| \u2265 \u03b3,\n\n2\u03b3|z| \u2212 \u03b32\n\n|z| \u2264 \u03b3\n|z| \u2265 \u03b3.\n\nexample 8.6 we consider a placement problem in r2 with 6 free points, 8 fixed\npoints, and 27 links. figures 8.15\u20138.17 show the optimal solutions for the criteria\n\nx(i,j)\u2208a\n\nkxi \u2212 xjk2, x(i,j)\u2208a\n\nkxi \u2212 xjk2\n\n2, x(i,j)\u2208a\n\nkxi \u2212 xjk4\n2,\n\ni.e., using the penalty functions h(z) = z, h(z) = z2, and h(z) = z4. the figures also\nshow the resulting distributions of the link lengths.\n\ncomparing the results, we see that the linear placement concentrates the free points in\na small area, while the quadratic and fourth-order placements spread the points over\nlarger areas. the linear placement includes many very short links, and a few very long\nones (3 lengths under 0.2 and 2 lengths above 1.5.). the quadratic penalty function\n\n "}, {"Page_number": 449, "text": "8.7 placement and location\n\n435\n\n1\n\n0\n\n\u22121\n\n1\n\n0\n\n\u22121\n\n4\n\n3\n\n2\n\n1\n\n0\n0\n\n1\n\n0\n\n\u22121\nfigure 8.15 linear placement. placement problem with 6 free points (shown\nas dots), 8 fixed points (shown as squares), and 27 links. the coordinates of\nthe free points minimize the sum of the euclidean lengths of the links. the\nright plot is the distribution of the 27 link lengths. the dashed curve is the\n(scaled) penalty function h(z) = z.\n\n0.5\n\n1.5\n\n1\n\n4\n\n3\n\n2\n\n1\n\n0\n\n\u22121\nfigure 8.16 quadratic placement. placement that minimizes the sum of\nsquares of the euclidean lengths of the links, for the same data as in fig-\nure 8.15. the dashed curve is the (scaled) penalty function h(z) = z2.\n\n0.5\n\n1\n\n1\n\n0\n0\n\n2\n\n1.5\n\n "}, {"Page_number": 450, "text": "436\n\n8 geometric problems\n\n1\n\n0\n\n\u22121\n\n6\n\n5\n\n4\n\n3\n\n2\n\n1\n\n0\n\n\u22121\nfigure 8.17 fourth-order placement. placement that minimizes the sum of\nthe fourth powers of the euclidean lengths of the links. the dashed curve\nis the (scaled) penalty function h(z) = z4.\n\n0.5\n\n1\n\n1\n\n0\n0\n\n1.5\n\nputs a higher penalty on long lengths relative to short lengths, and for lengths under\n0.1, the penalty is almost negligible. as a result, the maximum length is shorter (less\nthan 1.4), but we also have fewer short links. the fourth-order function puts an even\nhigher penalty on long lengths, and has a wider interval (between zero and about\n0.4) where it is negligible. as a result, the maximum length is shorter than for the\nquadratic placement, but we also have more lengths close to the maximum.\n\n8.7.4 location problems with path constraints\n\npath constraints\n\na p-link path along the points x1, . . . , xn is described by a sequence of nodes,\ni0, . . . , ip \u2208 {1, . . . , n}. the length of the path is given by\n\nkxi1 \u2212 xi0k + kxi2 \u2212 xi1k + \u00b7\u00b7\u00b7 + kxip \u2212 xip\u22121k,\n\nwhich is a convex function of x1, . . . , xn , so imposing an upper bound on the length\nof a path is a convex constraint. several interesting placement problems involve\npath constraints, or have an objective based on path lengths. we describe one\ntypical example, in which the objective is based on a maximum path length over a\nset of paths.\n\nminimax delay placement\n\nwe consider a directed acyclic graph with nodes 1, . . . , n , and arcs or links repre-\nsented by a set a of ordered pairs: (i, j) \u2208 a if and only if an arc points from i\nto j. we say node i is a source node if no arc a points to it; it is a sink node or\ndestination node if no arc in a leaves from it. we will be interested in the maximal\npaths in the graph, which begin at a source node and end at a sink node.\nthe arcs of the graph are meant to model some kind of flow, say of goods or\ninformation, in a network with nodes at positions x1, . . . , xn . the flow starts at\n\n "}, {"Page_number": 451, "text": "8.7 placement and location\n\n437\n\na source node, then moves along a path from node to node, ending at a sink or\ndestination node. we use the distance between successive nodes to model prop-\nagation time, or shipment time, of the goods between nodes; the total delay or\npropagation time of a path is (proportional to) the sum of the distances between\nsuccessive nodes.\n\nnow we can describe the minimax delay placement problem. some of the node\nlocations are fixed, and the others are free, i.e., optimization variables. the goal\nis to choose the free node locations in order to minimize the maximum total delay,\nfor any path from a source node to a sink node. evidently this is a convex problem,\nsince the objective\n\ntmax = max{kxi1 \u2212 xi0k + \u00b7\u00b7\u00b7 + kxip \u2212 xip\u22121k | i0, . . . , ip is a source-sink path}(8.29)\n\nis a convex function of the locations x1, . . . , xn .\n\nwhile the problem of minimizing (8.29) is convex, the number of source-sink\npaths can be very large, exponential in the number of nodes or arcs. there is\na useful reformulation of the problem, which avoids enumerating all sink-source\npaths.\n\nwe first explain how we can evaluate the maximum delay tmax far more ef-\nficiently than by evaluating the delay for every source-sink path, and taking the\nmaximum. let \u03c4k be the maximum total delay of any path from node k to a sink\nnode. clearly we have \u03c4k = 0 when k is a sink node. consider a node k, which has\noutgoing arcs to nodes j1, . . . , jp. for a path starting at node k and ending at a\nsink node, its first arc must lead to one of the nodes j1, . . . , jp. if such a path first\ntakes the arc leading to ji, and then takes the longest path from there to a sink\nnode, the total length is\n\nkxji \u2212 xkk + \u03c4ji,\n\ni.e., the length of the arc to ji, plus the total length of the longest path from ji to\na sink node. it follows that the maximum delay of a path starting at node k and\nleading to a sink node satisfies\n\n\u03c4k = max{kxj1 \u2212 xkk + \u03c4j1 , . . . ,kxjp \u2212 xkk + \u03c4jp}.\n\n(8.30)\n\n(this is a simple dynamic programming argument.)\n\nthe equations (8.30) give a recursion for finding the maximum delay from any\nnode: we start at the sink nodes (which have maximum delay zero), and then\nwork backward using the equations (8.30), until we reach all source nodes. the\nmaximum delay over any such path is then the maximum of all the \u03c4k, which will\noccur at one of the source nodes. this dynamic programming recursion shows\nhow the maximum delay along any source-sink path can be computed recursively,\nwithout enumerating all the paths. the number of arithmetic operations required\nfor this recursion is approximately the number of links.\n\nnow we show how the recursion based on (8.30) can be used to formulate the\n\nminimax delay placement problem. we can express the problem as\n\nminimize max{\u03c4k | k a source node}\nsubject to\n\nk a sink node\n\n\u03c4k = 0,\n\u03c4k = max{kxj \u2212 xkk + \u03c4j | there is an arc from k to j},\n\n "}, {"Page_number": 452, "text": "438\n\n8 geometric problems\n\nwith variables \u03c41, . . . , \u03c4n and the free positions. this problem is not convex, but\nwe can express it in an equivalent form that is convex, by replacing the equality\nconstraints with inequalities. we introduce new variables t1, . . . , tn , which will be\nupper bounds on \u03c41, . . . , \u03c4n , respectively. we will take tk = 0 for all sink nodes,\nand in place of (8.30) we take the inequalities\n\ntk \u2265 max{kxj1 \u2212 xkk + tj1 , . . . ,kxjp \u2212 xkk + tjp}.\n\nif these inequalities are satisfied, then tk \u2265 \u03c4k. now we form the problem\n\nminimize max{tk | k a source node}\nsubject to tk = 0,\n\nk a sink node\n\ntk \u2265 max{kxj \u2212 xkk + tj | there is an arc from k to j}.\n\nthis problem, with variables t1, . . . , tn and the free locations, is convex, and solves\nthe minimax delay location problem.\n\n8.8 floor planning\n\nin placement problems, the variables represent the coordinates of a number of\npoints that are to be optimally placed. a floor planning problem can be considered\nan extension of a placement problem in two ways:\n\n\u2022 the objects to be placed are rectangles or boxes aligned with the axes (as\n\nopposed to points), and must not overlap.\n\n\u2022 each rectangle or box to be placed can be reconfigured, within some limits.\nfor example we might fix the area of each rectangle, but not the length and\nheight separately.\n\nthe objective is usually to minimize the size (e.g., area, volume, perimeter) of the\nbounding box, which is the smallest box that contains the boxes to be configured\nand placed.\n\nthe non-overlap constraints make the general floor planning problem a compli-\ncated combinatorial optimization problem or rectangle packing problem. however,\nif the relative positioning of the boxes is specified, several types of floor planning\nproblems can be formulated as convex optimization problems. we explore some\nof these in this section. we consider the two-dimensional case, and make a few\ncomments on extensions to higher dimensions (when they are not obvious).\n\nwe have n cells or modules c1, . . . , cn that are to be configured and placed\nin a rectangle with width w and height h, and lower left corner at the position\n(0, 0). the geometry and position of the ith cell is specified by its width wi and\nheight hi, and the coordinates (xi, yi) of its lower left corner. this is illustrated in\nfigure 8.18.\n\nthe variables in the problem are xi, yi, wi, hi for i = 1, . . . , n , and the width\nin all floor planning problems, we\n\nw and height h of the bounding rectangle.\nrequire that the cells lie inside the bounding rectangle, i.e.,\n\nxi \u2265 0,\n\nyi \u2265 0,\n\nxi + wi \u2264 w,\n\nyi + hi \u2264 h,\n\ni = 1, . . . , n.\n\n(8.31)\n\n "}, {"Page_number": 453, "text": "8.8 floor planning\n\n439\n\nwi\n\nci\n\n(xi, yi)\n\nhi\n\nh\n\nw\n\nfigure 8.18 floor planning problem. non-overlapping rectangular cells are\nplaced in a rectangle with width w , height h, and lower left corner at (0, 0).\nthe ith cell is specified by its width wi, height hi, and the coordinates of its\nlower left corner, (xi, yi).\n\nwe also require that the cells do not overlap, except possibly on their boundaries:\n\nint (ci \u2229 cj) = \u2205 for i 6= j.\n\n(it is also possible to require a positive minimum clearance between the cells.) the\nnon-overlap constraint int(ci \u2229 cj) = \u2205 holds if and only if for i 6= j,\n\nci is left of cj, or ci is right of cj, or ci is below cj, or ci is above cj.\n\nthese four geometric conditions correspond to the inequalities\n\nxi + wi \u2264 xj, or xj + wj \u2264 xi, or yi + hj \u2264 yj, or yj + hi \u2264 yi,\n\n(8.32)\n\nat least one of which must hold for each i 6= j. note the combinatorial nature of\nthese constraints: for each pair i 6= j, at least one of the four inequalities above\nmust hold.\n\n8.8.1 relative positioning constraints\n\nthe idea of relative positioning constraints is to specify, for each pair of cells,\none of the four possible relative positioning conditions, i.e., left, right, above, or\nbelow. one simple method to specify these constraints is to give two relations on\n{1, . . . , n}: l (meaning \u2018left of\u2019) and b (meaning \u2018below\u2019). we then impose the\nconstraint that ci is to the left of cj if (i, j) \u2208 l, and ci is below cj if (i, j) \u2208 b.\nthis yields the constraints\n\nxi + wi \u2264 xj for (i, j) \u2208 l,\n\nyi + hi \u2264 yj for (i, j) \u2208 b,\n\n(8.33)\n\n "}, {"Page_number": 454, "text": "440\n\n8 geometric problems\n\nfor i, j = 1, . . . , n . to ensure that the relations l and b specify the relative\npositioning of each pair of cells, we require that for each (i, j) with i 6= j, one of\nthe following holds:\n\n(i, j) \u2208 l,\n\n(j, i) \u2208 l,\n\n(i, j) \u2208 b,\n\n(j, i) \u2208 b,\n\nand that (i, i) 6\u2208 l, (i, i) 6\u2208 b. the inequalities (8.33) are a set of n (n \u2212 1)/2 linear\ninequalities in the variables. these inequalities imply the non-overlap inequali-\nties (8.32), which are a set of n (n \u2212 1)/2 disjunctions of four linear inequalities.\nwe can assume that the relations l and b are anti-symmetric (i.e., (i, j) \u2208\nl \u21d2 (j, i) 6\u2208 l) and transitive (i.e., (i, j) \u2208 l, (j, k) \u2208 l \u21d2 (i, k) \u2208 l). (if this\nwere not the case, the relative positioning constraints would clearly be infeasible.)\ntransitivity corresponds to the obvious condition that if cell ci is to the left of cell\ncj, which is to the left of cell ck, then cell ci must be to the left of cell ck. in\nthis case the inequality corresponding to (i, k) \u2208 l is redundant; it is implied by\nthe other two. by exploiting transitivity of the relations l and b we can remove\nredundant constraints, and obtain a compact set of relative positioning inequalities.\na minimal set of relative positioning constraints is conveniently described using\ntwo directed acyclic graphs h and v (for horizontal and vertical). both graphs have\nn nodes, corresponding to the n cells in the floor planning problem. the graph\nh generates the relation l as follows: we have (i, j) \u2208 l if and only if there is\na (directed) path in h from i to j. similarly, the graph v generates the relation\nb: (i, j) \u2208 b if and only if there is a (directed) path in v from i to j. to ensure\nthat a relative positioning constraint is given for every pair of cells, we require that\nfor every pair of cells, there is a directed path from one to the other in one of the\ngraphs.\n\nevidently, we only need to impose the inequalities that correspond to the edges\nof the graphs h and v; the others follow from transitivity. we arrive at the set of\ninequalities\n\nyi + hi \u2264 yj for (i, j) \u2208 v,\n\nxi + wi \u2264 xj for (i, j) \u2208 h,\n\n(8.34)\nwhich is a set of linear inequalities, one for each edge in h and v. the set of\ninequalities (8.34) is a subset of the set of inequalities (8.33), and equivalent.\nin a similar way, the 4n inequalities (8.31) can be reduced to a minimal, equiv-\nalent set. the constraint xi \u2265 0 only needs to be imposed on the left-most cells,\ni.e., for i that are minimal in the relation l. these correspond to the sources in\nthe graph h, i.e., those nodes that have no edges pointing to them. similarly, the\ninequalities xi + wi \u2264 w only need to be imposed for the right-most cells. in the\nsame way the vertical bounding box inequalities can be pruned to a minimal set.\nthis yields the minimal equivalent set of bounding box inequalities\nxi + wi \u2264 w for i l maximal,\nyi + hi \u2264 h for i b maximal.\n\nxi \u2265 0 for i l minimal,\nyi \u2265 0 for i b minimal,\n\n(8.35)\n\na simple example is shown in figure 8.19. in this example, the l minimal or\nleft-most cells are c1, c2, and c4, and the only right-most cell is c5. the minimal\nset of inequalities specifying the horizontal relative positioning is given by\nx1 + w1 \u2264 x3,\n\nx5 + w5 \u2264 w,\n\nx1 \u2265 0,\n\nx4 \u2265 0,\n\nx2 \u2265 0,\n\nx2 + w2 \u2264 x3,\n\nx3 + w3 \u2264 x5,\n\nx4 + w4 \u2264 x5.\n\n "}, {"Page_number": 455, "text": "8.8 floor planning\n\n441\n\n1\n\n2\n\n2\n\nh\n\nv\n\n3\n\n4\n\n1\n\n3\n\n5\n\n4\n\n5\n\n4\n\n1\n\n2\n\n5\n\n3\n\nfigure 8.19 example illustrating the horizontal and vertical graphs h and\nv that specify the relative positioning of the cells. if there is a path from\nnode i to node j in h, then cell i must be placed to the left of cell j. if there\nis a path from node i to node j in v, then cell i must be placed below cell\nj. the floorplan shown at right satisfies the relative positioning specified by\nthe two graphs.\n\nthe minimal set of inequalities specifying the vertical relative positioning is given\nby\n\ny2 \u2265 0,\n\ny3 \u2265 0,\n\ny2 + h2 \u2264 y1,\n\ny5 \u2265 0,\n\ny4 + h4 \u2264 h,\n\ny1 + h1 \u2264 y4,\n\ny3 + h3 \u2264 y4.\n\ny5 + h5 \u2264 h,\n\n8.8.2 floor planning via convex optimization\n\nin this formulation, the variables are the bounding box width and height w and\nh, and the cell widths, heights, and positions: wi, hi, xi, and wi, for i = 1, . . . , n .\nwe impose the bounding box constraints (8.35) and the relative positioning con-\nstraints (8.34), which are linear inequalities. as objective, we take the perimeter\nof the bounding box, i.e., 2(w + h), which is a linear function of the variables.\nwe now list some of the constraints that can be expressed as convex inequalities\nor linear equalities in the variables.\n\nminimum spacing\n\nwe can impose a minimum spacing \u03c1 > 0 between cells by changing the relative\nposition constraints from xi + wi \u2264 xj for (i, j) \u2208 h, to xi + wi + \u03c1 \u2264 xj for\n(i, j) \u2208 h, and similarly for the vertical graph. we can have a different minimum\nspacing associated with each edge in h and v. another possibility is to fix w and\nh, and maximize the minimum spacing \u03c1 as objective.\n\n "}, {"Page_number": 456, "text": "442\n\n8 geometric problems\n\nminimum cell area\n\nfor each cell we specify a minimum area, i.e., we require that wihi \u2265 ai, where\nai > 0. these minimum cell area constraints can be expressed as convex inequali-\nties in several ways, e.g., wi \u2265 ai/hi, (wihi)1/2 \u2265 a1/2\n, or log wi + log hi \u2265 log ai.\n\ni\n\naspect ratio constraints\n\nwe can impose upper and lower bounds on the aspect ratio of each cell, i.e.,\n\nli \u2264 hi/wi \u2264 ui.\n\nmultiplying through by wi transforms these constraints into linear inequalities. we\ncan also fix the aspect ratio of a cell, which results in a linear equality constraint.\n\nalignment constraints\n\nwe can impose the constraint that two edges, or a center line, of two cells are\naligned. for example, the horizontal center line of cell i aligns with the top of cell\nj when\n\nyi + wi/2 = yj + wj.\n\nthese are linear equality constraints. in a similar way we can require that a cell is\nflushed against the bounding box boundary.\n\nsymmetry constraints\n\nwe can require pairs of cells to be symmetric about a vertical or horizontal axis,\nthat can be fixed or floating (i.e., whose position is fixed or not). for example, to\nspecify that the pair of cells i and j are symmetric about the vertical axis x = xaxis,\nwe impose the linear equality constraint\n\nxaxis \u2212 (xi + wi/2) = xj + wj/2 \u2212 xaxis.\n\nwe can require that several pairs of cells be symmetric about an unspecified vertical\naxis by imposing these equality constraints, and introducing xaxis as a new variable.\n\nsimilarity constraints\n\nwe can require that cell i be an a-scaled translate of cell j by the equality con-\nstraints wi = awj, hi = ahj. here the scaling factor a must be fixed. by imposing\nonly one of these constraints, we require that the width (or height) of one cell be\na given factor times the width (or height) of the other cell.\n\ncontainment constraints\n\nwe can require that a particular cell contains a given point, which imposes two lin-\near inequalities. we can require that a particular cell lie inside a given polyhedron,\nagain by imposing linear inequalities.\n\n "}, {"Page_number": 457, "text": "8.8 floor planning\n\ndistance constraints\n\n443\n\nwe can impose a variety of constraints that limit the distance between pairs of\ncells.\nin the simplest case, we can limit the distance between the center points\nof cell i and j (or any other fixed points on the cells, such as lower left corners).\nfor example, to limit the distance between the centers of cells i and j, we use the\n(convex) inequality\n\nk(xi + wi/2, yi + hi/2) \u2212 (xj + wj/2, yj + hj/2)k \u2264 dij.\n\nas in placement problems, we can limit sums of distances, or use sums of distances\nas the objective.\n\nwe can also limit the distance dist(ci, cj) between cell i and cell j, i.e., the\nminimum distance between a point in cell i and a point in cell j. in the general\ncase this can be done as follows. to limit the distance between cells i and j in the\nnorm k \u00b7 k, we can introduce four new variables ui, vi, uj, vj. the pair (ui, vi)\nwill represent a point in ci, and the pair (uj, vj) will represent a point in cj. to\nensure this we impose the linear inequalities\n\nxi \u2264 ui \u2264 xi + wi,\n\nyi \u2264 vi \u2264 yi + hi,\n\nand similarly for cell j. finally, to limit dist(ci, cj), we add the convex inequality\n\nk(ui, vi) \u2212 (uj, vj)k \u2264 dij.\n\nin many specific cases we can express these distance constraints more efficiently,\nby exploiting the relative positioning constraints or deriving a more explicit formu-\nlation. as an example consider the \u2113\u221e-norm, and suppose cell i lies to the left of\ncell j (by a relative positioning constraint). the horizontal displacement between\nthe two cells is xj \u2212 (xi + wi) then we have dist(ci, cj) \u2264 dij if and only if\nyi \u2212 (yj + hj) \u2264 dij.\n\nxj \u2212 (xi + wi) \u2264 dij,\n\nyj \u2212 (yi + hi) \u2264 dij,\n\nthe first inequality states that the horizontal displacement between the right edge\nof cell i and the left edge of cell j does not exceed dij. the second inequality\nrequires that the bottom of cell j is no more than dij above the top of cell i, and\nthe third inequality requires that the bottom of cell i is no more than dij above the\ntop of cell j. these three inequalities together are equivalent to dist(ci, cj) \u2264 dij.\nin this case, we do not need to introduce any new variables.\nwe can limit the \u21131- (or \u21132-) distance between two cells in a similar way. here\nwe introduce one new variable dv, which will serve as a bound on the vertical\ndisplacement between the cells. to limit the \u21131-distance, we add the constraints\n\nyj \u2212 (yi + hi) \u2264 dv,\n\nyi \u2212 (yj + hj) \u2264 dv,\n\ndv \u2265 0\n\nand the constraints\n\nxj \u2212 (xi + wi) + dv \u2264 dij.\n\n(the first term is the horizontal displacement and the second is an upper bound\non the vertical displacement.) to limit the euclidean distance between the cells,\nwe replace this last constraint with\n\n(xj \u2212 (xi + wi))2 + d2\n\nv \u2264 d2\nij.\n\n "}, {"Page_number": 458, "text": "444\n\n8 geometric problems\n\n4\n\n4\n\n1\n\n2\n\n1\n\n2\n\n5\n\n3\n\n5\n\n3\n\n4\n\n1\n\n2\n\n3\n\n5\n\n4\n\n1\n\n2\n\n5\n\n3\n\nfigure 8.20 four instances of an optimal floor plan, using the relative po-\nsitioning constraints shown in figure 8.19. in each case the objective is to\nminimize the perimeter, and the same minimum spacing constraint between\ncells is imposed. we also require the aspect ratios to lie between 1/5 and 5.\nthe four cases differ in the minimum areas required for each cell. the sum\nof the minimum areas is the same for each case.\n\nexample 8.7 figure 8.20 shows an example with 5 cells, using the ordering constraints\nof figure 8.19, and four different sets of constraints.\nin each case we impose the\nsame minimum required spacing constraint, and the same aspect ratio constraint\n1/5 \u2264 wi/hi \u2264 5. the four cases differ in the minimum required cell areas ai. the\ni=1 ai is the same\nfor each case.\n\nvalues of ai are chosen so that the total minimum required areap5\n\n8.8.3 floor planning via geometric programming\n\nthe floor planning problem can also be formulated as a geometric program in the\nvariables xi, yi, wi, hi, w, h. the objectives and constraints that can be handled\nin this formulation are a bit different from those that can be expressed in the convex\nformulation.\n\nfirst we note that the bounding box constraints (8.35) and the relative po-\n\n "}, {"Page_number": 459, "text": "8.8 floor planning\n\n445\n\nsitioning constraints (8.34) are posynomial inequalities, since the lefthand sides\nare sums of variables, and the righthand sides are single variables, hence monomi-\nals. dividing these inequalities by the righthand side yields standard posynomial\ninequalities.\n\nin the geometric programming formulation we can minimize the bounding box\narea, since w h is a monomial, hence posynomial. we can also exactly specify\nthe area of each cell, since wihi = ai is a monomial equality constraint. on the\nother hand alignment, symmetry, and distance constraints cannot be handled in\nthe geometric programming formulation. similarity, however, can be; indeed it\nis possible to require that one cell be similar to another, without specifying the\nscaling ratio (which can be treated as just another variable).\n\n "}, {"Page_number": 460, "text": "446\n\n8 geometric problems\n\nbibliography\n\nthe characterization of euclidean distance matrices in \u00a78.3.3 appears in schoenberg\n[sch35]; see also gower [gow85].\n\nour use of the term l\u00a8owner-john ellipsoid follows gr\u00a8otschel, lov\u00b4asz, and schrijver\n[gls88, page 69]. the efficiency results for ellipsoidal approximations in \u00a78.4 were proved\nby john [joh85]. boyd, el ghaoui, feron, and balakrishnan [befb94, \u00a73.7] give con-\nvex formulations of several ellipsoidal approximation problems involving sets defined as\nunions, intersections or sums of ellipsoids.\nthe different centers defined in \u00a78.5 have applications in design centering (see, for exam-\nple, seifi, ponnambalan, and vlach [spv99]), and cutting-plane methods (elzinga and\nmoore [em75], tarasov, khachiyan, and `erlikh [tke88], and ye [ye97, chapter 8]). the\ninner ellipsoid defined by the hessian of the logarithmic barrier function (page 420) is\nsometimes called the dikin ellipsoid, and is the basis of dikin\u2019s algorithm for linear and\nquadratic programming [dik67]. the expression for the outer ellipsoid at the analytic\ncenter was given by sonnevend [son86]. for extensions to nonpolyhedral convex sets, see\nboyd and el ghaoui [be93], jarre [jar94], and nesterov and nemirovski [nn94, page\n34].\n\nconvex optimization has been applied to linear and nonlinear discrimination problems\nsince the 1960s; see mangasarian [man65] and rosen [ros65]. standard texts that dis-\ncuss pattern classification include duda, hart, and stork [dhs99] and hastie, tibshirani,\nand friedman [htf01]. for a detailed discussion of support vector classifiers, see vap-\nnik [vap00] or sch\u00a8olkopf and smola [ss01].\n\nthe weber point defined in example 8.4 is named after weber [web71]. linear and\nquadratic placement is used in circuit design (kleinhaus, sigl, johannes, and antre-\nich [ksja91, sdj91]). sherwani [she99] is a recent overview of algorithms for placement,\nlayout, floor planning, and other geometric optimization problems in vlsi circuit design.\n\n "}, {"Page_number": 461, "text": "exercises\n\nexercises\n\nprojection on a set\n\n447\n\n8.1 uniqueness of projection. show that if c \u2286 rn is nonempty, closed and convex, and the\nnorm k \u00b7 k is strictly convex, then for every x0 there is exactly one x \u2208 c closest to x0. in\nother words the projection of x0 on c is unique.\n8.2 [web94, val64] chebyshev characterization of convexity. a set c \u2208 rn is called a cheby-\nshev set if for every x0 \u2208 rn, there is a unique point in c closest (in euclidean norm)\nto x0. from the result in exercise 8.1, every nonempty, closed, convex set is a chebyshev\nset. in this problem we show the converse, which is known as motzkin\u2019s theorem.\nlet c \u2208 rn be a chebyshev set.\n(a) show that c is nonempty and closed.\n(b) show that pc , the euclidean projection on c, is continuous.\n(c) suppose x0 6\u2208 c. show that pc (x) = pc (x0) for all x = \u03b8x0 + (1 \u2212 \u03b8)pc (x0) with\n0 \u2264 \u03b8 \u2264 1.\n(d) suppose x0 6\u2208 c. show that pc (x) = pc (x0) for all x = \u03b8x0 + (1 \u2212 \u03b8)pc (x0) with\n\u03b8 \u2265 1.\n(e) combining parts (c) and (d), we can conclude that all points on the ray with base\npc (x0) and direction x0 \u2212 pc (x0) have projection pc (x0). show that this implies\nthat c is convex.\n\n8.3 euclidean projection on proper cones.\n\n(a) nonnegative orthant. show that euclidean projection onto the nonnegative orthant\n\nis given by the expression on page 399.\n\n(b) positive semidefinite cone. show that euclidean projection onto the positive semidef-\n\ninite cone is given by the expression on page 399.\n\n(c) second-order cone. show that the euclidean projection of (x0, t0) on the second-\n\norder cone\n\nis given by\n\nk = {(x, t) \u2208 rn+1 | kxk2 \u2264 t}\n\npk (x0, t0) =( 0\n\n(x0, t0)\n(1/2)(1 + t0/kx0k2)(x0,kx0k2)\n\nkx0k2 \u2264 \u2212t0\nkx0k2 \u2264 t0\nkx0k2 \u2265 |t0|.\n\n8.4 the euclidean projection of a point on a convex set yields a simple separating hyperplane\n\n(pc (x0) \u2212 x0)t (x \u2212 (1/2)(x0 + pc (x0))) = 0.\n\nfind a counterexample that shows that this construction does not work for general norms.\n8.5 [hul93, volume 1, page 154] depth function and signed distance to boundary. let c \u2286 rn\nbe a nonempty convex set, and let dist(x, c) be the distance of x to c in some norm.\nwe already know that dist(x, c) is a convex function of x.\n\n(a) show that the depth function,\n\nis concave for x \u2208 c.\n\n(b) the signed distance to the boundary of c is defined as\n\ndepth(x, c) = dist(x, rn \\ c),\n\ns(x) =(cid:26) dist(x, c)\n\nx 6\u2208 c\n\u2212 depth(x, c) x \u2208 c.\n\nthus, s(x) is positive outside c, zero on its boundary, and negative on its interior.\nshow that s is a convex function.\n\n "}, {"Page_number": 462, "text": "448\n\n8 geometric problems\n\ndistance between sets\n\n8.6 let c, d be convex sets.\n\n(a) show that dist(c, x + d) is a convex function of x.\n(b) show that dist(tc, x + td) is a convex function of (x, t) for t > 0.\n\n8.7 separation of ellipsoids. let e1 and e2 be two ellipsoids defined as\n\ne1 = {x | (x \u2212 x1)t p \u22121\n\n1\n\n(x \u2212 x1) \u2264 1},\n\ne2 = {x | (x \u2212 x2)t p \u22121\n\n2\n\n(x \u2212 x2) \u2264 1},\n\nwhere p1, p2 \u2208 sn\n\n++. show that e1 \u2229 e2 = \u2205 if and only if there exists an a \u2208 rn with\n\nkp 1/2\n\n2 ak2 + kp 1/2\n\n1 ak2 < at (x1 \u2212 x2).\n\n8.8 intersection and containment of polyhedra. let p1 and p2 be two polyhedra defined as\n\np1 = {x | ax (cid:22) b},\n\np2 = {x | f x (cid:22) g},\n\nwith a \u2208 rm\u00d7n, b \u2208 rm, f \u2208 rp\u00d7n, g \u2208 rp. formulate each of the following problems\nas an lp feasibility problem, or a set of lp feasibility problems.\n(a) find a point in the intersection p1 \u2229 p2.\n(b) determine whether p1 \u2286 p2.\nfor each problem, derive a set of linear inequalities and equalities that forms a strong\nalternative, and give a geometric interpretation of the alternative.\nrepeat the question for two polyhedra defined as\n\np1 = conv{v1, . . . , vk},\n\np2 = conv{w1, . . . , wl}.\n\neuclidean distance and angle problems\n\n8.9 closest euclidean distance matrix to given data. we are given data \u02c6dij, for i, j = 1, . . . , n,\n\nwhich are corrupted measurements of the euclidean distances between vectors in rk:\n\n\u02c6dij = kxi \u2212 xjk2 + vij,\n\ni, j = 1, . . . , n,\n\nwhere vij is some noise or error. these data satisfy \u02c6dij \u2265 0 and \u02c6dij = \u02c6dji, for all i, j. the\ndimension k is not specified.\nshow how to solve the following problem using convex optimization. find a dimension\ni,j=1(dij \u2212 \u02c6dij)2 is minimized, where dij = kxi \u2212 xjk2,\ni, j = 1, . . . , n. in other words, given some data that are approximate euclidean distances,\nyou are to find the closest set of actual euclidean distances, in the least-squares sense.\n8.10 minimax angle fitting. suppose that y1, . . . , ym \u2208 rk are affine functions of a variable\n\nk and x1, . . . , xn \u2208 rk so thatpn\n\nx \u2208 rn:\nand z1, . . . , zm \u2208 rk are given nonzero vectors. we want to choose the variable x, subject\nto some convex constraints, (e.g., linear inequalities) to minimize the maximum angle\nbetween yi and zi,\n\nyi = aix + bi,\n\ni = 1, . . . , m,\n\nthe angle between nonzero vectors is defined as usual:\n\nmax{6 (y1, z1), . . . , 6 (ym, zm)}.\n\n6 (u, v) = cos\u22121(cid:18) ut v\n\nkuk2kvk2(cid:19) ,\n\nwhere we take cos\u22121(a) \u2208 [0, \u03c0]. we are only interested in the case when the optimal\nobjective value does not exceed \u03c0/2.\nformulate this problem as a convex or quasiconvex optimization problem. when the\nconstraints on x are linear inequalities, what kind of problem (or problems) do you have\nto solve?\n\n "}, {"Page_number": 463, "text": "exercises\n\n449\n\n8.11 smallest euclidean cone containing given points. in rn, we define a euclidean cone, with\n\ncenter direction c 6= 0, and angular radius \u03b8, with 0 \u2264 \u03b8 \u2264 \u03c0/2, as the set\n\n{x \u2208 rn | 6 (c, x) \u2264 \u03b8}.\n\n(a euclidean cone is a second-order cone, i.e., it can be represented as the image of the\nsecond-order cone under a nonsingular linear mapping.)\nlet a1, . . . , am \u2208 rn. how would you find the euclidean cone, of smallest angular radius,\nthat contains a1, . . . , am? (in particular, you should explain how to solve the feasibility\nproblem, i.e., how to determine whether there is a euclidean cone which contains the\npoints.)\n\nextremal volume ellipsoids\n\n8.12 show that the maximum volume ellipsoid enclosed in a set is unique. show that the\n\nl\u00a8owner-john ellipsoid of a set is unique.\n\n8.13 l\u00a8owner-john ellipsoid of a simplex. in this exercise we show that the l\u00a8owner-john el-\nlipsoid of a simplex in rn must be shrunk by a factor n to fit inside the simplex. since\nthe l\u00a8owner-john ellipsoid is affinely invariant, it is sufficient to show the result for one\nparticular simplex.\nderive the l\u00a8owner-john ellipsoid elj for the simplex c = conv{0, e1, . . . , en}. show that\nelj must be shrunk by a factor 1/n to fit inside the simplex.\n8.14 efficiency of ellipsoidal inner approximation. let c be a polyhedron in rn described as\n\nc = {x | ax (cid:22) b}, and suppose that {x | ax \u227a b} is nonempty.\n(a) show that the maximum volume ellipsoid enclosed in c, expanded by a factor n\n\nabout its center, is an ellipsoid that contains c.\n\n(b) show that if c is symmetric about the origin, i.e., of the form c = {x | \u22121 (cid:22) ax (cid:22)\n1}, then expanding the maximum volume inscribed ellipsoid by a factor \u221an gives\n\nan ellipsoid that contains c.\n\n8.15 minimum volume ellipsoid covering union of ellipsoids. formulate the following problem\nas a convex optimization problem. find the minimum volume ellipsoid e = {x | (x \u2212\nx0)t a\u22121(x \u2212 x0) \u2264 1} that contains k given ellipsoids\ni x + ci \u2264 0},\n\nei = {x | xt aix + 2bt\n\ni = 1, . . . , k.\n\nhint. see appendix b.\n\n8.16 maximum volume rectangle inside a polyhedron. formulate the following problem as a\n\nconvex optimization problem. find the rectangle\n\nr = {x \u2208 rn | l (cid:22) x (cid:22) u}\n\nof maximum volume, enclosed in a polyhedron p = {x | ax (cid:22) b}. the variables are\nl, u \u2208 rn. your formulation should not involve an exponential number of constraints.\ncentering\n\n8.17 affine invariance of analytic center. show that the analytic center of a set of inequalities is\naffine invariant. show that it is invariant with respect to positive scaling of the inequalities.\n\n8.18 analytic center and redundant inequalities. two sets of linear inequalities that describe\nthe same polyhedron can have different analytic centers. show that by adding redundant\ninequalities, we can make any interior point x0 of a polyhedron\n\np = {x \u2208 rn | ax (cid:22) b}\n\n "}, {"Page_number": 464, "text": "450\n\n8 geometric problems\n\nthe analytic center. more specifically, suppose a \u2208 rm\u00d7n and ax0 \u227a b. show that there\nexist c \u2208 rn, \u03b3 \u2208 r, and a positive integer q, such that p is the solution set of the m + q\ninequalities\n(8.36)\n(where the inequality ct x \u2264 \u03b3 is added q times), and x0 is the analytic center of (8.36).\n\nct x \u2264 \u03b3,\n\nct x \u2264 \u03b3,\n\nct x \u2264 \u03b3\n\nax (cid:22) b,\n\n. . . ,\n\n8.19 let xac be the analytic center of a set of linear inequalities\n\nand define h as the hessian of the logarithmic barrier function at xac:\n\nat\ni x \u2264 bi,\n\ni = 1, . . . , m,\n\nh =\n\nmxi=1\n\n1\n(bi \u2212 at\ni xac)2\n\naiat\ni .\n\nshow that the kth inequality is redundant (i.e., it can be deleted without changing the\nfeasible set) if\n\nbk \u2212 at\n\nk xac \u2265 m(at\n\nk h \u22121ak)1/2.\n\n8.20 ellipsoidal approximation from analytic center of linear matrix inequality. let c be the\n\nsolution set of the lmi\n\nwhere ai, b \u2208 sm, and let xac be its analytic center. show that\n\nx1a1 + x2a2 + \u00b7\u00b7\u00b7 + xnan (cid:22) b,\n\neinner \u2286 c \u2286 eouter,\n\nwhere\n\neinner = {x | (x \u2212 xac)t h(x \u2212 xac) \u2264 1},\neouter = {x | (x \u2212 xac)t h(x \u2212 xac) \u2264 m(m \u2212 1)},\n\nand h is the hessian of the logarithmic barrier function\n\n\u2212 log det(b \u2212 x1a1 \u2212 x2a2 \u2212 \u00b7\u00b7\u00b7 \u2212 xnan)\n\nevaluated at xac.\n\n8.21 [byt99] maximum likelihood interpretation of analytic center. we use the linear mea-\n\nsurement model of page 352,\n\ny = ax + v,\n\nwhere a \u2208 rm\u00d7n. we assume the noise components vi are iid with support [\u22121, 1]. the\nset of parameters x consistent with the measurements y \u2208 rm is the polyhedron defined\nby the linear inequalities\n(8.37)\n\n\u22121 + y (cid:22) ax (cid:22) 1 + y.\n\nsuppose the probability density function of vi has the form\n\np(v) =(cid:26) \u03b1r(1 \u2212 v2)r \u22121 \u2264 v \u2264 1\n\notherwise,\n\n0\n\nwhere r \u2265 1 and \u03b1r > 0. show that the maximum likelihood estimate of x is the analytic\ncenter of (8.37).\n8.22 center of gravity. the center of gravity of a set c \u2286 rn with nonempty interior is defined\n\nas\n\nxcg = rc\nrc\n\nu du\n\n1 du\n\n.\n\n "}, {"Page_number": 465, "text": "exercises\n\n451\n\nthe center of gravity is affine invariant, and (clearly) a function of the set c, and not\nits particular description. unlike the centers described in the chapter, however, it is very\ndifficult to compute the center of gravity, except in simple cases (e.g., ellipsoids, balls,\nsimplexes).\nshow that the center of gravity xcg is the minimizer of the convex function\n\nf (x) =zc ku \u2212 xk2\n\n2 du.\n\nclassification\n\n8.23 robust linear discrimination. consider the robust linear discrimination problem given\n\nin (8.23).\n\n(a) show that the optimal value t\u22c6 is positive if and only if the two sets of points can\nbe linearly separated. when the two sets of points can be linearly separated, show\nthat the inequality kak2 \u2264 1 is tight, i.e., we have ka\u22c6k2 = 1, for the optimal a\u22c6.\n\n(b) using the change of variables \u02dca = a/t, \u02dcb = b/t, prove that the problem (8.23) is\n\nequivalent to the qp\n\nminimize\nsubject to\n\nk\u02dcak2\n\u02dcat xi \u2212 \u02dcb \u2265 1,\n\u02dcat yi \u2212 \u02dcb \u2264 \u22121,\n\ni = 1, . . . , n\n\ni = 1, . . . , m.\n\n8.24 linear discrimination maximally robust to weight errors. suppose we are given two sets of\npoints {x1, . . . , xn} and and {y1, . . . , ym} in rn that can be linearly separated. in \u00a78.6.1\nwe showed how to find the affine function that discriminates the sets, and gives the largest\ngap in function values. we can also consider robustness with respect to changes in the\nvector a, which is sometimes called the weight vector. for a given a and b for which\nf (x) = at x \u2212 b separates the two sets, we define the weight error margin as the norm of\nthe smallest u \u2208 rn such that the affine function (a + u)t x \u2212 b no longer separates the\ntwo sets of points. in other words, the weight error margin is the maximum \u03c1 such that\n\n(a + u)t xi \u2265 b,\n\ni = 1, . . . , n,\n\n(a + u)t yj \u2264 b,\n\ni = 1, . . . , m,\n\nholds for all u with kuk2 \u2264 \u03c1.\nshow how to find a and b that maximize the weight error margin, subject to the normal-\nization constraint kak2 \u2264 1.\n8.25 most spherical separating ellipsoid. we are given two sets of vectors x1, . . . , xn \u2208 rn, and\ny1, . . . , ym \u2208 rn, and wish to find the ellipsoid with minimum eccentricity (i.e., minimum\ncondition number of the defining matrix) that contains the points x1, . . . , xn , but not the\npoints y1, . . . , ym . formulate this as a convex optimization problem.\n\nplacement and floor planning\n\n8.26 quadratic placement. we consider a placement problem in r2, defined by an undirected\n\ngraph a with n nodes, and with quadratic costs:\n\nminimize p(i,j)\u2208a kxi \u2212 xjk2\n\n2.\n\nthe variables are the positions xi \u2208 r2, i = 1, . . . , m . the positions xi, i = m + 1, . . . , n\nare given. we define two vectors u, v \u2208 rm by\n\nu = (x11, x21, . . . , xm 1),\n\nv = (x12, x22, . . . , xm 2),\n\ncontaining the first and second components, respectively, of the free nodes.\n\n "}, {"Page_number": 466, "text": "452\n\n8 geometric problems\n\nshow that u and v can be found by solving two sets of linear equations,\n\ncu = d1,\n\ncv = d2,\n\nwhere c \u2208 sm . give a simple expression for the coefficients of c in terms of the graph a.\n8.27 problems with minimum distance constraints. we consider a problem with variables\nx1, . . . , xn \u2208 rk. the objective, f0(x1, . . . , xn ), is convex, and the constraints\n\nfi(x1, . . . , xn ) \u2264 0,\n\ni = 1, . . . , m,\n\nare convex (i.e., the functions fi : rn k \u2192 r are convex).\nminimum distance constraints\n\nin addition, we have the\n\nkxi \u2212 xjk2 \u2265 dmin,\n\ni 6= j,\n\ni, j = 1, . . . , n.\n\nin general, this is a hard nonconvex problem.\nfollowing the approach taken in floorplanning, we can form a convex restriction of the\nproblem, i.e., a problem which is convex, but has a smaller feasible set. (solving the\nrestricted problem is therefore easy, and any solution is guaranteed to be feasible for the\nnonconvex problem.) let aij \u2208 rk, for i < j, i, j = 1, . . . , n , satisfy kaijk2 = 1.\nshow that the restricted problem\n\nminimize\nsubject to\n\nf0(x1, . . . , xn )\nfi(x1, . . . , xn ) \u2264 0,\nat\nij(xi \u2212 xj) \u2265 dmin,\n\ni = 1, . . . , m\n\ni < j, i, j = 1, . . . , n,\n\nis convex, and that every feasible point satisfies the minimum distance constraint.\nremark. there are many good heuristics for choosing the directions aij. one simple\none starts with an approximate solution \u02c6x1, . . . , \u02c6xn (that need not satisfy the minimum\ndistance constraints). we then set aij = (\u02c6xi \u2212 \u02c6xj)/k\u02c6xi \u2212 \u02c6xjk2.\nmiscellaneous problems\n\n8.28 let p1 and p2 be two polyhedra described as\n\np1 = {x | ax (cid:22) b} ,\n\np2 = {x | \u22121 (cid:22) cx (cid:22) 1} ,\n\nwhere a \u2208 rm\u00d7n, c \u2208 rp\u00d7n, and b \u2208 rm. the polyhedron p2 is symmetric about the\norigin. for t \u2265 0 and xc \u2208 rn, we use the notation tp2 + xc to denote the polyhedron\n\ntp2 + xc = {tx + xc | x \u2208 p2},\n\nwhich is obtained by first scaling p2 by a factor t about the origin, and then translating\nits center to xc.\nshow how to solve the following two problems, via an lp, or a set of lps.\n\n(a) find the largest polyhedron tp2 + xc enclosed in p1, i.e.,\n\nmaximize\nsubject to\n\nt\ntp2 + xc \u2286 p1\nt \u2265 0.\n\n(b) find the smallest polyhedron tp2 + xc containing p1, i.e.,\n\nt\n\nminimize\nsubject to p1 \u2286 tp2 + xc\n\nt \u2265 0.\n\n "}, {"Page_number": 467, "text": "exercises\n\n453\n\nin both problems the variables are t \u2208 r and xc \u2208 rn.\n8.29 outer polyhedral approximations. let p = {x \u2208 rn | ax (cid:22) b} be a polyhedron, and\nc \u2286 rn a given set (not necessarily convex). use the support function sc to formulate\nthe following problem as an lp:\n\nt\n\nminimize\nsubject to c \u2286 tp + x\n\nt \u2265 0.\n\nhere tp + x = {tu + x | u \u2208 p}, the polyhedron p scaled by a factor of t about the origin,\nand translated by x. the variables are t \u2208 r and x \u2208 rn.\n8.30 interpolation with piecewise-arc curve. a sequence of points a1, . . . , an \u2208 r2 is given. we\nconstruct a curve that passes through these points, in order, and is an arc (i.e., part of a\ncircle) or line segment (which we think of as an arc of infinite radius) between consecutive\npoints. many arcs connect ai and ai+1; we parameterize these arcs by giving the angle\n\u03b8i \u2208 (\u2212\u03c0, \u03c0) between its tangent at ai and the line segment [ai, ai+1]. thus, \u03b8i = 0 means\nthe arc between ai and ai+1 is in fact the line segment [ai, ai+1]; \u03b8i = \u03c0/2 means the arc\nbetween ai and ai+1 is a half-circle (above the linear segment [a1, a2]); \u03b8i = \u2212\u03c0/2 means\nthe arc between ai and ai+1 is a half-circle (below the linear segment [a1, a2]). this is\nillustrated below.\n\n\u03b8i = 3\u03c0/4\n\n\u03b8i = \u03c0/2\n\n\u03b8i = \u03c0/4\n\n\u03b8i = 0\n\nai\n\nai+1\n\nour curve is completely specified by the angles \u03b81, . . . , \u03b8n, which can be chosen in the\ninterval (\u2212\u03c0, \u03c0). the choice of \u03b8i affects several properties of the curve, for example, its\ntotal arc length l, or the joint angle discontinuities, which can be described as follows.\nat each point ai, i = 2, . . . , n\u2212 1, two arcs meet, one coming from the previous point and\none going to the next point. if the tangents to these arcs exactly oppose each other, so the\ncurve is differentiable at ai, we say there is no joint angle discontinuity at ai. in general,\nwe define the joint angle discontinuity at ai as |\u03b8i\u22121+\u03b8i+\u03c8i|, where \u03c8i is the angle between\nthe line segment [ai, ai+1] and the line segment [ai\u22121, ai], i.e., \u03c8i = 6 (ai\u2212 ai+1, ai\u22121\u2212 ai).\nthis is shown below. note that the angles \u03c8i are known (since the ai are known).\n\n\u03b8i\u22121\n\nai\n\n\u03c8i\n\n\u03b8i\n\nai+1\n\nai\u22121\n\nwe define the total joint angle discontinuity as\n\nd =\n\n|\u03b8i\u22121 + \u03b8i + \u03c8i|.\n\nnxi=2\n\nformulate the problem of minimizing total arc length length l, and total joint angle\ndiscontinuity d, as a bi-criterion convex optimization problem. explain how you would\nfind the extreme points on the optimal trade-off curve.\n\n "}, {"Page_number": 468, "text": " "}, {"Page_number": 469, "text": "part iii\n\nalgorithms\n\n "}, {"Page_number": 470, "text": " "}, {"Page_number": 471, "text": "chapter 9\n\nunconstrained minimization\n\n9.1 unconstrained minimization problems\n\nin this chapter we discuss methods for solving the unconstrained optimization\nproblem\n\nf (x)\n\nminimize\n\n(9.1)\nwhere f : rn \u2192 r is convex and twice continuously differentiable (which implies\nthat dom f is open). we will assume that the problem is solvable, i.e., there exists\nan optimal point x\u22c6. (more precisely, the assumptions later in the chapter will\nimply that x\u22c6 exists and is unique.) we denote the optimal value, inf x f (x) =\nf (x\u22c6), as p\u22c6.\n\nsince f is differentiable and convex, a necessary and sufficient condition for a\n\npoint x\u22c6 to be optimal is\n\n\u2207f (x\u22c6) = 0\n\n(9.2)\n(see \u00a74.2.3). thus, solving the unconstrained minimization problem (9.1) is the\nsame as finding a solution of (9.2), which is a set of n equations in the n variables\nx1, . . . , xn. in a few special cases, we can find a solution to the problem (9.1) by\nanalytically solving the optimality equation (9.2), but usually the problem must\nbe solved by an iterative algorithm. by this we mean an algorithm that computes\na sequence of points x(0), x(1), . . . \u2208 dom f with f (x(k)) \u2192 p\u22c6 as k \u2192 \u221e. such\na sequence of points is called a minimizing sequence for the problem (9.1). the\nalgorithm is terminated when f (x(k)) \u2212 p\u22c6 \u2264 \u01eb, where \u01eb > 0 is some specified\ntolerance.\n\ninitial point and sublevel set\n\nthe methods described in this chapter require a suitable starting point x(0). the\nstarting point must lie in dom f , and in addition the sublevel set\n\ns = {x \u2208 dom f | f (x) \u2264 f (x(0))}\n\n(9.3)\n\nmust be closed. this condition is satisfied for all x(0) \u2208 dom f if the function f is\nclosed, i.e., all its sublevel sets are closed (see \u00a7a.3.3). continuous functions with\n\n "}, {"Page_number": 472, "text": "458\n\n9 unconstrained minimization\n\ndom f = rn are closed, so if dom f = rn, the initial sublevel set condition is\nsatisfied by any x(0). another important class of closed functions are continuous\nfunctions with open domains, for which f (x) tends to infinity as x approaches\nbd dom f .\n\n9.1.1 examples\n\nquadratic minimization and least-squares\n\nthe general convex quadratic minimization problem has the form\n\nminimize\n\n(1/2)xt p x + qt x + r,\n\n(9.4)\n+, q \u2208 rn, and r \u2208 r. this problem can be solved via the optimality\nwhere p \u2208 sn\nconditions, p x\u22c6 + q = 0, which is a set of linear equations. when p \u227b 0, there is\na unique solution, x\u22c6 = \u2212p \u22121q. in the more general case when p is not positive\ndefinite, any solution of p x\u22c6 = \u2212q is optimal for (9.4); if p x\u22c6 = \u2212q does not\nhave a solution, then the problem (9.4) is unbounded below (see exercise 9.1). our\nability to analytically solve the quadratic minimization problem (9.4) is the basis\nfor newton\u2019s method, a powerful method for unconstrained minimization described\nin \u00a79.5.\nquently is the least-squares problem\nkax \u2212 bk2\n\none special case of the quadratic minimization problem that arises very fre-\n\n2 = xt (at a)x \u2212 2(at b)t x + bt b.\n\nminimize\n\nthe optimality conditions\n\nat ax\u22c6 = at b\n\nare called the normal equations of the least-squares problem.\n\nunconstrained geometric programming\n\nas a second example, we consider an unconstrained geometric program in convex\nform,\n\nminimize\n\nthe optimality condition is\n\ni=1 exp(at\n\ni x + bi)(cid:1) .\n\nf (x) = log(cid:0)pm\nmxi=1\n\nj x\u22c6 + bj)\n\n1\n\nexp(at\n\ni x\u22c6 + bi)ai = 0,\n\n\u2207f (x\u22c6) =\n\nj=1 exp(at\n\npm\n\nwhich in general has no analytical solution, so here we must resort to an iterative\nalgorithm. for this problem, dom f = rn, so any point can be chosen as the\ninitial point x(0).\n\nanalytic center of linear inequalities\n\nwe consider the optimization problem\n\nminimize\n\nf (x) = \u2212pm\n\ni=1 log(bi \u2212 at\n\ni x),\n\n(9.5)\n\n "}, {"Page_number": 473, "text": "9.1 unconstrained minimization problems\n\n459\n\nwhere the domain of f is the open set\n\ndom f = {x | at\n\ni x < bi, i = 1, . . . , m}.\n\nthe objective function f in this problem is called the logarithmic barrier for the\ninequalities at\ni x \u2264 bi. the solution of (9.5), if it exists, is called the analytic\ncenter of the inequalities. the initial point x(0) must satisfy the strict inequalities\nat\ni x(0) < bi, i = 1, . . . , m. since f is closed, the sublevel set s for any such point\nis closed.\n\nanalytic center of a linear matrix inequality\n\na closely related problem is\n\nminimize\nwhere f : rn \u2192 sp is affine, i.e.,\n\nf (x) = log det f (x)\u22121\n\n(9.6)\n\nf (x) = f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn,\n\nwith fi \u2208 sp. here the domain of f is\n\ndom f = {x | f (x) \u227b 0}.\n\nthe objective function f is called the logarithmic barrier for the linear matrix\ninequality f (x) (cid:23) 0, and the solution (if it exists) is called the analytic center of\nthe linear matrix inequality. the initial point x(0) must satisfy the strict linear\nmatrix inequality f (x(0)) \u227b 0. as in the previous example, the sublevel set of any\nsuch point will be closed, since f is closed.\n\n9.1.2 strong convexity and implications\n\nin much of this chapter (with the exception of \u00a79.6) we assume that the objective\nfunction is strongly convex on s, which means that there exists an m > 0 such that\n\n\u22072f (x) (cid:23) mi\n\n(9.7)\n\nfor all x \u2208 s. strong convexity has several interesting consequences. for x, y \u2208 s\nwe have\n\nf (y) = f (x) + \u2207f (x)t (y \u2212 x) +\n\n(y \u2212 x)t\u22072f (z)(y \u2212 x)\n\n1\n2\n\nfor some z on the line segment [x, y]. by the strong convexity assumption (9.7), the\nlast term on the righthand side is at least (m/2)ky\u2212 xk2\n2, so we have the inequality\nm\n2 ky \u2212 xk2\n\nf (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x) +\n\n(9.8)\n\n2\n\nfor all x and y in s. when m = 0, we recover the basic inequality characterizing\nconvexity; for m > 0 we obtain a better lower bound on f (y) than follows from\nconvexity alone.\n\n "}, {"Page_number": 474, "text": "460\n\n9 unconstrained minimization\n\nwe will first show that the inequality (9.8) can be used to bound f (x) \u2212 p\u22c6,\nwhich is the suboptimality of the point x, in terms of k\u2207f (x)k2. the righthand\nside of (9.8) is a convex quadratic function of y (for fixed x). setting the gradient\nwith respect to y equal to zero, we find that \u02dcy = x \u2212 (1/m)\u2207f (x) minimizes the\nrighthand side. therefore we have\n\nf (y) \u2265 f (x) + \u2207f (x)t (y \u2212 x) +\n\u2265 f (x) + \u2207f (x)t (\u02dcy \u2212 x) +\n= f (x) \u2212\n\n1\n2mk\u2207f (x)k2\n2.\n\n2\n\nm\n2 ky \u2212 xk2\nm\n2 k\u02dcy \u2212 xk2\n\n2\n\nsince this holds for any y \u2208 s, we have\np\u22c6 \u2265 f (x) \u2212\n\n1\n2mk\u2207f (x)k2\n2.\n\n(9.9)\n\nthis inequality shows that if the gradient is small at a point, then the point is\nnearly optimal. the inequality (9.9) can also be interpreted as a condition for\nsuboptimality which generalizes the optimality condition (9.2):\nk\u2207f (x)k2 \u2264 (2m\u01eb)1/2 =\u21d2 f (x) \u2212 p\u22c6 \u2264 \u01eb.\n\n(9.10)\n\nwe can also derive a bound on kx \u2212 x\u22c6k2, the distance between x and any\n\noptimal point x\u22c6, in terms of k\u2207f (x)k2:\nkx \u2212 x\u22c6k2 \u2264\n\n2\nmk\u2207f (x)k2.\n\n(9.11)\n\nto see this, we apply (9.8) with y = x\u22c6 to obtain\n\np\u22c6 = f (x\u22c6) \u2265 f (x) + \u2207f (x)t (x\u22c6 \u2212 x) +\n\n\u2265 f (x) \u2212 k\u2207f (x)k2kx\u22c6 \u2212 xk2 +\n\nm\n2 kx\u22c6 \u2212 xk2\n\n2\n\nm\n2 kx\u22c6 \u2212 xk2\n2,\n\nwhere we use the cauchy-schwarz inequality in the second inequality. since p\u22c6 \u2264\nf (x), we must have\n\n\u2212k\u2207f (x)k2 kx\u22c6 \u2212 xk2 +\n\nm\n2 kx\u22c6 \u2212 xk2\n\n2 \u2264 0,\n\nfrom which (9.11) follows. one consequence of (9.11) is that the optimal point x\u22c6\nis unique.\n\nupper bound on \u22072f (x)\nthe inequality (9.8) implies that the sublevel sets contained in s are bounded, so in\nparticular, s is bounded. therefore the maximum eigenvalue of \u22072f (x), which is a\ncontinuous function of x on s, is bounded above on s, i.e., there exists a constant\nm such that\n\n\u22072f (x) (cid:22) m i\n\n(9.12)\n\n "}, {"Page_number": 475, "text": "9.1 unconstrained minimization problems\n\n461\n\nfor all x \u2208 s. this upper bound on the hessian implies for any x, y \u2208 s,\n\nm\n2 ky \u2212 xk2\n2,\nwhich is analogous to (9.8). minimizing each side over y yields\n\nf (y) \u2264 f (x) + \u2207f (x)t (y \u2212 x) +\n\np\u22c6 \u2264 f (x) \u2212\n\n1\n2m k\u2207f (x)k2\n2,\n\nthe counterpart of (9.9).\n\ncondition number of sublevel sets\n\n(9.13)\n\n(9.14)\n\nfrom the strong convexity inequality (9.7) and the inequality (9.12), we have\n\nmi (cid:22) \u22072f (x) (cid:22) m i\n\n(9.15)\n\nfor all x \u2208 s. the ratio \u03ba = m/m is thus an upper bound on the condition\nnumber of the matrix \u22072f (x), i.e., the ratio of its largest eigenvalue to its smallest\neigenvalue. we can also give a geometric interpretation of (9.15) in terms of the\nsublevel sets of f .\n\nwe define the width of a convex set c \u2286 rn, in the direction q, where kqk2 = 1,\n\nas\n\nw (c, q) = sup\nz\u2208c\n\nqt z \u2212 inf\n\nz\u2208c\n\nqt z.\n\nthe minimum width and maximum width of c are given by\n\nwmin = inf\n\nkqk2=1\n\nw (c, q),\n\nwmax = sup\n\nw (c, q).\n\nkqk2=1\n\nthe condition number of the convex set c is defined as\n\ncond(c) =\n\nw 2\nw 2\n\nmax\n\n,\n\nmin\n\ni.e., the square of the ratio of its maximum width to its minimum width. the\ncondition number of c gives a measure of its anisotropy or eccentricity.\nif the\ncondition number of a set c is small (say, near one) it means that the set has\napproximately the same width in all directions, i.e., it is nearly spherical. if the\ncondition number is large, it means that the set is far wider in some directions than\nin others.\n\nexample 9.1 condition number of an ellipsoid. let e be the ellipsoid\n\ne = {x | (x \u2212 x0)t a\u22121(x \u2212 x0) \u2264 1},\n\nwhere a \u2208 sn\nsup\nz\u2208e\n\n++. the width of e in the direction q is\nqt z \u2212 inf\n\nqt z = (ka1/2qk2 + qt x0) \u2212 (\u2212ka1/2qk2 + qt x0)\n\nz\u2208e\n\n= 2ka1/2qk2.\n\n "}, {"Page_number": 476, "text": "462\n\n9 unconstrained minimization\n\nit follows that its minimum and maximum width are\n\nwmin = 2\u03bbmin(a)1/2,\n\nwmax = 2\u03bbmax(a)1/2,\n\nand its condition number is\n\ncond(e) =\n\n\u03bbmax(a)\n\u03bbmin(a)\n\n= \u03ba(a),\n\nwhere \u03ba(a) denotes the condition number of the matrix a, i.e., the ratio of its\nmaximum singular value to its minimum singular value. thus the condition number\nof the ellipsoid e is the same as the condition number of the matrix a that defines\nit.\n\nnow suppose f satisfies mi (cid:22) \u22072f (x) (cid:22) m i for all x \u2208 s. we will derive\na bound on the condition number of the \u03b1-sublevel c\u03b1 = {x | f (x) \u2264 \u03b1}, where\np\u22c6 < \u03b1 \u2264 f (x(0)). applying (9.13) and (9.8) with x = x\u22c6, we have\n2 \u2265 f (y) \u2265 p\u22c6 + (m/2)ky \u2212 x\u22c6k2\n2.\n\np\u22c6 + (m/2)ky \u2212 x\u22c6k2\n\nthis implies that binner \u2286 c\u03b1 \u2286 bouter where\n\nbinner = {y | ky \u2212 x\u22c6k2 \u2264 (2(\u03b1 \u2212 p\u22c6)/m )1/2},\nbouter = {y | ky \u2212 x\u22c6k2 \u2264 (2(\u03b1 \u2212 p\u22c6)/m)1/2}.\n\nin other words, the \u03b1-sublevel set contains binner, and is contained in bouter, which\nare balls with radii\n\n(2(\u03b1 \u2212 p\u22c6)/m )1/2,\n\n(2(\u03b1 \u2212 p\u22c6)/m)1/2,\n\nrespectively. the ratio of the radii squared gives an upper bound on the condition\nnumber of c\u03b1:\n\ncond(c\u03b1) \u2264\n\nm\nm\n\n.\n\nwe can also give a geometric interpretation of the condition number \u03ba(\u22072f (x\u22c6))\nof the hessian at the optimum. from the taylor series expansion of f around x\u22c6,\n\nf (y) \u2248 p\u22c6 +\n\n1\n2\n\n(y \u2212 x\u22c6)t\u22072f (x\u22c6)(y \u2212 x\u22c6),\n\nwe see that, for \u03b1 close to p\u22c6,\n\nc\u03b1 \u2248 {y | (y \u2212 x\u22c6)t\u22072f (x\u22c6)(y \u2212 x\u22c6) \u2264 2(\u03b1 \u2212 p\u22c6)},\n\ni.e., the sublevel set is well approximated by an ellipsoid with center x\u22c6. therefore\n\nlim\n\u03b1\u2192p\u22c6\n\ncond(c\u03b1) = \u03ba(\u22072f (x\u22c6)).\n\nwe will see that the condition number of the sublevel sets of f (which is bounded\nby m/m) has a strong effect on the efficiency of some common methods for uncon-\nstrained minimization.\n\n "}, {"Page_number": 477, "text": "9.2 descent methods\n\n463\n\nthe strong convexity constants\n\nit must be kept in mind that the constants m and m are known only in rare cases,\nso the inequality (9.10) cannot be used as a practical stopping criterion. it can be\nconsidered a conceptual stopping criterion; it shows that if the gradient of f at x\nis small enough, then the difference between f (x) and p\u22c6 is small. if we terminate\nan algorithm when k\u2207f (x(k))k2 \u2264 \u03b7, where \u03b7 is chosen small enough to be (very\nlikely) smaller than (m\u01eb)1/2, then we have f (x(k)) \u2212 p\u22c6 \u2264 \u01eb (very likely).\nin the following sections we give convergence proofs for algorithms, which in-\nclude bounds on the number of iterations required before f (x(k)) \u2212 p\u22c6 \u2264 \u01eb, where\n\u01eb is some positive tolerance. many of these bounds involve the (usually unknown)\nconstants m and m , so the same comments apply. these results are at least con-\nceptually useful; they establish that the algorithm converges, even if the bound on\nthe number of iterations required to reach a given accuracy depends on constants\nthat are unknown.\n\nwe will encounter one important exception to this situation. in \u00a79.6 we will\nstudy a special class of convex functions, called self-concordant, for which we can\nprovide a complete convergence analysis (for newton\u2019s method) that does not de-\npend on any unknown constants.\n\n9.2 descent methods\n\nthe algorithms described in this chapter produce a minimizing sequence x(k), k =\n1, . . . , where\n\nx(k+1) = x(k) + t(k)\u2206x(k)\n\nand t(k) > 0 (except when x(k) is optimal). here the concatenated symbols \u2206 and\nx that form \u2206x are to be read as a single entity, a vector in rn called the step or\nsearch direction (even though it need not have unit norm), and k = 0, 1, . . . denotes\nthe iteration number. the scalar t(k) \u2265 0 is called the step size or step length at\niteration k (even though it is not equal to kx(k+1) \u2212 x(k)k unless k\u2206x(k)k = 1).\nthe terms \u2018search step\u2019 and \u2018scale factor\u2019 are more accurate, but \u2018search direction\u2019\nand \u2018step length\u2019 are the ones widely used. when we focus on one iteration of\nan algorithm, we sometimes drop the superscripts and use the lighter notation\nx+ = x + t\u2206x, or x := x + t\u2206x, in place of x(k+1) = x(k) + t(k)\u2206x(k).\nall the methods we study are descent methods, which means that\n\nf (x(k+1)) < f (x(k)),\n\nexcept when x(k) is optimal. this implies that for all k we have x(k) \u2208 s, the initial\nsublevel set, and in particular we have x(k) \u2208 dom f . from convexity we know\nthat \u2207f (x(k))t (y \u2212 x(k)) \u2265 0 implies f (y) \u2265 f (x(k)), so the search direction in a\ndescent method must satisfy\n\ni.e., it must make an acute angle with the negative gradient. we call such a\ndirection a descent direction (for f , at x(k)).\n\n\u2207f (x(k))t \u2206x(k) < 0,\n\n "}, {"Page_number": 478, "text": "464\n\n9 unconstrained minimization\n\nthe outline of a general descent method is as follows. it alternates between two\n\nsteps: determining a descent direction \u2206x, and the selection of a step size t.\n\nalgorithm 9.1 general descent method.\n\ngiven a starting point x \u2208 dom f .\nrepeat\n\n1. determine a descent direction \u2206x.\n2. line search. choose a step size t > 0.\n3. update. x := x + t\u2206x.\n\nuntil stopping criterion is satisfied.\n\nthe second step is called the line search since selection of the step size t deter-\nmines where along the line {x + t\u2206x | t \u2208 r+} the next iterate will be. (a more\naccurate term might be ray search.)\na practical descent method has the same general structure, but might be or-\nganized differently. for example, the stopping criterion is often checked while, or\nimmediately after, the descent direction \u2206x is computed. the stopping criterion\nis often of the form k\u2207f (x)k2 \u2264 \u03b7, where \u03b7 is small and positive, as suggested by\nthe suboptimality condition (9.9).\n\nexact line search\n\none line search method sometimes used in practice is exact line search, in which t\nis chosen to minimize f along the ray {x + t\u2206x | t \u2265 0}:\nt = argmins\u22650 f (x + s\u2206x).\n\n(9.16)\n\nan exact line search is used when the cost of the minimization problem with one\nvariable, required in (9.16), is low compared to the cost of computing the search\ndirection itself. in some special cases the minimizer along the ray can be found an-\nalytically, and in others it can be computed efficiently. (this is discussed in \u00a79.7.1.)\nbacktracking line search\n\nmost line searches used in practice are inexact: the step length is chosen to ap-\nproximately minimize f along the ray {x + t\u2206x | t \u2265 0}, or even to just reduce\nf \u2018enough\u2019. many inexact line search methods have been proposed. one inexact\nline search method that is very simple and quite effective is called backtracking line\nsearch. it depends on two constants \u03b1, \u03b2 with 0 < \u03b1 < 0.5, 0 < \u03b2 < 1.\n\nalgorithm 9.2 backtracking line search.\n\ngiven a descent direction \u2206x for f at x \u2208 dom f , \u03b1 \u2208 (0, 0.5), \u03b2 \u2208 (0, 1).\nt := 1.\nwhile f (x + t\u2206x) > f (x) + \u03b1t\u2207f (x)t \u2206x,\n\nt := \u03b2t.\n\n "}, {"Page_number": 479, "text": "9.2 descent methods\n\n465\n\nf (x + t\u2206x)\n\nf (x) + t\u2207f (x)t \u2206x\n\nf (x) + \u03b1t\u2207f (x)t \u2206x\nt\n\nt = 0\n\nt0\n\nfigure 9.1 backtracking line search. the curve shows f , restricted to the line\nover which we search. the lower dashed line shows the linear extrapolation\nof f , and the upper dashed line has a slope a factor of \u03b1 smaller. the\nbacktracking condition is that f lies below the upper dashed line, i.e., 0 \u2264\nt \u2264 t0.\n\nthe line search is called backtracking because it starts with unit step size and\nthen reduces it by the factor \u03b2 until the stopping condition f (x + t\u2206x) \u2264 f (x) +\n\u03b1t\u2207f (x)t \u2206x holds. since \u2206x is a descent direction, we have \u2207f (x)t \u2206x < 0, so\nfor small enough t we have\n\nf (x + t\u2206x) \u2248 f (x) + t\u2207f (x)t \u2206x < f (x) + \u03b1t\u2207f (x)t \u2206x,\n\nwhich shows that the backtracking line search eventually terminates. the constant\n\u03b1 can be interpreted as the fraction of the decrease in f predicted by linear extrap-\nolation that we will accept. (the reason for requiring \u03b1 to be smaller than 0.5 will\nbecome clear later.)\n\nthe backtracking condition is illustrated in figure 9.1. this figure suggests,\nand it can be shown, that the backtracking exit inequality f (x + t\u2206x) \u2264 f (x) +\n\u03b1t\u2207f (x)t \u2206x holds for t \u2265 0 in an interval (0, t0]. it follows that the backtracking\nline search stops with a step length t that satisfies\n\nt = 1,\n\nor\n\nt \u2208 (\u03b2t0, t0].\n\nthe first case occurs when the step length t = 1 satisfies the backtracking condition,\ni.e., 1 \u2264 t0. in particular, we can say that the step length obtained by backtracking\nline search satisfies\n\nt \u2265 min{1, \u03b2t0}.\n\nwhen dom f is not all of rn, the condition f (x + t\u2206x) \u2264 f (x) + \u03b1t\u2207f (x)t \u2206x\nin the backtracking line search must be interpreted carefully. by our convention\nthat f is infinite outside its domain, the inequality implies that x + t\u2206x \u2208 dom f .\nin a practical implementation, we first multiply t by \u03b2 until x + t\u2206x \u2208 dom f ;\n\n "}, {"Page_number": 480, "text": "466\n\n9 unconstrained minimization\n\nthen we start to check whether the inequality f (x + t\u2206x) \u2264 f (x) + \u03b1t\u2207f (x)t \u2206x\nholds.\nthe parameter \u03b1 is typically chosen between 0.01 and 0.3, meaning that we\naccept a decrease in f between 1% and 30% of the prediction based on the linear\nextrapolation. the parameter \u03b2 is often chosen to be between 0.1 (which corre-\nsponds to a very crude search) and 0.8 (which corresponds to a less crude search).\n\n9.3 gradient descent method\n\na natural choice for the search direction is the negative gradient \u2206x = \u2212\u2207f (x).\nthe resulting algorithm is called the gradient algorithm or gradient descent method.\n\nalgorithm 9.3 gradient descent method.\n\ngiven a starting point x \u2208 dom f .\nrepeat\n\n1. \u2206x := \u2212\u2207f (x).\n2. line search. choose step size t via exact or backtracking line search.\n3. update. x := x + t\u2206x.\n\nuntil stopping criterion is satisfied.\n\nthe stopping criterion is usually of the form k\u2207f (x)k2 \u2264 \u03b7, where \u03b7 is small and\npositive. in most implementations, this condition is checked after step 1, rather\nthan after the update.\n\n9.3.1 convergence analysis\n\nin this section we present a simple convergence analysis for the gradient method,\nusing the lighter notation x+ = x + t\u2206x for x(k+1) = x(k) + t(k)\u2206x(k), where \u2206x =\n\u2212\u2207f (x). we assume f is strongly convex on s, so there are positive constants m\nand m such that mi (cid:22) \u22072f (x) (cid:22) m i for all x \u2208 s. define the function \u02dcf : r \u2192 r\nby \u02dcf (t) = f (x \u2212 t\u2207f (x)), i.e., f as a function of the step length t in the negative\ngradient direction. in the following discussion we will only consider t for which\nx \u2212 t\u2207f (x) \u2208 s. from the inequality (9.13), with y = x \u2212 t\u2207f (x), we obtain a\nquadratic upper bound on \u02dcf :\n\n\u02dcf (t) \u2264 f (x) \u2212 tk\u2207f (x)k2\n\n2 +\n\nm t2\n2 k\u2207f (x)k2\n2.\n\n(9.17)\n\nanalysis for exact line search\n\nwe now assume that an exact line search is used, and minimize over t both sides\nof the inequality (9.17). on the lefthand side we get \u02dcf (texact), where texact is the\nstep length that minimizes \u02dcf . the righthand side is a simple quadratic, which\n\n "}, {"Page_number": 481, "text": "9.3 gradient descent method\n\n467\n\nis minimized by t = 1/m , and has minimum value f (x) \u2212 (1/(2m ))k\u2207f (x)k2\n2.\ntherefore we have\n\nf (x+) = \u02dcf (texact) \u2264 f (x) \u2212\n\n1\n2m k\u2207(f (x))k2\n2.\n\nsubtracting p\u22c6 from both sides, we get\n\nf (x+) \u2212 p\u22c6 \u2264 f (x) \u2212 p\u22c6 \u2212\n\n1\n2m k\u2207f (x)k2\n2.\n\nwe combine this with k\u2207f (x)k2\nconclude\n\n2 \u2265 2m(f (x) \u2212 p\u22c6) (which follows from (9.9)) to\n\napplying this inequality recursively, we find that\n\nf (x+) \u2212 p\u22c6 \u2264 (1 \u2212 m/m )(f (x) \u2212 p\u22c6).\n\n(9.18)\nwhere c = 1 \u2212 m/m < 1, which shows that f (x(k)) converges to p\u22c6 as k \u2192 \u221e. in\nparticular, we must have f (x(k)) \u2212 p\u22c6 \u2264 \u01eb after at most\n\nf (x(k)) \u2212 p\u22c6 \u2264 ck(f (x(0)) \u2212 p\u22c6)\n\nlog((f (x(0)) \u2212 p\u22c6)/\u01eb)\n\nlog(1/c)\n\n(9.19)\n\niterations of the gradient method with exact line search.\n\nthis bound on the number of iterations required, even though crude, can give\n\nsome insight into the gradient method. the numerator,\n\nlog((f (x(0)) \u2212 p\u22c6)/\u01eb)\n\ncan be interpreted as the log of the ratio of the initial suboptimality (i.e., gap\nbetween f (x(0)) and p\u22c6), to the final suboptimality (i.e., less than \u01eb). this term\nsuggests that the number of iterations depends on how good the initial point is,\nand what the final required accuracy is.\n\nthe denominator appearing in the bound (9.19), log(1/c), is a function of m/m,\nwhich we have seen is a bound on the condition number of \u22072f (x) over s, or the\ncondition number of the sublevel sets {z | f (z) \u2264 \u03b1}. for large condition number\nbound m/m, we have\n\nlog(1/c) = \u2212 log(1 \u2212 m/m ) \u2248 m/m,\n\nso our bound on the number of iterations required increases approximately linearly\nwith increasing m/m.\n\nwe will see that the gradient method does in fact require a large number of\niterations when the hessian of f , near x\u22c6, has a large condition number. conversely,\nwhen the sublevel sets of f are relatively isotropic, so that the condition number\nbound m/m can be chosen to be relatively small, the bound (9.18) shows that\nconvergence is rapid, since c is small, or at least not too close to one.\n\nthe bound (9.18) shows that the error f (x(k)) \u2212 p\u22c6 converges to zero at least\nas fast as a geometric series. in the context of iterative numerical methods, this\nis called linear convergence, since the error lies below a line on a log-linear plot of\nerror versus iteration number.\n\n "}, {"Page_number": 482, "text": "468\n\n9 unconstrained minimization\n\nanalysis for backtracking line search\n\nnow we consider the case where a backtracking line search is used in the gradient\ndescent method. we will show that the backtracking exit condition,\n\n\u02dcf (t) \u2264 f (x) \u2212 \u03b1tk\u2207f (x)k2\n2,\n\nis satisfied whenever 0 \u2264 t \u2264 1/m . first note that\nm t2\n2 \u2264 \u2212t/2\n\n0 \u2264 t \u2264 1/m =\u21d2 \u2212 t +\n\n(which follows from convexity of \u2212t+m t2/2). using this result and the bound (9.17),\nwe have, for 0 \u2264 t \u2264 1/m ,\n\n\u02dcf (t) \u2264 f (x) \u2212 tk\u2207f (x)k2\n\n2 +\n\u2264 f (x) \u2212 (t/2)k\u2207f (x)k2\n\u2264 f (x) \u2212 \u03b1tk\u2207f (x)k2\n2,\n\n2\n\nm t2\n2 k\u2207(f (x))k2\n\n2\n\nsince \u03b1 < 1/2. therefore the backtracking line search terminates either with t = 1\nor with a value t \u2265 \u03b2/m . this provides a lower bound on the decrease in the\nobjective function. in the first case we have\n\nf (x+) \u2264 f (x) \u2212 \u03b1k\u2207f (x)k2\n2,\n\nand in the second case we have\n\nf (x+) \u2264 f (x) \u2212 (\u03b2\u03b1/m )k\u2207f (x)k2\n2.\n\nputting these together, we always have\n\nf (x+) \u2264 f (x) \u2212 min{\u03b1, \u03b2\u03b1/m}k\u2207f (x)k2\n2.\n\nnow we can proceed exactly as in the case of exact line search. we subtract p\u22c6\nfrom both sides to get\n\nf (x+) \u2212 p\u22c6 \u2264 f (x) \u2212 p\u22c6 \u2212 min{\u03b1, \u03b2\u03b1/m}k\u2207f (x)k2\n2,\n\nand combine this with k\u2207f (x)k2\n\n2 \u2265 2m(f (x) \u2212 p\u22c6) to obtain\n\nf (x+) \u2212 p\u22c6 \u2264 (1 \u2212 min{2m\u03b1, 2\u03b2\u03b1m/m})(f (x) \u2212 p\u22c6).\n\nfrom this we conclude\n\nf (x(k)) \u2212 p\u22c6 \u2264 ck(f (x(0)) \u2212 p\u22c6)\n\nwhere\n\nc = 1 \u2212 min{2m\u03b1, 2\u03b2\u03b1m/m} < 1.\n\nin particular, f (x(k)) converges to p\u22c6 at least as fast as a geometric series with an\nexponent that depends (at least in part) on the condition number bound m/m. in\nthe terminology of iterative methods, the convergence is at least linear.\n\n "}, {"Page_number": 483, "text": "9.3 gradient descent method\n\n469\n\n4\n\n2\nx\n\n0\n\n\u22124\n\n\u221210\n\n0\nx1\n\nx(0)\n\nx(1)\n\n10\n\nfigure 9.2 some contour lines of the function f (x) = (1/2)(x2\n2). the\ncondition number of the sublevel sets, which are ellipsoids, is exactly 10.\nthe figure shows the iterates of the gradient method with exact line search,\nstarted at x(0) = (10, 1).\n\n1 + 10x2\n\n9.3.2 examples\n\na quadratic problem in r2\n\nour first example is very simple. we consider the quadratic objective function on\nr2\n\nf (x) =\n\n(x2\n\n1 + \u03b3x2\n\n2),\n\n1\n2\n\nwhere \u03b3 > 0. clearly, the optimal point is x\u22c6 = 0, and the optimal value is 0. the\nhessian of f is constant, and has eigenvalues 1 and \u03b3, so the condition numbers of\nthe sublevel sets of f are all exactly\n\nmax{1, \u03b3}\nmin{1, \u03b3}\n\n= max{\u03b3, 1/\u03b3}.\n\nthe tightest choices for the strong convexity constants m and m are\n\nm = min{1, \u03b3},\n\nm = max{1, \u03b3}.\n\nwe apply the gradient descent method with exact line search, starting at the\npoint x(0) = (\u03b3, 1). in this case we can derive the following closed-form expressions\nfor the iterates x(k) and their function values (exercise 9.6):\n\nand\n\nx(k)\n\n,\n\nx(k)\n\n1 = \u03b3(cid:18) \u03b3 \u2212 1\n\u03b3 + 1(cid:19)k\n(cid:18) \u03b3 \u2212 1\n\u03b3 + 1(cid:19)2k\n\n\u03b3(\u03b3 + 1)\n\n\u03b3 \u2212 1\n\n\u03b3 + 1(cid:19)k\n2 =(cid:18)\u2212\n\u03b3 + 1(cid:19)2k\n=(cid:18) \u03b3 \u2212 1\n\n2\n\n,\n\nf (x(k)) =\n\nf (x(0)).\n\nthis is illustrated in figure 9.2, for \u03b3 = 10.\n\nfor this simple example, convergence is exactly linear, i.e., the error is exactly\na geometric series, reduced by the factor |(\u03b3 \u2212 1)/(\u03b3 + 1)|2 at each iteration. for\n\n "}, {"Page_number": 484, "text": "470\n\n9 unconstrained minimization\n\n\u03b3 = 1, the exact solution is found in one iteration; for \u03b3 not far from one (say,\nbetween 1/3 and 3) convergence is rapid. the convergence is very slow for \u03b3 \u226b 1\nor \u03b3 \u226a 1.\nwe can compare the convergence with the bound derived above in \u00a79.3.1. using\nthe least conservative values m = min{1, \u03b3} and m = max{1, \u03b3}, the bound (9.18)\nguarantees that the error in each iteration is reduced at least by the factor c =\n(1 \u2212 m/m ). we have seen that the error is in fact reduced exactly by the factor\n\n1 + m/m(cid:19)2\n(cid:18) 1 \u2212 m/m\n\nin each iteration. for small m/m , which corresponds to large condition number,\nthe upper bound (9.19) implies that the number of iterations required to obtain\na given level of accuracy grows at most like m/m. for this example, the exact\nnumber of iterations required grows approximately like (m/m)/4, i.e., one quarter\nof the value of the bound. this shows that for this simple example, the bound on\nthe number of iterations derived in our simple analysis is only about a factor of four\nconservative (using the least conservative values for m and m ). in particular, the\nconvergence rate (as well as its upper bound) is very dependent on the condition\nnumber of the sublevel sets.\n\na nonquadratic problem in r2\n\nwe now consider a nonquadratic example in r2, with\n\nf (x1, x2) = ex1+3x2\u22120.1 + ex1\u22123x2\u22120.1 + e\u2212x1\u22120.1.\n\n(9.20)\n\nwe apply the gradient method with a backtracking line search, with \u03b1 = 0.1,\n\u03b2 = 0.7. figure 9.3 shows some level curves of f , and the iterates x(k) generated\nby the gradient method (shown as small circles). the lines connecting successive\niterates show the scaled steps,\n\nx(k+1) \u2212 x(k) = \u2212t(k)\u2207f (x(k)).\n\nfigure 9.4 shows the error f (x(k))\u2212 p\u22c6 versus iteration k. the plot reveals that\nthe error converges to zero approximately as a geometric series, i.e., the convergence\nis approximately linear. in this example, the error is reduced from about 10 to\nabout 10\u22127 in 20 iterations, so the error is reduced by a factor of approximately\n10\u22128/20 \u2248 0.4 each iteration. this reasonably rapid convergence is predicted by\nour convergence analysis, since the sublevel sets of f are not too badly conditioned,\nwhich in turn means that m/m can be chosen as not too large.\n\nto compare backtracking line search with an exact line search, we use the\ngradient method with an exact line search, on the same problem, and with the\nsame starting point. the results are given in figures 9.5 and 9.4. here too the\nconvergence is approximately linear, about twice as fast as the gradient method\nwith backtracking line search. with exact line search, the error is reduced by\nabout 10\u221211 in 15 iterations, i.e., a reduction by a factor of about 10\u221211/15 \u2248 0.2\nper iteration.\n\n "}, {"Page_number": 485, "text": "9.3 gradient descent method\n\n471\n\nx(0)\n\nx(2)\n\nx(1)\n\nfigure 9.3 iterates of the gradient method with backtracking line search,\nfor the problem in r2 with objective f given in (9.20). the dashed curves\nare level curves of f , and the small circles are the iterates of the gradient\nmethod. the solid lines, which connect successive iterates, show the scaled\nsteps t(k)\u2206x(k).\n\n105\n\n100\n\n\u22c6\np\n\u2212\n\n10\u22125\n\n)\n)\nk\n(\nx\n(\nf\n\n10\u221210\n\nbacktracking l.s.\n\nexact l.s.\n\n10\u221215\n0\n\n5\n\n10\n\n15\nk\n\n20\n\n25\n\nfigure 9.4 error f (x(k))\u2212 p\u22c6 versus iteration k of the gradient method with\nbacktracking and exact line search, for the problem in r2 with objective f\ngiven in (9.20). the plot shows nearly linear convergence, with the error\nreduced approximately by the factor 0.4 in each iteration of the gradient\nmethod with backtracking line search, and by the factor 0.2 in each iteration\nof the gradient method with exact line search.\n\n "}, {"Page_number": 486, "text": "472\n\n9 unconstrained minimization\n\nx(0)\n\nx(1)\n\nfigure 9.5 iterates of the gradient method with exact line search for the\nproblem in r2 with objective f given in (9.20).\n\na problem in r100\n\nwe next consider a larger example, of the form\n\nf (x) = ct x \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x),\n\n(9.21)\n\nwith m = 500 terms and n = 100 variables.\n\nthe progress of the gradient method with backtracking line search, with pa-\nrameters \u03b1 = 0.1, \u03b2 = 0.5, is shown in figure 9.6. in this example we see an initial\napproximately linear and fairly rapid convergence for about 20 iterations, followed\nby a slower linear convergence. overall, the error is reduced by a factor of around\n106 in around 175 iterations, which gives an average error reduction by a factor of\naround 10\u22126/175 \u2248 0.92 per iteration. the initial convergence rate, for the first 20\niterations, is around a factor of 0.8 per iteration; the slower final convergence rate,\nafter the first 20 iterations, is around a factor of 0.94 per iteration.\n\nfigure 9.6 shows the convergence of the gradient method with exact line search.\nthe convergence is again approximately linear, with an overall error reduction by\napproximately a factor 10\u22126/140 \u2248 0.91 per iteration. this is only a bit faster than\nthe gradient method with backtracking line search.\nfinally, we examine the influence of the backtracking line search parameters \u03b1\nand \u03b2 on the convergence rate, by determining the number of iterations required\nto obtain f (x(k)) \u2212 p\u22c6 \u2264 10\u22125. in the first experiment, we fix \u03b2 = 0.5, and vary\n\u03b1 from 0.05 to 0.5. the number of iterations required varies from about 80, for\nlarger values of \u03b1, in the range 0.2\u20130.5, to about 170 for smaller values of \u03b1. this,\nand other experiments, suggest that the gradient method works better with fairly\nlarge \u03b1, in the range 0.2\u20130.5.\n\nsimilarly, we can study the effect of the choice of \u03b2 by fixing \u03b1 = 0.1 and\nvarying \u03b2 from 0.05 to 0.95. again the variation in the total number of iterations\nis not large, ranging from around 80 (when \u03b2 \u2248 0.5) to around 200 (for \u03b2 small,\nor near 1). this experiment, and others, suggest that \u03b2 \u2248 0.5 is a good choice.\n\n "}, {"Page_number": 487, "text": "9.3 gradient descent method\n\n473\n\n104\n\n102\n\n\u22c6\np\n\u2212\n)\n)\nk\n(\nx\n(\nf\n\n100\n\n10\u22122\n\n10\u22124\n0\n\nexact l.s.\n\nbacktracking l.s.\n\n50\n\n100\nk\n\n150\n\n200\n\nfigure 9.6 error f (x(k))\u2212 p\u22c6 versus iteration k for the gradient method with\nbacktracking and exact line search, for a problem in r100.\n\nthese experiments suggest that the effect of the backtracking parameters on the\nconvergence is not large, no more than a factor of two or so.\n\ngradient method and condition number\n\nour last experiment will illustrate the importance of the condition number of\n\u22072f (x) (or the sublevel sets) on the rate of convergence of the gradient method.\nwe start with the function given by (9.21), but replace the variable x by x = t \u00afx,\nwhere\n\nt = diag((1, \u03b31/n, \u03b32/n, . . . , \u03b3(n\u22121)/n)),\n\ni.e., we minimize\n\n\u00aff (\u00afx) = ct t \u00afx \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni t \u00afx).\n\n(9.22)\n\nthis gives us a family of optimization problems, indexed by \u03b3, which affects the\nproblem condition number.\n\nfigure 9.7 shows the number of iterations required to achieve \u00aff (\u00afx(k))\u2212\u00afp\u22c6 < 10\u22125\nas a function of \u03b3, using a backtracking line search with \u03b1 = 0.3 and \u03b2 = 0.7. this\nplot shows that for diagonal scaling as small as 10 : 1 (i.e., \u03b3 = 10), the number of\niterations grows to more than a thousand; for a diagonal scaling of 20 or more, the\ngradient method slows to essentially useless.\n\nthe condition number of the hessian \u22072 \u00aff (\u00afx\u22c6) at the optimum is shown in\nfigure 9.8. for large and small \u03b3, the condition number increases roughly as\nmax{\u03b32, 1/\u03b32}, in a very similar way as the number of iterations depends on \u03b3.\nthis shows again that the relation between conditioning and convergence speed is\na real phenomenon, and not just an artifact of our analysis.\n\n "}, {"Page_number": 488, "text": "474\n\n9 unconstrained minimization\n\n103\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\n102\n\n10\u22121\n\n100\n\u03b3\n\n101\n\nfigure 9.7 number of iterations of the gradient method applied to prob-\nlem (9.22). the vertical axis shows the number of iterations required to\nobtain \u00aff (\u00afx(k)) \u2212 \u00afp\u22c6 < 10\u22125. the horizontal axis shows \u03b3, which is a param-\neter that controls the amount of diagonal scaling. we use a backtracking\nline search with \u03b1 = 0.3, \u03b2 = 0.7.\n\n104\n\n103\n\n102\n\n)\n)\n\u22c6\n\u00afx\n(\n\u00aff\n2\n\n\u2207\n(\n\u03ba\n\n101\n\n10\u22121\n\n100\n\u03b3\n\n101\n\nfigure 9.8 condition number of the hessian of the function at its minimum,\nas a function of \u03b3. by comparing this plot with the one in figure 9.7, we see\nthat the condition number has a very strong influence on convergence rate.\n\n "}, {"Page_number": 489, "text": "9.4 steepest descent method\n\n475\n\nconclusions\n\nfrom the numerical examples shown, and others, we can make the conclusions\nsummarized below.\n\n\u2022 the gradient method often exhibits approximately linear convergence, i.e.,\nthe error f (x(k)) \u2212 p\u22c6 converges to zero approximately as a geometric series.\n\u2022 the choice of backtracking parameters \u03b1, \u03b2 has a noticeable but not dramatic\neffect on the convergence. an exact line search sometimes improves the con-\nvergence of the gradient method, but the effect is not large (and probably\nnot worth the trouble of implementing the exact line search).\n\n\u2022 the convergence rate depends greatly on the condition number of the hessian,\nor the sublevel sets. convergence can be very slow, even for problems that are\nmoderately well conditioned (say, with condition number in the 100s). when\nthe condition number is larger (say, 1000 or more) the gradient method is so\nslow that it is useless in practice.\n\nthe main advantage of the gradient method is its simplicity. its main disadvantage\nis that its convergence rate depends so critically on the condition number of the\nhessian or sublevel sets.\n\n9.4 steepest descent method\n\nthe first-order taylor approximation of f (x + v) around x is\n\nf (x + v) \u2248 bf (x + v) = f (x) + \u2207f (x)t v.\n\nthe second term on the righthand side, \u2207f (x)t v, is the directional derivative of\nf at x in the direction v. it gives the approximate change in f for a small step v.\nthe step v is a descent direction if the directional derivative is negative.\n\nwe now address the question of how to choose v to make the directional deriva-\ntive as negative as possible. since the directional derivative \u2207f (x)t v is linear in\nv, it can be made as negative as we like by taking v large (provided v is a descent\ndirection, i.e., \u2207f (x)t v < 0). to make the question sensible we have to limit the\nsize of v, or normalize by the length of v.\nlet k \u00b7 k be any norm on rn. we define a normalized steepest descent direction\n\n(with respect to the norm k \u00b7 k) as\n\n\u2206xnsd = argmin{\u2207f (x)t v | kvk = 1}.\n\n(9.23)\n\n(we say \u2018a\u2019 steepest descent direction because there can be multiple minimizers.)\na normalized steepest descent direction \u2206xnsd is a step of unit norm that gives the\nlargest decrease in the linear approximation of f .\n\na normalized steepest descent direction can be interpreted geometrically as\n\nfollows. we can just as well define \u2206xnsd as\n\n\u2206xnsd = argmin{\u2207f (x)t v | kvk \u2264 1},\n\n "}, {"Page_number": 490, "text": "476\n\n9 unconstrained minimization\n\ni.e., as the direction in the unit ball of k \u00b7 k that extends farthest in the direction\n\u2212\u2207f (x).\nit is also convenient to consider a steepest descent step \u2206xsd that is unnormal-\nized, by scaling the normalized steepest descent direction in a particular way:\n\n(9.24)\nwhere k \u00b7 k\u2217 denotes the dual norm. note that for the steepest descent step, we\nhave\n\n\u2206xsd = k\u2207f (x)k\u2217\u2206xnsd,\n\n\u2207f (x)t \u2206xsd = k\u2207f (x)k\u2217\u2207f (x)t \u2206xnsd = \u2212k\u2207f (x)k2\n\n\u2217\n\n(see exercise 9.7).\n\nthe steepest descent method uses the steepest descent direction as search direc-\n\ntion.\n\nalgorithm 9.4 steepest descent method.\n\ngiven a starting point x \u2208 dom f .\nrepeat\n\n1. compute steepest descent direction \u2206xsd.\n2. line search. choose t via backtracking or exact line search.\n3. update. x := x + t\u2206xsd.\n\nuntil stopping criterion is satisfied.\n\nwhen exact line search is used, scale factors in the descent direction have no effect,\nso the normalized or unnormalized direction can be used.\n\n9.4.1 steepest descent for euclidean and quadratic norms\n\nsteepest descent for euclidean norm\nif we take the norm k\u00b7k to be the euclidean norm we find that the steepest descent\ndirection is simply the negative gradient, i.e., \u2206xsd = \u2212\u2207f (x). the steepest\ndescent method for the euclidean norm coincides with the gradient descent method.\n\nsteepest descent for quadratic norm\n\nwe consider the quadratic norm\n\nwhere p \u2208 sn\n\n++. the normalized steepest descent direction is given by\n\nkzkp = (zt p z)1/2 = kp 1/2zk2,\n\u2206xnsd = \u2212(cid:0)\u2207f (x)t p \u22121\u2207f (x)(cid:1)\u22121/2\n\np \u22121\u2207f (x).\n\nthe dual norm is given by kzk\u2217 = kp \u22121/2zk2, so the steepest descent step with\nrespect to k \u00b7 kp is given by\n\n\u2206xsd = \u2212p \u22121\u2207f (x).\n\n(9.25)\n\nthe normalized steepest descent direction for a quadratic norm is illustrated in\nfigure 9.9.\n\n "}, {"Page_number": 491, "text": "9.4 steepest descent method\n\n477\n\n\u2212\u2207f (x)\n\n\u2206xnsd\n\nfigure 9.9 normalized steepest descent direction for a quadratic norm. the\nellipsoid shown is the unit ball of the norm, translated to the point x. the\nnormalized steepest descent direction \u2206xnsd at x extends as far as possible\nin the direction \u2212\u2207f (x) while staying in the ellipsoid. the gradient and\nnormalized steepest descent directions are shown.\n\ninterpretation via change of coordinates\n\nwe can give an interesting alternative interpretation of the steepest descent direc-\ntion \u2206xsd as the gradient search direction after a change of coordinates is applied\nto the problem. define \u00afu = p 1/2u, so we have kukp = k\u00afuk2. using this change\nof coordinates, we can solve the original problem of minimizing f by solving the\nequivalent problem of minimizing the function \u00aff : rn \u2192 r, given by\n\n\u00aff (\u00afu) = f (p \u22121/2 \u00afu) = f (u).\n\nif we apply the gradient method to \u00aff , the search direction at a point \u00afx (which\ncorresponds to the point x = p \u22121/2 \u00afx for the original problem) is\n\n\u2206\u00afx = \u2212\u2207 \u00aff (\u00afx) = \u2212p \u22121/2\u2207f (p \u22121/2 \u00afx) = \u2212p \u22121/2\u2207f (x).\n\nthis gradient search direction corresponds to the direction\n\n\u2206x = p \u22121/2(cid:16)\u2212p \u22121/2\u2207f (x)(cid:17) = \u2212p \u22121\u2207f (x)\n\nfor the original variable x.\nin other words, the steepest descent method in the\nquadratic norm k \u00b7 kp can be thought of as the gradient method applied to the\nproblem after the change of coordinates \u00afx = p 1/2x.\n\n9.4.2 steepest descent for \u21131-norm\n\nas another example, we consider the steepest descent method for the \u21131-norm. a\nnormalized steepest descent direction,\n\n\u2206xnsd = argmin{\u2207f (x)t v | kvk1 \u2264 1},\n\n "}, {"Page_number": 492, "text": "478\n\n9 unconstrained minimization\n\n\u2212\u2207f (x)\n\n\u2206xnsd\n\nfigure 9.10 normalized steepest descent direction for the \u21131-norm. the\ndiamond is the unit ball of the \u21131-norm, translated to the point x. the\nnormalized steepest descent direction can always be chosen in the direction\nof a standard basis vector; in this example we have \u2206xnsd = e1.\n\nis easily characterized. let i be any index for which k\u2207f (x)k\u221e = |(\u2207f (x))i|. then\na normalized steepest descent direction \u2206xnsd for the \u21131-norm is given by\n\n\u2206xnsd = \u2212sign(cid:18) \u2202f (x)\n\n\u2202xi (cid:19) ei,\n\nwhere ei is the ith standard basis vector. an unnormalized steepest descent step\nis then\n\n\u2206xsd = \u2206xnsdk\u2207f (x)k\u221e = \u2212\n\n\u2202f (x)\n\u2202xi\n\nei.\n\nthus, the normalized steepest descent step in \u21131-norm can always be chosen to be a\nstandard basis vector (or a negative standard basis vector). it is the coordinate axis\ndirection along which the approximate decrease in f is greatest. this is illustrated\nin figure 9.10.\n\nthe steepest descent algorithm in the \u21131-norm has a very natural interpretation:\nat each iteration we select a component of \u2207f (x) with maximum absolute value,\nand then decrease or increase the corresponding component of x, according to the\nsign of (\u2207f (x))i. the algorithm is sometimes called a coordinate-descent algorithm,\nsince only one component of the variable x is updated at each iteration. this can\ngreatly simplify, or even trivialize, the line search.\n\nexample 9.2 frobenius norm scaling. in \u00a74.5.4 we encountered the unconstrained\ngeometric program\n\nwhere m \u2208 rn\u00d7n is given, and the variable is d \u2208 rn. using the change of variables\nxi = 2 log di we can express this geometric program in convex form as\n\ni,j=1 m 2\n\nijd2\n\ni /d2\nj ,\n\nminimize pn\nf (x) = log(cid:16)pn\n\nminimize\n\ni,j=1 m 2\n\nijexi\u2212xj(cid:17) .\n\n "}, {"Page_number": 493, "text": "9.4 steepest descent method\n\n479\n\nit is easy to minimize f one component at a time. keeping all components except\nthe kth fixed, we can write f (x) = log(\u03b1k + \u03b2ke\u2212xk + \u03b3kexk ), where\n\n\u03b1k = m 2\n\nkk + xi,j6=k\n\nm 2\n\nijexi\u2212xj ,\n\n\u03b2k =xi6=k\n\nm 2\n\nikexi ,\n\n\u03b3k =xj6=k\n\nm 2\n\nkje\u2212xj .\n\nthe minimum of f (x), as a function of xk, is obtained for xk = log(\u03b2k/\u03b3k)/2. so\nfor this problem an exact line search can be carried out using a simple analytical\nformula.\n\nthe \u21131-steepest descent algorithm with exact line search consists of repeating the\nfollowing steps.\n\n1. compute the gradient\n\n(\u2207f (x))i = \u2212\u03b2ie\u2212xi + \u03b3iexi\n\n\u03b1i + \u03b2ie\u2212xi + \u03b3iexi\n\n,\n\ni = 1, . . . , n.\n\n2. select a largest (in absolute value) component of \u2207f (x): |\u2207f (x)|k = k\u2207f (x)k\u221e.\n3. minimize f over the scalar variable xk, by setting xk = log(\u03b2k/\u03b3k)/2.\n\n9.4.3 convergence analysis\n\nin this section we extend the convergence analysis for the gradient method with\nbacktracking line search to the steepest descent method for an arbitrary norm. we\nwill use the fact that any norm can be bounded in terms of the euclidean norm,\nso there exists constants \u03b3, \u02dc\u03b3 \u2208 (0, 1] such that\n\nkxk \u2265 \u03b3kxk2,\n\nkxk\u2217 \u2265 \u02dc\u03b3kxk2\n\n(see \u00a7a.1.4).\nagain we assume f is strongly convex on the initial sublevel set s. the upper\nbound \u22072f (x) (cid:22) m i implies an upper bound on the function f (x + t\u2206xsd) as a\nfunction of t:\n\nf (x + t\u2206xsd) \u2264 f (x) + t\u2207f (x)t \u2206xsd +\n\u2264 f (x) + t\u2207f (x)t \u2206xsd +\nm\n2\u03b32 t2k\u2207f (x)k2\n= f (x) \u2212 tk\u2207f (x)k2\n\u2217.\n\nmk\u2206xsdk2\nmk\u2206xsdk2\n\n\u2217 +\n\n2\u03b32\n\nt2\n\nt2\n\n2\n\n2\n\n(9.26)\n\nthe step size \u02c6t = \u03b32/m (which minimizes the quadratic upper bound (9.26))\nsatisfies the exit condition for the backtracking line search:\n\nf (x + \u02c6t\u2206xsd) \u2264 f (x) \u2212\n\n\u03b32\n2m k\u2207f (x)k2\n\n\u2217 \u2264 f (x) +\n\n\u03b1\u03b32\nm \u2207f (x)t \u2206xsd\n\n(9.27)\n\n "}, {"Page_number": 494, "text": "480\n\n9 unconstrained minimization\n\nsince \u03b1 < 1/2 and \u2207f (x)t \u2206xsd = \u2212k\u2207f (x)k2\nstep size t \u2265 min{1, \u03b2\u03b32/m}, and we have\n\n\u2217. the line search therefore returns a\n\nf (x+) = f (x + t\u2206xsd) \u2264 f (x) \u2212 \u03b1 min{1, \u03b2\u03b32/m}k\u2207f (x)k2\n\n\u2217\n\n\u2264 f (x) \u2212 \u03b1\u02dc\u03b32 min{1, \u03b2\u03b32/m}k\u2207f (x)k2\n2.\n\nsubtracting p\u22c6 from both sides and using (9.9), we obtain\n\nf (x+) \u2212 p\u22c6 \u2264 c(f (x) \u2212 p\u22c6),\n\nwhere\n\nc = 1 \u2212 2m\u03b1\u02dc\u03b32 min{1, \u03b2\u03b32/m} < 1.\n\ntherefore we have\n\nf (x(k)) \u2212 p\u22c6 \u2264 ck(f (x(0)) \u2212 p\u22c6),\ni.e., linear convergence exactly as in the gradient method.\n\n9.4.4 discussion and examples\n\nchoice of norm for steepest descent\n\nthe choice of norm used to define the steepest descent direction can have a dra-\nmatic effect on the convergence rate. for simplicity, we consider the case of steep-\nest descent with quadratic p -norm. in \u00a79.4.1, we showed that the steepest descent\nmethod with quadratic p -norm is the same as the gradient method applied to the\nproblem after the change of coordinates \u00afx = p 1/2x. we know that the gradient\nmethod works well when the condition numbers of the sublevel sets (or the hes-\nsian near the optimal point) are moderate, and works poorly when the condition\nnumbers are large. it follows that when the sublevel sets, after the change of coor-\ndinates \u00afx = p 1/2x, are moderately conditioned, the steepest descent method will\nwork well.\n\nthis observation provides a prescription for choosing p : it should be chosen\nso that the sublevel sets of f , transformed by p \u22121/2, are well conditioned. for\nexample if an approximation \u02c6h of the hessian at the optimal point h(x\u22c6) were\nknown, a very good choice of p would be p = \u02c6h, since the hessian of \u02dcf at the\noptimum is then\n\n\u02c6h \u22121/2\u22072f (x\u22c6) \u02c6h \u22121/2 \u2248 i,\n\nand so is likely to have a low condition number.\n\nthis same idea can be described without a change of coordinates. saying that\na sublevel set has low condition number after the change of coordinates \u00afx = p 1/2x\nis the same as saying that the ellipsoid\n\ne = {x | xt p x \u2264 1}\n\napproximates the shape of the sublevel set. (in other words, it gives a good ap-\nproximation after appropriate scaling and translation.)\n\nthis dependence of the convergence rate on the choice of p can be viewed from\ntwo sides. the optimist\u2019s viewpoint is that for any problem, there is always a\n\n "}, {"Page_number": 495, "text": "9.4 steepest descent method\n\n481\n\nx(0)\n\nx(1)\n\nx(2)\n\nfigure 9.11 steepest descent method with a quadratic norm k \u00b7 kp1 . the\nellipses are the boundaries of the norm balls {x | kx \u2212 x(k)kp1 \u2264 1} at x(0)\nand x(1).\n\nchoice of p for which the steepest descent method works very well. the challenge,\nof course, is to find such a p . the pessimist\u2019s viewpoint is that for any problem,\nthere are a huge number of choices of p for which steepest descent works very\npoorly. in summary, we can say that the steepest descent method works well in\ncases where we can identify a matrix p for which the transformed problem has\nmoderate condition number.\n\nexamples\n\nin this section we illustrate some of these ideas using the nonquadratic problem in\nr2 with objective function (9.20). we apply the steepest descent method to the\nproblem, using the two quadratic norms defined by\n\np1 =(cid:20) 2\n\n0\n\n0\n\n8 (cid:21) ,\n\np2 =(cid:20) 8 0\n0 2 (cid:21) .\n\nin both cases we use a backtracking line search with \u03b1 = 0.1 and \u03b2 = 0.7.\n\nfigures 9.11 and 9.12 show the iterates for steepest descent with norm k\u00b7kp1 and\nnorm k\u00b7kp2 . figure 9.13 shows the error versus iteration number for both norms.\nfigure 9.13 shows that the choice of norm strongly influences the convergence.\nwith the norm k \u00b7 kp1, convergence is a bit more rapid than the gradient method,\nwhereas with the norm k \u00b7 kp2, convergence is far slower.\nthis can be explained by examining the problems after the changes of coor-\ndinates \u00afx = p 1/2\n2 x, respectively. figures 9.14 and 9.15 show the\nproblems in the transformed coordinates. the change of variables associated with\np1 yields sublevel sets with modest condition number, so convergence is fast. the\nchange of variables associated with p2 yields sublevel sets that are more poorly\nconditioned, which explains the slower convergence.\n\n1 x and \u00afx = p 1/2\n\n "}, {"Page_number": 496, "text": "482\n\n9 unconstrained minimization\n\nx(0)\n\nx(2)\n\nx(1)\n\nfigure 9.12 steepest descent method, with quadratic norm k \u00b7 kp2 .\n\n105\n\n100\n\n\u22c6\np\n\u2212\n\n10\u22125\n\n)\n)\nk\n(\nx\n(\nf\n\n10\u221210\n\np2\n\np1\n\n10\u221215\n0\n\n10\n\n20\nk\n\n30\n\n40\n\nfigure 9.13 error f (x(k)) \u2212 p\u22c6 versus iteration k, for the steepest descent\nmethod with the quadratic norm k \u00b7 kp1 and the quadratic norm k \u00b7 kp2 .\nconvergence is rapid for the norm k \u00b7 kp1 and very slow for k \u00b7 kp2 .\n\n "}, {"Page_number": 497, "text": "9.4 steepest descent method\n\n483\n\n\u00afx(0)\n\n\u00afx(1)\n\nfigure 9.14 the iterates of steepest descent with norm k \u00b7 kp1 , after the\nchange of coordinates. this change of coordinates reduces the condition\nnumber of the sublevel sets, and so speeds up convergence.\n\n\u00afx(0)\n\n\u00afx(1)\n\nfigure 9.15 the iterates of steepest descent with norm k \u00b7 kp2 , after the\nchange of coordinates. this change of coordinates increases the condition\nnumber of the sublevel sets, and so slows down convergence.\n\n "}, {"Page_number": 498, "text": "484\n\n9 unconstrained minimization\n\n(x, f (x))\n\n(x + \u2206xnt, f (x + \u2206xnt))\n\nbf\n\nf\n\nfigure 9.16 the function f (shown solid) and its second-order approximation\n\nbf at x (dashed). the newton step \u2206xnt is what must be added to x to give\nthe minimizer of bf .\n\n9.5 newton\u2019s method\n\n9.5.1 the newton step\n\nfor x \u2208 dom f , the vector\n\n\u2206xnt = \u2212\u22072f (x)\u22121\u2207f (x)\n\nis called the newton step (for f , at x). positive definiteness of \u22072f (x) implies that\n\n\u2207f (x)t \u2206xnt = \u2212\u2207f (x)t\u22072f (x)\u22121\u2207f (x) < 0\n\nunless \u2207f (x) = 0, so the newton step is a descent direction (unless x is optimal).\nthe newton step can be interpreted and motivated in several ways.\n\nminimizer of second-order approximation\n\nthe second-order taylor approximation (or model) bf of f at x is\nvt\u22072f (x)v,\n\n1\n2\n\nbf (x + v) = f (x) + \u2207f (x)t v +\n\nwhich is a convex quadratic function of v, and is minimized when v = \u2206xnt. thus,\nthe newton step \u2206xnt is what should be added to the point x to minimize the\nsecond-order approximation of f at x. this is illustrated in figure 9.16.\n\nthis interpretation gives us some insight into the newton step. if the function\nif the function f is\nf is quadratic, then x + \u2206xnt is the exact minimizer of f .\nnearly quadratic, intuition suggests that x + \u2206xnt should be a very good estimate\nof the minimizer of f , i.e., x\u22c6. since f is twice differentiable, the quadratic model\nof f will be very accurate when x is near x\u22c6. it follows that when x is near x\u22c6,\nthe point x + \u2206xnt should be a very good estimate of x\u22c6. we will see that this\nintuition is correct.\n\n(9.28)\n\n "}, {"Page_number": 499, "text": "9.5 newton\u2019s method\n\n485\n\nx\n\nx + \u2206xnsd\nx + \u2206xnt\n\nfigure 9.17 the dashed lines are level curves of a convex function. the\nellipsoid shown (with solid line) is {x + v | vt\u22072f (x)v \u2264 1}. the arrow\nshows \u2212\u2207f (x), the gradient descent direction. the newton step \u2206xnt is\nthe steepest descent direction in the norm k \u00b7 k\u22072f (x). the figure also shows\n\u2206xnsd, the normalized steepest descent direction for the same norm.\n\nsteepest descent direction in hessian norm\n\nthe newton step is also the steepest descent direction at x, for the quadratic norm\ndefined by the hessian \u22072f (x), i.e.,\n\nkuk\u22072f (x) = (ut\u22072f (x)u)1/2.\n\nthis gives another insight into why the newton step should be a good search\ndirection, and a very good search direction when x is near x\u22c6.\n\nrecall from our discussion above that steepest descent, with quadratic norm\nk \u00b7 kp , converges very rapidly when the hessian, after the associated change of\ncoordinates, has small condition number. in particular, near x\u22c6, a very good choice\nis p = \u22072f (x\u22c6). when x is near x\u22c6, we have \u22072f (x) \u2248 \u22072f (x\u22c6), which explains\nwhy the newton step is a very good choice of search direction. this is illustrated\nin figure 9.17.\n\nsolution of linearized optimality condition\nif we linearize the optimality condition \u2207f (x\u22c6) = 0 near x we obtain\n\n\u2207f (x + v) \u2248 \u2207f (x) + \u22072f (x)v = 0,\n\nwhich is a linear equation in v, with solution v = \u2206xnt. so the newton step \u2206xnt is\nwhat must be added to x so that the linearized optimality condition holds. again,\nthis suggests that when x is near x\u22c6 (so the optimality conditions almost hold),\nthe update x + \u2206xnt should be a very good approximation of x\u22c6.\n\nwhen n = 1, i.e., f : r \u2192 r, this interpretation is particularly simple. the\nsolution x\u22c6 of the minimization problem is characterized by f \u2032(x\u22c6) = 0, i.e., it is\n\n "}, {"Page_number": 500, "text": "486\n\n9 unconstrained minimization\n\nbf \u2032\n\nf \u2032\n\n(x + \u2206xnt, f \u2032(x + \u2206xnt))\n\n(x, f \u2032(x))\n\nfigure 9.18 the solid curve is the derivative f \u2032 of the function f shown in\n\nfigure 9.16. bf \u2032 is the linear approximation of f \u2032 at x. the newton step \u2206xnt\nis the difference between the root of bf \u2032 and the point x.\n\nthe zero-crossing of the derivative f \u2032, which is monotonically increasing since f is\nconvex. given our current approximation x of the solution, we form a first-order\ntaylor approximation of f \u2032 at x. the zero-crossing of this affine approximation is\nthen x + \u2206xnt. this interpretation is illustrated in figure 9.18.\n\naffine invariance of the newton step\n\nan important feature of the newton step is that it is independent of linear (or\naffine) changes of coordinates. suppose t \u2208 rn\u00d7n is nonsingular, and define\n\u00aff (y) = f (t y). then we have\n\n\u2207 \u00aff (y) = t t\u2207f (x),\n\n\u22072 \u00aff (y) = t t\u22072f (x)t,\n\nwhere x = t y. the newton step for \u00aff at y is therefore\n\n\u2206ynt = \u2212(cid:0)t t\u22072f (x)t(cid:1)\u22121(cid:0)t t\u2207f (x)(cid:1)\n\n= \u2212t \u22121\u22072f (x)\u22121\u2207f (x)\n= t \u22121\u2206xnt,\n\nwhere \u2206xnt is the newton step for f at x. hence the newton steps of f and \u00aff are\nrelated by the same linear transformation, and\n\nx + \u2206xnt = t (y + \u2206ynt).\n\nthe newton decrement\n\nthe quantity\n\n\u03bb(x) =(cid:0)\u2207f (x)t\u22072f (x)\u22121\u2207f (x)(cid:1)1/2\n\nis called the newton decrement at x. we will see that the newton decrement\nplays an important role in the analysis of newton\u2019s method, and is also useful\n\n "}, {"Page_number": 501, "text": "9.5 newton\u2019s method\n\n487\n\nas a stopping criterion. we can relate the newton decrement to the quantity\n\nf (x) \u2212 inf y bf (y), where bf is the second-order approximation of f at x:\nthus, \u03bb2/2 is an estimate of f (x) \u2212 p\u22c6, based on the quadratic approximation of f\nat x.\n\ny bf (y) = f (x) \u2212 bf (x + \u2206xnt) =\n\nf (x) \u2212 inf\n\n\u03bb(x)2.\n\n1\n2\n\nwe can also express the newton decrement as\n\nthis shows that \u03bb is the norm of the newton step, in the quadratic norm defined\nby the hessian, i.e., the norm\n\n.\n\n(9.29)\n\nnt\u22072f (x)\u2206xnt(cid:1)1/2\n\u03bb(x) =(cid:0)\u2206xt\nkuk\u22072f (x) =(cid:0)ut\u22072f (x)u(cid:1)1/2\n\u2207f (x)t \u2206xnt = \u2212\u03bb(x)2.\n\n.\n\nthe newton decrement comes up in backtracking line search as well, since we have\n\n(9.30)\n\nthis is the constant used in a backtracking line search, and can be interpreted as\nthe directional derivative of f at x in the direction of the newton step:\n\n\u2212\u03bb(x)2 = \u2207f (x)t \u2206xnt =\n\nd\ndt\n\nf (x + \u2206xntt)(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\n.\n\nfinally, we note that the newton decrement is, like the newton step, affine in-\nvariant. in other words, the newton decrement of \u00aff (y) = f (t y) at y, where t is\nnonsingular, is the same as the newton decrement of f at x = t y.\n\n9.5.2 newton\u2019s method\n\nnewton\u2019s method, as outlined below,\nis sometimes called the damped newton\nmethod or guarded newton method, to distinguish it from the pure newton method,\nwhich uses a fixed step size t = 1.\n\nalgorithm 9.5 newton\u2019s method.\n\ngiven a starting point x \u2208 dom f , tolerance \u01eb > 0.\nrepeat\n\n1. compute the newton step and decrement.\n\n\u2206xnt := \u2212\u22072f (x)\u22121\u2207f (x);\n\n\u03bb2 := \u2207f (x)t\u22072f (x)\u22121\u2207f (x).\n\n2. stopping criterion. quit if \u03bb2/2 \u2264 \u01eb.\n3. line search. choose step size t by backtracking line search.\n4. update. x := x + t\u2206xnt.\n\nthis is essentially the general descent method described in \u00a79.2, using the new-\nton step as search direction. the only difference (which is very minor) is that the\nstopping criterion is checked after computing the search direction, rather than after\nthe update.\n\n "}, {"Page_number": 502, "text": "488\n\n9 unconstrained minimization\n\n9.5.3 convergence analysis\n\nwe assume, as before, that f is twice continuously differentiable, and strongly\nconvex with constant m, i.e., \u22072f (x) (cid:23) mi for x \u2208 s. we have seen that this also\nimplies that there exists an m > 0 such that \u22072f (x) (cid:22) m i for all x \u2208 s.\nin addition, we assume that the hessian of f is lipschitz continuous on s with\nconstant l, i.e.,\n\nk\u22072f (x) \u2212 \u22072f (y)k2 \u2264 lkx \u2212 yk2\n\n(9.31)\nfor all x, y \u2208 s. the coefficient l, which can be interpreted as a bound on the\nthird derivative of f , can be taken to be zero for a quadratic function. more\ngenerally l measures how well f can be approximated by a quadratic model, so\nwe can expect the lipschitz constant l to play a critical role in the performance\nof newton\u2019s method. intuition suggests that newton\u2019s method will work very well\nfor a function whose quadratic model varies slowly (i.e., has small l).\n\nidea and outline of convergence proof\n\nwe first give the idea and outline of the convergence proof, and the main conclusion,\nand then the details of the proof. we will show there are numbers \u03b7 and \u03b3 with\n0 < \u03b7 \u2264 m2/l and \u03b3 > 0 such that the following hold.\n\n\u2022 if k\u2207f (x(k))k2 \u2265 \u03b7, then\n\nf (x(k+1)) \u2212 f (x(k)) \u2264 \u2212\u03b3.\n\n(9.32)\n\n\u2022 if k\u2207f (x(k))k2 < \u03b7, then the backtracking line search selects t(k) = 1 and\n\nl\n\n2m2k\u2207f (x(k+1))k2 \u2264(cid:18) l\n\n2m2k\u2207f (x(k))k2(cid:19)2\n\n.\n\n(9.33)\n\nlet us analyze the implications of the second condition. suppose that it\nis satisfied for iteration k, i.e., k\u2207f (x(k))k2 < \u03b7. since \u03b7 \u2264 m2/l, we have\nk\u2207f (x(k+1))k2 < \u03b7, i.e., the second condition is also satisfied at iteration k + 1.\ncontinuing recursively, we conclude that once the second condition holds, it will\nhold for all future iterates, i.e., for all l \u2265 k, we have k\u2207f (x(l))k2 < \u03b7. therefore\nfor all l \u2265 k, the algorithm takes a full newton step t = 1, and\n\nl\n\n2m2k\u2207f (x(l+1))k2 \u2264(cid:18) l\n\n2m2k\u2207f (x(l))k2(cid:19)2\n\n.\n\n(9.34)\n\napplying this inequality recursively, we find that for l \u2265 k,\n\nl\n\n2m2k\u2207f (x(l))k2 \u2264(cid:18) l\n\n2m2k\u2207f (x(k))k2(cid:19)2l\u2212k\nl2 (cid:18) 1\n\n2(cid:19)2l\u2212k\n\u2264(cid:18) 1\n2(cid:19)2l\u2212k+1\n\n1\n2mk\u2207f (x(l))k2\n\n2 \u2264\n\n2m3\n\n.\n\n,\n\n(9.35)\n\nand hence\n\nf (x(l)) \u2212 p\u22c6 \u2264\n\n "}, {"Page_number": 503, "text": "9.5 newton\u2019s method\n\n489\n\nthis last inequality shows that convergence is extremely rapid once the second\ncondition is satisfied. this phenomenon is called quadratic convergence. roughly\nspeaking, the inequality (9.35) means that, after a sufficiently large number of\niterations, the number of correct digits doubles at each iteration.\n\nthe iterations in newton\u2019s method naturally fall into two stages. the second\nstage, which occurs once the condition k\u2207f (x)k2 \u2264 \u03b7 holds, is called the quadrat-\nically convergent stage. we refer to the first stage as the damped newton phase,\nbecause the algorithm can choose a step size t < 1. the quadratically convergent\nstage is also called the pure newton phase, since in these iterations a step size t = 1\nis always chosen.\n\nnow we can estimate the total complexity. first we derive an upper bound on\nthe number of iterations in the damped newton phase. since f decreases by at\nleast \u03b3 at each iteration, the number of damped newton steps cannot exceed\n\nf (x(0)) \u2212 p\u22c6\n\n\u03b3\n\n,\n\nsince if it did, f would be less than p\u22c6, which is impossible.\n\nwe can bound the number of iterations in the quadratically convergent phase\nusing the inequality (9.35). it implies that we must have f (x) \u2212 p\u22c6 \u2264 \u01eb after no\nmore than\n\nlog2 log2(\u01eb0/\u01eb)\n\niterations in the quadratically convergent phase, where \u01eb0 = 2m3/l2.\n\noverall, then, the number of iterations until f (x)\u2212 p\u22c6 \u2264 \u01eb is bounded above by\n(9.36)\n\nf (x(0)) \u2212 p\u22c6\n\n+ log2 log2(\u01eb0/\u01eb).\n\n\u03b3\n\nthe term log2 log2(\u01eb0/\u01eb), which bounds the number of iterations in the quadrati-\ncally convergent phase, grows extremely slowly with required accuracy \u01eb, and can\nbe considered a constant for practical purposes, say five or six. (six iterations of\nthe quadratically convergent stage gives an accuracy of about \u01eb \u2248 5 \u00b7 10\u221220\u01eb0.)\nrequired to minimize f is bounded above by\nf (x(0)) \u2212 p\u22c6\n\nnot quite accurately, then, we can say that the number of newton iterations\n\n(9.37)\n\n+ 6.\n\n\u03b3\n\na more precise statement is that (9.37) is a bound on the number of iterations to\ncompute an extremely good approximation of the solution.\n\ndamped newton phase\nwe now establish the inequality (9.32). assume k\u2207f (x)k2 \u2265 \u03b7. we first derive a\nlower bound on the step size selected by the line search. strong convexity implies\nthat \u22072f (x) (cid:22) m i on s, and therefore\n\nf (x + t\u2206xnt) \u2264 f (x) + t\u2207f (x)t \u2206xnt +\n\nmk\u2206xntk2\n\n2\n\n2\n\nt2\n\n\u2264 f (x) \u2212 t\u03bb(x)2 +\n\nm\n2m\n\nt2\u03bb(x)2,\n\n "}, {"Page_number": 504, "text": "490\n\n9 unconstrained minimization\n\nwhere we use (9.30) and\n\n\u03bb(x)2 = \u2206xt\n\nnt\u22072f (x)\u2206xnt \u2265 mk\u2206xntk2\n2.\n\nthe step size \u02c6t = m/m satisfies the exit condition of the line search, since\n\nf (x + \u02c6t\u2206xnt) \u2264 f (x) \u2212\n\nm\n2m\n\n\u03bb(x)2 \u2264 f (x) \u2212 \u03b1\u02c6t\u03bb(x)2.\n\ntherefore the line search returns a step size t \u2265 \u03b2m/m , resulting in a decrease of\nthe objective function\n\nf (x+) \u2212 f (x) \u2264 \u2212\u03b1t\u03bb(x)2\n\n\u03bb(x)2\n\nm\nm\nm\nm 2k\u2207f (x)k2\n\n\u2264 \u2212\u03b1\u03b2\n\u2264 \u2212\u03b1\u03b2\n\u2264 \u2212\u03b1\u03b2\u03b72 m\nm 2 ,\n\n2\n\nwhere we use\n\n\u03bb(x)2 = \u2207f (x)t\u22072f (x)\u22121\u2207f (x) \u2265 (1/m )k\u2207f (x)k2\n2.\n\ntherefore, (9.32) is satisfied with\n\n\u03b3 = \u03b1\u03b2\u03b72 m\nm 2 .\n\n(9.38)\n\nquadratically convergent phase\nwe now establish the inequality (9.33). assume k\u2207f (x)k2 < \u03b7. we first show that\nthe backtracking line search selects unit steps, provided\n\n\u03b7 \u2264 3(1 \u2212 2\u03b1)\n\nm2\nl\n\n.\n\nby the lipschitz condition (9.31), we have, for t \u2265 0,\n\nk\u22072f (x + t\u2206xnt) \u2212 \u22072f (x)k2 \u2264 tlk\u2206xntk2,\n\nand therefore\n\nnt(cid:0)\u22072f (x + t\u2206xnt) \u2212 \u22072f (x)(cid:1) \u2206xnt(cid:12)(cid:12) \u2264 tlk\u2206xntk3\n(cid:12)(cid:12)\u2206xt\n\n2.\n\nwith \u02dcf (t) = f (x + t\u2206xnt), we have \u02dcf \u2032\u2032(t) = \u2206xt\ninequality above is\n\nnt\u22072f (x + t\u2206xnt)\u2206xnt, so the\n\nwe will use this inequality to determine an upper bound on \u02dcf (t). we start with\n\n| \u02dcf \u2032\u2032(t) \u2212 \u02dcf \u2032\u2032(0)| \u2264 tlk\u2206xntk3\n2.\n\n\u02dcf \u2032\u2032(t) \u2264 \u02dcf \u2032\u2032(0) + tlk\u2206xntk3\n\n2 \u2264 \u03bb(x)2 + t\n\nl\nm3/2 \u03bb(x)3,\n\n "}, {"Page_number": 505, "text": "9.5 newton\u2019s method\n\n491\n\n2. we integrate the inequality\n\nwhere we use \u02dcf \u2032\u2032(0) = \u03bb(x)2 and \u03bb(x)2 \u2265 mk\u2206xntk2\nto get\n\u02dcf \u2032(t) \u2264 \u02dcf \u2032(0) + t\u03bb(x)2 + t2 l\n= \u2212\u03bb(x)2 + t\u03bb(x)2 + t2 l\nusing \u02dcf \u2032(0) = \u2212\u03bb(x)2. we integrate once more to get\n\n2m3/2 \u03bb(x)3\n\n2m3/2 \u03bb(x)3,\n\n\u02dcf (t) \u2264 \u02dcf (0) \u2212 t\u03bb(x)2 + t2 1\n\n2\n\n\u03bb(x)2 + t3 l\n\n6m3/2 \u03bb(x)3.\n\nfinally, we take t = 1 to obtain\n\nf (x + \u2206xnt) \u2264 f (x) \u2212\n\n1\n2\n\n\u03bb(x)2 +\n\nl\n\n6m3/2 \u03bb(x)3.\n\n(9.39)\n\nnow suppose k\u2207f (x)k2 \u2264 \u03b7 \u2264 3(1 \u2212 2\u03b1)m2/l. by strong convexity, we have\n\nand by (9.39) we have\n\n\u03bb(x) \u2264 3(1 \u2212 2\u03b1)m3/2/l,\nf (x + \u2206xnt) \u2264 f (x) \u2212 \u03bb(x)2(cid:18) 1\n\u2264 f (x) \u2212 \u03b1\u03bb(x)2\n= f (x) + \u03b1\u2207f (x)t \u2206xnt,\n\n2 \u2212\n\nl\u03bb(x)\n\n6m3/2(cid:19)\n\nwhich shows that the unit step t = 1 is accepted by the backtracking line search.\nlet us now examine the rate of convergence. applying the lipschitz condition,\n\nwe have\n\nk\u2207f (x+)k2 = k\u2207f (x + \u2206xnt) \u2212 \u2207f (x) \u2212 \u22072f (x)\u2206xntk2\n\n= (cid:13)(cid:13)(cid:13)(cid:13)z 1\n\n0 (cid:0)\u22072f (x + t\u2206xnt) \u2212 \u22072f (x)(cid:1) \u2206xnt dt(cid:13)(cid:13)(cid:13)(cid:13)2\n\n\u2264\n=\n\n2\n\nl\n2 k\u2206xntk2\nl\n2 k\u22072f (x)\u22121\u2207f (x)k2\nl\n2m2k\u2207f (x)k2\n2,\n\n2\n\n\u2264\ni.e., the inequality (9.33).\n\nin conclusion, the algorithm selects unit steps and satisfies the condition (9.33)\n\nif k\u2207f (x(k))k2 < \u03b7, where\n\n\u03b7 = min{1, 3(1 \u2212 2\u03b1)}\n\nm2\nl\n\n.\n\nsubstituting this bound and (9.38) into (9.37), we find that the number of iterations\nis bounded above by\n\n6 +\n\nm 2l2/m5\n\n\u03b1\u03b2 min{1, 9(1 \u2212 2\u03b1)2}\n\n(f (x(0)) \u2212 p\u22c6).\n\n(9.40)\n\n "}, {"Page_number": 506, "text": "492\n\n9 unconstrained minimization\n\nx(0)\n\nx(1)\n\nfigure 9.19 newton\u2019s method for the problem in r2, with objective f given\nin (9.20), and backtracking line search parameters \u03b1 = 0.1, \u03b2 = 0.7. also\nshown are the ellipsoids {x | kx\u2212x(k)k\u22072f (x(k)) \u2264 1} at the first two iterates.\n\n9.5.4 examples\n\nexample in r2\n\nwe first apply newton\u2019s method with backtracking line search on the test func-\ntion (9.20), with line search parameters \u03b1 = 0.1, \u03b2 = 0.7. figure 9.19 shows the\nnewton iterates, and also the ellipsoids\n\n{x | kx \u2212 x(k)k\u22072f (x(k)) \u2264 1}\n\nfor the first two iterates k = 0, 1. the method works well because these ellipsoids\ngive good approximations of the shape of the sublevel sets.\n\nfigure 9.20 shows the error versus iteration number for the same example.\nthis plot shows that convergence to a very high accuracy is achieved in only five\niterations. quadratic convergence is clearly apparent: the last step reduces the\nerror from about 10\u22125 to 10\u221210.\n\nexample in r100\n\nfigure 9.21 shows the convergence of newton\u2019s method with backtracking and exact\nline search for a problem in r100. the objective function has the form (9.21), with\nthe same problem data and the same starting point as was used in figure 9.6. the\nplot for the backtracking line search shows that a very high accuracy is attained in\neight iterations. like the example in r2, quadratic convergence is clearly evident\nafter about the third iteration. the number of iterations in newton\u2019s method\nwith exact line search is only one smaller than with a backtracking line search.\nthis is also typical. an exact line search usually gives a very small improvement in\nconvergence of newton\u2019s method. figure 9.22 shows the step sizes for this example.\nafter two damped steps, the steps taken by the backtracking line search are all full,\ni.e., t = 1.\n\nexperiments with the values of the backtracking parameters \u03b1 and \u03b2 reveal that\nthey have little effect on the performance of newton\u2019s method, for this example\n\n "}, {"Page_number": 507, "text": "9.5 newton\u2019s method\n\n493\n\n105\n\n100\n\n\u22c6\np\n\u2212\n)\n)\nk\n(\nx\n(\nf\n\n10\u22125\n\n10\u221210\n\n10\u221215\n0\n\n1\n\n2\n\nk\n\n3\n\n4\n\n5\n\nfigure 9.20 error versus iteration k of newton\u2019s method for the problem\nin r2. convergence to a very high accuracy is achieved in five iterations.\n\n105\n\n100\n\n\u22c6\np\n\u2212\n\n10\u22125\n\n)\n)\nk\n(\nx\n(\nf\n\n10\u221210\n\n10\u221215\n0\n\nbacktracking l.s.\n\nexact l.s.\n\n2\n\n4\n\nk\n\n6\n\n8\n\n10\n\nfigure 9.21 error versus iteration for newton\u2019s method for the problem in\nr100. the backtracking line search parameters are \u03b1 = 0.01, \u03b2 = 0.5. here\ntoo convergence is extremely rapid: a very high accuracy is attained in only\nseven or eight iterations. the convergence of newton\u2019s method with exact\nline search is only one iteration faster than with backtracking line search.\n\n "}, {"Page_number": 508, "text": "494\n\n9 unconstrained minimization\n\n2\n\n1.5\n\n1\n\n0.5\n\n)\nk\n(\nt\n\ne\nz\ni\ns\n\np\ne\nt\ns\n\nexact l.s.\n\nbacktracking l.s.\n\n0\n0\n\n2\n\n4\nk\n\n6\n\n8\n\nfigure 9.22 the step size t versus iteration for newton\u2019s method with back-\ntracking and exact line search, applied to the problem in r100. the back-\ntracking line search takes one backtracking step in the first two iterations.\nafter the first two iterations it always selects t = 1.\n\n(and others). with \u03b1 fixed at 0.01, and values of \u03b2 varying between 0.2 and 1,\nthe number of iterations required varies between 8 and 12. with \u03b2 fixed at 0.5,\nthe number of iterations is 8, for all values of \u03b1 between 0.005 and 0.5. for these\nreasons, most practical implementations use a backtracking line search with a small\nvalue of \u03b1, such as 0.01, and a larger value of \u03b2, such as 0.5.\n\nexample in r10000\n\nin this last example we consider a larger problem, of the form\n\nminimize \u2212\n\nnxi=1\n\nlog(1 \u2212 x2\n\ni ) \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x)\n\nwith m = 100000 and n = 10000. the problem data ai are randomly generated\nsparse vectors. figure 9.23 shows the convergence of newton\u2019s method with back-\ntracking line search, with parameters \u03b1 = 0.01, \u03b2 = 0.5. the performance is very\nsimilar to the previous convergence plots. a linearly convergent initial phase of\nabout 13 iterations is followed by a quadratically convergent phase, that achieves\na very high accuracy in 4 or 5 more iterations.\n\naffine invariance of newton\u2019s method\n\na very important feature of newton\u2019s method is that it is independent of linear\n(or affine) changes of coordinates. let x(k) be the kth iterate of newton\u2019s method,\napplied to f : rn \u2192 r. suppose t \u2208 rn\u00d7n is nonsingular, and define \u00aff (y) =\nf (t y). if we use newton\u2019s method (with the same backtracking parameters) to\n\n "}, {"Page_number": 509, "text": "9.5 newton\u2019s method\n\n495\n\n105\n\n100\n\n\u22c6\np\n\u2212\n)\n)\nk\n(\nx\n(\nf\n\n10\u22125\n\n0\n\n5\n\n10\nk\n\n15\n\n20\n\nfigure 9.23 error versus iteration of newton\u2019s method,\nfor a problem\nin r10000. a backtracking line search with parameters \u03b1 = 0.01, \u03b2 = 0.5 is\nused. even for this large scale problem, newton\u2019s method requires only 18\niterations to achieve very high accuracy.\n\nminimize \u00aff , starting from y(0) = t \u22121x(0), then we have\n\nt y(k) = x(k)\n\nfor all k. in other words, newton\u2019s method is the same: the iterates are related\nby the same change of coordinates. even the stopping criterion is the same, since\nthe newton decrement for \u00aff at y(k) is the same as the newton decrement for f at\nx(k). this is in stark contrast to the gradient (or steepest descent) method, which\nis strongly affected by changes of coordinates.\n\nas an example, consider the family of problems given in (9.22), indexed by the\nparameter \u03b3, which affects the condition number of the sublevel sets. we observed\n(in figures 9.7 and 9.8) that the gradient method slows to useless for values of \u03b3\nsmaller than 0.05 or larger than 20. in contrast, newton\u2019s method (with \u03b1 = 0.01,\n\u03b2 = 0.5) solves this problem (in fact, to a far higher accuracy) in nine iterations,\nfor all values of \u03b3 between 10\u221210 and 1010.\n\nin a real implementation, with finite precision arithmetic, newton\u2019s method is\nnot exactly independent of affine changes of coordinates, or the condition number\nof the sublevel sets. but we can say that condition numbers ranging up to very\nlarge values such as 1010 do not adversely affect a real implementation of newton\u2019s\nmethod. for the gradient method, a far smaller range of condition numbers can\nbe tolerated. while choice of coordinates (or condition number of sublevel sets) is\na first-order issue for gradient and steepest descent methods, it is a second-order\nissue for newton\u2019s method; its only effect is in the numerical linear algebra required\nto compute the newton step.\n\n "}, {"Page_number": 510, "text": "496\n\n9 unconstrained minimization\n\nsummary\n\nnewton\u2019s method has several very strong advantages over gradient and steepest\ndescent methods:\n\n\u2022 convergence of newton\u2019s method is rapid in general, and quadratic near x\u22c6.\nonce the quadratic convergence phase is reached, at most six or so iterations\nare required to produce a solution of very high accuracy.\n\n\u2022 newton\u2019s method is affine invariant. it is insensitive to the choice of coordi-\n\nnates, or the condition number of the sublevel sets of the objective.\n\n\u2022 newton\u2019s method scales well with problem size. its performance on problems\nin r10000 is similar to its performance on problems in r10, with only a modest\nincrease in the number of steps required.\n\n\u2022 the good performance of newton\u2019s method is not dependent on the choice\nof algorithm parameters. in contrast, the choice of norm for steepest descent\nplays a critical role in its performance.\n\nthe main disadvantage of newton\u2019s method is the cost of forming and storing\nthe hessian, and the cost of computing the newton step, which requires solving\na set of linear equations. we will see in \u00a79.7 that in many cases it is possible to\nexploit problem structure to substantially reduce the cost of computing the newton\nstep.\n\nanother alternative is provided by a family of algorithms for unconstrained op-\ntimization called quasi-newton methods. these methods require less computational\neffort to form the search direction, but they share some of the strong advantages\nof newton methods, such as rapid convergence near x\u22c6. since quasi-newton meth-\nods are described in many books, and tangential to our main theme, we will not\nconsider them in this book.\n\n9.6 self-concordance\n\nthere are two major shortcomings of the classical convergence analysis of newton\u2019s\nmethod given in \u00a79.5.3. the first is a practical one: the resulting complexity\nestimates involve the three constants m, m , and l, which are almost never known\nin practice. as a result, the bound (9.40) on the number of newton steps required\nis almost never known specifically, since it depends on three constants that are, in\ngeneral, not known. of course the convergence analysis and complexity estimate\nare still conceptually useful.\n\nthe second shortcoming is that while newton\u2019s method is affinely invariant, the\nclassical analysis of newton\u2019s method is very much dependent on the coordinate\nsystem used. if we change coordinates the constants m, m , and l all change. if\nfor no reason other than aesthetic, we should seek an analysis of newton\u2019s method\nin\nthat is, like the method itself, independent of affine changes of coordinates.\n\n "}, {"Page_number": 511, "text": "9.6 self-concordance\n\n497\n\nother words, we seek an alternative to the assumptions\n\nmi (cid:22) \u22072f (x) (cid:22) m i,\n\nk\u22072f (x) \u2212 \u22072f (y)k2 \u2264 lkx \u2212 yk2,\n\nthat is independent of affine changes of coordinates, and also allows us to analyze\nnewton\u2019s method.\n\na simple and elegant assumption that achieves this goal was discovered by\nnesterov and nemirovski, who gave the name self-concordance to their condition.\nself-concordant functions are important for several reasons.\n\n\u2022 they include many of the logarithmic barrier functions that play an impor-\ntant role in interior-point methods for solving convex optimization problems.\n\n\u2022 the analysis of newton\u2019s method for self-concordant functions does not de-\n\npend on any unknown constants.\n\n\u2022 self-concordance is an affine-invariant property, i.e., if we apply a linear\ntransformation of variables to a self-concordant function, we obtain a self-\nconcordant function. therefore the complexity estimate that we obtain for\nnewton\u2019s method applied to a self-concordant function is independent of\naffine changes of coordinates.\n\n9.6.1 definition and examples\n\nself-concordant functions on r\nwe start by considering functions on r. a convex function f : r \u2192 r is self-\nconcordant if\n(9.41)\nfor all x \u2208 dom f . since linear and (convex) quadratic functions have zero third\nderivative, they are evidently self-concordant. some more interesting examples are\ngiven below.\n\n|f \u2032\u2032\u2032(x)| \u2264 2f \u2032\u2032(x)3/2\n\nexample 9.3 logarithm and entropy.\n\n\u2022 negative logarithm. the function f (x) = \u2212 log x is self-concordant. using\n\nf \u2032\u2032(x) = 1/x2, f \u2032\u2032\u2032(x) = \u22122/x3, we find that\n2/x3\n\n|f \u2032\u2032\u2032(x)|\n2f \u2032\u2032(x)3/2 =\n\n2(1/x2)3/2 = 1,\n\nso the defining inequality (9.41) holds with equality.\n\n\u2022 negative entropy plus negative logarithm. the function f (x) = x log x \u2212 log x is\n\nself-concordant. to verify this, we use\n\nto obtain\n\nf \u2032\u2032(x) =\n\nx + 1\n\nx2\n\n,\n\nf \u2032\u2032\u2032(x) = \u2212\n\nx + 2\n\nx3\n\n|f \u2032\u2032\u2032(x)|\n2f \u2032\u2032(x)3/2 =\n\nx + 2\n\n2(x + 1)3/2 .\n\n "}, {"Page_number": 512, "text": "498\n\n9 unconstrained minimization\n\nthe function on the righthand side is maximized on r+ by x = 0, where its\nvalue is 1.\n\nthe negative entropy function by itself is not self-concordant; see exercise 11.13.\n\nwe should make two important remarks about the self-concordance defini-\ntion (9.41). the first concerns the mysterious constant 2 that appears in the\ndefinition. in fact, this constant is chosen for convenience, in order to simplify the\nformulas later on; any other positive constant could be used instead. suppose, for\nexample, that the convex function f : r \u2192 r satisfies\n\nwhere k is some positive constant. then the function \u02dcf (x) = (k2/4)f (x) satisfies\n\n|f \u2032\u2032\u2032(x)| \u2264 kf \u2032\u2032(x)3/2\n\n(9.42)\n\n| \u02dcf \u2032\u2032\u2032(x)| = (k2/4)|f \u2032\u2032\u2032(x)|\n\u2264 (k3/4)f \u2032\u2032(x)3/2\n= (k3/4)(cid:16)(4/k2) \u02dcf \u2032\u2032(x)(cid:17)3/2\n\n= 2 \u02dcf \u2032\u2032(x)3/2\n\nand therefore is self-concordant. this shows that a function that satisfies (9.42)\nfor some positive k can be scaled to satisfy the standard self-concordance inequal-\nity (9.41). so what is important is that the third derivative of the function is\nbounded by some multiple of the 3/2-power of its second derivative. by appropri-\nately scaling the function, we can change the multiple to the constant 2.\n\nthe second comment is a simple calculation that shows why self-concordance\nis so important: it is affine invariant. suppose we define the function \u02dcf by \u02dcf (y) =\nf (ay + b), where a 6= 0. then \u02dcf is self-concordant if and only if f is. to see this,\nwe substitute\n\n\u02dcf \u2032\u2032(y) = a2f \u2032\u2032(x),\n\n\u02dcf \u2032\u2032\u2032(y) = a3f \u2032\u2032\u2032(x),\n\nwhere x = ay + b,\n2 \u02dcf \u2032\u2032(y)3/2, to obtain\n\ninto the self-concordance inequality for \u02dcf , i.e.,\n\n| \u02dcf \u2032\u2032\u2032(y)| \u2264\n\n|a3f \u2032\u2032\u2032(x)| \u2264 2(a2f \u2032\u2032(x))3/2,\n\nwhich (after dividing by a3) is the self-concordance inequality for f . roughly\nspeaking, the self-concordance condition (9.41) is a way to limit the third derivative\nof a function, in a way that is independent of affine coordinate changes.\n\nself-concordant functions on rn\nwe now consider functions on rn with n > 1. we say a function f : rn \u2192 r\nis self-concordant if it is self-concordant along every line in its domain, i.e., if the\nfunction \u02dcf (t) = f (x + tv) is a self-concordant function of t for all x \u2208 dom f and\nfor all v.\n\n "}, {"Page_number": 513, "text": "9.6 self-concordance\n\n499\n\n9.6.2 self-concordant calculus\n\nscaling and sum\n\nself-concordance is preserved by scaling by a factor exceeding one: if f is self-\nconcordant and a \u2265 1, then af is self-concordant. self-concordance is also preserved\nby addition: if f1, f2 are self-concordant, then f1 + f2 is self-concordant. to show\nthis, it is sufficient to consider functions f1, f2 : r \u2192 r. we have\n\n1 (x) + f \u2032\u2032\u2032\n|f \u2032\u2032\u2032\n\n2 (x)| \u2264 |f \u2032\u2032\u2032\n\u2264 2(f \u2032\u2032\n\u2264 2(f \u2032\u2032\n\n1 (x)| + |f \u2032\u2032\u2032\n2 (x)|\n1 (x)3/2 + f \u2032\u2032\n1 (x) + f \u2032\u2032\n\n2 (x))3/2.\n\n2 (x)3/2)\n\nin the last step we use the inequality\n\n(u3/2 + v3/2)2/3 \u2264 u + v,\n\nwhich holds for u, v \u2265 0.\ncomposition with affine function\nif f : rn \u2192 r is self-concordant, and a \u2208 rn\u00d7m, b \u2208 rn, then f (ax + b) is\nself-concordant.\n\nexample 9.4 log barrier for linear inequalities. the function\n\nf (x) = \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x),\n\nwith dom f = {x | at\nat\ni x) is the composition of \u2212 log y with the affine transformation y = bi \u2212 at\nhence self-concordant. therefore the sum is also self-concordant.\n\ni x < bi, i = 1, . . . , m}, is self-concordant. each term \u2212 log(bi \u2212\ni x, and\n\nexample 9.5 log-determinant. the function f (x) = \u2212 log det x is self-concordant\n++. to show this, we consider the function \u02dcf (t) = f (x + tv ), where\non dom f = sn\nx \u227b 0 and v \u2208 sn. it can be expressed as\n\n\u02dcf (t) = \u2212 log det(x 1/2(i + tx \u22121/2v x \u22121/2)x 1/2)\n= \u2212 log det x \u2212 log det(i + tx \u22121/2v x \u22121/2)\n= \u2212 log det x \u2212\n\nlog(1 + t\u03bbi)\n\nnxi=1\n\nwhere \u03bbi are the eigenvalues of x \u22121/2v x \u22121/2. each term \u2212 log(1 + t\u03bbi) is a self-\nconcordant function of t, so the sum, \u02dcf , is self-concordant.\nit follows that f is\nself-concordant.\n\nexample 9.6 log of concave quadratic. the function\n\nf (x) = \u2212 log(xt p x + qt x + r),\n\n "}, {"Page_number": 514, "text": "500\n\n9 unconstrained minimization\n\nwhere p \u2208 \u2212sn\n\n+, is self-concordant on\n\ndom f = {x | xt p x + qt x + r > 0}.\n\nto show this, it suffices to consider the case n = 1 (since by restricting f to a line,\nthe general case reduces to the n = 1 case). we can then express f as\nf (x) = \u2212 log(px2 + qx + r) = \u2212 log (\u2212p(x \u2212 a)(b \u2212 x))\n\nwhere dom f = (a, b) (i.e., a and b are the roots of px2 +qx+r). using this expression\nwe have\n\nwhich establishes self-concordance.\n\nf (x) = \u2212 log(\u2212p) \u2212 log(x \u2212 a) \u2212 log(b \u2212 x),\n\ncomposition with logarithm\nlet g : r \u2192 r be a convex function with dom g = r++, and\n\ng\u2032\u2032(x)\n\n|g\u2032\u2032\u2032(x)| \u2264 3\n\nx\n\n(9.43)\n\nfor all x. then\n\nf (x) = \u2212 log(\u2212g(x)) \u2212 log x\n\nis self-concordant on {x | x > 0, g(x) < 0}. (for a proof, see exercise 9.14.)\nthe condition (9.43) is homogeneous and preserved under addition. it is sat-\nisfied by all (convex) quadratic functions, i.e., functions of the form ax2 + bx + c,\nwhere a \u2265 0. therefore if (9.43) holds for a function g, then it holds for the function\ng(x) + ax2 + bx + c, where a \u2265 0.\n\nexample 9.7 the following functions g satisfy the condition (9.43).\n\n\u2022 g(x) = \u2212xp for 0 < p \u2264 1.\n\u2022 g(x) = \u2212 log x.\n\u2022 g(x) = x log x.\n\u2022 g(x) = xp for \u22121 \u2264 p \u2264 0.\n\u2022 g(x) = (ax + b)2/x.\n\nit follows that in each case, the function f (x) = \u2212 log(\u2212g(x))\u2212log x is self-concordant.\nmore generally, the function f (x) = \u2212 log(\u2212g(x) \u2212 ax2 \u2212 bx \u2212 c) \u2212 log x is self-\nconcordant on its domain,\n\n{x | x > 0, g(x) + ax2 + bx + c < 0},\n\nprovided a \u2265 0.\n\nexample 9.8 the composition with logarithm rule allows us to show self-concordance\nof the following functions.\n\n\u2022 f (x, y) = \u2212 log(y2 \u2212 xt x) on {(x, y) | kxk2 < y}.\n\u2022 f (x, y) = \u22122 log y \u2212 log(y2/p \u2212 x2), with p \u2265 1, on {(x, y) \u2208 r2 | |x|p < y}.\n\u2022 f (x, y) = \u2212 log y \u2212 log(log y \u2212 x) on {(x, y) | ex < y}.\n\nwe leave the details as an exercise (exercise 9.15).\n\n "}, {"Page_number": 515, "text": "9.6 self-concordance\n\n501\n\n9.6.3 properties of self-concordant functions\n\nin \u00a79.1.2 we used strong convexity to derive bounds on the suboptimality of a point\nx in terms of the norm of the gradient at x. for strictly convex self-concordant\nfunctions, we can obtain similar bounds in terms of the newton decrement\n\n\u03bb(x) =(cid:0)\u2207f (x)t\u22072f (x)\u22121\u2207f (x)(cid:1)1/2\n\n.\n\n(it can be shown that the hessian of a strictly convex self-concordant function is\npositive definite everywhere; see exercise 9.17.) unlike the bounds based on the\nnorm of the gradient, the bounds based on the newton decrement are not affected\nby an affine change of coordinates.\n\nfor future reference we note that the newton decrement can also be expressed\n\nas\n\n\u03bb(x) = sup\nv6=0\n\n\u2212vt\u2207f (x)\n\n(vt\u22072f (x)v)1/2\n\n(see exercise 9.9). in other words, we have\n\n\u2212vt\u2207f (x)\n(vt\u22072f (x)v)1/2 \u2264 \u03bb(x)\n\n(9.44)\n\nfor any nonzero v, with equality for v = \u2206xnt.\n\nupper and lower bounds on second derivatives\nsuppose f : r \u2192 r is a strictly convex self-concordant function. we can write the\nself-concordance inequality (9.41) as\n\nfor all t \u2208 dom f (see exercise 9.16). assuming t \u2265 0 and the interval between 0\nand t is in dom f , we can integrate (9.45) between 0 and t to obtain\n\nd\n\n(cid:12)(cid:12)(cid:12)(cid:12)\n\u2212t \u2264z t\n\ndt(cid:16)f \u2032\u2032(t)\u22121/2(cid:17)(cid:12)(cid:12)(cid:12)(cid:12) \u2264 1\nd\u03c4 (cid:16)f \u2032\u2032(\u03c4 )\u22121/2(cid:17) d\u03c4 \u2264 t,\n\nd\n\n0\n\ni.e., \u2212t \u2264 f \u2032\u2032(t)\u22121/2 \u2212 f \u2032\u2032(0)\u22121/2 \u2264 t. from this we obtain lower and upper bounds\non f \u2032\u2032(t):\n\nf \u2032\u2032(0)\n\n(cid:0)1 + tf \u2032\u2032(0)1/2(cid:1)2 \u2264 f \u2032\u2032(t) \u2264\n\n(cid:0)1 \u2212 tf \u2032\u2032(0)1/2(cid:1)2 .\n\nf \u2032\u2032(0)\n\nthe lower bound is valid for all nonnegative t \u2208 dom f ; the upper bound is valid\nif t \u2208 dom f and 0 \u2264 t < f \u2032\u2032(0)\u22121/2.\nbound on suboptimality\nlet f : rn \u2192 r be a strictly convex self-concordant function, and let v be a\ndescent direction (i.e., any direction satisfying vt\u2207f (x) < 0, not necessarily the\n\n(9.45)\n\n(9.46)\n\n "}, {"Page_number": 516, "text": "502\n\n9 unconstrained minimization\n\nnewton direction). define \u02dcf : r \u2192 r as \u02dcf (t) = f (x + tv). by definition, the\nfunction \u02dcf is self-concordant.\n\nintegrating the lower bound in (9.46) yields a lower bound on \u02dcf \u2032(t):\n\n\u02dcf \u2032(t) \u2265 \u02dcf \u2032(0) + \u02dcf \u2032\u2032(0)1/2 \u2212\nintegrating again yields a lower bound on \u02dcf (t):\n\n\u02dcf \u2032\u2032(0)1/2\n\n1 + t \u02dcf \u2032\u2032(0)1/2\n\n.\n\n\u02dcf (t) \u2265 \u02dcf (0) + t \u02dcf \u2032(0) + t \u02dcf \u2032\u2032(0)1/2 \u2212 log(1 + t \u02dcf \u2032\u2032(0)1/2).\n\nthe righthand side reaches its minimum at\n\n(9.47)\n\n(9.48)\n\n\u00aft =\n\n\u2212 \u02dcf \u2032(0)\n\n\u02dcf \u2032\u2032(0) + \u02dcf \u2032\u2032(0)1/2 \u02dcf \u2032(0)\n\n,\n\nand evaluating at \u00aft provides a lower bound on \u02dcf :\n\ninf\nt\u22650\n\n\u02dcf (t) \u2265 \u02dcf (0) + \u00aft \u02dcf \u2032(0) + \u00aft \u02dcf \u2032\u2032(0)1/2 \u2212 log(1 + \u00aft \u02dcf \u2032\u2032(0)1/2)\n\n= \u02dcf (0) \u2212 \u02dcf \u2032(0) \u02dcf \u2032\u2032(0)\u22121/2 + log(1 + \u02dcf \u2032(0) \u02dcf \u2032\u2032(0)\u22121/2).\n\nthe inequality (9.44) can be expressed as\n\n(with equality when v = \u2206xnt), since we have\n\n\u03bb(x) \u2265 \u2212 \u02dcf \u2032(0) \u02dcf \u2032\u2032(0)\u22121/2\n\n\u02dcf \u2032(0) = vt\u2207f (x),\n\n\u02dcf \u2032\u2032(0) = vt\u22072f (x)v.\n\nnow using the fact that u + log(1 \u2212 u) is a monotonically decreasing function of u,\nand the inequality above, we get\n\n\u02dcf (t) \u2265 \u02dcf (0) + \u03bb(x) + log(1 \u2212 \u03bb(x)).\nthis inequality holds for any descent direction v. therefore\n\ninf\nt\u22650\n\n(9.49)\nprovided \u03bb(x) < 1. the function \u2212 (\u03bb + log(1 \u2212 \u03bb)) is plotted in figure 9.24. it\nsatisfies\n\np\u22c6 \u2265 f (x) + \u03bb(x) + log(1 \u2212 \u03bb(x))\n\nfor small \u03bb, and the bound\n\n\u2212 (\u03bb + log(1 \u2212 \u03bb)) \u2248 \u03bb2/2,\n\nfor \u03bb \u2264 0.68. thus, we have the bound on suboptimality\n\n\u2212 (\u03bb + log(1 \u2212 \u03bb)) \u2264 \u03bb2\n\np\u22c6 \u2265 f (x) \u2212 \u03bb(x)2,\n\n(9.50)\n\nvalid for \u03bb(x) \u2264 0.68.\nrecall that \u03bb(x)2/2 is the estimate of f (x) \u2212 p\u22c6, based on the quadratic model\nat x; the inequality (9.50) shows that for self-concordant functions, doubling this\nestimate gives us a provable bound. in particular, it shows that for self-concordant\nfunctions, we can use the stopping criterion\n\n(where \u01eb < 0.682), and guarantee that on exit f (x) \u2212 p\u22c6 \u2264 \u01eb.\n\n\u03bb(x)2 \u2264 \u01eb,\n\n "}, {"Page_number": 517, "text": "9.6 self-concordance\n\n503\n\n0.8\n\n0.6\n\n0.4\n\n0.2\n\n0\n0\n\n0.2\n\n0.4\n\n0.6\n\n0.8\n\n1\n\nfigure 9.24 the solid line is the function \u2212(\u03bb+log(1\u2212\u03bb)), which for small \u03bb\nis approximately \u03bb2/2. the dashed line shows \u03bb2, which is an upper bound\nin the interval 0 \u2264 \u03bb \u2264 0.68.\n\n9.6.4 analysis of newton\u2019s method for self-concordant functions\n\nwe now analyze newton\u2019s method with backtracking line search, when applied to\na strictly convex self-concordant function f . as before, we assume that a starting\npoint x(0) is known, and that the sublevel set s = {x | f (x) \u2264 f (x(0))} is closed.\nwe also assume that f is bounded below. (this implies that f has a minimizer x\u22c6;\nsee exercise 9.19.)\n\nthe analysis is very similar to the classical analysis given in \u00a79.5.2, except that\nwe use self-concordance as the basic assumption instead of strong convexity and\nthe lipschitz condition on the hessian, and the newton decrement will play the\nrole of the norm of the gradient. we will show that there are numbers \u03b7 and \u03b3 > 0,\nwith 0 < \u03b7 \u2264 1/4, that depend only on the line search parameters \u03b1 and \u03b2, such\nthat the following hold:\n\u2022 if \u03bb(x(k)) > \u03b7, then\n\n\u2022 if \u03bb(x(k)) \u2264 \u03b7, then the backtracking line search selects t = 1 and\n\nf (x(k+1)) \u2212 f (x(k)) \u2264 \u2212\u03b3.\n2\u03bb(x(k+1)) \u2264(cid:16)2\u03bb(x(k))(cid:17)2\n\n.\n\n(9.51)\n\n(9.52)\n\nthese are the analogs of (9.32) and (9.33). as in \u00a79.5.3, the second condition can\nbe applied recursively, so we can conclude that for all l \u2265 k, we have \u03bb(x(l)) \u2264 \u03b7,\nand\n\nas a consequence, for all l \u2265 k,\n\n\u2264 (2\u03b7)2l\u2212k\n\n2\u03bb(x(l)) \u2264(cid:16)2\u03bb(x(k))(cid:17)2l\u2212k\n4(cid:18) 1\n2(cid:19)2l\u2212k+1\n\nf (x(l)) \u2212 p\u22c6 \u2264 \u03bb(x(l))2 \u2264\n\n1\n\n.\n\n\u2264(cid:18) 1\n\u2264(cid:18) 1\n\n2(cid:19)2l\u2212k\n2(cid:19)2l\u2212k+1\n\n,\n\n "}, {"Page_number": 518, "text": "504\n\n9 unconstrained minimization\n\nand hence f (x(l)) \u2212 p\u22c6 \u2264 \u01eb if l \u2212 k \u2265 log2 log2(1/\u01eb).\nthe first inequality implies that the damped phase cannot require more than\n(f (x(0)) \u2212 p\u22c6)/\u03b3 steps. thus the total number of iterations required to obtain an\naccuracy f (x) \u2212 p\u22c6 \u2264 \u01eb, starting at a point x(0), is bounded by\n\nf (x(0)) \u2212 p\u22c6\n\n\u03b3\n\n+ log2 log2(1/\u01eb).\n\n(9.53)\n\nthis is the analog of the bound (9.36) in the classical analysis of newton\u2019s method.\n\ndamped newton phase\nlet \u02dcf (t) = f (x + t\u2206xnt), so we have\n\n\u02dcf \u2032(0) = \u2212\u03bb(x)2,\n\n\u02dcf \u2032\u2032(0) = \u03bb(x)2.\n\nif we integrate the upper bound in (9.46) twice, we obtain an upper bound for \u02dcf (t):\n\n\u02dcf (t) \u2264 \u02dcf (0) + t \u02dcf \u2032(0) \u2212 t \u02dcf \u2032\u2032(0)1/2 \u2212 log(cid:16)1 \u2212 t \u02dcf \u2032\u2032(0)1/2(cid:17)\n\n= \u02dcf (0) \u2212 t\u03bb(x)2 \u2212 t\u03bb(x) \u2212 log(1 \u2212 t\u03bb(x)),\n\n(9.54)\n\nvalid for 0 \u2264 t < 1/\u03bb(x).\nwe can use this bound to show the backtracking line search always results in a\nstep size t \u2265 \u03b2/(1 + \u03bb(x)). to prove this we note that the point \u02c6t = 1/(1 + \u03bb(x))\nsatisfies the exit condition of the line search:\n\n\u02dcf (\u02c6t) \u2264 \u02dcf (0) \u2212 \u02c6t\u03bb(x)2 \u2212 \u02c6t\u03bb(x) \u2212 log(1 \u2212 \u02c6t\u03bb(x))\n\n= \u02dcf (0) \u2212 \u03bb(x) + log(1 + \u03bb(x))\n\u2264 \u02dcf (0) \u2212 \u03b1\n1 + \u03bb(x)\n= \u02dcf (0) \u2212 \u03b1\u03bb(x)2\u02c6t.\n\n\u03bb(x)2\n\nthe second inequality follows from the fact that\n\n\u2212x + log(1 + x) +\n\nx2\n\n2(1 + x) \u2264 0\n\nfor x \u2265 0. since t \u2265 \u03b2/(1 + \u03bb(x)), we have\n\nso (9.51) holds with\n\n\u02dcf (t) \u2212 \u02dcf (0) \u2264 \u2212\u03b1\u03b2\n\n\u03bb(x)2\n\n1 + \u03bb(x)\n\n,\n\n\u03b3 = \u03b1\u03b2\n\n\u03b72\n\n1 + \u03b7\n\n.\n\n "}, {"Page_number": 519, "text": "9.6 self-concordance\n\n505\n\nquadratically convergent phase\n\nwe will show that we can take\n\n\u03b7 = (1 \u2212 2\u03b1)/4,\n\n(which satisfies 0 < \u03b7 < 1/4, since 0 < \u03b1 < 1/2), i.e., if \u03bb(x(k)) \u2264 (1 \u2212 2\u03b1)/4, then\nthe backtracking line search accepts the unit step and (9.52) holds.\nwe first note that the upper bound (9.54) implies that a unit step t = 1 yields a\npoint in dom f if \u03bb(x) < 1. moreover, if \u03bb(x) \u2264 (1 \u2212 2\u03b1)/2, we have, using (9.54),\n\n\u02dcf (1) \u2264 \u02dcf (0) \u2212 \u03bb(x)2 \u2212 \u03bb(x) \u2212 log(1 \u2212 \u03bb(x))\n\n\u03bb(x)2 + \u03bb(x)3\n\n1\n2\n\n\u2264 \u02dcf (0) \u2212\n\u2264 \u02dcf (0) \u2212 \u03b1\u03bb(x)2,\n\nthe inequality (9.52) follows from the following fact, proved in exercise 9.18. if\n\nso the unit step satisfies the condition of sufficient decrease.\nfollows from the fact that \u2212x \u2212 log(1 \u2212 x) \u2264 1\n\u03bb(x) < 1, and x+ = x \u2212 \u22072f (x)\u22121\u2207f (x), then\n\u03bb(x)2\n\n2 x2 + x3 for 0 \u2264 x \u2264 0.81.)\n\n(the second line\n\n(9.55)\n\n\u03bb(x+) \u2264\n\n(1 \u2212 \u03bb(x))2 .\n\nin particular, if \u03bb(x) \u2264 1/4,\n\n\u03bb(x+) \u2264 2\u03bb(x)2,\nwhich proves that (9.52) holds when \u03bb(x(k)) \u2264 \u03b7.\nthe final complexity bound\n\nputting it all together, the bound (9.53) on the number of newton iterations be-\ncomes\n\nf (x(0)) \u2212 p\u22c6\n\n\u03b3\n\n+ log2 log2(1/\u01eb) =\n\n20 \u2212 8\u03b1\n\u03b1\u03b2(1 \u2212 2\u03b1)2 (f (x(0))\u2212 p\u22c6) + log2 log2(1/\u01eb). (9.56)\n\nthis expression depends only on the line search parameters \u03b1 and \u03b2, and the final\naccuracy \u01eb. moreover the term involving \u01eb can be safely replaced by the constant\nsix, so the bound really depends only on \u03b1 and \u03b2. for typical values of \u03b1 and \u03b2, the\nconstant that scales f (x(0)) \u2212 p\u22c6 is on the order of several hundred. for example,\nwith \u03b1 = 0.1, \u03b2 = 0.8, the scaling factor is 375. with tolerance \u01eb = 10\u221210, we\nobtain the bound\n\n375(f (x(0)) \u2212 p\u22c6) + 6.\n\n(9.57)\n\nwe will see that this bound is fairly conservative, but does capture what appears\nto be the general form of the worst-case number of newton steps required. a more\nrefined analysis, such as the one originally given by nesterov and nemirovski, gives\na similar bound, with a substantially smaller constant scaling f (x(0)) \u2212 p\u22c6.\n\n "}, {"Page_number": 520, "text": "506\n\n9 unconstrained minimization\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\n25\n\n20\n\n15\n\n10\n\n5\n\n0\n0\n\n5\n\n10\n\n20\n15\nf (x(0)) \u2212 p\u22c6\n\n25\n\n30\n\n35\n\nfigure 9.25 number of newton iterations required to minimize self-\nconcordant functions versus f (x(0)) \u2212 p\u22c6. the function f has the form\ni x), where the problem data ai and b are ran-\ndomly generated. the circles show problems with m = 100, n = 50; the\nsquares show problems with m = 1000, n = 500; and the diamonds show\nproblems with m = 1000, n = 50. fifty instances of each are shown.\n\nf (x) = \u2212pm\n\ni=1 log(bi \u2212 at\n\n9.6.5 discussion and numerical examples\n\na family of self-concordant functions\n\nit is interesting to compare the upper bound (9.57) with the actual number of\niterations required to minimize a self-concordant function. we consider a family of\nproblems of the form\n\nf (x) = \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x).\n\nthe problem data ai and b were generated as follows. for each problem instance,\nthe coefficients of ai were generated from independent normal distributions with\nmean zero and unit variance, and the coefficients b were generated from a uniform\ndistribution on [0, 1]. problem instances which were unbounded below were dis-\ncarded. for each problem we first compute x\u22c6. we then generate a starting point\nby choosing a random direction v, and taking x(0) = x\u22c6 + sv, where s is chosen so\nthat f (x(0)) \u2212 p\u22c6 has a prescribed value between 0 and 35. (we should point out\nthat starting points with values f (x(0)) \u2212 p\u22c6 = 10 or higher are actually very close\nto the boundary of the polyhedron.) we then minimize the function using new-\nton\u2019s method with a backtracking line search with parameters \u03b1 = 0.1, \u03b2 = 0.8,\nand tolerance \u01eb = 10\u221210.\n\nfigure 9.25 shows the number of newton iterations required versus f (x(0))\u2212 p\u22c6\nfor 150 problem instances. the circles show 50 problems with m = 100, n = 50;\nthe squares show 50 problems with m = 1000, n = 500; and the diamonds show 50\nproblems with m = 1000, n = 50.\n\n "}, {"Page_number": 521, "text": "9.6 self-concordance\n\n507\n\nfor the values of the backtracking parameters used, the complexity bound found\n\nabove is\n\n375(f (x(0)) \u2212 p\u22c6) + 6,\n\n(9.58)\n\nclearly a much larger value than the number of iterations required (for these 150\ninstances). the plot suggests that there is a valid bound of the same form, but\nwith a much smaller constant (say, around 1.5) scaling f (x(0)) \u2212 p\u22c6. indeed, the\nexpression\n\nf (x(0)) \u2212 p\u22c6 + 6\n\nis not a bad gross predictor of the number of newton steps required, although it is\nclearly not the only factor. first, there are plenty of problems instances where the\nnumber of newton steps is somewhat smaller, which correspond, we can guess, to\n\u2018lucky\u2019 starting points. note also that for the larger problems, with 500 variables\n(represented by the squares), there seem to be even more cases where the number\nof newton steps is unusually small.\n\nwe should mention here that the problem family we study is not just self-\nconcordant, but in fact minimally self-concordant, by which we mean that \u03b1f\nis not self-concordant for \u03b1 < 1. hence, the bound (9.58) cannot be improved\n(the function f (x) = \u221220 log x is an example of a self-\nby simply scaling f .\nconcordant function which is not minimally self-concordant, since (1/20)f is also\nself-concordant.)\n\npractical importance of self-concordance\n\nwe have already observed that newton\u2019s method works in general very well for\nstrongly convex objective functions. we can justify this vague statement empir-\nically, and also using the classical analysis of newton\u2019s method, which yields a\ncomplexity bound, but one that depends on several constants that are almost al-\nways unknown.\n\nfor self-concordant functions we can say somewhat more. we have a complexity\nbound that is completely explicit, and does not depend on any unknown constants.\nempirical studies suggest that this bound can be tightened considerably, but its\ngeneral form, a small constant plus a multiple of f (x(0)) \u2212 p\u22c6, seems to predict, at\nleast crudely, the number of newton steps required to minimize an approximately\nminimally self-concordant function.\n\nit is not yet clear whether self-concordant functions are in practice more easily\nminimized by newton\u2019s method than non-self-concordant functions.\n(it is not\neven clear how one would make this statement precise.) at the moment, we can\nsay that self-concordant functions are a class of functions for which we can say\nconsiderably more about the complexity of newton\u2019s method than is the case for\nnon-self-concordant functions.\n\n "}, {"Page_number": 522, "text": "508\n\n9 unconstrained minimization\n\n9.7 implementation\n\nin this section we discuss some of the issues that arise in implementing an un-\nconstrained minimization algorithm. we refer the reader to appendix c for more\ndetails on numerical linear algebra.\n\n9.7.1 pre-computation for line searches\n\nin the simplest implementation of a line search, f (x + t\u2206x) is evaluated for each\nvalue of t in the same way that f (z) is evaluated for any z \u2208 dom f . but in some\ncases we can exploit the fact that f (and its derivatives, in an exact line search) are\nto be evaluated at many points along the ray {x + t\u2206x | t \u2265 0} to reduce the total\ncomputational effort. this usually requires some pre-computation, which is often\non the same order as computing f at any point, after which f (and its derivatives)\ncan be computed more efficiently along the ray.\n\nsuppose that x \u2208 dom f and \u2206x \u2208 rn, and define \u02dcf as f restricted to the line\nor ray determined by x and \u2206x, i.e., \u02dcf (t) = f (x + t\u2206x). in a backtracking line\nsearch we must evaluate \u02dcf for several, and possibly many, values of t; in an exact\nline search method we must evaluate \u02dcf and one or more derivatives at a number of\nvalues of t. in the simple method described above, we evaluate \u02dcf (t) by first forming\nz = x + t\u2206x, and then evaluating f (z). to evaluate \u02dcf \u2032(t), we form z = x + t\u2206x,\nthen evaluate \u2207f (z), and then compute \u02dcf \u2032(t) = \u2207f (z)t \u2206x. in some representative\nexamples below we show how \u02dcf can be computed at a number of values of t more\nefficiently.\n\ncomposition with an affine function\n\na very general case in which pre-computation can speed up the line search process\noccurs when the objective has the form f (x) = \u03c6(ax + b), where a \u2208 rp\u00d7n, and \u03c6\nis easy to evaluate (for example, separable). to evaluate \u02dcf (t) = f (x + t\u2206x) for k\nvalues of t using the simple approach, we form a(x + t\u2206x) + b for each value of t\n(which costs 2kpn flops), and then evaluate \u03c6(a(x + t\u2206x) + b) for each value of t.\nthis can be done more efficiently by first computing ax + b and a\u2206x (4pn flops),\nthen forming a(x + t\u2206x) + b for each value of t using\n\na(x + t\u2206x) + b = (ax + b) + t(a\u2206x),\n\nwhich costs 2kp flops. the total cost, keeping only the dominant terms, is 4pn+2kp\nflops, compared to 2kpn for the simple method.\n\nanalytic center of a linear matrix inequality\n\nhere we give an example that is more specific, and more complete. we consider\nthe problem (9.6) of computing the analytic center of a linear matrix inequality,\ni.e., minimizing log det f (x)\u22121, where x \u2208 rn and f : rn \u2192 sp is affine. along\nthe line through x with direction \u2206x we have\n\n\u02dcf (t) = log det(f (x + t\u2206x))\u22121 = \u2212 log det(a + tb)\n\n "}, {"Page_number": 523, "text": "509\n\n9.7\n\nimplementation\n\nwhere\n\na = f (x),\n\nb = \u2206x1f1 + \u00b7\u00b7\u00b7 + \u2206xnfn \u2208 sp.\n\nsince a \u227b 0, it has a cholesky factorization a = llt , where l is lower triangular\nand nonsingular. therefore we can express \u02dcf as\n\u02dcf (t) = \u2212 log det(cid:0)l(i + tl\u22121bl\u2212t )lt(cid:1) = \u2212 log det a \u2212\n\npxi=1\n\nlog(1 + t\u03bbi)\n\n(9.59)\n\nwhere \u03bb1, . . . , \u03bbp are the eigenvalues of l\u22121bl\u2212t . once these eigenvalues are\ncomputed, we can evaluate \u02dcf (t), for any t, with 4p simple arithmetic computations,\nby using the formula on the right hand side of (9.59). we can evaluate \u02dcf \u2032(t) (and\nsimilarly, any higher derivative) in 4p operations, using the formula\n\n\u02dcf \u2032(t) = \u2212\n\n\u03bbi\n\n1 + t\u03bbi\n\n.\n\npxi=1\n\nlet us compare the two methods for carrying out a line search, assuming that\nwe need to evaluate f (x + t\u2206x) for k values of t. in the simple method, for each\nvalue of t we form f (x+t\u2206x), and then evaluate f (x+t\u2206x) as \u2212 log det f (x+t\u2206x).\nfor example, we can find the cholesky factorization of f (x + t\u2206x) = llt , and\nthen evaluate\n\n\u2212 log det f (x + t\u2206x) = \u22122\n\nlog lii.\n\npxi=1\n\nthe cost is np2 to form f (x + t\u2206x), plus (1/3)p3 for the cholesky factorization.\ntherefore the total cost of the line search is\n\nk(np2 + (1/3)p3) = knp2 + (1/3)kp3.\n\nusing the method outlined above, we first form a, which costs np2, and factor\nit, which costs (1/3)p3. we also form b (which costs np2), and l\u22121bl\u2212t , which\ncosts 2p3. the eigenvalues of this matrix are then computed, at a cost of about\n(4/3)p3 flops. this pre-computation requires a total of 2np2 + (11/3)p3 flops. after\nfinishing this pre-computation, we can now evaluate \u02dcf (t) for each value of t at a\ncost of 4p flops. the total cost is then\n\n2np2 + (11/3)p3 + 4kp.\n\nassuming k is small compared to p(2n + (11/3)p), this means the entire line search\ncan be carried out at an effort comparable to simply evaluating f . depending on\nthe values of k, p, and n, the savings over the simple method can be as large as\norder k.\n\n9.7.2 computing the newton step\n\nin this section we briefly describe some of the issues that arise in implementing\nnewton\u2019s method. in most cases, the work of computing the newton step \u2206xnt\n\n "}, {"Page_number": 524, "text": "510\n\n9 unconstrained minimization\n\ndominates the work involved in the line search. to compute the newton step\n\u2206xnt, we first evaluate and form the hessian matrix h = \u22072f (x) and the gradient\ng = \u2207f (x) at x. then we solve the system of linear equations h\u2206xnt = \u2212g to\nfind the newton step. this set of equations is sometimes called the newton system\n(since its solution gives the newton step) or the normal equations, since the same\ntype of equation arises in solving a least-squares problem (see \u00a79.1.1).\nwhile a general linear equation solver can be used, it is better to use methods\nthat take advantage of the symmetry and positive definiteness of h. the most\ncommon approach is to form the cholesky factorization of h, i.e., to compute a\nlower triangular matrix l that satisfies llt = h (see \u00a7c.3.2). we then solve lw =\n\u2212g by forward substitution, to obtain w = \u2212l\u22121g, and then solve lt \u2206xnt = w by\nback substitution, to obtain\n\n\u2206xnt = l\u2212t w = \u2212l\u2212t l\u22121g = \u2212h \u22121g.\n\nwe can compute the newton decrement as \u03bb2 = \u2212\u2206xt\n2 = kwk2\n2.\n\n\u03bb2 = gt h \u22121g = kl\u22121gk2\n\nntg, or use the formula\n\nif a dense (unstructured) cholesky factorization is used, the cost of the forward and\nback substitution is dominated by the cost of the cholesky factorization, which is\n(1/3)n3 flops. the total cost of computing the newton step \u2206xnt is thus f +(1/3)n3\nflops, where f is the cost of forming h and g.\n\nit is often possible to solve the newton system h\u2206xnt = \u2212g more efficiently,\nby exploiting special structure in h, such as band structure or sparsity. in this\ncontext, \u2018structure of h\u2019 means structure that is the same for all x. for example,\nwhen we say that \u2018h is tridiagonal\u2019 we mean that for every x \u2208 dom f , \u22072f (x) is\ntridiagonal.\n\nband structure\nif the hessian h is banded with bandwidth k, i.e., hij = 0 for |i\u2212 j| > k, then the\nbanded cholesky factorization can be used, as well as banded forward and back\nsubstitutions. the cost of computing the newton step \u2206xnt = \u2212h \u22121g is then\nf + nk2 flops (assuming k \u226a n), compared to f + (1/3)n3 for a dense factorization\nand substitution method.\n\nthe hessian band structure condition\n\n\u22072f (x)ij =\n\n\u22022f (x)\n\u2202xi\u2202xj\n\n= 0\n\nfor\n\n|i \u2212 j| > k,\n\nfor all x \u2208 dom f , has an interesting interpretation in terms of the objective\nfunction f . roughly speaking it means that in the objective function, each variable\nxi couples nonlinearly only to the 2k + 1 variables xj, j = i \u2212 k, . . . , i + k. this\noccurs when f has the partial separability form\n\nf (x) = \u03c81(x1, . . . , xk+1) + \u03c82(x2, . . . , xk+2) + \u00b7\u00b7\u00b7 + \u03c8n\u2212k(xn\u2212k, . . . , xn),\n\nwhere \u03c8i : rk+1 \u2192 r. in other words, f can be expressed as a sum of functions\nof k consecutive variables.\n\n "}, {"Page_number": 525, "text": "9.7\n\nimplementation\n\n511\n\nexample 9.9 consider the problem of minimizing f : rn \u2192 r, which has the form\n\nf (x) = \u03c81(x1, x2) + \u03c82(x2, x3) + \u00b7\u00b7\u00b7 + \u03c8n\u22121(xn\u22121, xn),\n\nwhere \u03c8i : r2 \u2192 r are convex and twice differentiable. because of this form, the\nhessian \u22072f is tridiagonal, since \u22022f /\u2202xi\u2202xj = 0 for |i \u2212 j| > 1. (and conversely, if\nthe hessian of a function is tridiagonal for all x, then it has this form.)\n\nusing cholesky factorization and forward and back substitution algorithms for tridi-\nagonal matrices, we can solve the newton system for this problem in order n flops.\nthis should be compared to order n3 flops, if the special form of f were not exploited.\n\nsparse structure\n\nmore generally we can exploit sparsity of the hessian h in solving the newton\nsystem. this sparse structure occurs whenever each variable xi is nonlinearly\ncoupled (in the objective) to only a few other variables, or equivalently, when the\nobjective function can be expressed as a sum of functions, each depending on only\na few variables, and each variable appearing in only a few of these functions.\n\nto solve h\u2206x = \u2212g when h is sparse, a sparse cholesky factorization is used\n\nto compute a permutation matrix p and lower triangular matrix l for which\n\nh = p llt p t .\n\nthe cost of this factorization depends on the particular sparsity pattern, but is\noften far smaller than (1/3)n3, and an empirical complexity of order n (for large\nn) is not uncommon. the forward and back substitution are very similar to the\nbasic method without the permutation. we solve lw = \u2212p t g using forward\nsubstitution, and then solve lt v = w by back substitution to obtain\n\nv = l\u2212t w = \u2212l\u2212t l\u22121p t g.\n\nthe newton step is then \u2206x = p v.\n\nsince the sparsity pattern of h does not change as x varies (or more precisely,\nsince we only exploit sparsity that does not change with x) we can use the same\npermutation matrix p for each of the newton steps. the step of determining a\ngood permutation matrix p , which is called the symbolic factorization step, can be\ndone once, for the whole newton process.\n\ndiagonal plus low rank\n\nthere are many other types of structure that can be exploited in solving the new-\nton system h\u2206xnt = \u2212g. here we briefly describe one, and refer the reader to\nappendix c for more details. suppose the hessian h can be expressed as a diago-\nnal matrix plus one of low rank, say, p. this occurs when the objective function f\nhas the special form\n\nf (x) =\n\nnxi=1\n\n\u03c8i(xi) + \u03c80(ax + b)\n\n(9.60)\n\n "}, {"Page_number": 526, "text": "512\n\n9 unconstrained minimization\n\nwhere a \u2208 rp\u00d7n, \u03c81, . . . , \u03c8n : r \u2192 r, and \u03c80 : rp \u2192 r.\nin other words, f\nis a separable function, plus a function that depends on a low dimensional affine\nfunction of x.\n\nto find the newton step \u2206xnt for (9.60) we must solve the newton system\n\nh\u2206xnt = \u2212g, with\n\nh = d + at h0a.\nn(xn)) is diagonal, and h0 = \u22072\u03c80(ax + b) is the\nhere d = diag(\u03c8\u2032\u2032\nhessian of \u03c80. if we compute the newton step without exploiting the structure,\nthe cost of solving the newton system is (1/3)n3 flops.\n\n1 (x1), . . . , \u03c8\u2032\u2032\n\nlet h0 = l0lt\n\nrary variable w = lt\n\n0 be the cholesky factorization of h0. we introduce the tempo-\n0 a\u2206xnt \u2208 rp, and express the newton system as\nd\u2206xnt + at l0w = \u2212g,\n\n0 a\u2206xnt.\n\nw = lt\n\nsubstituting \u2206xnt = \u2212d\u22121(at l0w + g) (from the first equation) into the second\nequation, we obtain\n\n(i + lt\n\n0 ad\u22121at l0)w = \u2212lt\n\n0 ad\u22121g,\n\n(9.61)\n\nwhich is a system of p linear equations.\n\nnow we proceed as follows to compute the newton step \u2206xnt. first we compute\nthe cholesky factorization of h0, which costs (1/3)p3. we then form the dense,\npositive definite symmetric matrix appearing on the lefthand side of (9.61), which\ncosts 2p2n. we then solve (9.61) for w using a cholesky factorization and a back and\nforward substitution, which costs (1/3)p3 flops. finally, we compute \u2206xnt using\n\u2206xnt = \u2212d\u22121(at l0w + g), which costs 2np flops. the total cost of computing\n\u2206xnt is (keeping only the dominant term) 2p2n flops, which is far smaller than\n(1/3)n3 for p \u226a n.\n\n "}, {"Page_number": 527, "text": "bibliography\n\nbibliography\n\n513\n\ndennis and schnabel [ds96] and ortega and rheinboldt [or00] are two standard refer-\nences on algorithms for unconstrained minimization and nonlinear equations. the result\non quadratic convergence, assuming strong convexity and lipschitz continuity of the hes-\nsian, is attributed to kantorovich [kan52]. polyak [pol87, \u00a71.6] gives some insightful\ncomments on the role of convergence results that involve unknown constants, such as the\nresults derived in \u00a79.5.3.\nself-concordant functions were introduced by nesterov and nemirovski [nn94]. all our\nresults in \u00a79.6 and exercises 9.14\u20139.20 can be found in their book, although often in a\nmore general form or with different notation. renegar [ren01] gives a concise and elegant\npresentation of self-concordant functions and their role in the analysis of primal-dual\ninterior-point algorithms. peng, roos, and terlaky [prt02] study interior-point methods\nfrom the viewpoint of self-regular functions, a class of functions that is similar, but not\nidentical, to self-concordant functions.\nreferences for the material in \u00a79.7 are given at the end of appendix c.\n\n "}, {"Page_number": 528, "text": "514\n\n9 unconstrained minimization\n\nexercises\n\nunconstrained minimization\n\n9.1 minimizing a quadratic function.\n\nconsider the problem of minimizing a quadratic\n\nfunction:\n\nminimize\n\nf (x) = (1/2)xt p x + qt x + r,\n\nwhere p \u2208 sn (but we do not assume p (cid:23) 0).\n(a) show that if p 6(cid:23) 0, i.e., the objective function f is not convex, then the problem is\n(b) now suppose that p (cid:23) 0 (so the objective function is convex), but the optimality\ncondition p x\u22c6 = \u2212q does not have a solution. show that the problem is unbounded\nbelow.\n\nunbounded below.\n\n9.2 minimizing a quadratic-over-linear fractional function. consider the problem of minimiz-\n\ning the function f : rn \u2192 r, defined as\n\nf (x) = kax \u2212 bk2\nct x + d\n\n2\n\n,\n\ndom f = {x | ct x + d > 0}.\n\nwe assume rank a = n and b 6\u2208 r(a).\n(a) show that f is closed.\n(b) show that the minimizer x\u22c6 of f is given by\n\nx\u22c6 = x1 + tx2\n\nwhere x1 = (at a)\u22121at b, x2 = (at a)\u22121c, and t \u2208 r can be calculated by solving\na quadratic equation.\n\n9.3 initial point and sublevel set condition. consider the function f (x) = x2\n\n1 + x2\n\n2 with domain\n\ndom f = {(x1, x2) | x1 > 1}.\n(a) what is p\u22c6?\n(b) draw the sublevel set s = {x | f (x) \u2264 f (x(0))} for x(0) = (2, 2). is the sublevel set\n(c) what happens if we apply the gradient method with backtracking line search, start-\n\ns closed? is f strongly convex on s?\n\ning at x(0)? does f (x(k)) converge to p\u22c6?\n\n9.4 do you agree with the following argument? the \u21131-norm of a vector x \u2208 rm can be\n\nexpressed as\n\nkxk1 = (1/2) inf\n\ny\u227b0  mxi=1\n\ni /yi + 1t y! .\n\nx2\n\ntherefore the \u21131-norm approximation problem\n\nminimize\n\nkax \u2212 bk1\n\nis equivalent to the minimization problem\n\nf (x, y) =pm\n\nminimize\n\ni=1(at\n\ni x \u2212 bi)2/yi + 1t y,\n\n(9.62)\n\nwith dom f = {(x, y) \u2208 rn \u00d7 rm | y \u227b 0}, where at\nis the ith row of a. since f is twice\ndifferentiable and convex, we can solve the \u21131-norm approximation problem by applying\nnewton\u2019s method to (9.62).\n\ni\n\n9.5 backtracking line search. suppose f is strongly convex with mi (cid:22) \u22072f (x) (cid:22) m i. let\n\u2206x be a descent direction at x. show that the backtracking stopping condition holds for\n\nuse this to give an upper bound on the number of backtracking iterations.\n\n0 < t \u2264 \u2212\u2207f (x)t \u2206x\nmk\u2206xk2\n\n2\n\n.\n\n "}, {"Page_number": 529, "text": "exercises\n\n515\n\ngradient and steepest descent methods\n\n9.6 quadratic problem in r2. verify the expressions for the iterates x(k) in the first example\n\nof \u00a79.3.2.\n\n9.7 let \u2206xnsd and \u2206xsd be the normalized and unnormalized steepest descent directions at\n\nx, for the norm k \u00b7 k. prove the following identities.\n(a) \u2207f (x)t \u2206xnsd = \u2212k\u2207f (x)k\u2217.\n(b) \u2207f (x)t \u2206xsd = \u2212k\u2207f (x)k2\n\u2217.\n(c) \u2206xsd = argminv(\u2207f (x)t v + (1/2)kvk2).\n\n9.8 steepest descent method in \u2113\u221e-norm. explain how to find a steepest descent direction in\n\nthe \u2113\u221e-norm, and give a simple interpretation.\n\nnewton\u2019s method\n\n9.9 newton decrement. show that the newton decrement \u03bb(x) satisfies\n\n\u03bb(x) =\n\nsup\n\nvt \u22072f (x)v=1\n\n(\u2212vt\u2207f (x)) = sup\n\nv6=0\n\n\u2212vt\u2207f (x)\n(vt\u22072f (x)v)1/2 .\n\n9.10 the pure newton method. newton\u2019s method with fixed step size t = 1 can diverge if the\n\ninitial point is not close to x\u22c6. in this problem we consider two examples.\n\n(a) f (x) = log(ex + e\u2212x) has a unique minimizer x\u22c6 = 0. run newton\u2019s method with\n\nfixed step size t = 1, starting at x(0) = 1 and at x(0) = 1.1.\n\n(b) f (x) = \u2212 log x + x has a unique minimizer x\u22c6 = 1. run newton\u2019s method with fixed\n\nstep size t = 1, starting at x(0) = 3.\n\nplot f and f \u2032, and show the first few iterates.\n\n9.11 gradient and newton methods for composition functions. suppose \u03c6 : r \u2192 r is increasing\nand convex, and f : rn \u2192 r is convex, so g(x) = \u03c6(f (x)) is convex. (we assume that\nf and g are twice differentiable.) the problems of minimizing f and minimizing g are\nclearly equivalent.\ncompare the gradient method and newton\u2019s method, applied to f and g. how are the\nsearch directions related? how are the methods related if an exact line search is used?\nhint. use the matrix inversion lemma (see \u00a7c.4.3).\n9.12 trust region newton method. if \u22072f (x) is singular (or very ill-conditioned), the newton\nstep \u2206xnt = \u2212\u22072f (x)\u22121\u2207f (x) is not well defined. instead we can define a search direction\n\u2206xtr as the solution of\n\nminimize\nsubject to\n\n(1/2)vt hv + gt v\nkvk2 \u2264 \u03b3,\n\nwhere h = \u22072f (x), g = \u2207f (x), and \u03b3 is a positive constant. the point x+\u2206xtr minimizes\nthe second-order approximation of f at x, subject to the constraint that k(x+\u2206xtr)\u2212xk2 \u2264\n\u03b3. the set {v | kvk2 \u2264 \u03b3} is called the trust region. the parameter \u03b3, the size of the trust\nregion, reflects our confidence in the second-order model.\nshow that \u2206xtr minimizes\n\n(1/2)vt hv + gt v + \u02c6\u03b2kvk2\n2,\n\nfor some \u02c6\u03b2. this quadratic function can be interpreted as a regularized quadratic model\nfor f around x.\n\n "}, {"Page_number": 530, "text": "516\n\n9 unconstrained minimization\n\nself-concordance\n\n9.13 self-concordance and the inverse barrier.\n\n(a) show that f (x) = 1/x with domain (0, 8/9) is self-concordant.\n\n(b) show that the function\n\nf (x) = \u03b1\n\nmxi=1\n\n1\n\nbi \u2212 at\ni x\n\nwith dom f = {x \u2208 rn | at\nbounded and\n\ni x < bi, i = 1, . . . , m}, is self-concordant if dom f is\n\n\u03b1 > (9/8) max\n\ni=1,...,m\n\nsup\n\nx\u2208dom f\n\n(bi \u2212 at\n\ni x).\n\n9.14 composition with logarithm. let g : r \u2192 r be a convex function with dom g = r++,\n\nand\n\n|g\u2032\u2032\u2032(x)| \u2264 3\n\ng\u2032\u2032(x)\n\nx\n\nfor all x. prove that f (x) = \u2212 log(\u2212g(x)) \u2212 log x is self-concordant on {x | x > 0, g(x) <\n0}. hint. use the inequality\n\nrp2 + q3 +\n\n3\n2\n\n3\n2\n\np2q + r3 \u2264 1\n\n9.15 prove that the following functions are self-concordant. in your proof, restrict the function\n\nwhich holds for p, q, r \u2208 r+ with p2 + q2 + r2 = 1.\nto a line, and apply the composition with logarithm rule.\n(a) f (x, y) = \u2212 log(y2 \u2212 xt x) on {(x, y) | kxk2 < y}.\n(b) f (x, y) = \u22122 log y \u2212 log(y2/p \u2212 x2), with p \u2265 1, on {(x, y) \u2208 r2 | |x|p < y}.\n(c) f (x, y) = \u2212 log y \u2212 log(log y \u2212 x) on {(x, y) | ex < y}.\n\n9.16 let f : r \u2192 r be a self-concordant function.\n\n(a) suppose f \u2032\u2032(x) 6= 0. show that the self-concordance condition (9.41) can be ex-\n\npressed as\n\n(cid:12)(cid:12)(cid:12)\n\nd\n\ndx(cid:0)f \u2032\u2032(x)\u22121/2(cid:1)(cid:12)(cid:12)(cid:12) \u2264 1.\n\nfind the \u2018extreme\u2019 self-concordant functions of one variable, i.e., the functions f\nand \u02dcf that satisfy\n\nd\n\ndx(cid:0)f \u2032\u2032(x)\u22121/2(cid:1) = 1,\n\nd\n\ndx(cid:0) \u02dcf \u2032\u2032(x)\u22121/2(cid:1) = \u22121,\n\nrespectively.\n\n(b) show that either f \u2032\u2032(x) = 0 for all x \u2208 dom f , or f \u2032\u2032(x) > 0 for all x \u2208 dom f .\n\n9.17 upper and lower bounds on the hessian of a self-concordant function.\n\n(a) let f : r2 \u2192 r be a self-concordant function. show that\n\n,\n\n(cid:12)(cid:12)(cid:12)(cid:12)\n(cid:12)(cid:12)(cid:12)(cid:12)\n\n\u22023f (x)\n\n\u2202x2\n\n\u22023xi (cid:12)(cid:12)(cid:12)(cid:12) \u2264 2(cid:18) \u22022f (x)\ni (cid:19)3/2\ni \u2202xj(cid:12)(cid:12)(cid:12)(cid:12) \u2264 2\ni (cid:18) \u22022f (x)\n\n\u22022f (x)\n\n\u2202x2\n\n\u2202x2\n\n\u22023f (x)\n\u2202x2\n\nj (cid:19)1/2\n\ni = 1, 2,\n\n,\n\ni 6= j\n\nfor all x \u2208 dom f .\n\n "}, {"Page_number": 531, "text": "exercises\n\n517\n\nhint. if h : r2 \u00d7 r2 \u00d7 r2 \u2192 r is a symmetric trilinear form, i.e.,\n\nh(u, v, w) = a1u1v1w1 + a2(u1v1w2 + u1v2w1 + u2v1w1)\n\n+ a3(u1v2w2 + u2v1w1 + u2v2w1) + a4u2v2w2,\n\nthen\n\nsup\n\nu,v,w6=0\n\nh(u, v, w)\n\nkuk2kvk2kwk2\n\n= sup\nu6=0\n\nh(u, u, u)\n\nkuk3\n\n2\n\n.\n\n(b) let f : rn \u2192 r be a self-concordant function. show that the nullspace of \u22072f (x)\nis independent of x. show that if f is strictly convex, then \u22072f (x) is nonsingular\nfor all x \u2208 dom f .\nhint. prove that if wt\u22072f (x)w = 0 for some x \u2208 dom f , then wt\u22072f (y)w = 0 for\nall y \u2208 dom f . to show this, apply the result in (a) to the self-concordant function\n\u02dcf (t, s) = f (x + t(y \u2212 x) + sw).\n(c) let f : rn \u2192 r be a self-concordant function. suppose x \u2208 dom f , v \u2208 rn. show\nthat\n\n(1 \u2212 t\u03b1)2\u22072f (x) (cid:22) \u22072f (x + tv) (cid:22)\n\n1\n\n(1 \u2212 t\u03b1)2 \u22072f (x)\n\nfor x + tv \u2208 dom f , 0 \u2264 t < \u03b1, where \u03b1 = (vt\u22072f (x)v)1/2.\n\n9.18 quadratic convergence. let f : rn \u2192 r be a strictly convex self-concordant function.\nsuppose \u03bb(x) < 1, and define x+ = x \u2212 \u22072f (x)\u22121\u2207f (x). prove that \u03bb(x+) \u2264 \u03bb(x)2/(1 \u2212\n\u03bb(x))2. hint. use the inequalities in exercise 9.17, part (c).\n9.19 bound on the distance from the optimum. let f : rn \u2192 r be a strictly convex self-\n\nconcordant function.\n\n(a) suppose \u03bb(\u00afx) < 1 and the sublevel set {x | f (x) \u2264 f (\u00afx)} is closed. show that the\n\nminimum of f is attained and\n\n(cid:0)(\u00afx \u2212 x\u22c6)t\u22072f (\u00afx)(\u00afx \u2212 x\u22c6)(cid:1)1/2\n\n\u2264\n\n\u03bb(\u00afx)\n\n1 \u2212 \u03bb(\u00afx)\n\n.\n\n(b) show that if f has a closed sublevel set, and is bounded below, then its minimum is\n\nattained.\n\n9.20 conjugate of a self-concordant function. suppose f : rn \u2192 r is closed, strictly convex,\nand self-concordant. we show that its conjugate (or legendre transform) f \u2217 is self-\nconcordant.\n(a) show that for each y \u2208 dom f \u2217, there is a unique x \u2208 dom f that satisfies y =\n(b) suppose \u00afy = \u2207f (\u00afx). define\n\n\u2207f (x). hint. refer to the result of exercise 9.19.\n\ng(t) = f (\u00afx + tv),\n\nh(t) = f \u2217(\u00afy + tw)\n\nwhere v \u2208 rn and w = \u22072f (\u00afx)v. show that\n\nuse these identities to show that f \u2217 is self-concordant.\n\ng\u2032\u2032(0) = h\u2032\u2032(0),\n\ng\u2032\u2032\u2032(0) = \u2212h\u2032\u2032\u2032(0).\n\n9.21 optimal line search parameters. consider the upper bound (9.56) on the number of\nnewton iterations required to minimize a strictly convex self-concordant functions. what\nis the minimum value of the upper bound, if we minimize over \u03b1 and \u03b2?\n\n9.22 suppose that f is strictly convex and satisfies (9.42). give a bound on the number of\n\nnewton steps required to compute p\u22c6 within \u01eb, starting at x(0).\n\n "}, {"Page_number": 532, "text": "518\n\n9 unconstrained minimization\n\nimplementation\n\n9.23 pre-computation for line searches. for each of the following functions, explain how the\ncomputational cost of a line search can be reduced by a pre-computation. give the cost\nof the pre-computation, and the cost of evaluating g(t) = f (x + t\u2206x) and g\u2032(t) with and\nwithout the pre-computation.\n\ni x).\n\ni=1 log(bi \u2212 at\ni=1 exp(at\n\n(a) f (x) = \u2212pm\n(b) f (x) = log(cid:0)pm\ni x + bi)(cid:1).\nb \u2208 rm and dom f = {x | p0 +pn\n\n(c) f (x) = (ax \u2212 b)t (p0 + x1p1 + \u00b7\u00b7\u00b7 + xnpn)\u22121(ax \u2212 b), where pi \u2208 sm, a \u2208 rm\u00d7n,\n\ni=1 xipi \u227b 0}.\n\n9.24 exploiting block diagonal structure in the newton system. suppose the hessian \u22072f (x) of\na convex function f is block diagonal. how do we exploit this structure when computing\nthe newton step? what does it mean about f ?\n\n9.25 smoothed fit to given data. consider the problem\n\nminimize\n\nf (x) =pn\n\ni=1 \u03c8(xi \u2212 yi) + \u03bbpn\u22121\n\ni=1 (xi+1 \u2212 xi)2\n\nwhere \u03bb > 0 is smoothing parameter, \u03c8 is a convex penalty function, and x \u2208 rn is the\nvariable. we can interpret x as a smoothed fit to the vector y.\n\n(a) what is the structure in the hessian of f ?\n\n(b) extend to the problem of making a smooth fit to two-dimensional data, i.e., mini-\n\nmizing the function\n\n\u03c8(xij \u2212 yij) + \u03bb n\u22121xi=1\n\nnxj=1\n\nnxi,j=1\n\n(xi+1,j \u2212 xij)2 +\n\n(xi,j+1 \u2212 xij)2! ,\n\nnxi=1\n\nn\u22121xj=1\n\nwith variable x \u2208 rn\u00d7n, where y \u2208 rn\u00d7n and \u03bb > 0 are given.\n\n9.26 newton equations with linear structure. consider the problem of minimizing a function\n\nof the form\n\nf (x) =\n\nnxi=1\n\n\u03c8i(aix + bi)\n\n(9.63)\n\nwhere ai \u2208 rmi\u00d7n, bi \u2208 rmi , and the functions \u03c8i : rmi \u2192 r are twice differentiable\nand convex. the hessian h and gradient g of f at x are given by\n\nh =\n\nnxi=1\n\nat\n\ni hiai,\n\ng =\n\nat\n\ni gi.\n\nnxi=1\n\n(9.64)\n\nwhere hi = \u22072\u03c8i(aix + bi) and gi = \u2207\u03c8i(aix + bi).\ndescribe how you would implement newton\u2019s method for minimizing f . assume that\nn \u226b mi, the matrices ai are very sparse, but the hessian h is dense.\n\n9.27 analytic center of linear inequalities with variable bounds. give the most efficient method\n\nfor computing the newton step of the function\n\nf (x) = \u2212\n\nnxi=1\n\nlog(xi + 1) \u2212\n\nnxi=1\n\nlog(1 \u2212 xi) \u2212\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x),\n\nwith dom f = {x \u2208 rn | \u22121 \u227a x \u227a 1, ax \u227a b}, where at\nis dense, and distinguish two cases: m \u2265 n and m \u2264 n. (see also exercise 9.30.)\n\nis the ith row of a. assume a\n\ni\n\n "}, {"Page_number": 533, "text": "exercises\n\n519\n\n9.28 analytic center of quadratic inequalities. describe an efficient method for computing the\n\nnewton step of the function\n\nf (x) = \u2212\n\nlog(\u2212xt aix \u2212 bt\n\ni x \u2212 ci),\n\nmxi=1\n\nwith dom f = {x | xt aix + bt\nai \u2208 sn\nhint. the hessian and gradient of f at x are given by\n\n++ are large and sparse, and m \u226a n.\n\ni x + ci < 0, i = 1, . . . , m}. assume that the matrices\n\nh =\n\n(2\u03b1iai + \u03b12\n\ni (2aix + bi)(2aix + bi)t ),\n\ng =\n\n\u03b1i(2aix + bi),\n\nmxi=1\n\nmxi=1\n\ni x \u2212 ci).\n\nwhere \u03b1i = 1/(\u2212xt aix \u2212 bt\n9.29 exploiting structure in two-stage optimization. this exercise continues exercise 4.64, which\ndescribes optimization with recourse, or two-stage optimization. using the notation and\nassumptions in exercise 4.64, we assume in addition that the cost function f is a twice\ndifferentiable function of (x, z), for each scenario i = 1, . . . , s.\nexplain how to efficiently compute the newton step for the problem of finding the optimal\npolicy. how does the approximate flop count for your method compare to that of a generic\nmethod (which exploits no structure), as a function of s, the number of scenarios?\n\nnumerical experiments\n\n9.30 gradient and newton methods. consider the unconstrained problem\n\nminimize\n\ni=1 log(1 \u2212 at\n\ni=1 log(1 \u2212 x2\ni ),\n\nf (x) = \u2212pm\n\ni x) \u2212pn\n\nwith variable x \u2208 rn, and dom f = {x | at\nthis is the problem of computing the analytic center of the set of linear inequalities\n\ni x < 1, i = 1, . . . , m, |xi| < 1, i = 1, . . . , n}.\n\nat\ni x \u2264 1,\n\ni = 1, . . . , m,\n\n|xi| \u2264 1,\n\ni = 1, . . . , n.\n\nnote that we can choose x(0) = 0 as our initial point. you can generate instances of this\nproblem by choosing ai from some distribution on rn.\n\n(a) use the gradient method to solve the problem, using reasonable choices for the back-\ntracking parameters, and a stopping criterion of the form k\u2207f (x)k2 \u2264 \u03b7. plot the\nobjective function and step length versus iteration number. (once you have deter-\nmined p\u22c6 to high accuracy, you can also plot f \u2212 p\u22c6 versus iteration.) experiment\nwith the backtracking parameters \u03b1 and \u03b2 to see their effect on the total number of\niterations required. carry these experiments out for several instances of the problem,\nof different sizes.\n\n(b) repeat using newton\u2019s method, with stopping criterion based on the newton decre-\nment \u03bb2. look for quadratic convergence. you do not have to use an efficient method\nto compute the newton step, as in exercise 9.27; you can use a general purpose dense\nsolver, although it is better to use one that is based on a cholesky factorization.\n\nhint. use the chain rule to find expressions for \u2207f (x) and \u22072f (x).\n9.31 some approximate newton methods. the cost of newton\u2019s method is dominated by the\ncost of evaluating the hessian \u22072f (x) and the cost of solving the newton system. for large\nproblems, it is sometimes useful to replace the hessian by a positive definite approximation\nthat makes it easier to form and solve for the search step. in this problem we explore\nsome common examples of this idea.\nfor each of the approximate newton methods described below, test the method on some\ninstances of the analytic centering problem described in exercise 9.30, and compare the\nresults to those obtained using the newton method and gradient method.\n\n "}, {"Page_number": 534, "text": "520\n\n9 unconstrained minimization\n\n(a) re-using the hessian. we evaluate and factor the hessian only every n iterations,\nwhere n > 1, and use the search step \u2206x = \u2212h \u22121\u2207f (x), where h is the last hessian\nevaluated. (we need to evaluate and factor the hessian once every n steps; for the\nother steps, we compute the search direction using back and forward substitution.)\n\n(b) diagonal approximation. we replace the hessian by its diagonal, so we only have\ni , and computing the search step is\n\nto evaluate the n second derivatives \u22022f (x)/\u2202x2\nvery easy.\n\n9.32 gauss-newton method for convex nonlinear least-squares problems. we consider a (non-\n\nlinear) least-squares problem, in which we minimize a function of the form\n\nf (x) =\n\nfi(x)2,\n\n1\n2\n\nmxi=1\n\nwhere fi are twice differentiable functions. the gradient and hessian of f at x are given\nby\n\n\u2207f (x) =\n\nmxi=1\n\nfi(x)\u2207fi(x),\n\n\u22072f (x) =\n\nmxi=1(cid:0)\u2207fi(x)\u2207fi(x)t + fi(x)\u22072fi(x)(cid:1) .\n\nwe consider the case when f is convex. this occurs, for example, if each fi is either\nnonnegative and convex, or nonpositive and concave, or affine.\nthe gauss-newton method uses the search direction\n\n\u2206xgn = \u2212  mxi=1\n\n\u2207fi(x)\u2207fi(x)t!\u22121  mxi=1\n\nfi(x)\u2207fi(x)! .\n\n(we assume here that the inverse exists, i.e., the vectors \u2207f1(x), . . . , \u2207fm(x) span rn.)\nthis search direction can be considered an approximate newton direction (see exer-\ncise 9.31), obtained by dropping the second derivative terms from the hessian of f .\nwe can give another simple interpretation of the gauss-newton search direction \u2206xgn.\nusing the first-order approximation fi(x + v) \u2248 fi(x) + \u2207fi(x)t v we obtain the approxi-\nmation\n\nf (x + v) \u2248\n\n1\n2\n\n(fi(x) + \u2207fi(x)t v)2.\n\nmxi=1\n\nthe gauss-newton search step \u2206xgn is precisely the value of v that minimizes this ap-\nproximation of f . (moreover, we conclude that \u2206xgn can be computed by solving a linear\nleast-squares problem.)\ntest the gauss-newton method on some problem instances of the form\n\nfi(x) = (1/2)xt aix + bt\n\ni x + 1,\n\nwith ai \u2208 sn\n\n++ and bt\n\ni a\u22121\n\ni bi \u2264 2 (which ensures that f is convex).\n\n "}, {"Page_number": 535, "text": "chapter 10\n\nequality constrained\nminimization\n\n10.1 equality constrained minimization problems\n\nin this chapter we describe methods for solving a convex optimization problem\nwith equality constraints,\n\nminimize\nsubject to ax = b,\n\nf (x)\n\n(10.1)\n\nwhere f : rn \u2192 r is convex and twice continuously differentiable, and a \u2208 rp\u00d7n\nwith rank a = p < n. the assumptions on a mean that there are fewer equality\nconstraints than variables, and that the equality constraints are independent. we\nwill assume that an optimal solution x\u22c6 exists, and use p\u22c6 to denote the optimal\nvalue, p\u22c6 = inf{f (x) | ax = b} = f (x\u22c6).\nand only if there is a \u03bd\u22c6 \u2208 rp such that\n\nrecall (from \u00a74.2.3 or \u00a75.5.3) that a point x\u22c6 \u2208 dom f is optimal for (10.1) if\n\nax\u22c6 = b,\n\n\u2207f (x\u22c6) + at \u03bd\u22c6 = 0.\n\n(10.2)\n\nsolving the equality constrained optimization problem (10.1) is therefore equivalent\nto finding a solution of the kkt equations (10.2), which is a set of n + p equations\nin the n + p variables x\u22c6, \u03bd\u22c6. the first set of equations, ax\u22c6 = b, are called\nthe primal feasibility equations, which are linear. the second set of equations,\n\u2207f (x\u22c6) + at \u03bd\u22c6 = 0, are called the dual feasibility equations, and are in general\nnonlinear. as with unconstrained optimization, there are a few problems for which\nwe can solve these optimality conditions analytically. the most important special\ncase is when f is quadratic, which we examine in \u00a710.1.1.\nany equality constrained minimization problem can be reduced to an equiv-\nalent unconstrained problem by eliminating the equality constraints, after which\nthe methods of chapter 9 can be used to solve the problem. another approach\nis to solve the dual problem (assuming the dual function is twice differentiable)\nusing an unconstrained minimization method, and then recover the solution of the\n\n "}, {"Page_number": 536, "text": "522\n\n10 equality constrained minimization\n\nequality constrained problem (10.1) from the dual solution. the elimination and\ndual methods are briefly discussed in \u00a710.1.2 and \u00a710.1.3, respectively.\nthe bulk of this chapter is devoted to extensions of newton\u2019s method that di-\nrectly handle equality constraints. in many cases these methods are preferable to\nmethods that reduce an equality constrained problem to an unconstrained one. one\nreason is that problem structure, such as sparsity, is often destroyed by elimination\n(or forming the dual); in contrast, a method that directly handles equality con-\nstraints can exploit the problem structure. another reason is conceptual: methods\nthat directly handle equality constraints can be thought of as methods for directly\nsolving the optimality conditions (10.2).\n\n10.1.1 equality constrained convex quadratic minimization\n\nconsider the equality constrained convex quadratic minimization problem\n\nminimize\nsubject to ax = b,\n\nf (x) = (1/2)xt p x + qt x + r\n\n(10.3)\n\n+ and a \u2208 rp\u00d7n. this problem is important on its own, and also\nwhere p \u2208 sn\nbecause it forms the basis for an extension of newton\u2019s method to equality con-\nstrained problems.\n\nhere the optimality conditions (10.2) are\n\nax\u22c6 = b,\n\np x\u22c6 + q + at \u03bd\u22c6 = 0,\n\nwhich we can write as\n\na 0 (cid:21)(cid:20) x\u22c6\n(cid:20) p at\n\n\u03bd\u22c6 (cid:21) =(cid:20) \u2212q\nb (cid:21) .\n\n(10.4)\n\nthis set of n + p linear equations in the n + p variables x\u22c6, \u03bd\u22c6 is called the kkt\nsystem for the equality constrained quadratic optimization problem (10.3). the\ncoefficient matrix is called the kkt matrix.\n\nwhen the kkt matrix is nonsingular, there is a unique optimal primal-dual\npair (x\u22c6, \u03bd\u22c6). if the kkt matrix is singular, but the kkt system is solvable, any\nsolution yields an optimal pair (x\u22c6, \u03bd\u22c6). if the kkt system is not solvable, the\nquadratic optimization problem is unbounded below or infeasible. indeed, in this\ncase there exist v \u2208 rn and w \u2208 rp such that\nav = 0,\n\np v + at w = 0,\n\n\u2212qt v + bt w > 0.\n\nlet \u02c6x be any feasible point. the point x = \u02c6x + tv is feasible for all t and\n\nf (\u02c6x + tv) = f (\u02c6x) + t(vt p \u02c6x + qt v) + (1/2)t2vt p v\n\n= f (\u02c6x) + t(\u2212\u02c6xt at w + qt v) \u2212 (1/2)t2wt av\n= f (\u02c6x) + t(\u2212bt w + qt v),\n\nwhich decreases without bound as t \u2192 \u221e.\n\n "}, {"Page_number": 537, "text": "10.1 equality constrained minimization problems\n\n523\n\nnonsingularity of the kkt matrix\nrecall our assumption that p \u2208 sn\nconditions equivalent to nonsingularity of the kkt matrix:\n\n+ and rank a = p < n. there are several\n\n\u2022 n (p ) \u2229 n (a) = {0}, i.e., p and a have no nontrivial common nullspace.\n\u2022 ax = 0, x 6= 0 =\u21d2 xt p x > 0, i.e., p is positive definite on the nullspace of\n\na.\n\n\u2022 f t p f \u227b 0, where f \u2208 rn\u00d7(n\u2212p) is a matrix for which r(f ) = n (a).\n\n(see exercise 10.1.) as an important special case, we note that if p \u227b 0, the kkt\nmatrix must be nonsingular.\n\n10.1.2 eliminating equality constraints\n\none general approach to solving the equality constrained problem (10.1) is to elim-\ninate the equality constraints, as described in \u00a74.2.4, and then solve the resulting\nunconstrained problem using methods for unconstrained minimization. we first\nfind a matrix f \u2208 rn\u00d7(n\u2212p) and vector \u02c6x \u2208 rn that parametrize the (affine)\nfeasible set:\n\n{x | ax = b} = {f z + \u02c6x | z \u2208 rn\u2212p}.\n\nhere \u02c6x can be chosen as any particular solution of ax = b, and f \u2208 rn\u00d7(n\u2212p)\nis any matrix whose range is the nullspace of a. we then form the reduced or\neliminated optimization problem\n\nminimize\n\n(10.5)\nwhich is an unconstrained problem with variable z \u2208 rn\u2212p. from its solution z\u22c6,\nwe can find the solution of the equality constrained problem as x\u22c6 = f z\u22c6 + \u02c6x.\nwe can also construct an optimal dual variable \u03bd\u22c6 for the equality constrained\n\n\u02dcf (z) = f (f z + \u02c6x),\n\nproblem, as\n\nto show that this expression is correct, we must verify that the dual feasibility\ncondition\n\n\u03bd\u22c6 = \u2212(aat )\u22121a\u2207f (x\u22c6).\n\nholds. to show this, we note that\n\n\u2207f (x\u22c6) + at (\u2212(aat )\u22121a\u2207f (x\u22c6)) = 0\na (cid:21)(cid:0)\u2207f (x\u22c6) \u2212 at (aat )\u22121a\u2207f (x\u22c6)(cid:1) = 0,\n(cid:20) f t\n\nwhere in the top block we use f t\u2207f (x\u22c6) = \u2207 \u02dcf (z\u22c6) = 0 and af = 0. since the\nmatrix on the left is nonsingular, this implies (10.6).\n\n(10.6)\n\nexample 10.1 optimal allocation with resource constraint. we consider the problem\n\nminimize pn\nsubject to pn\n\ni=1 fi(xi)\ni=1 xi = b,\n\n "}, {"Page_number": 538, "text": "524\n\n10 equality constrained minimization\n\nwhere the functions fi : r \u2192 r are convex and twice differentiable, and b \u2208 r is\na problem parameter. we interpret this as the problem of optimally allocating a\nsingle resource, with a fixed total amount b (the budget) to n otherwise independent\nactivities.\n\nwe can eliminate xn (for example) using the parametrization\n\nwhich corresponds to the choices\n\nxn = b \u2212 x1 \u2212 \u00b7\u00b7\u00b7 \u2212 xn\u22121,\n\n\u02c6x = ben,\n\ni\n\nf =(cid:20)\n\n\u22121t (cid:21) \u2208 rn\u00d7(n\u22121).\nfn(b \u2212 x1 \u2212 \u00b7\u00b7\u00b7 \u2212 xn\u22121) +pn\u22121\n\ni=1 fi(xi),\n\nthe reduced problem is then\n\nminimize\n\nwith variables x1, . . . , xn\u22121.\n\nchoice of elimination matrix\n\nthere are, of course, many possible choices for the elimination matrix f , which can\nbe chosen as any matrix in rn\u00d7(n\u2212p) with r(f ) = n (a). if f is one such matrix,\nand t \u2208 r(n\u2212p)\u00d7(n\u2212p) is nonsingular, then \u02dcf = f t is also a suitable elimination\nmatrix, since\n\nr( \u02dcf ) = r(f ) = n (a).\n\nconversely, if f and \u02dcf are any two suitable elimination matrices, then there is\nsome nonsingular t such that \u02dcf = f t .\n\nif we eliminate the equality constraints using f , we solve the unconstrained\n\nproblem\n\nwhile if \u02dcf is used, we solve the unconstrained problem\n\nminimize\n\nf (f z + \u02c6x),\n\nminimize\n\nf ( \u02dcf \u02dcz + \u02c6x) = f (f (t \u02dcz) + \u02c6x).\n\nthis problem is equivalent to the one above, and is simply obtained by the change\nof coordinates z = t \u02dcz. in other words, changing the elimination matrix can be\nthought of as changing variables in the reduced problem.\n\n10.1.3 solving equality constrained problems via the dual\n\nanother approach to solving (10.1) is to solve the dual, and then recover the optimal\nprimal variable x\u22c6, as described in \u00a75.5.5. the dual function of (10.1) is\n\nx\n\n(f (x) + \u03bdt ax)\n\ng(\u03bd) = \u2212bt \u03bd + inf\n= \u2212bt \u03bd \u2212 sup\n= \u2212bt \u03bd \u2212 f \u2217(\u2212at \u03bd),\n\nx (cid:0)(\u2212at \u03bd)t x \u2212 f (x)(cid:1)\n\n "}, {"Page_number": 539, "text": "10.2 newton\u2019s method with equality constraints\n\n525\n\nwhere f \u2217 is the conjugate of f , so the dual problem is\n\nmaximize \u2212bt \u03bd \u2212 f \u2217(\u2212at \u03bd).\n\nsince by assumption there is an optimal point, the problem is strictly feasible, so\nslater\u2019s condition holds. therefore strong duality holds, and the dual optimum is\nattained, i.e., there exists a \u03bd\u22c6 with g(\u03bd\u22c6) = p\u22c6.\n\nif the dual function g is twice differentiable, then the methods for unconstrained\nminimization described in chapter 9 can be used to maximize g. (in general, the\ndual function g need not be twice differentiable, even if f is.) once we find an\noptimal dual variable \u03bd\u22c6, we reconstruct an optimal primal solution x\u22c6 from it.\n(this is not always straightforward; see \u00a75.5.5.)\n\nexample 10.2 equality constrained analytic center. we consider the problem\n\nminimize\nsubject to ax = b,\n\nf (x) = \u2212pn\n\ni=1 log xi\n\nwhere a \u2208 rp\u00d7n, with implicit constraint x \u227b 0. using\n\nf \u2217(y) =\n\nnxi=1\n\n(\u22121 \u2212 log(\u2212yi)) = \u2212n \u2212\n\nnxi=1\n\nlog(\u2212yi)\n\n(with dom f \u2217 = \u2212rn\n\n++), the dual problem is\n\nmaximize\n\ng(\u03bd) = \u2212bt \u03bd + n +pn\n\ni=1 log(at \u03bd)i,\n\n(10.7)\n\n(10.8)\n\nwith implicit constraint at \u03bd \u227b 0. here we can easily solve the dual feasibility\nequation, i.e., find the x that minimizes l(x, \u03bd):\n\n\u2207f (x) + at \u03bd = \u2212(1/x1, . . . , 1/xn) + at \u03bd = 0,\n\nand so\n\nxi(\u03bd) = 1/(at \u03bd)i.\n\n(10.9)\n\nto solve the equality constrained analytic centering problem (10.7), we solve the\n(unconstrained) dual problem (10.8), and then recover the optimal solution of (10.7)\nvia (10.9).\n\n10.2 newton\u2019s method with equality constraints\n\nin this section we describe an extension of newton\u2019s method to include equality\nconstraints. the method is almost the same as newton\u2019s method without con-\nstraints, except for two differences: the initial point must be feasible (i.e., satisfy\nx \u2208 dom f and ax = b), and the definition of newton step is modified to take\nthe equality constraints into account. in particular, we make sure that the newton\nstep \u2206xnt is a feasible direction, i.e., a\u2206xnt = 0.\n\n "}, {"Page_number": 540, "text": "526\n\n10 equality constrained minimization\n\n10.2.1 the newton step\n\ndefinition via second-order approximation\n\nto derive the newton step \u2206xnt for the equality constrained problem\n\nminimize\nsubject to ax = b,\n\nf (x)\n\nat the feasible point x, we replace the objective with its second-order taylor ap-\nproximation near x, to form the problem\n\nminimize\nsubject to a(x + v) = b,\n\nbf (x + v) = f (x) + \u2207f (x)t v + (1/2)vt\u22072f (x)v\n\n(10.10)\n\nwith variable v. this is a (convex) quadratic minimization problem with equality\nconstraints, and can be solved analytically. we define \u2206xnt, the newton step at x,\nas the solution of the convex quadratic problem (10.10), assuming the associated\nkkt matrix is nonsingular. in other words, the newton step \u2206xnt is what must\nbe added to x to solve the problem when the quadratic approximation is used in\nplace of f .\n\nfrom our analysis in \u00a710.1.1 of the equality constrained quadratic problem, the\n\nnewton step \u2206xnt is characterized by\n\n(cid:20) \u22072f (x) at\n\n0 (cid:21)(cid:20) \u2206xnt\n\nw (cid:21) =(cid:20) \u2212\u2207f (x)\n\na\n\n0\n\n(cid:21) ,\n\n(10.11)\n\nwhere w is the associated optimal dual variable for the quadratic problem. the\nnewton step is defined only at points for which the kkt matrix is nonsingular.\n\nas in newton\u2019s method for unconstrained problems, we observe that when the\nobjective f is exactly quadratic, the newton update x + \u2206xnt exactly solves the\nequality constrained minimization problem, and in this case the vector w is the op-\ntimal dual variable for the original problem. this suggests, as in the unconstrained\ncase, that when f is nearly quadratic, x + \u2206xnt should be a very good estimate of\nthe solution x\u22c6, and w should be a good estimate of the optimal dual variable \u03bd\u22c6.\n\nsolution of linearized optimality conditions\n\nwe can interpret the newton step \u2206xnt, and the associated vector w, as the solu-\ntions of a linearized approximation of the optimality conditions\n\nax\u22c6 = b,\n\n\u2207f (x\u22c6) + at \u03bd\u22c6 = 0.\n\nwe substitute x + \u2206xnt for x\u22c6 and w for \u03bd\u22c6, and replace the gradient term in the\nsecond equation by its linearized approximation near x, to obtain the equations\n\u2207f (x + \u2206xnt) + at w \u2248 \u2207f (x) + \u22072f (x)\u2206xnt + at w = 0.\n\na(x + \u2206xnt) = b,\n\nusing ax = b, these become\n\na\u2206xnt = 0,\n\n\u22072f (x)\u2206xnt + at w = \u2212\u2207f (x),\n\nwhich are precisely the equations (10.11) that define the newton step.\n\n "}, {"Page_number": 541, "text": "10.2 newton\u2019s method with equality constraints\n\n527\n\nthe newton decrement\n\nwe define the newton decrement for the equality constrained problem as\n\n\u03bb(x) = (\u2206xt\n\nnt\u22072f (x)\u2206xnt)1/2.\n\n(10.12)\n\nthis is exactly the same expression as (9.29), used in the unconstrained case, and\nthe same interpretations hold. for example, \u03bb(x) is the norm of the newton step,\nin the norm determined by the hessian.\n\nlet\n\n(10.13)\n\nbe the second-order taylor approximation of f at x. the difference between f (x)\nand the minimum of the second-order model satisfies\n\nbf (x + v) = f (x) + \u2207f (x)t v + (1/2)vt\u22072f (x)v\nf (x) \u2212 inf{bf (x + v) | a(x + v) = b} = \u03bb(x)2/2,\n\nexactly as in the unconstrained case (see exercise 10.6). this means that, as in the\nunconstrained case, \u03bb(x)2/2 gives an estimate of f (x)\u2212 p\u22c6, based on the quadratic\nmodel at x, and also that \u03bb(x) (or a multiple of \u03bb(x)2) serves as the basis of a good\nstopping criterion.\n\nthe newton decrement comes up in the line search as well, since the directional\n\nderivative of f in the direction \u2206xnt is\n\nd\ndt\n\nf (x + t\u2206xnt)(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\nas in the unconstrained case.\n\n= \u2207f (x)t \u2206xnt = \u2212\u03bb(x)2,\n\n(10.14)\n\nfeasible descent direction\nsuppose that ax = b. we say that v \u2208 rn is a feasible direction if av = 0. in this\ncase, every point of the form x + tv is also feasible, i.e., a(x + tv) = b. we say that\nv is a descent direction for f at x, if for small t > 0, f (x + tv) < f (x).\n\nthe newton step is always a feasible descent direction (except when x is opti-\nmal, in which case \u2206xnt = 0). indeed, the second set of equations that define \u2206xnt\nare a\u2206xnt = 0, which shows it is a feasible direction; that it is a descent direction\nfollows from (10.14).\n\naffine invariance\n\nlike the newton step and decrement for unconstrained optimization, the new-\nton step and decrement for equality constrained optimization are affine invariant.\nsuppose t \u2208 rn\u00d7n is nonsingular, and define \u00aff (y) = f (t y). we have\n\n\u2207 \u00aff (y) = t t\u2207f (t y),\n\n\u22072 \u00aff (y) = t t\u22072f (t y)t,\n\nand the equality constraint ax = b becomes at y = b.\n\nnow consider the problem of minimizing \u00aff (y), subject to at y = b. the newton\n\nstep \u2206ynt at y is given by the solution of\n\n(cid:20) t t\u22072f (t y)t t t at\n\nat\n\n0\n\n(cid:21)(cid:20) \u2206ynt\n\n\u00afw (cid:21) =(cid:20) \u2212t t\u2207f (t y)\n\n0\n\n(cid:21) .\n\n "}, {"Page_number": 542, "text": "528\n\n10 equality constrained minimization\n\ncomparing with the newton step \u2206xnt for f at x = t y, given in (10.11), we see\nthat\n\nt \u2206ynt = \u2206xnt\n\n(and w = \u00afw), i.e., the newton steps at y and x are related by the same change of\ncoordinates as t y = x.\n\n10.2.2 newton\u2019s method with equality constraints\n\nthe outline of newton\u2019s method with equality constraints is exactly the same as\nfor unconstrained problems.\n\nalgorithm 10.1 newton\u2019s method for equality constrained minimization.\n\ngiven starting point x \u2208 dom f with ax = b, tolerance \u01eb > 0.\nrepeat\n\n1. compute the newton step and decrement \u2206xnt, \u03bb(x).\n2. stopping criterion. quit if \u03bb2/2 \u2264 \u01eb.\n3. line search. choose step size t by backtracking line search.\n4. update. x := x + t\u2206xnt.\n\nthe method is called a feasible descent method, since all the iterates are feasi-\nble, with f (x(k+1)) < f (x(k)) (unless x(k) is optimal). newton\u2019s method requires\nthat the kkt matrix be invertible at each x; we will be more precise about the\nassumptions required for convergence in \u00a710.2.4.\n\n10.2.3 newton\u2019s method and elimination\n\nwe now show that the iterates in newton\u2019s method for the equality constrained\nproblem (10.1) coincide with the iterates in newton\u2019s method applied to the re-\nduced problem (10.5). suppose f satisfies r(f ) = n (a) and rank f = n \u2212 p,\nand \u02c6x satisfies a\u02c6x = b. the gradient and hessian of the reduced objective function\n\u02dcf (z) = f (f z + \u02c6x) are\n\n\u2207 \u02dcf (z) = f t\u2207f (f z + \u02c6x),\n\n\u22072 \u02dcf (z) = f t\u22072f (f z + \u02c6x)f.\n\nfrom the hessian expression, we see that the newton step for the equality con-\nstrained problem is defined, i.e., the kkt matrix\n\n0 (cid:21)\n(cid:20) \u22072f (x) at\n\na\n\nis invertible, if and only if the newton step for the reduced problem is defined, i.e.,\n\u22072 \u02dcf (z) is invertible.\n\nthe newton step for the reduced problem is\n\n\u2206znt = \u2212\u22072 \u02dcf (z)\u22121\u2207 \u02dcf (z) = \u2212(f t\u22072f (x)f )\u22121f t\u2207f (x),\n\n(10.15)\n\n "}, {"Page_number": 543, "text": "10.2 newton\u2019s method with equality constraints\n\n529\n\nwhere x = f z + \u02c6x. this search direction for the reduced problem corresponds to\nthe direction\n\nf \u2206znt = \u2212f (f t\u22072f (x)f )\u22121f t\u2207f (x)\n\nfor the original, equality constrained problem. we claim this is precisely the same\nas the newton direction \u2206xnt for the original problem, defined in (10.11).\n\nto show this, we take \u2206xnt = f \u2206znt, choose\n\nw = \u2212(aat )\u22121a(\u2207f (x) + \u22072f (x)\u2206xnt),\n\nand verify that the equations defining the newton step,\n\n\u22072f (x)\u2206xnt + at w + \u2207f (x) = 0,\n\na\u2206xnt = 0,\n\n(10.16)\n\nhold. the second equation, a\u2206xnt = 0, is satisfied because af = 0. to verify the\nfirst equation, we observe that\n\na (cid:21)(cid:0)\u22072f (x)\u2206xnt + at w + \u2207f (x)(cid:1)\n(cid:20) f t\n= (cid:20) f t\u22072f (x)\u2206xnt + f t at w + f t\u2207f (x)\na\u22072f (x)\u2206xnt + aat w + a\u2207f (x)\n\n= 0.\n\n(cid:21)\n\nsince the matrix on the left of the first line is nonsingular, we conclude that (10.16)\nholds.\n\nin a similar way, the newton decrement \u02dc\u03bb(z) of \u02dcf at z and the newton decrement\n\nof f at x turn out to be equal:\n\n\u02dc\u03bb(z)2 = \u2206zt\n= \u2206zt\n= \u2206xt\n= \u03bb(x)2.\n\nnt\u22072 \u02dcf (z)\u2206znt\nntf t\u22072f (x)f \u2206znt\nnt\u22072f (x)\u2206xnt\n\n10.2.4 convergence analysis\n\nwe saw above that applying newton\u2019s method with equality constraints is exactly\nthe same as applying newton\u2019s method to the reduced problem obtained by elimi-\nnating the equality constraints. everything we know about the convergence of new-\nton\u2019s method for unconstrained problems therefore transfers to newton\u2019s method\nfor equality constrained problems. in particular, the practical performance of new-\nton\u2019s method with equality constraints is exactly like the performance of newton\u2019s\nmethod for unconstrained problems. once x(k) is near x\u22c6, convergence is extremely\nrapid, with a very high accuracy obtained in only a few iterations.\n\nassumptions\n\nwe make the following assumptions.\n\n "}, {"Page_number": 544, "text": "530\n\n10 equality constrained minimization\n\n\u2022 the sublevel set s = {x | x \u2208 dom f, f (x) \u2264 f (x(0)), ax = b} is closed,\nwhere x(0) \u2208 dom f satisfies ax(0) = b. this is the case if f is closed\n(see \u00a7a.3.3).\n\n\u2264 k,\n\n(10.17)\n\n\u2022 on the set s, we have \u22072f (x) (cid:22) m i, and\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n(cid:20) \u22072f (x) at\n\n0 (cid:21)\u22121(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\na\n\ni.e., the inverse of the kkt matrix is bounded on s. (of course the inverse\nmust exist in order for the newton step to be defined at each point in s.)\n\n\u2022 for x, \u02dcx \u2208 s, \u22072f satisfies the lipschitz condition k\u22072f (x) \u2212 \u22072f (\u02dcx)k2 \u2264\n\nlkx \u2212 \u02dcxk2.\n\nbounded inverse kkt matrix assumption\n\nthe condition (10.17) plays the role of the strong convexity assumption in the\nstandard newton method (\u00a79.5.3, page 488). when there are no equality con-\nstraints, (10.17) reduces to the condition k\u22072f (x)\u22121k2 \u2264 k on s, so we can take\nk = 1/m, if \u22072f (x) (cid:23) mi on s, where m > 0. with equality constraints, the\ncondition is not as simple as a positive lower bound on the minimum eigenvalue.\nsince the kkt matrix is symmetric, the condition (10.17) is that its eigenvalues,\nn of which are positive, and p of which are negative, are bounded away from zero.\n\nanalysis via the eliminated problem\nthe assumptions above imply that the eliminated objective function \u02dcf , together\nwith the associated initial point z(0), where x(0) = \u02c6x + f z(0), satisfy the assump-\ntions required in the convergence analysis of newton\u2019s method for unconstrained\nproblems, given in \u00a79.5.3 (with different constants \u02dcm, \u02dcm , and \u02dcl). it follows that\nnewton\u2019s method with equality constraints converges to x\u22c6 (and \u03bd\u22c6 as well).\nto show that the assumptions above imply that the eliminated problem satisfies\nthe assumptions for the unconstrained newton method is mostly straightforward\n(see exercise 10.4). here we show the one implication that is tricky: that the\nbounded inverse kkt condition, together with the upper bound \u22072f (x) (cid:22) m i,\nimplies that \u22072 \u02dcf (z) (cid:23) mi for some positive constant m. more specifically we will\nshow that this inequality holds for\n\nm =\n\n\u03c3min(f )2\n\nk 2m\n\n,\n\n(10.18)\n\nwhich is positive, since f is full rank.\n\nwe show this by contradiction. suppose that f t hf 6(cid:23) mi, where h = \u22072f (x).\nthen we can find u, with kuk2 = 1, such that ut f t hf u < m, i.e., kh 1/2f uk2 <\nm1/2. using af = 0, we have\n\n(cid:20) h at\n\n0 (cid:21)(cid:20) f u\n\n0 (cid:21) =(cid:20) hf u\n\na\n\n0\n\n(cid:21) ,\n\n "}, {"Page_number": 545, "text": "10.3\n\ninfeasible start newton method\n\n531\n\nand so\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n(cid:20) h at\n\n0 (cid:21)\u22121(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\na\n\nusing kf uk2 \u2265 \u03c3min(f ) and\n\n\u2265 (cid:13)(cid:13)(cid:13)(cid:13)(cid:20) f u\n0 (cid:21)(cid:13)(cid:13)(cid:13)(cid:13)2\n(cid:21)(cid:13)(cid:13)(cid:13)(cid:13)2\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:20) hf u\n\n0\n\n= kf uk2\nkhf uk2\n\n.\n\nkhf uk2 \u2264 kh 1/2k2kh 1/2f uk2 < m 1/2m1/2,\n\nwe conclude\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n(cid:20) h at\n\n0 (cid:21)\u22121(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\na\n\n\u2265 kf uk2\nkhf uk2\n\n>\n\n\u03c3min(f )\nm 1/2m1/2 = k,\n\nusing our expression for m given in (10.18).\n\nconvergence analysis for self-concordant functions\nif f is self-concordant, then so is \u02dcf (z) = f (f z + \u02c6x). it follows that if f is self-\nconcordant, we have the exact same complexity estimate as for unconstrained prob-\nlems: the number of iterations required to produce a solution within an accuracy\n\u01eb is no more than\n\n20 \u2212 8\u03b1\n\u03b1\u03b2(1 \u2212 2\u03b1)2 (f (x(0)) \u2212 p\u22c6) + log2 log2(1/\u01eb),\n\nwhere \u03b1 and \u03b2 are the backtracking parameters (see (9.56)).\n\n10.3 infeasible start newton method\n\nnewton\u2019s method, as described in \u00a710.2, is a feasible descent method.\nin this\nsection we describe a generalization of newton\u2019s method that works with initial\npoints, and iterates, that are not feasible.\n\n10.3.1 newton step at infeasible points\n\nas in newton\u2019s method, we start with the optimality conditions for the equality\nconstrained minimization problem:\n\nax\u22c6 = b,\n\n\u2207f (x\u22c6) + at \u03bd\u22c6 = 0.\n\nlet x denote the current point, which we do not assume to be feasible, but we do\nassume satisfies x \u2208 dom f . our goal is to find a step \u2206x so that x + \u2206x satisfies\n(at least approximately) the optimality conditions, i.e., x + \u2206x \u2248 x\u22c6. to do this\n\n "}, {"Page_number": 546, "text": "532\n\n10 equality constrained minimization\n\nwe substitute x + \u2206x for x\u22c6 and w for \u03bd\u22c6 in the optimality conditions, and use the\nfirst-order approximation\n\n\u2207f (x + \u2206x) \u2248 \u2207f (x) + \u22072f (x)\u2206x\n\nfor the gradient to obtain\n\na(x + \u2206x) = b,\n\nthis is a set of linear equations for \u2206x and w,\n\n\u2207f (x) + \u22072f (x)\u2206x + at w = 0.\n0 (cid:21)(cid:20) \u2206x\n\nax \u2212 b (cid:21) .\nw (cid:21) = \u2212(cid:20) \u2207f (x)\n\n(cid:20) \u22072f (x) at\n\na\n\n(10.19)\n\nthe equations are the same as the equations (10.11) that define the newton step\nat a feasible point x, with one difference: the second block component of the\nrighthand side contains ax \u2212 b, which is the residual vector for the linear equality\nconstraints. when x is feasible, the residual vanishes, and the equations (10.19)\nreduce to the equations (10.11) that define the standard newton step at a feasible\npoint x. thus, if x is feasible, the step \u2206x defined by (10.19) coincides with the\nnewton step described above (but defined only when x is feasible). for this reason\nwe use the notation \u2206xnt for the step \u2206x defined by (10.19), and refer to it as the\nnewton step at x, with no confusion.\n\ninterpretation as primal-dual newton step\n\nwe can give an interpretation of the equations (10.19) in terms of a primal-dual\nmethod for the equality constrained problem. by a primal-dual method, we mean\none in which we update both the primal variable x, and the dual variable \u03bd, in\norder to (approximately) satisfy the optimality conditions.\n\nwe express the optimality conditions as r(x\u22c6, \u03bd\u22c6) = 0, where r : rn \u00d7 rp \u2192\n\nrn \u00d7 rp is defined as\n\nr(x, \u03bd) = (rdual(x, \u03bd), rpri(x, \u03bd)).\n\nhere\n\nrdual(x, \u03bd) = \u2207f (x) + at \u03bd,\n\nrpri(x, \u03bd) = ax \u2212 b\n\nare the dual residual and primal residual, respectively. the first-order taylor ap-\nproximation of r, near our current estimate y, is\n\nr(y + z) \u2248 \u02c6r(y + z) = r(y) + dr(y)z,\n\nwhere dr(y) \u2208 r(n+p)\u00d7(n+p) is the derivative of r, evaluated at y (see \u00a7a.4.1).\nwe define the primal-dual newton step \u2206ypd as the step z for which the taylor\napproximation \u02c6r(y + z) vanishes, i.e.,\n\ndr(y)\u2206ypd = \u2212r(y).\n\n(10.20)\n\nnote that here we consider both x and \u03bd as variables; \u2206ypd = (\u2206xpd, \u2206\u03bdpd) gives\nboth a primal and a dual step.\n\n "}, {"Page_number": 547, "text": "10.3\n\ninfeasible start newton method\n\n533\n\nevaluating the derivative of r, we can express (10.20) as\n\nwriting \u03bd + \u2206\u03bdpd as \u03bd+, we can express this as\n\n(cid:20) \u22072f (x) at\n\na\n\n0 (cid:21)(cid:20) \u2206xpd\n(cid:20) \u22072f (x) at\n\n\u2206\u03bdpd (cid:21) = \u2212(cid:20) rdual\n0 (cid:21)(cid:20) \u2206xpd\n\nrpri (cid:21) = \u2212(cid:20) \u2207f (x) + at \u03bd\n\u03bd+ (cid:21) = \u2212(cid:20) \u2207f (x)\nax \u2212 b (cid:21) ,\n\nax \u2212 b\n\na\n\n(cid:21) .\n\n(10.21)\n\n(10.22)\n\nwhich is exactly the same set of equations as (10.19). the solutions of (10.19),\n(10.21), and (10.22) are therefore related as\n\n\u2206xnt = \u2206xpd,\n\nw = \u03bd+ = \u03bd + \u2206\u03bdpd.\n\nthis shows that the (infeasible) newton step is the same as the primal part of\nthe primal-dual step, and the associated dual vector w is the updated primal-dual\nvariable \u03bd+ = \u03bd + \u2206\u03bdpd.\n\nthe two expressions for the newton step and dual variable (or dual step), given\nby (10.21) and (10.22), are of course equivalent, but each reveals a different feature\nof the newton step. the equation (10.21) shows that the newton step and the\nassociated dual step are obtained by solving a set of equations, with the primal\nand dual residuals as the righthand side. the equation (10.22), which is how we\noriginally defined the newton step, gives the newton step and the updated dual\nvariable, and shows that the current value of the dual variable is not needed to\ncompute the primal step, or the updated value of the dual variable.\n\nresidual norm reduction property\n\nthe newton direction, at an infeasible point, is not necessarily a descent direction\nfor f . from (10.19), we note that\n\nd\ndt\n\nf (x + t\u2206x)(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\n= \u2207f (x)t \u2206x\n= \u2212\u2206xt(cid:0)\u22072f (x)\u2206x + at w(cid:1)\n= \u2212\u2206xt\u22072f (x)\u2206x + (ax \u2212 b)t w,\n\nwhich is not necessarily negative (unless, of course, x is feasible, i.e., ax = b). the\nprimal-dual interpretation, however, shows that the norm of the residual decreases\nin the newton direction, i.e.,\n\nd\ndt kr(y + t\u2206ypd)k2\n\n= 2r(y)t dr(y)\u2206ypd = \u22122r(y)t r(y).\n\ntaking the derivative of the square, we obtain\n\n= \u2212kr(y)k2.\n\n(10.23)\n\nthis allows us to use krk2 to measure the progress of the infeasible start newton\nmethod, for example, in the line search. (for the standard newton method, we use\nthe function value f to measure progress of the algorithm, at least until quadratic\nconvergence is attained.)\n\n2(cid:12)(cid:12)(cid:12)(cid:12)t=0\ndt kr(y + t\u2206ypd)k2(cid:12)(cid:12)(cid:12)(cid:12)t=0\n\nd\n\n "}, {"Page_number": 548, "text": "534\n\n10 equality constrained minimization\n\nfull step feasibility property\n\nthe newton step \u2206xnt defined by (10.19) has the property (by construction) that\n\na(x + \u2206xnt) = b.\n\n(10.24)\n\nit follows that, if a step length of one is taken using the newton step \u2206xnt, the\nfollowing iterate will be feasible. once x is feasible, the newton step becomes a\nfeasible direction, so all future iterates will be feasible, regardless of the step sizes\ntaken.\n\nmore generally, we can analyze the effect of a damped step on the equality\nconstraint residual rpri. with a step length t \u2208 [0, 1], the next iterate is x+ =\nx + t\u2206xnt, so the equality constraint residual at the next iterate is\n\nr+\npri = a(x + \u2206xntt) \u2212 b = (1 \u2212 t)(ax \u2212 b) = (1 \u2212 t)rpri,\n\nusing (10.24). thus, a damped step, with length t, causes the residual to be scaled\nnt , for\nnt is the newton step at the point x(i) \u2208 dom f , and\n\ndown by a factor 1 \u2212 t. now suppose that we have x(i+1) = x(i) + t(i)\u2206x(i)\ni = 0, . . . , k \u2212 1, where \u2206x(i)\nt(i) \u2208 [0, 1]. then we have\n\nr(k) = k\u22121yi=0\n\n(1 \u2212 t(i))! r(0),\n\nwhere r(i) = ax(i) \u2212 b is the residual of x(i). this formula shows that the primal\nresidual at each step is in the direction of the initial primal residual, and is scaled\ndown at each step. it also shows that once a full step is taken, all future iterates\nare primal feasible.\n\n10.3.2 infeasible start newton method\n\nwe can develop an extension of newton\u2019s method, using the newton step \u2206xnt\ndefined by (10.19), with x(0) \u2208 dom f , but not necessarily satisfying ax(0) = b.\nwe also use the dual part of the newton step: \u2206\u03bdnt = w \u2212 \u03bd in the notation\nof (10.19), or equivalently, \u2206\u03bdnt = \u2206\u03bdpd in the notation of (10.21).\n\nalgorithm 10.2 infeasible start newton method.\n\ngiven starting point x \u2208 dom f , \u03bd, tolerance \u01eb > 0, \u03b1 \u2208 (0, 1/2), \u03b2 \u2208 (0, 1).\nrepeat\n\n1. compute primal and dual newton steps \u2206xnt, \u2206\u03bdnt.\n2. backtracking line search on krk2.\n\nt := 1.\nwhile kr(x + t\u2206xnt, \u03bd + t\u2206\u03bdnt)k2 > (1 \u2212 \u03b1t)kr(x, \u03bd)k2,\n\n3. update. x := x + t\u2206xnt, \u03bd := \u03bd + t\u2206\u03bdnt.\n\nt := \u03b2t.\n\nuntil ax = b and kr(x, \u03bd)k2 \u2264 \u01eb.\n\n "}, {"Page_number": 549, "text": "10.3\n\ninfeasible start newton method\n\n535\n\nthis algorithm is very similar to the standard newton method with feasible start-\ning point, with a few exceptions. first, the search directions include the extra\ncorrection terms that depend on the primal residual. second, the line search is\ncarried out using the norm of the residual, instead of the function value f . finally,\nthe algorithm terminates when primal feasibility has been achieved, and the norm\nof the (dual) residual is small.\n\nthe line search in step 2 deserves some comment. using the norm of the residual\nin the line search can increase the cost, compared to a line search based on the\nfunction value, but the increase is usually negligible. also, we note that the line\nsearch must terminate in a finite number of steps, since (10.23) shows that the line\nsearch exit condition is satisfied for small t.\n\nthe equation (10.24) shows that if at some iteration the step length is chosen to\nbe one, the next iterate will be feasible. thereafter, all iterates will be feasible, and\ntherefore the search direction for the infeasible start newton method coincides, once\na feasible iterate is obtained, with the search direction for the (feasible) newton\nmethod described in \u00a710.2.\nthere are many variations on the infeasible start newton method. for example,\nwe can switch to the (feasible) newton method described in \u00a710.2 once feasibility\nis achieved. (in other words, we change the line search to one based on f , and\nterminate when \u03bb(x)2/2 \u2264 \u01eb.) once feasibility is achieved, the infeasible start and\nthe standard (feasible) newton method differ only in the backtracking and exit\nconditions, and have very similar performance.\n\nusing infeasible start newton method to simplify initialization\n\nthe main advantage of the infeasible start newton method is in the initialization\nrequired. if dom f = rn, then initializing the (feasible) newton method simply\nrequires computing a solution to ax = b, and there is no particular advantage,\nother than convenience, in using the infeasible start newton method.\n\nwhen dom f is not all of rn, finding a point in dom f that satisfies ax = b\ncan itself be a challenge. one general approach, probably the best when dom f is\ncomplex and not known to intersect {z | az = b}, is to use a phase i method (de-\nscribed in \u00a711.4) to compute such a point (or verify that dom f does not intersect\n{z | az = b}). but when dom f is relatively simple, and known to contain a point\nsatisfying ax = b, the infeasible start newton method gives a simple alternative.\n++, as in the equality con-\nstrained analytic centering problem described in example 10.2. to initialize new-\nton\u2019s method for the problem\n\none common example occurs when dom f = rn\n\nminimize \u2212pn\n\nsubject to ax = b,\n\ni=1 log xi\n\n(10.25)\n\nrequires finding a point x(0) \u227b 0 with ax = b, which is equivalent to solving a stan-\ndard form lp feasibility problem. this can be carried out using a phase i method,\nor alternatively, using the infeasible start newton method, with any positive initial\npoint, e.g., x(0) = 1.\n\nthe same trick can be used to initialize unconstrained problems where a starting\npoint in dom f is not known. as an example, we consider the dual of the equality\n\n "}, {"Page_number": 550, "text": "536\n\n10 equality constrained minimization\n\nconstrained analytic centering problem (10.25),\n\nmaximize\n\ng(\u03bd) = \u2212bt \u03bd + n +pn\n\ni=1 log(at \u03bd)i.\n\nto initialize this problem for the (feasible start) newton method, we must find a\npoint \u03bd(0) that satisfies at \u03bd(0) \u227b 0, i.e., we must solve a set of linear inequalities.\nthis can be done using a phase i method, or using an infeasible start newton\nmethod, after reformulating the problem. we first express it as an equality con-\nstrained problem,\n\nmaximize \u2212bt \u03bd + n +pn\n\ny = at \u03bd,\n\nsubject to\n\ni=1 log yi\n\nwith new variable y \u2208 rn. we can now use the infeasible start newton method,\nstarting with any positive y(0) (and any \u03bd(0)).\nthe disadvantage of using the infeasible start newton method to initialize prob-\nlems for which a strictly feasible starting point is not known is that there is no clear\nway to detect that there exists no strictly feasible point; the norm of the residual\nwill simply converge, slowly, to some positive value. (phase i methods, in contrast,\ncan determine this fact unambiguously.) in addition, the convergence of the infea-\nsible start newton method, before feasibility is achieved, can be slow; see \u00a711.4.2.\n\n10.3.3 convergence analysis\n\nin this section we show that the infeasible start newton method converges to the\noptimal point, provided certain assumptions hold. the convergence proof is very\nsimilar to those for the standard newton method, or the standard newton method\nwith equality constraints. we show that once the norm of the residual is small\nenough, the algorithm takes full steps (which implies that feasibility is achieved),\nand convergence is subsequently quadratic. we also show that the norm of the\nresidual is reduced by at least a fixed amount in each iteration before the region\nof quadratic convergence is reached. since the norm of the residual cannot be\nnegative, this shows that within a finite number of steps, the residual will be small\nenough to guarantee full steps, and quadratic convergence.\n\nassumptions\n\nwe make the following assumptions.\n\n\u2022 the sublevel set\n\ns = {(x, \u03bd) | x \u2208 dom f, kr(x, \u03bd)k2 \u2264 kr(x(0), \u03bd(0))k2}\n\n(10.26)\n\nis closed. if f is closed, then krk2 is a closed function, and therefore this con-\ndition is satisfied for any x(0) \u2208 dom f and any \u03bd(0) \u2208 rp (see exercise 10.7).\n\n\u2022 on the set s, we have\n\nkdr(x, \u03bd)\u22121k2 =(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n\n(cid:20) \u22072f (x) at\n\na\n\n0 (cid:21)\u22121(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\n\u2264 k,\n\n(10.27)\n\n "}, {"Page_number": 551, "text": "10.3\n\ninfeasible start newton method\n\n537\n\nfor some k.\n\n\u2022 for (x, \u03bd), (\u02dcx, \u02dc\u03bd) \u2208 s, dr satisfies the lipschitz condition\n\nkdr(x, \u03bd) \u2212 dr(\u02dcx, \u02dc\u03bd)k2 \u2264 lk(x, \u03bd) \u2212 (\u02dcx, \u02dc\u03bd)k2.\n\n(this is equivalent to \u22072f (x) satisfying a lipschitz condition; see exer-\ncise 10.7.)\n\nas we will see below, these assumptions imply that dom f and {z | az = b}\nintersect, and that there is an optimal point (x\u22c6, \u03bd\u22c6).\n\ncomparison with standard newton method\nthe assumptions above are very similar to the ones made in \u00a710.2.4 (page 529)\nfor the analysis of the standard newton method. the second and third assump-\ntions, the bounded inverse kkt matrix and lipschitz condition, are essentially the\nsame. the sublevel set condition (10.26) for the infeasible start newton method\nis, however, more general than the sublevel set condition made in \u00a710.2.4.\n\nas an example, consider the equality constrained maximum entropy problem\n\nminimize\nsubject to ax = b,\n\nf (x) =pn\n\ni=1 xi log xi\n\nwith dom f = rn\n++. the objective f is not closed; it has sublevel sets that are not\nclosed, so the assumptions made in the standard newton method may not hold,\nat least for some initial points. the problem here is that the negative entropy\nfunction does not converge to \u221e as xi \u2192 0. on the other hand the sublevel set\ncondition (10.26) for the infeasible start newton method does hold for this problem,\nsince the norm of the gradient of the negative entropy function does converge to\n\u221e as xi \u2192 0. thus, the infeasible start newton method is guaranteed to solve the\nequality constrained maximum entropy problem. (we do not know whether the\nstandard newton method can fail for this problem; we are only observing here that\nour convergence analysis does not hold.) note that if the initial point satisfies the\nequality constraints, the only difference between the standard and infeasible start\nnewton methods is in the line searches, which differ only during the damped stage.\n\na basic inequality\nwe start by deriving a basic inequality. let y = (x, \u03bd) \u2208 s with kr(y)k2 6= 0, and\nlet \u2206ynt = (\u2206xnt, \u2206\u03bdnt) be the newton step at y. define\n\ntmax = inf{t > 0 | y + t\u2206ynt 6\u2208 s}.\n\nif y + t\u2206ynt \u2208 s for all t \u2265 0, we follow the usual convention and define tmax = \u221e.\notherwise, tmax is the smallest positive value of t such that kr(y + t\u2206ynt)k2 =\nkr(y(0))k2. in particular, it follows that y + t\u2206ynt \u2208 s for 0 \u2264 t \u2264 tmax.\n\nwe will show that\n\nkr(y + t\u2206ynt)k2 \u2264 (1 \u2212 t)kr(y)k2 + (k 2l/2)t2kr(y)k2\n\n2\n\n(10.28)\n\n "}, {"Page_number": 552, "text": "538\n\n10 equality constrained minimization\n\nfor 0 \u2264 t \u2264 min{1, tmax}.\n\nwe have\n\nr(y + t\u2206ynt) = r(y) +z 1\n\n0\n\ndr(y + \u03c4 t\u2206ynt)t\u2206ynt d\u03c4\n\n= r(y) + tdr(y)\u2206ynt +z 1\n\n= r(y) + tdr(y)\u2206ynt + e\n= (1 \u2212 t)r(y) + e,\n\n0\n\n(dr(y + \u03c4 t\u2206ynt) \u2212 dr(y))t\u2206ynt d\u03c4\n\nusing dr(y)\u2206ynt = \u2212r(y), and defining\n\ne =z 1\n\n0\n\n(dr(y + \u03c4 t\u2206ynt) \u2212 dr(y))t\u2206ynt d\u03c4.\n\nnow suppose 0 \u2264 t \u2264 tmax, so y + \u03c4 t\u2206ynt \u2208 s for 0 \u2264 \u03c4 \u2264 1. we can bound kek2\nas follows:\n\n0 kdr(y + \u03c4 t\u2206ynt) \u2212 dr(y)k2 d\u03c4\n\nkek2 \u2264 kt\u2206yntk2z 1\n\u2264 kt\u2206yntk2z 1\n= (l/2)t2k\u2206yntk2\n= (l/2)t2kdr(y)\u22121r(y)k2\n\u2264 (k 2l/2)t2kr(y)k2\n2,\n\n0\n\n2\n\n2\n\nlk\u03c4 t\u2206yntk2 d\u03c4\n\nusing the lipschitz condition on the second line, and the bound kdr(y)\u22121k2 \u2264 k\non the last. now we can derive the bound (10.28): for 0 \u2264 t \u2264 min{1, tmax},\n\nkr(y + t\u2206ynt)k2 = k(1 \u2212 t)r(y) + ek2\n\n\u2264 (1 \u2212 t)kr(y)k2 + kek2\n\u2264 (1 \u2212 t)kr(y)k2 + (k 2l/2)t2kr(y)k2\n2.\n\ndamped newton phase\nwe first show that if kr(y)k2 > 1/(k 2l), one iteration of the infeasible start\nnewton method reduces krk2 by at least a certain minimum amount.\nthe righthand side of the basic inequality (10.28) is quadratic in t, and mono-\ntonically decreasing between t = 0 and its minimizer\n\n\u00aft =\n\n1\n\nk 2lkr(y)k2\n\n< 1.\n\nwe must have tmax > \u00aft, because the opposite would imply kr(y + tmax\u2206ynt)k2 <\nkr(y)k2, which is false. the basic inequality is therefore valid at t = \u00aft, and therefore\n\nkr(y + \u00aft\u2206ynt)k2 \u2264 kr(y)k2 \u2212 1/(2k 2l)\n\u2264 kr(y)k2 \u2212 \u03b1/(k 2l)\n= (1 \u2212 \u03b1\u00aft)kr(y)k2,\n\n "}, {"Page_number": 553, "text": "10.3\n\ninfeasible start newton method\n\n539\n\nwhich shows that the step length \u00aft satisfies the line search exit condition. therefore\nwe have t \u2265 \u03b2\u00aft, where t is the step length chosen by the backtracking algorithm.\nfrom t \u2265 \u03b2\u00aft we have (from the exit condition in the backtracking line search)\n\nkr(y + t\u2206ynt)k2 \u2264 (1 \u2212 \u03b1t)kr(y)k2\n\u2264 (1 \u2212 \u03b1\u03b2\u00aft)kr(y)k2\n= (cid:18)1 \u2212\n\nk 2lkr(y)k2(cid:19)kr(y)k2\n\n\u03b1\u03b2\n\n= kr(y)k2 \u2212\n\n\u03b1\u03b2\nk 2l\n\n.\n\nthus, as long as we have kr(y)k2 > 1/(k 2l), we obtain a minimum decrease in\nkrk2, per iteration, of \u03b1\u03b2/(k 2l). it follows that a maximum of\n\nkr(y(0))k2k 2l\n\n\u03b1\u03b2\n\niterations can be taken before we have kr(y(k))k2 \u2264 1/(k 2l).\nquadratically convergent phase\nnow suppose kr(y)k2 \u2264 1/(k 2l). the basic inequality gives\nkr(y + t\u2206ynt)k2 \u2264 (1 \u2212 t + (1/2)t2)kr(y)k2\n\n(10.29)\n\nfor 0 \u2264 t \u2264 min{1, tmax}. we must have tmax > 1, because otherwise it would follow\nfrom (10.29) that kr(y + tmax\u2206ynt)k2 < kr(y)k2, which contradicts the definition\nof tmax. the inequality (10.29) therefore holds with t = 1, i.e., we have\n\nkr(y + \u2206ynt)k2 \u2264 (1/2)kr(y)k2 \u2264 (1 \u2212 \u03b1)kr(y)k2.\n\nthis shows that the backtracking line search exit criterion is satisfied for t = 1,\nso a full step will be taken. moreover, for all future iterations we have kr(y)k2 \u2264\n1/(k 2l), so a full step will be taken for all following iterations.\n\nwe can write the inequality (10.28) (for t = 1) as\n\nk 2lkr(y+)k2\n\n2\n\n\u2264(cid:18) k 2lkr(y)k2\n\n2\n\n(cid:19)2\n\n,\n\nwhere y+ = y + \u2206ynt. therefore, if r(y+k) denotes the residual k steps after an\niteration in which kr(y)k2 \u2264 1/k 2l, we have\n\nk 2lkr(y+k)k2\n\n2\n\n\u2264(cid:18) k 2lkr(y)k2\n\n2\n\n(cid:19)2k\n\n\u2264(cid:18) 1\n2(cid:19)2k\n\n,\n\ni.e., we have quadratic convergence of kr(y)k2 to zero.\nto show that the sequence of iterates converges, we will show that it is a cauchy\nsequence. suppose y is an iterate satisfying kr(y)k2 \u2264 1/(k 2l), and y+k denotes\n\n "}, {"Page_number": 554, "text": "540\n\n10 equality constrained minimization\n\nthe kth iterate after y. since these iterates are in the region of quadratic conver-\ngence, the step size is one, so we have\n\nky+k \u2212 yk2 \u2264 ky+k \u2212 y+(k\u22121)k2 + \u00b7\u00b7\u00b7 + ky+ \u2212 yk2\n= kdr(y+(k\u22121))\u22121r(y+(k\u22121))k2 + \u00b7\u00b7\u00b7 + kdr(y)\u22121r(y)k2\n\u2264 k(cid:16)kr(y+(k\u22121))k2 + \u00b7\u00b7\u00b7 + kr(y)k2(cid:17)\n(cid:19)2i\u22121\n\n\u2264 kkr(y)k2\n\n2\n\nk\u22121xi=0(cid:18) k 2lkr(y)k2\nk\u22121xi=0(cid:18) 1\n\n2(cid:19)2i\u22121\n\n\u2264 kkr(y)k2\n\u2264 2kkr(y)k2\n\nwhere in the third line we use the assumption that kdr\u22121k2 \u2264 k for all iterates.\nsince kr(y(k))k2 converges to zero, we conclude y(k) is a cauchy sequence, and\ntherefore converges. by continuity of r, the limit point y\u22c6 satisfies r(y\u22c6) = 0. this\nestablishes our earlier claim that the assumptions at the beginning of this section\nimply that there is an optimal point (x\u22c6, \u03bd\u22c6).\n\n10.3.4 convex-concave games\n\nthe proof of convergence for the infeasible start newton method reveals that the\nmethod can be used for a larger class of problems than equality constrained convex\noptimization problems. suppose r : rn \u2192 rn is differentiable, its derivative\nsatisfies a lipschitz condition on s, and kdr(x)\u22121k2 is bounded on s, where\n\ns = {x \u2208 dom r | kr(x)k2 \u2264 kr(x(0))k2}\n\nis a closed set. then the infeasible start newton method, started at x(0), converges\nto a solution of r(x) = 0 in s. in the infeasible start newton method, we apply\nthis to the specific case in which r is the residual for the equality constrained\nconvex optimization problem. but it applies in several other interesting cases. one\ninteresting example is solving a convex-concave game. (see \u00a75.4.3 and exercise 5.25\nfor discussion of other, related games).\nan unconstrained (zero-sum, two-player) game on rp \u00d7 rq is defined by its\npayoff function f : rp+q \u2192 r. the meaning is that player 1 chooses a value (or\nmove) u \u2208 rp, and player 2 chooses a value (or move) v \u2208 rq; based on these\nchoices, player 1 makes a payment to player 2, in the amount f (u, v). the goal of\nplayer 1 is to minimize this payment, while the goal of player 2 is to maximize it.\nif player 1 makes his choice u first, and player 2 knows the choice, then player 2\nwill choose v to maximize f (u, v), which results in a payoff of supv f (u, v) (assuming\nthe supremum is achieved). if player 1 assumes that player 2 will make this choice,\nhe should choose u to minimize supv f (u, v). the resulting payoff, from player 1\nto player 2, will then be\n\ninf\nu\n\nsup\n\nf (u, v)\n\nv\n\n(10.30)\n\n "}, {"Page_number": 555, "text": "10.3\n\ninfeasible start newton method\n\n541\n\n(assuming that the supremum is achieved). on the other hand if player 2 makes\nthe first choice, the strategies are reversed, and the resulting payoff from player 1\nto player 2 is\n\nsup\n\nv\n\ninf\nu\n\nf (u, v).\n\n(10.31)\n\nthe payoff (10.30) is always greater than or equal to the payoff (10.31); the dif-\nference between the two payoffs can be interpreted as the advantage afforded the\nplayer who makes the second move, with knowledge of the other player\u2019s move. we\nsay that (u\u22c6, v\u22c6) is a solution of the game, or a saddle-point for the game, if for all\nu, v,\n\nf (u\u22c6, v) \u2264 f (u\u22c6, v\u22c6) \u2264 f (u, v\u22c6).\n\nwhen a solution exists, there is no advantage to making the second move; f (u\u22c6, v\u22c6)\nis the common value of both payoffs (10.30) and (10.31). (see exercise 3.14.)\n\nthe game is called convex-concave if for each v, f (u, v) is a convex function of\nu, and for each u, f (u, v) is a concave function of v. when f is differentiable (and\nconvex-concave), a saddle-point for the game is characterized by \u2207f (u\u22c6, v\u22c6) = 0.\nsolution via infeasible start newton method\n\nwe can use the infeasible start newton method to compute a solution of a convex-\nconcave game with twice differentiable payoff function. we define the residual as\n\nr(u, v) = \u2207f (u, v) =(cid:20) \u2207uf (u, v)\n\u2207vf (u, v) (cid:21) ,\n\nand apply the infeasible start newton method. in the context of games, the infea-\nsible start newton method is simply called newton\u2019s method (for convex-concave\ngames).\n\nwe can guarantee convergence of the (infeasible start) newton method provided\ndr = \u22072f has bounded inverse, and satisfies a lipschitz condition on the sublevel\nset\n\ns = {(u, v) \u2208 dom f | kr(u, v)k2 \u2264 kr(u(0), v(0))k2},\n\nwhere u(0), v(0) are the starting players\u2019 choices.\n\nthere is a simple analog of the strong convexity condition in an unconstrained\nminimization problem. we say the game with payoff function f is strongly convex-\nconcave if for some m > 0, we have \u22072\nvvf (u, v) (cid:22) \u2212mi, for\nall (u, v) \u2208 s. not surprisingly, this strong convex-concave assumption implies the\nbounded inverse condition (exercise 10.10).\n\nuuf (u, v) (cid:23) mi and \u22072\n\n10.3.5 examples\n\na simple example\n\nwe illustrate the infeasible start newton method on the equality constrained an-\nalytic center problem (10.25). our first example is an instance with dimensions\nn = 100 and m = 50, generated randomly, for which the problem is feasible and\nbounded below. the infeasible start newton method is used, with initial primal\n\n "}, {"Page_number": 556, "text": "542\n\n10 equality constrained minimization\n\nand dual points x(0) = 1, \u03bd(0) = 0, and backtracking parameters \u03b1 = 0.01 and\n\u03b2 = 0.5. the plot in figure 10.1 shows the norms of the primal and dual residu-\nals separately, versus iteration number, and the plot in figure 10.2 shows the step\nlengths. a full newton step is taken in iteration 8, so the primal residual becomes\n(almost) zero, and remains (almost) zero. after around iteration 9 or so, the (dual)\nresidual converges quadratically to zero.\n\nan infeasible example\n\nwe also consider a problem instance, of the same dimensions as the example above,\nfor which dom f does not intersect {z | az = b}, i.e., the problem is infeasible.\n(this violates the basic assumption in the chapter that problem (10.1) is solvable, as\nwell as the assumptions made in \u00a710.2.4; the example is meant only to show what\nhappens to the infeasible start newton method when dom f does not intersect\n{z | az = b}.) the norm of the residual for this example is shown in figure 10.3,\nand the step length in figure 10.4. here, of course, the step lengths are never one,\nand the residual does not converge to zero.\n\na convex-concave game\nour final example involves a convex-concave game on r100 \u00d7 r100, with payoff\nfunction\n\nf (u, v) = ut av + bt u + ct v \u2212 log(1 \u2212 ut u) + log(1 \u2212 vt v),\n\n(10.32)\n\ndefined on\n\ndom f = {(u, v) | ut u < 1, vt v < 1}.\n\nthe problem data a, b, and c were randomly generated. the progress of the\n(infeasible start) newton method, started at u(0) = v(0) = 0, with backtracking\nparameters \u03b1 = 0.01 and \u03b2 = 0.5, is shown in figure 10.5.\n\n10.4 implementation\n\n10.4.1 elimination\n\nto implement the elimination method, we have to calculate a full rank matrix f\nand an \u02c6x such that\n\n{x | ax = b} = {f z + \u02c6x | z \u2208 rn\u2212p}.\n\nseveral methods for this are described in \u00a7c.5.\n\n10.4.2 solving kkt systems\n\nin this section we describe methods that can be used to compute the newton step\nor infeasible newton step, both of which involve solving a set of linear equations\n\n "}, {"Page_number": 557, "text": "10.4\n\nimplementation\n\n543\n\n105\n\n100\n\n2\n\nk\n\nl\na\nu\nd\nr\nk\n\nd\nn\na\n\n10\u22125\n\n2\n\nk\n\ni\nr\np\nr\nk\n\n10\u221210\n\n10\u221215\n0\n\n2\n\n4\n8\niteration number\n\n6\n\n10\n\n12\n\nfigure 10.1 progress of infeasible start newton method on an equality con-\nstrained analytic centering problem with 100 variables and 50 constraints.\nthe figure shows krprik2 (solid line), and krdualk2 (dashed line). note that\nfeasibility is achieved (and maintained) after 8 iterations, and convergence\nis quadratic, starting from iteration 9 or so.\n\nt\n\n1\n\n0.5\n\n0\n\n2\n\n4\n8\niteration number\n\n6\n\n10\n\n12\n\nfigure 10.2 step length versus iteration number for the same example prob-\nlem. a full step is taken in iteration 8, which results in feasibility from\niteration 8 on.\n\n "}, {"Page_number": 558, "text": "544\n\n10 equality constrained minimization\n\n102\n\n2\n\nk\n\nl\na\nu\nd\nr\nk\n\nd\nn\na\n\n2\n\nk\n\ni\nr\np\nr\nk\n\n101\n0\n\n5\n\n10\n\niteration number\n\n15\n\n20\n\nfigure 10.3 progress of infeasible start newton method on an equality con-\nstrained analytic centering problem with 100 variables and 50 constraints,\nfor which dom f = r100\n++ does not intersect {z | az = b}. the figure shows\nkrprik2 (solid line), and krdualk2 (dashed line). in this case, the residuals do\nnot converge to zero.\n\nt\n\n0.3\n\n0.2\n\n0.1\n\n0\n0\n\n5\n\n10\n\niteration number\n\n15\n\n20\n\nfigure 10.4 step length versus iteration number for the infeasible example\nproblem. no full steps are taken, and the step lengths converge to zero.\n\n "}, {"Page_number": 559, "text": "10.4\n\nimplementation\n\n545\n\n105\n\n100\n\n2\n\nk\n)\nv\n,\n\nu\n(\nf\n\u2207\nk\n\n10\u22125\n\n10\u221210\n\n10\u221215\n0\n\n2\n\n4\n\niteration number\n\n6\n\n8\n\nfigure 10.5 progress of (infeasible start) newton method on a convex-\nconcave game. quadratic convergence becomes apparent after about 5 iter-\nations.\n\nwith kkt form\n\n0 (cid:21)(cid:20) v\n\n(cid:20) h at\nhere we assume h \u2208 sn\n+, and a \u2208 rp\u00d7n with rank a = p < n. similar methods\ncan be used to compute the newton step for a convex-concave game, in which\nthe bottom right entry of the coefficient matrix is negative semidefinite (see exer-\ncise 10.13).\n\nh (cid:21) .\nw (cid:21) = \u2212(cid:20) g\n\n(10.33)\n\na\n\nsolving full kkt system\n\none straightforward approach is to simply solve the kkt system (10.33), which is\na set of n + p linear equations in n + p variables. the kkt matrix is symmetric,\nbut not positive definite, so a good way to do this is to use an ldlt factorization\n(see \u00a7c.3.3). if no structure of the matrix is exploited, the cost is (1/3)(n + p)3\nflops. this can be a reasonable approach when the problem is small (i.e., n and p\nare not too large), or when a and h are sparse.\n\nsolving kkt system via elimination\n\na method that is often better than directly solving the full kkt system is based\non eliminating the variable v (see \u00a7c.4). we start by describing the simplest case,\nin which h \u227b 0. starting from the first of the kkt equations\n\nwe solve for v to obtain\n\nhv + at w = \u2212g,\n\nav = \u2212h,\n\nv = \u2212h \u22121(g + at w).\n\n "}, {"Page_number": 560, "text": "546\n\n10 equality constrained minimization\n\nsubstituting this into the second kkt equation yields ah \u22121(g + at w) = h, so we\nhave\n\nw = (ah \u22121at )\u22121(h \u2212 ah \u22121g).\nthese formulas give us a method for computing v and w.\n\nthe matrix appearing in the formula for w is the schur complement s of h in\n\nthe kkt matrix:\n\nbecause of the special structure of the kkt matrix, and our assumption that a\nhas rank p, the matrix s is negative definite.\n\ns = \u2212ah \u22121at .\n\nalgorithm 10.3 solving kkt system by block elimination.\n\ngiven kkt system with h \u227b 0.\n1. form h \u22121at and h \u22121g.\n2. form schur complement s = \u2212ah \u22121at .\n3. determine w by solving sw = ah \u22121g \u2212 h.\n4. determine v by solving hv = \u2212at w \u2212 g.\n\nstep 1 can be done by a cholesky factorization of h, followed by p + 1 solves,\nwhich costs f + (p + 1)s, where f is the cost of factoring h and s is the cost of\nan associated solve. step 2 requires a p \u00d7 n by n \u00d7 p matrix multiplication. if we\nexploit no structure in this calculation, the cost is p2n flops. (since the result is\nsymmetric, we only need to compute the upper triangular part of s.) in some cases\nspecial structure in a and h can be exploited to carry out step 2 more efficiently.\nstep 3 can be carried out by cholesky factorization of \u2212s, which costs (1/3)p3\nflops if no further structure of s is exploited. step 4 can be carried out using the\nfactorization of h already calculated in step 1, so the cost is 2np + s flops. the\ntotal flop count, assuming that no structure is exploited in forming or factoring the\nschur complement, is\n\nf + ps + p2n + (1/3)p3\n\nflops (keeping only dominant terms). if we exploit structure in forming or factoring\ns, the last two terms are even smaller.\n\nif h can be factored efficiently, then block elimination gives us a flop count\nadvantage over directly solving the kkt system using an ldlt factorization. for\nexample, if h is diagonal (which corresponds to a separable objective function),\nwe have f = 0 and s = n, so the total cost is p2n + (1/3)p3 flops, which grows only\nlinearly with n. if h is banded with bandwidth k \u226a n, then f = nk2, s = 4nk, so\nthe total cost is around nk2 + 4nkp + p2n + (1/3)p3 which still grows only linearly\nwith n. other structures of h that can be exploited are block diagonal (which\ncorresponds to block separable objective function), sparse, or diagonal plus low\nrank; see appendix c and \u00a79.7 for more details and examples.\n\nexample 10.3 equality constrained analytic center. we consider the problem\n\nminimize \u2212pn\n\nsubject to ax = b.\n\ni=1 log xi\n\n "}, {"Page_number": 561, "text": "10.4\n\nimplementation\n\n547\n\nhere the objective is separable, so the hessian at x is diagonal:\n\nh = diag(x\u22122\n\n1 , . . . , x\u22122\n\nn ).\n\nif we compute the newton direction using a generic method such as an ldlt factor-\nization of the kkt matrix, the cost is (1/3)(n + p)3 flops.\nif we compute the newton step using block elimination, the cost is np2 + (1/3)p3\nflops. this is much smaller than the cost of the generic method.\n\nin fact this cost is the same as that of computing the newton step for the dual prob-\nlem, described in example 10.2 on page 525. for the (unconstrained) dual problem,\nthe hessian is\n\nwhere d is diagonal, with dii = (at \u03bd)\u22122\n. forming this matrix costs np2 flops, and\nsolving for the newton step by a cholesky factorization of \u2212hdual costs (1/3)p3 flops.\n\ni\n\nhdual = \u2212adat ,\n\nexample 10.4 minimum length piecewise-linear curve subject to equality constraints.\nwe consider a piecewise-linear curve in r2 with knot points (0, 0), (1, x1), . . . , (n, xn).\nto find the minimum length curve that satisfies the equality constraints ax = b, we\nform the problem\n\nminimize\nsubject to ax = b,\n\n(cid:0)1 + x2\n1(cid:1)1/2\n\n+pn\u22121\n\ni=1 (cid:0)1 + (xi+1 \u2212 xi)2(cid:1)1/2\n\nwith variable x \u2208 rn, and a \u2208 rp\u00d7n. in this problem, the objective is a sum of\nfunctions of pairs of adjacent variables, so the hessian h is tridiagonal. using block\nelimination, we can compute the newton step in around p2n + (1/3)p3 flops.\n\nelimination with singular h\n\nthe block elimination method described above obviously does not work when h\nis singular, but a simple variation on the method can be used in this more general\ncase. the more general method is based on the following result: the kkt matrix\nis nonsingular if and only if h + at qa \u227b 0 for some q (cid:23) 0, in which case,\nh + at qa \u227b 0 for all q \u227b 0. (see exercise 10.1.) we conclude, for example, that\nif the kkt matrix is nonsingular, then h + at a \u227b 0.\nlet q (cid:23) 0 be a matrix for which h +at qa \u227b 0. then the kkt system (10.33)\nis equivalent to\n\nw (cid:21) = \u2212(cid:20) g + at qh\nwhich can be solved using elimination since h + at qa \u227b 0.\n\n(cid:20) h + at qa at\n\n0 (cid:21)(cid:20) v\n\na\n\nh\n\n(cid:21) ,\n\n10.4.3 examples\n\nin this section we describe some longer examples, showing how structure can be\nexploited to efficiently compute the newton step. we also include some numerical\nresults.\n\n "}, {"Page_number": 562, "text": "548\n\n10 equality constrained minimization\n\nequality constrained analytic centering\n\nwe consider the equality constrained analytic centering problem\n\nminimize\nsubject to ax = b.\n\nf (x) = \u2212pn\n\ni=1 log xi\n\n(see examples 10.2 and 10.3.) we compare three methods, for a problem of size\np = 100, n = 500.\n\nthe first method is newton\u2019s method with equality constraints (\u00a710.2). the\n\nnewton step \u2206xnt is defined by the kkt system (10.11):\n\n(cid:20) h at\n\n0 (cid:21)(cid:20) \u2206xnt\n\nw (cid:21) =(cid:20) \u2212g\n0 (cid:21) ,\n\na\n\nwhere h = diag(1/x2\nn), and g = \u2212(1/x1, . . . , 1/xn). as explained in\nexample 10.3, page 546, the kkt system can be efficiently solved by elimination,\ni.e., by solving\n\n1, . . . , 1/x2\n\nah \u22121at w = \u2212ah \u22121g,\nand setting \u2206xnt = \u2212h \u22121(at w + g). in other words,\n\u2206xnt = \u2212 diag(x)2at w + x,\n\nwhere w is the solution of\n\na diag(x)2at w = b.\n\n(10.34)\n\nfigure 10.6 shows the error versus iteration. the different curves correspond to\nfour different starting points. we use a backtracking line search with \u03b1 = 0.1,\n\u03b2 = 0.5.\n\nthe second method is newton\u2019s method applied to the dual\n\n(see example 10.2, page 525). here the newton step is obtained from solving\n\nmaximize\n\ni=1 log(at \u03bd)i + n\n\ng(\u03bd) = \u2212bt \u03bd +pn\na diag(y)2at \u2206\u03bdnt = \u2212b + ay\n\n(10.35)\n\nwhere y = (1/(at \u03bd)1, . . . , 1/(at \u03bd)n). comparing (10.35) and (10.34) we see that\nboth methods have the same complexity. in figure 10.7 we show the error for four\ndifferent starting points. we use a backtracking line search with \u03b1 = 0.1, \u03b2 = 0.5.\n\nthe third method is the infeasible start newton method of \u00a710.3, applied to\n\nthe optimality conditions\n\n\u2207f (x\u22c6) + at \u03bd\u22c6 = 0,\n\nax\u22c6 = b.\n\nthe newton step is obtained by solving\n\n(cid:20) h at\n\n0 (cid:21)(cid:20) \u2206xnt\n\nax \u2212 b (cid:21) ,\n\u2206\u03bdnt (cid:21) = \u2212(cid:20) g + at \u03bd\n\na\n\n "}, {"Page_number": 563, "text": "10.4\n\nimplementation\n\n549\n\n105\n\n100\n\n\u22c6\np\n\u2212\n)\n)\nk\n(\nx\n(\nf\n\n10\u22125\n\n10\u221210\n0\n\n5\n\n10\nk\n\n15\n\n20\n\nfigure 10.6 error f (x(k)) \u2212 p\u22c6 in newton\u2019s method, applied to an equality\nconstrained analytic centering problem of size p = 100, n = 500. the\ndifferent curves correspond to four different starting points. final quadratic\nconvergence is clearly evident.\n\n105\n\n100\n\n)\n)\nk\n(\n\u03bd\n(\ng\n\u2212\n\u22c6\np\n\n10\u22125\n\n10\u221210\n0\n\n2\n\n4\n\nk\n\n6\n\n8\n\n10\n\nfigure 10.7 error |g(\u03bd(k)) \u2212 p\u22c6| in newton\u2019s method, applied to the dual of\nthe equality constrained analytic centering problem.\n\n "}, {"Page_number": 564, "text": "550\n\n10 equality constrained minimization\n\n1010\n\n105\n\n2\n\nk\n)\n)\nk\n(\n\u03bd\n,\n)\nk\n(\nx\n(\nr\nk\n\n100\n\n10\u22125\n\n10\u221210\n\n10\u221215\n0\n\n5\n\n10\n\nk\n\n15\n\n20\n\n25\n\nfigure 10.8 residual kr(x(k), \u03bd(k))k2 in the infeasible start newton method,\napplied to the equality constrained analytic centering problem.\n\nwhere h = diag(1/x2\nn), and g = \u2212(1/x1, . . . , 1/xn). this kkt system\ncan be efficiently solved by elimination, at the same cost as (10.34) or (10.35). for\nexample, if we first solve\n\n1, . . . , 1/x2\n\na diag(x)2at w = 2ax \u2212 b,\n\nthen \u2206\u03bdnt and \u2206xnt follow from\n\u2206\u03bdnt = w \u2212 \u03bd,\n\n\u2206xnt = x \u2212 diag(x)2at w.\n\nfigure 10.8 shows the norm of the residual\n\nr(x, \u03bd) = (\u2207f (x) + at \u03bd, ax \u2212 b)\n\nversus iteration, for four different starting points. we use a backtracking line search\nwith \u03b1 = 0.1, \u03b2 = 0.5.\n\nthe figures show that for this problem, the dual method appears to be faster,\nbut only by a factor of two or three.\nit takes about six iterations to reach the\nregion of quadratic convergence, as opposed to 12\u201315 in the primal method and\n10\u201320 in the infeasible start newton method.\n\nthe methods also differ in the initialization they require. the primal method\nrequires knowledge of a primal feasible point, i.e., satisfying ax(0) = b, x(0) \u227b 0.\nthe dual method requires a dual feasible point, i.e., at \u03bd(0) \u227b 0. depending on\nthe problem, one or the other might be more readily available. the infeasible start\nnewton method requires no initialization; the only requirement is that x(0) \u227b 0.\noptimal network flow\n\nwe consider a connected directed graph or network with n edges and p + 1 nodes.\nwe let xj denote the flow or traffic on arc j, with xj > 0 meaning flow in the\n\n "}, {"Page_number": 565, "text": "10.4\n\nimplementation\n\n551\n\ndirection of the arc, and xj < 0 meaning flow in the direction opposite the arc.\nthere is also a given external source (or sink) flow si that enters (if si > 0) or\nleaves (if si < 0) node i. the flow must satisfy a conservation equation, which\nstates that at each node, the total flow entering the node, including the external\nsources and sinks, is zero. this conservation equation can be expressed as \u02dcax = s\nwhere \u02dca \u2208 r(p+1)\u00d7n is the node incidence matrix of the graph,\n\n1\n\u22121\n0\n\narc j leaves node i\narc j enters node i\notherwise.\n\n\u02dcaij =\uf8f1\uf8f2\uf8f3\n\nthe flow conservation equation \u02dcax = s is inconsistent unless 1t s = 0, which we\nassume is the case. (in other words, the total of the source flows must equal the\ntotal of the sink flows.) the flow conservation equations \u02dcax = s are also redundant,\nsince 1t \u02dca = 0. to obtain an independent set of equations we can delete any one\nequation, to obtain ax = b, where a \u2208 rp\u00d7n is the reduced node incidence matrix\nof the graph (i.e., the node incidence matrix with one row removed) and b \u2208 rp is\nreduced source vector (i.e., s with the associated entry removed).\nin summary, flow conservation is given by ax = b, where a is the reduced node\nincidence matrix of the graph and b is the reduced source vector. the matrix a is\nvery sparse, since each column has at most two nonzero entries (which can only be\n+1 or \u22121).\nintroduce the objective function\n\nwe will take traffic flows x as the variables, and the sources as given. we\n\nf (x) =\n\n\u03c6i(xi),\n\nnxi=1\n\nwhere \u03c6i : r \u2192 r is the flow cost function for arc i. we assume that the flow cost\nfunctions are strictly convex and twice differentiable.\nthe problem of choosing the best flow, that satisfies the flow conservation re-\n\nquirement, is\n\nminimize pn\n\nsubject to ax = b.\n\ni=1 \u03c6i(xi)\n\n(10.36)\n\nhere the hessian h is diagonal, since the objective is separable.\n\nwe have several choices for computing the newton step for the optimal network\nflow problem (10.36). the most straightforward is to solve the full kkt system,\nusing a sparse ldlt factorization.\n\nfor this problem it is probably better to compute the newton step using block\nelimination. we can characterize the sparsity pattern of the schur complement\ns = \u2212ah \u22121at in terms of the graph: we have sij 6= 0 if and only if node i and\nnode j are connected by an arc. it follows that if the network is sparse, i.e., if each\nnode is connected by an arc to only a few other nodes, then the schur complement\ns is sparse. in this case, we can exploit sparsity in forming s, and in the associated\nfactorization and solve steps, as well. we can expect the computational complexity\nof computing the newton step to grow approximately linearly with the number of\narcs (which is the number of variables).\n\n "}, {"Page_number": 566, "text": "552\n\n10 equality constrained minimization\n\noptimal control\n\nwe consider the problem\n\nminimize pn\n\nsubject to\n\nt=1 \u03c6t(z(t)) +pn \u22121\n\nz(t + 1) = atz(t) + btu(t),\n\nt=0 \u03c8t(u(t))\n\nt = 0, . . . , n \u2212 1.\n\nhere\n\n\u2022 z(t) \u2208 rk is the system state at time t\n\u2022 u(t) \u2208 rl is the input or control action at time t\n\u2022 \u03c6t : rk \u2192 r is the state cost function\n\u2022 \u03c8t : rl \u2192 r is the input cost function\n\u2022 n is called the time horizon for the problem.\n\nwe assume that the input and state cost functions are strictly convex and twice dif-\nferentiable. the variables in the problem are u(0), . . . , u(n\u22121), and z(1), . . . , z(n ).\nthe initial state z(0) is given. the linear equality constraints are called the state\nequations or dynamic evolution equations. we define the overall optimization vari-\nable x as\n\nx = (u(0), z(1), u(1), . . . , u(n \u2212 1), z(n )) \u2208 rn (k+l).\n\nsince the objective is block separable (i.e., a sum of functions of z(t) and u(t)),\n\nthe hessian is block diagonal:\n\nh = diag(r0, q1, . . . , rn \u22121, qn ),\n\nwhere\n\nrt = \u22072\u03c8t(u(t)),\n\nt = 0, . . . , n \u2212 1,\n\nqt = \u22072\u03c6t(z(t)),\n\nt = 1, . . . , n.\n\nwe can collect all the equality constraints (i.e., the state equations) and express\nthem as ax = b where\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\n0\n0\n0\n...\ni\n\n0\n0\n0\n...\n0\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7 \u2212an \u22121 \u2212bn \u22121\n\n0\n0\n0\n...\n0\ni\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\na =\n\nb =\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n\u2212b0\n0\n0\n...\n0\n0\n\ni\n0\n\u2212a1 \u2212b1\n0\n0\n...\n...\n0\n0\n0\n0\n\n0\n0\ni\n0\n\u2212a2 \u2212b2\n...\n...\n0\n0\n0\n0\n\na0z(0)\n\n0\n0\n...\n0\n0\n\n.\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\n "}, {"Page_number": 567, "text": "10.4\n\nimplementation\n\n553\n\nthe number of rows of a (i.e., equality constraints) is n k.\n\ndirectly solving the kkt system for the newton step, using a dense ldlt\n\nfactorization, would cost\n\n(1/3)(2n k + n l)3 = (1/3)n 3(2k + l)3\n\nflops. using a sparse ldlt factorization would give a large improvement, since\nthe method would exploit the many zero entries in a and h.\n\nin fact we can do better by exploiting the special block structure of h and\na, using block elimination to compute the newton step. the schur complement\ns = \u2212ah \u22121at turns out to be block tridiagonal, with k \u00d7 k blocks:\n\ns = \u2212ah \u22121at\na1q\u22121\n1\n\ns11\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8ef\uf8f0\n\n0\n...\n0\n0\n\n=\n\nwhere\n\nq\u22121\n1 at\n1\ns22\n\na2q\u22121\n2\n\n...\n0\n0\n\n0\nq\u22121\n2 at\n2\ns33\n...\n0\n0\n\n0\n0\n0\n...\n\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7\n. . .\n\u00b7\u00b7\u00b7\n\u00b7\u00b7\u00b7 an \u22121q\u22121\n\nn \u22121\n\nsn \u22121,n \u22121 q\u22121\n\nn \u22121at\nsn n\n\nn \u22121\n\n0\n0\n0\n...\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fa\uf8fb\n\ns11 = \u2212b0r\u22121\n0 bt\nsii = \u2212ai\u22121q\u22121\n\n0 \u2212 q\u22121\n1 ,\ni\u22121at\n\ni\u22121 \u2212 bi\u22121r\u22121\n\ni\u22121bt\n\ni\u22121 \u2212 q\u22121\n\ni\n\n,\n\ni = 2, . . . , n.\n\nin particular, s is banded, with bandwidth 2k \u2212 1, so we can factor it in order\nk3n flops. therefore we can compute the newton step in order k3n flops, assuming\nk \u226a n . note that this grows linearly with the time horizon n , whereas for a generic\nmethod, the flop count grows like n 3.\nfor this problem we could go one step further and exploit the block tridiagonal\nstructure of s. applying a standard block tridiagonal factorization method would\nresult in the classic riccati recursion for solving a quadratic optimal control prob-\nlem. still, using only the banded nature of s yields an algorithm that is the same\norder.\n\nanalytic center of a linear matrix inequality\n\nwe consider the problem\n\nminimize\nsubject to\n\nf (x) = \u2212 log det x\ntr(aix) = bi,\n\ni = 1, . . . , p,\n\n(10.37)\n\nwhere x \u2208 sn is the variable, ai \u2208 sn, bi \u2208 r, and dom f = sn\nconditions for this problem are\n\n++. the kkt\n\n\u2212x \u22c6\u22121 +\n\nmxi=1\n\n\u03bd\u22c6\ni ai = 0,\n\ntr(aix \u22c6) = bi,\n\ni = 1, . . . , p.\n\n(10.38)\n\nthe dimension of the variable x is n(n + 1)/2. we could simply ignore the\nspecial matrix structure of x, and consider it as (vector) variable x \u2208 rn(n+1)/2,\n\n "}, {"Page_number": 568, "text": "554\n\n10 equality constrained minimization\n\nand solve the problem (10.37) using a generic method for a problem with n(n+1)/2\nvariables and p equality constraints. the cost for computing a newton step would\nthen be at least\n\n(1/3)(n(n + 1)/2 + p)3\n\nflops, which is order n6 in n. we will see that there are a number of far more\nattractive alternatives.\n\na first option is to solve the dual problem. the conjugate of f is\n\nf \u2217(y ) = log det(\u2212y )\u22121 \u2212 n\n\n++ (see example 3.23, page 92), so the dual problem is\n\nwith dom f \u2217 = \u2212sn\nmaximize \u2212bt \u03bd + log det(pp\nwith domain {\u03bd | pp\ni=1 \u03bdiai \u227b 0}. this is an unconstrained problem with variable\n\u03bd \u2208 rp. the optimal x \u22c6 can be recovered from the optimal \u03bd\u22c6 by solving the first\n(dual feasibility) equation in (10.38), i.e., x \u22c6 = (pp\nlet us work out the cost of computing the newton step for the dual prob-\nlem (10.39). we have to form the gradient and hessian of g, and then solve for the\nnewton step. the gradient and hessian are given by\n\ni=1 \u03bdiai) + n,\n\ni ai)\u22121.\n\ni=1 \u03bd\u22c6\n\n(10.39)\n\ni = 1 . . . , p,\n\ni, j = 1, . . . , p,\n\n\u22072g(\u03bd)ij = \u2212 tr(a\u22121aia\u22121aj),\n\u2207g(\u03bd)i = tr(a\u22121ai) \u2212 bi,\nwhere a = pp\ni=1 \u03bdiai. to form \u22072g(\u03bd) and \u2207g(\u03bd) we proceed as follows. we\nfirst form a (pn2 flops), and a\u22121aj for each j (2pn3 flops). then we form the\nmatrix \u22072g(\u03bd). each of the p(p + 1)/2 entries of \u22072g(\u03bd) is the inner product of\ntwo matrices in sn, each of which costs n(n + 1) flops, so the total is (dropping\ndominated terms) (1/2)p2n2 flops. forming \u2207g(\u03bd) is cheap since we already have\nthe matrices a\u22121ai. finally, we solve for the newton step \u2212\u22072g(\u03bd)\u22121\u2207g(\u03bd), which\ncosts (1/3)p3 flops. all together, and keeping only the leading terms, the total cost\nof computing the newton step is 2pn3 + (1/2)p2n2 + (1/3)p3. note that this is\norder n3 in n, which is far better than the simple primal method described above,\nwhich is order n6.\n\nwe can also solve the primal problem more efficiently, by exploiting its special\nmatrix structure. to derive the kkt system for the newton step \u2206xnt at a feasible\nx, we replace x \u22c6 in the kkt conditions by x + \u2206xnt and \u03bd\u22c6 by w, and linearize\nthe first equation using the first-order approximation\n\n(x + \u2206xnt)\u22121 \u2248 x \u22121 \u2212 x \u22121\u2206xntx \u22121.\n\nthis gives the kkt system\n\n\u2212x \u22121 + x \u22121\u2206xntx \u22121 +\n\npxi=1\n\nwiai = 0,\n\ntr(ai\u2206xnt) = 0,\n\ni = 1, . . . , p.\n\n(10.40)\nthis is a set of n(n + 1)/2 + p linear equations in the variables \u2206xnt \u2208 sn and\nw \u2208 rp. if we solved these equations using a generic method, the cost would be\norder n6.\n\n "}, {"Page_number": 569, "text": "10.4\n\nimplementation\n\n555\n\nwe can use block elimination to solve the kkt system (10.40) far more effi-\n\nciently. we eliminate the variable \u2206xnt, by solving the first equation to get\n\n\u2206xnt = x \u2212 x  pxi=1\n\nwiai! x = x \u2212\n\npxi=1\n\nwixaix.\n\n(10.41)\n\nsubstituting this expression for \u2206xnt into the other equation gives\n\ntr(aj\u2206xnt) = tr(ajx) \u2212\n\npxi=1\n\nwi tr(ajxaix) = 0,\n\nj = 1, . . . , p.\n\nthis is a set of p linear equations in w:\n\ncw = d\n\nwhere cij = tr(aixajx), di = tr(aix). the coefficient matrix c is symmetric\nand positive definite, so a cholesky factorization can be used to find w. once we\nhave w, we can compute \u2206xnt from (10.41).\n\nthe cost of this method is as follows. we form the products aix (2pn3 flops),\nand then form the matrix c. each of the p(p + 1)/2 entries of c is the inner\nproduct of two matrices in rn\u00d7n, so forming c costs p2n2 flops. then we solve\nfor w = c \u22121d, which costs (1/3)p3. finally we compute \u2206xnt.\nif we use the\nfirst expression in (10.41), i.e., first compute the sum and then pre- and post-\nmultiply with x, the cost is approximately pn2 + 3n3. all together, the total cost\nis 2pn3 + p2n2 + (1/3)p3 flops to form the newton step for the primal problem,\nusing block elimination. this is far better than the simple method, which is order\nn6. note also that the cost is the same as that of computing the newton step for\nthe dual problem.\n\n "}, {"Page_number": 570, "text": "556\n\n10 equality constrained minimization\n\nbibliography\n\nthe two key assumptions in our analysis of the infeasible start newton method (the\nderivative dr has a bounded inverse and satisfies a lipschitz condition) are central to\nmost convergence proofs of newton\u2019s method; see ortega and rheinboldt [or00] and\ndennis and schnabel [ds96].\n\nthe relative merits of solving kkt systems via direct factorization of the full system, or\nvia elimination, have been extensively studied in the context of interior-point methods\nfor linear and quadratic programming; see, for example, wright [wri97, chapter 11] and\nnocedal and wright [nw99, \u00a716.1-2]. the riccati recursion from optimal control can\nbe interpreted as a method for exploiting the block tridiagonal structure in the schur\ncomplement s of the example on page 552. this observation was made by rao, wright,\nand rawlings [rwr98, \u00a73.3].\n\n "}, {"Page_number": 571, "text": "exercises\n\nexercises\n\n557\n\nequality constrained minimization\n\n10.1 nonsingularity of the kkt matrix. consider the kkt matrix\n\n(cid:20) p at\n0 (cid:21) ,\n\na\n\nwhere p \u2208 sn\n(a) show that each of the following statements is equivalent to nonsingularity of the\n\n+, a \u2208 rp\u00d7n, and rank a = p < n.\n\nkkt matrix.\n\n\u2022 n (p ) \u2229 n (a) = {0}.\n\u2022 ax = 0, x 6= 0 =\u21d2 xt p x > 0.\n\u2022 f t p f \u227b 0, where f \u2208 rn\u00d7(n\u2212p) is a matrix for which r(f ) = n (a).\n\u2022 p + at qa \u227b 0 for some q (cid:23) 0.\n\n(b) show that if the kkt matrix is nonsingular, then it has exactly n positive and p\n\nnegative eigenvalues.\n\n10.2 projected gradient method. in this problem we explore an extension of the gradient method\nto equality constrained minimization problems. suppose f is convex and differentiable,\nand x \u2208 dom f satisfies ax = b, where a \u2208 rp\u00d7n with rank a = p < n. the euclidean\nprojection of the negative gradient \u2212\u2207f (x) on n (a) is given by\n\n\u2206xpg = argmin\n\nau=0 k\u2212\u2207f (x) \u2212 uk2.\n\n(a) let (v, w) be the unique solution of\n\n(cid:20) i at\n\n0 (cid:21)(cid:20) v\n\nw (cid:21) =(cid:20) \u2212\u2207f (x)\n\na\n\n0\n\n(cid:21) .\n\nshow that v = \u2206xpg and w = argminy k\u2207f (x) + at yk2.\n\n(b) what is the relation between the projected negative gradient \u2206xpg and the negative\n\ngradient of the reduced problem (10.5), assuming f t f = i?\n\n(c) the projected gradient method for solving an equality constrained minimization\nproblem uses the step \u2206xpg, and a backtracking line search on f . use the re-\nsults of part (b) to give some conditions under which the projected gradient method\nconverges to the optimal solution, when started from a point x(0) \u2208 dom f with\nax(0) = b.\n\nnewton\u2019s method with equality constraints\n\n10.3 dual newton method. in this problem we explore newton\u2019s method for solving the dual\nof the equality constrained minimization problem (10.1). we assume that f is twice\ndifferentiable, \u22072f (x) \u227b 0 for all x \u2208 dom f , and that for each \u03bd \u2208 rp, the lagrangian\nl(x, \u03bd) = f (x) + \u03bdt (ax \u2212 b) has a unique minimizer, which we denote x(\u03bd).\n(a) show that the dual function g is twice differentiable. find an expression for the\nnewton step for the dual function g, evaluated at \u03bd, in terms of f , \u2207f , and \u22072f ,\nevaluated at x = x(\u03bd). you can use the results of exercise 3.40.\n\n "}, {"Page_number": 572, "text": "558\n\n10 equality constrained minimization\n\n(b) suppose there exists a k such that\n\n(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)\n(cid:20) \u22072f (x) at\n\n0 (cid:21)\u22121(cid:13)(cid:13)(cid:13)(cid:13)(cid:13)2\n\na\n\n\u2264 k\n\nfor all x \u2208 dom f . show that g is strongly concave, with \u22072g(\u03bd) (cid:22) \u2212(1/k)i.\n\n10.4 strong convexity and lipschitz constant of the reduced problem. suppose f satisfies the\nassumptions given on page 529. show that the reduced objective function \u02dcf (z) = f (f z+\u02c6x)\nis strongly convex, and that its hessian is lipschitz continuous (on the associated sublevel\nset \u02dcs). express the strong convexity and lipschitz constants of \u02dcf in terms of k, m , l,\nand the maximum and minimum singular values of f .\n\n10.5 adding a quadratic term to the objective. suppose q (cid:23) 0. the problem\n\nminimize\nsubject to ax = b\n\nf (x) + (ax \u2212 b)t q(ax \u2212 b)\n\nis equivalent to the original equality constrained optimization problem (10.1).\nnewton step for this problem the same as the newton step for the original problem?\n\nis the\n\n10.6 the newton decrement. show that (10.13) holds, i.e.,\n\ninfeasible start newton method\n\nf (x) \u2212 inf{bf (x + v) | a(x + v) = b} = \u03bb(x)2/2.\n\n10.7 assumptions for infeasible start newton method. consider the set of assumptions given\n\non page 536.\n\n(a) suppose that the function f is closed. show that this implies that the norm of the\n\nresidual, kr(x, \u03bd)k2, is closed.\n\n10.8 infeasible start newton method and initially satisfied equality constraints. suppose we use\n\n(b) show that dr satisfies a lipschitz condition if and only if \u22072f does.\nthe infeasible start newton method to minimize f (x) subject to at\n\ni x = bi, i = 1, . . . , p.\n\n(a) suppose the initial point x(0) satisfies the linear equality at\n\nlinear equality will remain satisfied for future iterates, i.e., if at\n\ni x = bi. show that the\ni x(k) = bi for all k.\n(b) suppose that one of the equality constraints becomes satisfied at iteration k, i.e.,\ni x(k) = bi. show that at iteration k, all the equality\n\nwe have at\nconstraints are satisfied.\n\ni x(k\u22121) 6= bi, at\n\n10.9 equality constrained entropy maximization. consider the equality constrained entropy\n\nmaximization problem\n\nminimize\nsubject to ax = b,\n\nf (x) =pn\n\ni=1 xi log xi\n\n(10.42)\n\nwith dom f = rn\np < n.\n\n++ and a \u2208 rp\u00d7n. we assume the problem is feasible and that rank a =\n\n(a) show that the problem has a unique optimal solution x\u22c6.\n(b) find a, b, and feasible x(0) for which the sublevel set\n\n{x \u2208 rn\n\n++ | ax = b, f (x) \u2264 f (x(0))}\n\nis not closed. thus, the assumptions listed in \u00a710.2.4, page 529, are not satisfied for\nsome feasible initial points.\n\n "}, {"Page_number": 573, "text": "exercises\n\n559\n\n(c) show that the problem (10.42) satisfies the assumptions for the infeasible start\n\nnewton method listed in \u00a710.3.3, page 536, for any feasible starting point.\n\n(d) derive the lagrange dual of (10.42), and explain how to find the optimal solution\nof (10.42) from the optimal solution of the dual problem. show that the dual problem\nsatisfies the assumptions listed in \u00a710.2.4, page 529, for any starting point.\n\nthe results of part (b), (c), and (d) do not mean the standard newton method will fail,\nor that the infeasible start newton method or dual method will work better in practice.\nit only means our convergence analysis for the standard newton method does not apply,\nwhile our convergence analysis does apply to the infeasible start and dual methods. (see\nexercise 10.15.)\n\n10.10 bounded inverse derivative condition for strongly convex-concave game. consider a convex-\nuuf (u, v) (cid:23) mi and\n\nconcave game with payoff function f (see page 541). suppose \u22072\n\u22072\nvvf (u, v) (cid:22) \u2212mi, for all (u, v) \u2208 dom f . show that\n\nkdr(u, v)\u22121k2 = k\u22072f (u, v)\u22121k2 \u2264 1/m.\n\nimplementation\n\n10.11 consider the resource allocation problem described in example 10.1. you can assume the\n\nfi are strongly convex, i.e., f \u2032\u2032\n\ni (z) \u2265 m > 0 for all z.\n\n(a) find the computational effort required to compute a newton step for the reduced\n\nproblem. be sure to exploit the special structure of the newton equations.\n\n(b) explain how to solve the problem via the dual. you can assume that the conjugate\nfunctions f \u2217\ni , and their derivatives, are readily computable, and that the equation\nf \u2032\ni (x) = \u03bd is readily solved for x, given \u03bd. what is the computational complexity of\nfinding a newton step for the dual problem?\n\n(c) what is the computational complexity of computing a newton step for the resource\nallocation problem? be sure to exploit the special structure of the kkt equations.\n\n10.12 describe an efficient way to compute the newton step for the problem\n\nminimize\nsubject to\n\ntr(x \u22121)\ntr(aix) = bi,\n\ni = 1, . . . , p\n\nwith domain sn\n++, assuming p and n have the same order of magnitude. also derive the\nlagrange dual problem and give the complexity of finding the newton step for the dual\nproblem.\n\n10.13 elimination method for computing newton step for convex-concave game. consider a\nconvex-concave game with payoff function f : rp \u00d7 rq \u2192 r (see page 541). we assume\nthat f is strongly convex-concave, i.e., for all (u, v) \u2208 dom f and some m > 0, we have\n\u22072\nuuf (u, v) (cid:23) mi and \u22072\n(a) show how to compute the newton step using cholesky factorizations of \u22072\n\nuuf (u, v)\nand \u2212\u22072fvv(u, v). compare the cost of this method with the cost of using an ldlt\nfactorization of \u2207f (u, v), assuming \u22072f (u, v) is dense.\n\u22072\nvvf (u, v). how much do you save, if you assume \u22072\n\n(b) show how you can exploit diagonal or block diagonal structure in \u22072\n\nvvf (u, v) (cid:22) \u2212mi.\n\nuvf (u, v) is dense?\n\nuuf (u, v) and/or\n\nnumerical experiments\n\n10.14 log-optimal investment. consider the log-optimal investment problem described in exer-\ncise 4.60, without the constraint x (cid:23) 0. use newton\u2019s method to compute the solution,\n\n "}, {"Page_number": 574, "text": "560\n\n10 equality constrained minimization\n\nwith the following problem data: there are n = 3 assets, and m = 4 scenarios, with\nreturns\n\np1 =\" 2\n\n1 # ,\n\n1.3\n\np2 =\" 2\n\n1 # ,\n\n0.5\n\np3 =\" 0.5\n1 # ,\n\n1.3\n\np4 =\" 0.5\n1 # .\n\n0.5\n\nthe probabilities of the four scenarios are given by \u03c0 = (1/3, 1/6, 1/3, 1/6).\n\n10.15 equality constrained entropy maximization. consider the equality constrained entropy\n\nmaximization problem\n\nminimize\nsubject to ax = b,\n\nf (x) =pn\n\ni=1 xi log xi\n\n++ and a \u2208 rp\u00d7n, with p < n. (see exercise 10.9 for some relevant\nwith dom f = rn\nanalysis.)\ngenerate a problem instance with n = 100 and p = 30 by choosing a randomly (checking\nthat it has full rank), choosing \u02c6x as a random positive vector (e.g., with entries uniformly\ndistributed on [0, 1]) and then setting b = a\u02c6x. (thus, \u02c6x is feasible.)\ncompute the solution of the problem using the following methods.\n\n(a) standard newton method. you can use initial point x(0) = \u02c6x.\n(b) infeasible start newton method. you can use initial point x(0) = \u02c6x (to compare with\n\nthe standard newton method), and also the initial point x(0) = 1.\n\n(c) dual newton method, i.e., the standard newton method applied to the dual problem.\n\nverify that the three methods compute the same optimal point (and lagrange multiplier).\ncompare the computational effort per step for the three methods, assuming relevant\nstructure is exploited. (your implementation, however, does not need to exploit structure\nto compute the newton step.)\n\n10.16 convex-concave game. use the infeasible start newton method to solve convex-concave\ngames of the form (10.32), with randomly generated data. plot the norm of the residual\nand step length versus iteration. experiment with the line search parameters and initial\npoint (which must satisfy kuk2 < 1, kvk2 < 1, however).\n\n "}, {"Page_number": 575, "text": "chapter 11\n\ninterior-point methods\n\n11.1 inequality constrained minimization problems\n\nin this chapter we discuss interior-point methods for solving convex optimization\nproblems that include inequality constraints,\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m\n\n(11.1)\n\nwhere f0, . . . , fm : rn \u2192 r are convex and twice continuously differentiable, and\na \u2208 rp\u00d7n with rank a = p < n. we assume that the problem is solvable, i.e., an\noptimal x\u22c6 exists. we denote the optimal value f0(x\u22c6) as p\u22c6.\nwe also assume that the problem is strictly feasible, i.e., there exists x \u2208 d that\nsatisfies ax = b and fi(x) < 0 for i = 1, . . . , m. this means that slater\u2019s constraint\nqualification holds, so there exist dual optimal \u03bb\u22c6 \u2208 rm, \u03bd\u22c6 \u2208 rp, which together\nwith x\u22c6 satisfy the kkt conditions\n\n\u2207f0(x\u22c6) +pm\n\ni=1 \u03bb\u22c6\n\nax\u22c6 = b,\n\nfi(x\u22c6) \u2264 0,\n\u03bb\u22c6 (cid:23) 0\ni \u2207fi(x\u22c6) + at \u03bd\u22c6 = 0\ni fi(x\u22c6) = 0,\n\u03bb\u22c6\n\ni = 1, . . . , m\n\ni = 1, . . . , m.\n\n(11.2)\n\ninterior-point methods solve the problem (11.1) (or the kkt conditions (11.2))\nby applying newton\u2019s method to a sequence of equality constrained problems, or\nto a sequence of modified versions of the kkt conditions. we will concentrate on\na particular interior-point algorithm, the barrier method, for which we give a proof\nof convergence and a complexity analysis. we also describe a simple primal-dual\ninterior-point method (in \u00a711.7), but do not give an analysis.\nwe can view interior-point methods as another level in the hierarchy of convex\noptimization algorithms. linear equality constrained quadratic problems are the\nsimplest. for these problems the kkt conditions are a set of linear equations,\nwhich can be solved analytically. newton\u2019s method is the next level in the hierarchy.\nwe can think of newton\u2019s method as a technique for solving a linear equality\n\n "}, {"Page_number": 576, "text": "562\n\n11\n\ninterior-point methods\n\nconstrained optimization problem, with twice differentiable objective, by reducing\nit to a sequence of linear equality constrained quadratic problems. interior-point\nmethods form the next level in the hierarchy: they solve an optimization problem\nwith linear equality and inequality constraints by reducing it to a sequence of linear\nequality constrained problems.\n\nexamples\n\nmany problems are already in the form (11.1), and satisfy the assumption that the\nobjective and constraint functions are twice differentiable. obvious examples are\nlps, qps, qcqps, and gps in convex form; another example is linear inequality\nconstrained entropy maximization,\n\nminimize pn\n\nsubject to f x (cid:22) g\nax = b,\n\ni=1 xi log xi\n\n++.\n\nwith domain d = rn\nmany other problems do not have the required form (11.1), with twice differen-\ntiable objective and constraint functions, but can be reformulated in the required\nform. we have already seen many examples of this, such as the transformation of\nan unconstrained convex piecewise-linear minimization problem\n\nminimize maxi=1,...,m(at\n\ni x + bi)\n\n(with nondifferentiable objective), to the lp\n\nminimize\nsubject to at\n\nt\n\ni x + bi \u2264 t,\n\ni = 1, . . . , m\n\n(which has twice differentiable objective and constraint functions).\n\nother convex optimization problems, such as socps and sdps, are not readily\nrecast in the required form, but can be handled by extensions of interior-point\nmethods to problems with generalized inequalities, which we describe in \u00a711.6.\n\n11.2 logarithmic barrier function and central path\n\nour goal is to approximately formulate the inequality constrained problem (11.1)\nas an equality constrained problem to which newton\u2019s method can be applied.\nour first step is to rewrite the problem (11.1), making the inequality constraints\nimplicit in the objective:\n\nminimize\nsubject to ax = b,\n\nf0(x) +pm\n\ni=1 i\u2212(fi(x))\n\n(11.3)\n\nwhere i\u2212 : r \u2192 r is the indicator function for the nonpositive reals,\n\ni\u2212(u) =(cid:26) 0\n\nu \u2264 0\n\u221e u > 0.\n\n "}, {"Page_number": 577, "text": "11.2 logarithmic barrier function and central path\n\n563\n\n10\n\n5\n\n0\n\n\u22125\n\u22123\n\n\u22122\n\n\u22121\nu\n\n0\n\n1\n\nfigure 11.1 the dashed lines show the function i\u2212(u), and the solid curves\n\nthe best approximation.\n\nshow bi\u2212(u) = \u2212(1/t) log(\u2212u), for t = 0.5, 1, 2. the curve for t = 2 gives\n\nthe problem (11.3) has no inequality constraints, but its objective function is not\n(in general) differentiable, so newton\u2019s method cannot be applied.\n\n11.2.1 logarithmic barrier\n\nthe basic idea of the barrier method is to approximate the indicator function i\u2212\nby the function\n\nbi\u2212(u) = \u2212(1/t) log(\u2212u),\n\ndombi\u2212 = \u2212r++,\n\nwhere t > 0 is a parameter that sets the accuracy of the approximation. like\n\nit increases to \u221e as u increases to 0. figure 11.1 shows the function i\u2212, and\nbecomes more accurate.\n\ni\u2212, the function bi\u2212 is convex and nondecreasing, and (by our convention) takes\non the value \u221e for u > 0. unlike i\u2212, however, bi\u2212 is differentiable and closed:\nthe approximation bi\u2212, for several values of t. as t increases, the approximation\nsubstituting bi\u2212 for i\u2212 in (11.3) gives the approximation\n\ni=1 \u2212(1/t) log(\u2212fi(x))\n\n(11.4)\n\nminimize\nsubject to ax = b.\n\nf0(x) +pm\n\nthe objective here is convex, since \u2212(1/t) log(\u2212u) is convex and increasing in u,\nand differentiable. assuming an appropriate closedness condition holds, newton\u2019s\nmethod can be used to solve it.\n\nthe function\n\n\u03c6(x) = \u2212\n\nmxi=1\n\nlog(\u2212fi(x)),\n\n(11.5)\n\n "}, {"Page_number": 578, "text": "564\n\n11\n\ninterior-point methods\n\nwith dom \u03c6 = {x \u2208 rn | fi(x) < 0, i = 1, . . . , m}, is called the logarithmic barrier\nor log barrier for the problem (11.1). its domain is the set of points that satisfy\nthe inequality constraints of (11.1) strictly. no matter what value the positive\nparameter t has, the logarithmic barrier grows without bound if fi(x) \u2192 0, for\nany i.\nof course, the problem (11.4) is only an approximation of the original prob-\nlem (11.3), so one question that arises immediately is how well a solution of (11.4)\napproximates a solution of the original problem (11.3). intuition suggests, and we\nwill soon confirm, that the quality of the approximation improves as the parameter\nt grows.\n\non the other hand, when the parameter t is large, the function f0 + (1/t)\u03c6 is\ndifficult to minimize by newton\u2019s method, since its hessian varies rapidly near the\nboundary of the feasible set. we will see that this problem can be circumvented\nby solving a sequence of problems of the form (11.4), increasing the parameter t\n(and therefore the accuracy of the approximation) at each step, and starting each\nnewton minimization at the solution of the problem for the previous value of t.\n\nfor future reference, we note that the gradient and hessian of the logarithmic\n\nbarrier function \u03c6 are given by\n\n\u2207\u03c6(x) =\n\n\u22072\u03c6(x) =\n\nmxi=1\nmxi=1\n\n(see \u00a7a.4.2 and \u00a7a.4.4).\n\n11.2.2 central path\n\n1\n\n\u2212fi(x)\u2207fi(x),\nfi(x)2\u2207fi(x)\u2207fi(x)t +\n\n1\n\nmxi=1\n\n1\n\n\u2212fi(x)\u22072fi(x)\n\nwe now consider in more detail the minimization problem (11.4). it will simplify\nnotation later on if we multiply the objective by t, and consider the equivalent\nproblem\n\nminimize\nsubject to ax = b,\n\ntf0(x) + \u03c6(x)\n\n(11.6)\n\nwhich has the same minimizers. we assume for now that the problem (11.6) can\nbe solved via newton\u2019s method, and, in particular, that it has a unique solution\nfor each t > 0. (we will discuss this assumption in more detail in \u00a711.3.3.)\nfor t > 0 we define x\u22c6(t) as the solution of (11.6). the central path associated\nwith problem (11.1) is defined as the set of points x\u22c6(t), t > 0, which we call\nthe central points. points on the central path are characterized by the following\nnecessary and sufficient conditions: x\u22c6(t) is strictly feasible, i.e., satisfies\n\nax\u22c6(t) = b,\n\nfi(x\u22c6(t)) < 0,\n\ni = 1, . . . , m,\n\nand there exists a \u02c6\u03bd \u2208 rp such that\n\n0 = t\u2207f0(x\u22c6(t)) + \u2207\u03c6(x\u22c6(t)) + at \u02c6\u03bd\n\n "}, {"Page_number": 579, "text": "11.2 logarithmic barrier function and central path\n\n565\n\n= t\u2207f0(x\u22c6(t)) +\n\nmxi=1\n\n1\n\n\u2212fi(x\u22c6(t))\u2207fi(x\u22c6(t)) + at \u02c6\u03bd\n\n(11.7)\n\nholds.\n\nexample 11.1 inequality form linear programming. the logarithmic barrier function\nfor an lp in inequality form,\n\nct x\n\nminimize\nsubject to ax (cid:22) b,\n\n(11.8)\n\nis given by\n\n\u03c6(x) = \u2212\n\nwhere at\nare\n\n1 , . . . , at\n\n\u2207\u03c6(x) =\nor, more compactly,\n\nmxi=1\n\nlog(bi \u2212 at\n\ni x),\n\ndom \u03c6 = {x | ax \u227a b},\n\nm are the rows of a. the gradient and hessian of the barrier function\n\nmxi=1\n\n1\n\nbi \u2212 at\ni x\n\nai,\n\n\u22072\u03c6(x) =\n\nmxi=1\n\n1\n(bi \u2212 at\n\ni x)2\n\naiat\ni ,\n\n\u2207\u03c6(x) = at d,\n\n\u22072\u03c6(x) = at diag(d)2a,\n\nwhere the elements of d \u2208 rm are given by di = 1/(bi \u2212 at\ni x). since x is strictly\nfeasible, we have d \u227b 0, so the hessian of \u03c6 is nonsingular if and only if a has rank n.\nthe centrality condition (11.7) is\n\ntc +\n\nmxi=1\n\n1\n\nbi \u2212 at\ni x\n\nai = tc + at d = 0.\n\n(11.9)\n\nwe can give a simple geometric interpretation of the centrality condition. at a point\nx\u22c6(t) on the central path the gradient \u2207\u03c6(x\u22c6(t)), which is normal to the level set of \u03c6\nthrough x\u22c6(t), must be parallel to \u2212c. in other words, the hyperplane ct x = ct x\u22c6(t)\nis tangent to the level set of \u03c6 through x\u22c6(t). figure 11.2 shows an example with\nm = 6 and n = 2.\n\ndual points from central path\n\nfrom (11.7) we can derive an important property of the central path: every central\npoint yields a dual feasible point, and hence a lower bound on the optimal value\np\u22c6. more specifically, define\n\n\u03bb\u22c6\ni (t) = \u2212\n\n1\n\ntfi(x\u22c6(t))\n\n,\n\ni = 1, . . . , m,\n\n\u03bd\u22c6(t) = \u02c6\u03bd/t.\n\n(11.10)\n\nwe claim that the pair \u03bb\u22c6(t), \u03bd\u22c6(t) is dual feasible.\n\nfirst, it is clear that \u03bb\u22c6(t) \u227b 0 because fi(x\u22c6(t)) < 0, i = 1, . . . , m. by\n\nexpressing the optimality conditions (11.7) as\n\n\u2207f0(x\u22c6(t)) +\n\nmxi=1\n\ni (t)\u2207fi(x\u22c6(t)) + at \u03bd\u22c6(t) = 0,\n\u03bb\u22c6\n\n "}, {"Page_number": 580, "text": "566\n\n11\n\ninterior-point methods\n\nc\n\nx\u22c6\n\nx\u22c6(10)\n\nfigure 11.2 central path for an lp with n = 2 and m = 6. the dashed\ncurves show three contour lines of the logarithmic barrier function \u03c6. the\ncentral path converges to the optimal point x\u22c6 as t \u2192 \u221e. also shown is the\npoint on the central path with t = 10. the optimality condition (11.9) at\nthis point can be verified geometrically: the line ct x = ct x\u22c6(10) is tangent\nto the contour line of \u03c6 through x\u22c6(10).\n\nwe see that x\u22c6(t) minimizes the lagrangian\n\nl(x, \u03bb, \u03bd) = f0(x) +\n\n\u03bbifi(x) + \u03bdt (ax \u2212 b),\n\nmxi=1\n\nfor \u03bb = \u03bb\u22c6(t) and \u03bd = \u03bd\u22c6(t), which means that \u03bb\u22c6(t), \u03bd\u22c6(t) is a dual feasible pair.\ntherefore the dual function g(\u03bb\u22c6(t), \u03bd\u22c6(t)) is finite, and\n\ng(\u03bb\u22c6(t), \u03bd\u22c6(t)) = f0(x\u22c6(t)) +\n\ni (t)fi(x\u22c6(t)) + \u03bd\u22c6(t)t (ax\u22c6(t) \u2212 b)\n\u03bb\u22c6\n\nmxi=1\n= f0(x\u22c6(t)) \u2212 m/t.\n\nin particular, the duality gap associated with x\u22c6(t) and the dual feasible pair \u03bb\u22c6(t),\n\u03bd\u22c6(t) is simply m/t. as an important consequence, we have\n\nf0(x\u22c6(t)) \u2212 p\u22c6 \u2264 m/t,\n\ni.e., x\u22c6(t) is no more than m/t-suboptimal. this confirms the intuitive idea that\nx\u22c6(t) converges to an optimal point as t \u2192 \u221e.\n\nexample 11.2 inequality form linear programming. the dual of the inequality form\nlp (11.8) is\n\nmaximize \u2212bt \u03bb\nsubject to at \u03bb + c = 0\n\u03bb (cid:23) 0.\n\nfrom the optimality conditions (11.9), it is clear that\n\n\u03bb\u22c6\ni (t) =\n\n1\nt(bi \u2212 at\ni x\u22c6(t))\n\n,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 581, "text": "11.2 logarithmic barrier function and central path\n\n567\n\nis dual feasible, with dual objective value\n\n\u2212bt \u03bb\u22c6(t) = ct x\u22c6(t) + (ax\u22c6(t) \u2212 b)t \u03bb\u22c6(t) = ct x\u22c6(t) \u2212 m/t.\n\ninterpretation via kkt conditions\n\nwe can also interpret the central path conditions (11.7) as a continuous deformation\nof the kkt optimality conditions (11.2). a point x is equal to x\u22c6(t) if and only if\nthere exists \u03bb, \u03bd such that\n\n\u2207f0(x) +pm\n\nax = b,\n\nfi(x) \u2264 0,\n\u03bb (cid:23) 0\ni=1 \u03bbi\u2207fi(x) + at \u03bd = 0\n\n\u2212\u03bbifi(x) = 1/t,\n\ni = 1, . . . , m\n\ni = 1, . . . , m.\n\n(11.11)\n\nthe only difference between the kkt conditions (11.2) and the centrality condi-\ntions (11.11) is that the complementarity condition \u2212\u03bbifi(x) = 0 is replaced by\nthe condition \u2212\u03bbifi(x) = 1/t. in particular, for large t, x\u22c6(t) and the associated\ndual point \u03bb\u22c6(t), \u03bd\u22c6(t) \u2018almost\u2019 satisfy the kkt optimality conditions for (11.1).\n\nforce field interpretation\n\nwe can give a simple mechanics interpretation of the central path in terms of\npotential forces acting on a particle in the strictly feasible set c. for simplicity we\nassume that there are no equality constraints.\nwe associate with each constraint the force\n\nfi(x) = \u2212\u2207 (\u2212 log(\u2212fi(x))) =\n\n1\nfi(x)\u2207fi(x)\n\nacting on the particle when it is at position x. the potential associated with the\ntotal force field generated by the constraints is the logarithmic barrier \u03c6. as the\nparticle moves toward the boundary of the feasible set, it is strongly repelled by\nthe forces generated by the constraints.\n\nnow we imagine another force acting on the particle, given by\n\nf0(x) = \u2212t\u2207f0(x),\n\nwhen the particle is at position x. this objective force field acts to pull the particle\nin the negative gradient direction, i.e., toward smaller f0. the parameter t scales\nthe objective force, relative to the constraint forces.\n\nthe central point x\u22c6(t) is the point where the constraint forces exactly balance\nthe objective force felt by the particle. as the parameter t increases, the particle is\nmore strongly pulled toward the optimal point, but it is always trapped in c by the\nbarrier potential, which becomes infinite as the particle approaches the boundary.\n\nexample 11.3 force field interpretation for inequality form lp. the force field asso-\nciated with the ith constraint of the lp (11.8) is\nfi(x) = \u2212ai\nbi \u2212 at\ni x\n\n.\n\n "}, {"Page_number": 582, "text": "568\n\n11\n\ninterior-point methods\n\n\u2212c\n\n\u22123c\n\nfigure 11.3 force field interpretation of central path. the central path is\nshown as the dashed curve. the two points x\u22c6(1) and x\u22c6(3) are shown as\ndots in the left and right plots, respectively. the objective force, which is\nequal to \u2212c and \u22123c, respectively, is shown as a heavy arrow. the other\narrows represent the constraint forces, which are given by an inverse-distance\nlaw. as the strength of the objective force varies, the equilibrium position\nof the particle traces out the central path.\n\nthis force is in the direction of the inward pointing normal to the constraint plane\nhi = {x | at\ni x = bi}, and has magnitude inversely proportional to the distance to\nhi, i.e.,\n\nkfi(x)k2 = kaik2\nbi \u2212 at\ni x\n\n=\n\n1\n\n.\n\ndist(x,hi)\n\nin other words, each constraint hyperplane has an associated repulsive force, given\nby the inverse distance to the hyperplane.\nthe term tct x is the potential associated with a constant force \u2212tc on the particle.\nthis \u2018objective force\u2019 pushes the particle in the direction of low cost. thus, x\u22c6(t)\nis the equilibrium position of the particle when it is subject to the inverse-distance\nconstraint forces, and the objective force \u2212tc. when t is very large, the particle is\npushed almost to the optimal point. the strong objective force is balanced by the\nopposing constraint forces, which are large because we are near the feasible boundary.\n\nfigure 11.3 illustrates this interpretation for a small lp with n = 2 and m = 5. the\nlefthand plot shows x\u22c6(t) for t = 1, as well as the constraint forces acting on it, which\nbalance the objective force. the righthand plot shows x\u22c6(t) and the associated forces\nfor t = 3. the larger value of objective force moves the particle closer to the optimal\npoint.\n\n11.3 the barrier method\n\nwe have seen that the point x\u22c6(t) is m/t-suboptimal, and that a certificate of this\naccuracy is provided by the dual feasible pair \u03bb\u22c6(t), \u03bd\u22c6(t). this suggests a very\nstraightforward method for solving the original problem (11.1) with a guaranteed\nspecified accuracy \u01eb: we simply take t = m/\u01eb and solve the equality constrained\n\n "}, {"Page_number": 583, "text": "11.3 the barrier method\n\n569\n\nproblem\n\nminimize\nsubject to ax = b\n\n(m/\u01eb)f0(x) + \u03c6(x)\n\nusing newton\u2019s method. this method could be called the unconstrained minimiza-\ntion method, since it allows us to solve the inequality constrained problem (11.1) to\na guaranteed accuracy by solving an unconstrained, or linearly constrained, prob-\nlem. although this method can work well for small problems, good starting points,\nand moderate accuracy (i.e., \u01eb not too small), it does not work well in other cases.\nas a result it is rarely, if ever, used.\n\n11.3.1 the barrier method\n\na simple extension of the unconstrained minimization method does work well. it\nis based on solving a sequence of unconstrained (or linearly constrained) mini-\nmization problems, using the last point found as the starting point for the next\nunconstrained minimization problem. in other words, we compute x\u22c6(t) for a se-\nquence of increasing values of t, until t \u2265 m/\u01eb, which guarantees that we have an\n\u01eb-suboptimal solution of the original problem. when the method was first proposed\nby fiacco and mccormick in the 1960s, it was called the sequential unconstrained\nminimization technique (sumt). today the method is usually called the barrier\nmethod or path-following method. a simple version of the method is as follows.\n\nalgorithm 11.1 barrier method.\n\ngiven strictly feasible x, t := t(0) > 0, \u00b5 > 1, tolerance \u01eb > 0.\n\nrepeat\n\n1. centering step.\n\ncompute x\u22c6(t) by minimizing tf0 + \u03c6, subject to ax = b, starting at x.\n\n2. update. x := x\u22c6(t).\n3. stopping criterion. quit if m/t < \u01eb.\n4. increase t. t := \u00b5t.\n\nat each iteration (except the first one) we compute the central point x\u22c6(t) starting\nfrom the previously computed central point, and then increase t by a factor \u00b5 > 1.\nthe algorithm can also return \u03bb = \u03bb\u22c6(t), and \u03bd = \u03bd\u22c6(t), a dual \u01eb-suboptimal point,\nor certificate for x.\n\nwe refer to each execution of step 1 as a centering step (since a central point\nis being computed) or an outer iteration, and to the first centering step (the com-\nputation of x\u22c6(t(0))) as the initial centering step. (thus the simple algorithm with\nt(0) = m/\u01eb consists of only the initial centering step.) although any method for\nlinearly constrained minimization can be used in step 1, we will assume that new-\nton\u2019s method is used. we refer to the newton iterations or steps executed during\nthe centering step as inner iterations. at each inner step, we have a primal fea-\nsible point; we have a dual feasible point, however, only at the end of each outer\n(centering) step.\n\n "}, {"Page_number": 584, "text": "570\n\n11\n\ninterior-point methods\n\naccuracy of centering\n\nwe should make some comments on the accuracy to which we solve the centering\nproblems. computing x\u22c6(t) exactly is not necessary since the central path has no\nsignificance beyond the fact that it leads to a solution of the original problem as\nt \u2192 \u221e; inexact centering will still yield a sequence of points x(k) that converges to\nan optimal point. inexact centering, however, means that the points \u03bb\u22c6(t), \u03bd\u22c6(t),\ncomputed from (11.10), are not exactly dual feasible. this can be corrected by\nadding a correction term to the formula (11.10), which yields a dual feasible point\nprovided the computed x is near the central path, i.e., x\u22c6(t) (see exercise 11.9).\n\non the other hand, the cost of computing an extremely accurate minimizer of\ntf0 + \u03c6, as compared to the cost of computing a good minimizer of tf0 + \u03c6, is\nonly marginally more, i.e., a few newton steps at most. for this reason it is not\nunreasonable to assume exact centering.\n\nchoice of \u00b5\n\nthe choice of the parameter \u00b5 involves a trade-off in the number of inner and outer\niterations required. if \u00b5 is small (i.e., near 1) then at each outer iteration t increases\nby a small factor. as a result the initial point for the newton process, i.e., the\nprevious iterate x, is a very good starting point, and the number of newton steps\nneeded to compute the next iterate is small. thus for small \u00b5 we expect a small\nnumber of newton steps per outer iteration, but of course a large number of outer\niterations since each outer iteration reduces the gap by only a small amount. in\nthis case the iterates (and indeed, the iterates of the inner iterations as well) closely\nfollow the central path. this explains the alternate name path-following method.\n\non the other hand if \u00b5 is large we have the opposite situation. after each\nouter iteration t increases a large amount, so the current iterate is probably not\na very good approximation of the next iterate. thus we expect many more inner\niterations. this \u2018aggressive\u2019 updating of t results in fewer outer iterations, since the\nduality gap is reduced by the large factor \u00b5 at each outer iteration, but more inner\niterations. with \u00b5 large, the iterates are widely separated on the central path; the\ninner iterates veer way off the central path.\n\nthis trade-off in the choice of \u00b5 is confirmed both in practice and, as we will\nsee, in theory. in practice, small values of \u00b5 (i.e., near one) result in many outer\niterations, with just a few newton steps for each outer iteration. for \u00b5 in a fairly\nlarge range, from around 3 to 100 or so, the two effects nearly cancel, so the total\nnumber of newton steps remains approximately constant. this means that the\nchoice of \u00b5 is not particularly critical; values from around 10 to 20 or so seem to\nwork well. when the parameter \u00b5 is chosen to give the best worst-case bound on\nthe total number of newton steps required, values of \u00b5 near one are used.\n\nchoice of t(0)\n\nanother important issue is the choice of initial value of t. here the trade-off is\nsimple: if t(0) is chosen too large, the first outer iteration will require too many it-\nerations. if t(0) is chosen too small, the algorithm will require extra outer iterations,\nand possibly too many inner iterations in the first centering step.\n\nsince m/t(0) is the duality gap that will result from the first centering step, one\n\n "}, {"Page_number": 585, "text": "11.3 the barrier method\n\n571\n\nreasonable choice is to choose t(0) so that m/t(0) is approximately of the same order\nas f0(x(0)) \u2212 p\u22c6, or \u00b5 times this amount. for example, if a dual feasible point \u03bb,\n\u03bd is known, with duality gap \u03b7 = f0(x(0)) \u2212 g(\u03bb, \u03bd), then we can take t(0) = m/\u03b7.\nthus, in the first outer iteration we simply compute a pair with the same duality\ngap as the initial primal and dual feasible points.\n\nanother possibility is suggested by the central path condition (11.7). we can\n\ninterpret\n\ninf\n\n\u03bd (cid:13)(cid:13)(cid:13)t\u2207f0(x(0)) + \u2207\u03c6(x(0)) + at \u03bd(cid:13)(cid:13)(cid:13)2\n\n(11.12)\n\nas a measure for the deviation of x(0) from the point x\u22c6(t), and choose for t(0) the\nvalue that minimizes (11.12). (this value of t and \u03bd can be found by solving a\nleast-squares problem.)\n\na variation on this approach uses an affine-invariant measure of deviation be-\ntween x and x\u22c6(t) in place of the euclidean norm. we choose t and \u03bd that minimize\n\n\u03b1(t, \u03bd) =(cid:16)t\u2207f0(x(0)) + \u2207\u03c6(x(0)) + at \u03bd(cid:17)t\n\nwhere\n\nh \u22121\n\n0 (cid:16)t\u2207f0(x(0)) + \u2207\u03c6(x(0)) + at \u03bd(cid:17) ,\n\nh0 = t\u22072f0(x(0)) + \u22072\u03c6(x(0)).\n\n(it can be shown that inf \u03bd \u03b1(t, \u03bd) is the square of the newton decrement of tf0 + \u03c6\nat x(0).) since \u03b1 is a quadratic-over-linear function of \u03bd and t, it is convex.\n\ninfeasible start newton method\n\nin one variation on the barrier method, an infeasible start newton method (de-\nscribed in \u00a710.3) is used for the centering steps. thus, the barrier method is ini-\ntialized with a point x(0) that satisfies x(0) \u2208 dom f0 and fi(x(0)) < 0, i = 1, . . . , m,\nbut not necessarily ax(0) = b. assuming the problem is strictly feasible, a full new-\nton step is taken at some point during the first centering step, and thereafter, the\niterates are all primal feasible, and the algorithm coincides with the (standard)\nbarrier method.\n\n11.3.2 examples\n\nlinear programming in inequality form\n\nour first example is a small lp in inequality form,\n\nct x\n\nminimize\nsubject to ax (cid:22) b\n\nwith a \u2208 r100\u00d750. the data were generated randomly, in such a way that the\nproblem is strictly primal and dual feasible, with optimal value p\u22c6 = 1.\nthe initial point x(0) is on the central path, with a duality gap of 100. the\nbarrier method is used to solve the problem, and terminated when the duality gap\nis less than 10\u22126. the centering problems are solved by newton\u2019s method with\nbacktracking, using parameters \u03b1 = 0.01, \u03b2 = 0.5. the stopping criterion for\n\n "}, {"Page_number": 586, "text": "572\n\n11\n\ninterior-point methods\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n102\n\n100\n\n10\u22122\n\n10\u22124\n\n10\u22126\n\n\u00b5 = 50 \u00b5 = 150\n\n\u00b5 = 2\n\n0\n\n20\n\n40\n\n60\nnewton iterations\n\n80\n\nfigure 11.4 progress of barrier method for a small lp, showing duality\ngap versus cumulative number of newton steps. three plots are shown,\ncorresponding to three values of the parameter \u00b5: 2, 50, and 150. in each\ncase, we have approximately linear convergence of duality gap.\n\nnewton\u2019s method is \u03bb(x)2/2 \u2264 10\u22125, where \u03bb(x) is the newton decrement of the\nfunction tct x + \u03c6(x).\nthe progress of the barrier method, for three values of the parameter \u00b5, is\nshown in figure 11.4. the vertical axis shows the duality gap on a log scale. the\nhorizontal axis shows the cumulative total number of inner iterations, i.e., newton\nsteps, which is the natural measure of computational effort. each of the plots has\na staircase shape, with each stair associated with one outer iteration. the width of\neach stair tread (i.e., horizontal portion) is the number of newton steps required\nfor that outer iteration. the height of each stair riser (i.e., the vertical portion) is\nexactly equal to (a factor of) \u00b5, since the duality gap is reduced by the factor \u00b5 at\nthe end of each outer iteration.\n\nthe plots illustrate several typical features of the barrier method. first of all,\nthe method works very well, with approximately linear convergence of the duality\ngap. this is a consequence of the approximately constant number of newton steps\nrequired to re-center, for each value of \u00b5. for \u00b5 = 50 and \u00b5 = 150, the barrier\nmethod solves the problem with a total number of newton steps between 35 and 40.\nthe plots in figure 11.4 clearly show the trade-off in the choice of \u00b5. for \u00b5 = 2,\nthe treads are short; the number of newton steps required to re-center is around 2\nor 3. but the risers are also short, since the duality gap reduction per outer iteration\nis only a factor of 2. at the other extreme, when \u00b5 = 150, the treads are longer,\ntypically around 7 newton steps, but the risers are also much larger, since the\nduality gap is reduced by the factor 150 in each outer iteration.\n\nthe trade-off in choice of \u00b5 is further examined in figure 11.5. we use the\nbarrier method to solve the lp, terminating when the duality gap is smaller than\n10\u22123, for 25 values of \u00b5 between 1.2 and 200. the plot shows the total number\nof newton steps required to solve the problem, as a function of the parameter \u00b5.\n\n "}, {"Page_number": 587, "text": "11.3 the barrier method\n\n573\n\n140\n\n120\n\n100\n\n80\n\n60\n\n40\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n0\n0\n\n40\n\n80\n\n\u00b5\n\n120\n\n160\n\n200\n\nfigure 11.5 trade-off in the choice of the parameter \u00b5, for a small lp. the\nvertical axis shows the total number of newton steps required to reduce the\nduality gap from 100 to 10\u22123, and the horizontal axis shows \u00b5. the plot\nshows the barrier method works well for values of \u00b5 larger than around 3,\nbut is otherwise not sensitive to the value of \u00b5.\n\nthis plot shows that the barrier method performs very well for a wide range of\nvalues of \u00b5, from around 3 to 200. as our intuition suggests, the total number of\nnewton steps rises when \u00b5 is too small, due to the larger number of outer iterations\nrequired. one interesting observation is that the total number of newton steps does\nnot vary much for values of \u00b5 larger than around 3. thus, as \u00b5 increases over this\nrange, the decrease in the number of outer iterations is offset by an increase in\nthe number of newton steps per outer iteration. for even larger values of \u00b5, the\nperformance of the barrier method becomes less predictable (i.e., more dependent\non the particular problem instance). since the performance does not improve with\nlarger values of \u00b5, a good choice is in the range 10 \u2013 100.\n\ngeometric programming\n\nwe consider a geometric program in convex form,\n\nminimize\n\n0kx + b0k)(cid:17)\nikx + bik)(cid:17) \u2264 0,\nwith variable x \u2208 rn, and associated logarithmic barrier\n\nk=1 exp(at\nk=1 exp(at\n\nsubject to\n\nlog(cid:16)pk0\nlog(cid:16)pki\nmxi=1\n\n\u03c6(x) = \u2212\n\nlog \u2212 log\n\nkixk=1\n\nexp(at\n\nikx + bik)! .\n\ni = 1, . . . , m,\n\nthe problem instance we consider has n = 50 variables and m = 100 inequalities\n(like the small lp considered above). the objective and constraint functions all\n\n "}, {"Page_number": 588, "text": "574\n\n11\n\ninterior-point methods\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n102\n\n100\n\n10\u22122\n\n10\u22124\n\n10\u22126\n\n\u00b5 = 150\n\n\u00b5 = 50\n\n\u00b5 = 2\n\n0\n\n20\n\n60\n\n40\n80\nnewton iterations\n\n100\n\n120\n\nfigure 11.6 progress of barrier method for a small gp, showing duality gap\nversus cumulative number of newton steps. again we have approximately\nlinear convergence of duality gap.\n\nhave ki = 5 terms. the problem instance was generated randomly, in such a way\nthat it is strictly primal and dual feasible, with optimal value one.\n\nwe start with a point x(0) on the central path, with a duality gap of 100. the\nbarrier method is used to solve the problem, with parameters \u00b5 = 2, \u00b5 = 50, and\n\u00b5 = 150, and terminated when the duality gap is less than 10\u22126. the centering\nproblems are solved using newton\u2019s method, with the same parameter values as in\nthe lp example, i.e., \u03b1 = 0.01, \u03b2 = 0.5, and stopping criterion \u03bb(x)2/2 \u2264 10\u22125.\nfigure 11.6 shows the duality gap versus cumulative number of newton steps.\nthis plot is very similar to the plot for lp, shown in figure 11.4. in particular,\nwe see an approximately constant number of newton steps required per centering\nstep, and therefore approximately linear convergence of the duality gap.\n\nthe variation of the total number of newton steps required to solve the problem,\nversus the parameter \u00b5, is very similar to that in the lp example. for this gp,\nthe total number of newton steps required to reduce the duality gap below 10\u22123\nis around 30 (ranging from around 20 to 40 or so) for values of \u00b5 between 10 and\n200. so here, too, a good choice of \u00b5 is in the range 10 \u2013 100.\n\na family of standard form lps\n\nin the examples above we examined the progress of the barrier method, in terms of\nduality gap versus cumulative number of newton steps, for a randomly generated\ninstance of an lp and a gp, with similar dimensions. the results for the two\nexamples are remarkably similar; each shows approximately linear convergence of\nduality gap with the number of newton steps. we also examined the variation in\nperformance with the parameter \u00b5, and found essentially the same results in the\ntwo cases. for \u00b5 above around 10, the barrier method performs very well, requiring\naround 30 newton steps to bring the duality gap down from 102 to 10\u22126. in both\n\n "}, {"Page_number": 589, "text": "11.3 the barrier method\n\n575\n\ncases, the choice of \u00b5 hardly affects the total number of newton steps required\n(provided \u00b5 is larger than 10 or so).\n\nin this section we examine the performance of the barrier method as a function\n\nof the problem dimensions. we consider lps in standard form,\n\nminimize\nsubject to ax = b,\n\nct x\n\nx (cid:23) 0\n\nwith a \u2208 rm\u00d7n, and explore the total number of newton steps required as a\nfunction of the number of variables n and number of equality constraints m, for a\nfamily of randomly generated problem instances. we take n = 2m, i.e., twice as\nmany variables as constraints.\n\nthe problems were generated as follows. the elements of a are independent and\nidentically distributed, with zero mean, unit variance normal distribution n (0, 1).\nwe take b = ax(0) where the elements of x(0) are independent, and uniformly\ndistributed in [0, 1]. this ensures that the problem is strictly primal feasible, since\nx(0) \u227b 0 is feasible. to construct the cost vector c, we first compute a vector\nz \u2208 rm with elements distributed according to n (0, 1) and a vector s \u2208 rn with\nelements from a uniform distribution on [0, 1]. we then take c = at z + s. this\nguarantees that the problem is strictly dual feasible, since at z \u227a c.\nthe algorithm parameters we use are \u00b5 = 100, and the same parameters for the\ncentering steps in the examples above: backtracking parameters \u03b1 = 0.01, \u03b2 = 0.5,\nand stopping criterion \u03bb(x)2/2 \u2264 10\u22125. the initial point is on the central path\nwith t(0) = 1 (i.e., gap n). the algorithm is terminated when the initial duality\ngap is reduced by a factor 104, i.e., after completing two outer iterations.\n\nfigure 11.7 shows the duality gap versus iteration number for three problem\ninstances, with dimensions m = 50, m = 500, and m = 1000. the plots look very\nmuch like the others, with approximately linear convergence of the duality gap.\nthe plots show a small increase in the number of newton steps required as the\nproblem size grows from 50 constraints (100 variables) to 1000 constraints (2000\nvariables).\n\nto examine the effect of problem size on the number of newton steps required,\nwe generate 100 problem instances for each of 20 values of m, ranging from m = 10\nto m = 1000. we solve each of these 2000 problems using the barrier method,\nnoting the number of newton steps required. the results are summarized in fig-\nure 11.8, which shows the mean and standard deviation in the number of newton\nsteps, for each value of m. the first comment we make is that the standard de-\nviation is around 2 iterations, and appears to be approximately independent of\nproblem size. since the average number of steps required is near 25, this means\nthat the number of newton steps required varies only around \u00b110%.\n\nthe plot shows that the number of newton steps required grows only slightly,\nfrom around 21 to around 27, as the problem dimensions increase by a factor of\n100. this behavior is typical for the barrier method in general: the number of\nnewton steps required grows very slowly with problem dimensions, and is almost\nalways around a few tens. of course, the computational effort to carry out one\nnewton step grows with the problem dimensions.\n\n "}, {"Page_number": 590, "text": "576\n\n11\n\ninterior-point methods\n\n104\n\n102\n\n100\n\n10\u22122\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n10\u22124\n0\n\n10\n\nm = 50 m = 500\n\nm = 1000\n\n20\n\n30\n\nnewton iterations\n\n40\n\n50\n\nfigure 11.7 progress of barrier method for three randomly generated stan-\ndard form lps of different dimensions, showing duality gap versus cumula-\ntive number of newton steps. the number of variables in each problem is\nn = 2m. here too we see approximately linear convergence of the duality\ngap, with a slight increase in the number of newton steps required for the\nlarger problems.\n\n35\n\n30\n\n25\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n15\n\n101\n\n102\nm\n\n103\n\nfigure 11.8 average number of newton steps required to solve 100 randomly\ngenerated lps of different dimensions, with n = 2m. error bars show stan-\ndard deviation, around the average value, for each value of m. the growth\nin the number of newton steps required, as the problem dimensions range\nover a 100 : 1 ratio, is very small.\n\n "}, {"Page_number": 591, "text": "11.3 the barrier method\n\n577\n\n11.3.3 convergence analysis\n\nconvergence analysis for the barrier method is straightforward. assuming that\ntf0 + \u03c6 can be minimized by newton\u2019s method for t = t(0), \u00b5t(0), \u00b52t(0), . . ., the\nduality gap after the initial centering step, and k additional centering steps, is\nm/(\u00b5kt(0)). therefore the desired accuracy \u01eb is achieved after exactly\n\n(cid:24) log(m/(\u01ebt(0)))\n\nlog \u00b5\n\n(cid:25)\n\n(11.13)\n\ncentering steps, plus the initial centering step.\n\nit follows that the barrier method works provided the centering problem (11.6)\nis solvable by newton\u2019s method, for t \u2265 t(0). for the standard newton method, it\nsuffices that for t \u2265 t(0), the function tf0 +\u03c6 satisfies the conditions given in \u00a710.2.4,\npage 529:\nits initial sublevel set is closed, the associated inverse kkt matrix is\nbounded, and the hessian satisfies a lipschitz condition. (another set of sufficient\nconditions, based on self-concordance, will be discussed in detail in \u00a711.5.) if the\ninfeasible start newton method is used for centering, then the conditions listed\nin \u00a710.3.3, page 536, are sufficient to guarantee convergence.\nassuming that f0, . . . , fm are closed, a simple modification of the original\nproblem ensures that these conditions hold. by adding a constraint of the form\n2 \u2264 r2 to the problem, it follows that tf0 + \u03c6 is strongly convex, for every\nkxk2\nt \u2265 0; in particular convergence of newton\u2019s method, for the centering steps, is\nguaranteed. (see exercise 11.4.)\nwhile this analysis shows that the barrier method does converge, under reason-\nable assumptions, it does not address a basic question: as the parameter t increases,\ndo the centering problems become more difficult (and therefore take more and more\niterations)? numerical evidence suggests that for a wide variety of problems, this\nis not the case; the centering problems appear to require a nearly constant number\nof newton steps to solve, even as t increases. we will see (in \u00a711.5) that this issue\ncan be resolved, for problems that satisfy certain self-concordance conditions.\n\n11.3.4 newton step for modified kkt equations\n\nin the barrier method, the newton step \u2206xnt, and associated dual variable are\ngiven by the linear equations\n\n(cid:20) t\u22072f0(x) + \u22072\u03c6(x) at\n\n0 (cid:21)(cid:20) \u2206xnt\n\n\u03bdnt (cid:21) = \u2212(cid:20) t\u2207f0(x) + \u2207\u03c6(x)\n\na\n\n0\n\n(cid:21) .\n\n(11.14)\n\nin this section we show how these newton steps for the centering problem can be\ninterpreted as newton steps for directly solving the modified kkt equations\n\n\u2207f0(x) +pm\n\ni=1 \u03bbi\u2207fi(x) + at \u03bd = 0\nax = b\n\n\u2212\u03bbifi(x) = 1/t,\n\ni = 1, . . . , m\n\n(11.15)\n\nin a particular way.\n\n "}, {"Page_number": 592, "text": "578\n\n11\n\ninterior-point methods\n\nto solve the modified kkt equations (11.15), which is a set of n + p + m\nnonlinear equations in the n + p + m variables x, \u03bd, and \u03bb, we first eliminate the\nvariables \u03bbi, using \u03bbi = \u22121/(tfi(x)). this yields\n\n\u2207f0(x) +\n\nmxi=1\n\n1\n\n\u2212tfi(x)\u2207fi(x) + at \u03bd = 0,\n\nax = b,\n\n(11.16)\n\nwhich is a set of n + p equations in the n + p variables x and \u03bd.\n\nto find the newton step for solving the set of nonlinear equations (11.16),\nwe form the taylor approximation for the nonlinear term occurring in the first\nequation. for v small, we have the taylor approximation\n\n\u2207f0(x + v) +\n\n\u2248 \u2207f0(x) +\n\n1\n\n1\n\nmxi=1\n\u2212tfi(x + v)\u2207fi(x + v)\nmxi=1\n\u2212tfi(x)\u2207fi(x) + \u22072f0(x)v\n\u2212tfi(x)\u22072fi(x)v +\n\n1\n\n1\n\nmxi=1\n\n+\n\nmxi=1\n\ntfi(x)2\u2207fi(x)\u2207fi(x)t v.\n\nthe newton step is obtained by replacing the nonlinear term in equation (11.16)\nby this taylor approximation, which yields the linear equations\n\nwhere\n\nhv + at \u03bd = \u2212g,\nmxi=1\nh = \u22072f0(x) +\n\u2212tfi(x)\u22072fi(x) +\nmxi=1\n\u2212tfi(x)\u2207fi(x).\n\ng = \u2207f0(x) +\n\n1\n\n1\n\nnow we observe that\n\nav = 0,\n\n(11.17)\n\n1\n\ntfi(x)2\u2207fi(x)\u2207fi(x)t\n\nmxi=1\n\nh = \u22072f0(x) + (1/t)\u22072\u03c6(x),\n\ng = \u2207f0(x) + (1/t)\u2207\u03c6(x),\n\nso, from (11.14), the newton steps \u2206xnt and \u03bdnt in the barrier method centering\nstep satisfy\n\ncomparing this with (11.17) shows that\n\nth\u2206xnt + at \u03bdnt = \u2212tg,\n\na\u2206xnt = 0.\n\nv = \u2206xnt,\n\n\u03bd = (1/t)\u03bdnt.\n\nthis shows that the newton step for the centering problem (11.6) can be inter-\npreted, after scaling the dual variable, as the newton step for solving the modified\nkkt equations (11.16).\n\nin this approach, we first eliminated the variable \u03bb from the modified kkt\nequations, and then applied newton\u2019s method to solve the resulting set of equations.\nanother variation on this approach is to directly apply newton\u2019s method to the\nmodified kkt equations, without first eliminating \u03bb. this method yields the so-\ncalled primal-dual search directions, discussed in \u00a711.7.\n\n "}, {"Page_number": 593, "text": "11.4 feasibility and phase i methods\n\n579\n\n11.4 feasibility and phase i methods\n\nthe barrier method requires a strictly feasible starting point x(0). when such a\npoint is not known, the barrier method is preceded by a preliminary stage, called\nphase i, in which a strictly feasible point is computed (or the constraints are found\nto be infeasible). the strictly feasible point found during phase i is then used as\nthe starting point for the barrier method, which is called the phase ii stage. in\nthis section we describe several phase i methods.\n\n11.4.1 basic phase i method\n\nwe consider a set of inequalities and equalities in the variables x \u2208 rn,\n\ni = 1, . . . , m,\n\nfi(x) \u2264 0,\n\n(11.18)\nwhere fi : rn \u2192 r are convex, with continuous second derivatives. we assume\nthat we are given a point x(0) \u2208 dom f1 \u2229 \u00b7\u00b7\u00b7 \u2229 dom fm, with ax(0) = b.\nour goal is to find a strictly feasible solution of these inequalities and equalities,\nor determine that none exists. to do this we form the following optimization\nproblem:\n\nax = b,\n\nminimize\nsubject to\n\ns\nfi(x) \u2264 s,\nax = b\n\ni = 1, . . . , m\n\n(11.19)\n\nin the variables x \u2208 rn, s \u2208 r. the variable s can be interpreted as a bound on\nthe maximum infeasibility of the inequalities; the goal is to drive the maximum\ninfeasibility below zero.\n\nthis problem is always strictly feasible, since we can choose x(0) as starting\npoint for x, and for s, we can choose any number larger than maxi=1,...,m fi(x(0)).\nwe can therefore apply the barrier method to solve the problem (11.19), which is\ncalled the phase i optimization problem associated with the inequality and equality\nsystem (11.19).\n\nwe can distinguish three cases depending on the sign of the optimal value \u00afp\u22c6\n\nof (11.19).\n\n1. if \u00afp\u22c6 < 0, then (11.18) has a strictly feasible solution. moreover if (x, s) is\nfeasible for (11.19) with s < 0, then x satisfies fi(x) < 0. this means we do\nnot need to solve the optimization problem (11.19) with high accuracy; we\ncan terminate when s < 0.\n\n2. if \u00afp\u22c6 > 0, then (11.18) is infeasible. as in case 1, we do not need to solve\nthe phase i optimization problem (11.19) to high accuracy; we can terminate\nwhen a dual feasible point is found with positive dual objective (which proves\nthat \u00afp\u22c6 > 0). in this case, we can construct the alternative that proves (11.18)\nis infeasible from the dual feasible point.\n\n3. if \u00afp\u22c6 = 0 and the minimum is attained at x\u22c6 and s\u22c6 = 0, then the set of\ninequalities is feasible, but not strictly feasible. if \u00afp\u22c6 = 0 and the minimum\nis not attained, then the inequalities are infeasible.\n\n "}, {"Page_number": 594, "text": "580\n\n11\n\ninterior-point methods\n\nin practice it is impossible to determine exactly that \u00afp\u22c6 = 0.\ninstead, an\noptimization algorithm applied to (11.19) will terminate with the conclusion\nthat |\u00afp\u22c6| < \u01eb for some small, positive \u01eb. this allows us to conclude that the\ninequalities fi(x) \u2264 \u2212\u01eb are infeasible, while the inequalities fi(x) \u2264 \u01eb are\nfeasible.\n\nsum of infeasibilities\n\nthere are many variations on the basic phase i method just described. one method\nis based on minimizing the sum of the infeasibilities, instead of the maximum\ninfeasibility. we form the problem\n\nminimize\nsubject to\n\n1t s\nfi(x) \u2264 si,\nax = b\ns (cid:23) 0.\n\ni = 1, . . . , m\n\n(11.20)\n\nfor fixed x, the optimal value of si is max{fi(x), 0}, so in this problem we are\nminimizing the sum of the infeasibilities. the optimal value of (11.20) is zero and\nachieved if and only if the original set of equalities and inequalities is feasible.\n\nthis sum of infeasibilities phase i method has a very interesting property when\nthe system of equalities and inequalities (11.19) is infeasible. in this case, the op-\ntimal point for the phase i problem (11.20) often violates only a small number,\nsay r, of the inequalities. therefore, we have computed a point that satisfies many\n(m \u2212 r) of the inequalities, i.e., we have identified a large subset of inequalities\nthat is feasible. in this case, the dual variables associated with the strictly satisfied\ninequalities are zero, so we have also proved infeasibility of a subset of the inequal-\nities. this is more informative than finding that the m inequalities, together, are\nmutually infeasible. (this phenomenon is closely related to \u21131-norm regularization,\nor basis pursuit, used to find sparse approximate solutions; see \u00a76.1.2 and \u00a76.5.4).\n\nexample 11.4 comparison of phase i methods. we apply two phase i methods to\nan infeasible set of inequalities ax (cid:22) b with dimensions m = 100, n = 50. the first\nmethod is the basic phase i method\n\ns\n\nminimize\nsubject to ax (cid:22) b + 1s,\n\nwhich minimizes the maximum infeasibility. the second method minimizes the sum\nof the infeasibilities, i.e., solves the lp\n\n1t s\n\nminimize\nsubject to ax (cid:22) b + s\n\ns (cid:23) 0.\n\nfigure 11.9 shows the distributions of the infeasibilities bi \u2212 at\ni x for these two values\nof x, denoted xmax and xsum, respectively. the point xmax satisfies 39 of the 100\ninequalities, whereas the point xsum satisfies 79 of the inequalities.\n\n "}, {"Page_number": 595, "text": "replacemen\n\n11.4 feasibility and phase i methods\n\n581\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\nr\ne\nb\nm\nu\nn\n\n60\n\n50\n\n40\n\n30\n\n20\n\n10\n\nr\ne\nb\nm\nu\nn\n\n0\n\u22121 \u22120.5\n\n1\n\n1.5\n\n0.5\ni xmax\n\n0\nbi \u2212 at\n\n0\n\u22121 \u22120.5\nfigure 11.9 distributions of the infeasibilities bi \u2212 at\ni x for an infeasible set\nof 100 inequalities at\ni x \u2264 bi, with 50 variables. the vector xmax used in\nthe left plot was obtained by the basic phase i algorithm.\nit satisfies 39\nof the 100 inequalities. in the right plot the vector xsum was obtained by\nminimizing the sum of the infeasibilities. this vector satisfies 79 of the 100\ninequalities.\n\n0\nbi \u2212 at\n\n0.5\ni xsum\n\n1\n\n1.5\n\ntermination near the phase ii central path\n\na simple variation on the basic phase i method, using the barrier method, has\nthe property that (when the equalities and inequalities are strictly feasible) the\ncentral path for the phase i problem intersects the central path for the original\noptimization problem (11.1).\n\nwe assume a point x(0) \u2208 d = dom f0\u2229 dom f1\u2229\u00b7\u00b7\u00b7\u2229 dom fm, with ax(0) = b\n\nis given. we form the phase i optimization problem\n\nminimize\nsubject to\n\ns\nfi(x) \u2264 s,\nf0(x) \u2264 m\nax = b,\n\ni = 1, . . . , m\n\n(11.21)\n\nwhere m is a constant chosen to be larger than max{f0(x(0)), p\u22c6}.\nwe assume now that the original problem (11.1) is strictly feasible, so the\noptimal value \u00afp\u22c6 of (11.21) is negative. the central path of (11.21) is characterized\nby\n\nmxi=1\n\n1\n\ns \u2212 fi(x)\n\n= \u00aft,\n\n1\n\nm \u2212 f0(x)\u2207f0(x) +\n\nmxi=1\n\n1\n\ns \u2212 fi(x)\u2207fi(x) + at \u03bd = 0,\n\nwhere \u00aft is the parameter. if (x, s) is on the central path and s = 0, then x and \u03bd\nsatisfy\n\nt\u2207f0(x) +\n\nmxi=1\n\n1\n\n\u2212fi(x)\u2207fi(x) + at \u03bd = 0\n\nfor t = 1/(m \u2212 f0(x)). this means that x is on the central path for the original\n\n "}, {"Page_number": 596, "text": "582\n\n11\n\ninterior-point methods\n\noptimization problem (11.1), with associated duality gap\nm(m \u2212 f0(x)) \u2264 m(m \u2212 p\u22c6).\n\n(11.22)\n\n11.4.2 phase i via infeasible start newton method\n\nwe can also carry out the phase i stage using an infeasible start newton method,\napplied to a modified version of the original problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b.\n\ni = 1, . . . , m\n\nwe first express the problem in the (obviously equivalent) form\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 s,\nax = b,\n\ni = 1, . . . , m\n\ns = 0,\n\nwith the additional variable s \u2208 r. to start the barrier method, we use an infeasible\nstart newton method to solve\n\nminimize\nsubject to ax = b,\n\nt(0)f0(x) \u2212pm\n\ns = 0.\n\ni=1 log(s \u2212 fi(x))\n\nthis can be initialized with any x \u2208 d, and any s > maxi fi(x). provided the\nproblem is strictly feasible, the infeasible start newton method will eventually\ntake an undamped step, and thereafter we will have s = 0, i.e., x strictly feasible.\nthe same trick can be applied if a point in d, the common domain of the\nfunctions, is not known. we simply apply the infeasible start newton method to\nthe problem\n\nminimize\nsubject to ax = b,\n\nt(0)f0(x + z0) \u2212pm\n\ns = 0,\n\ni=1 log(s \u2212 fi(x + zi))\nzm = 0\nz0 = 0,\n\n. . . ,\n\nwith variables x, z0, . . . , zm, and s \u2208 r. we initialize zi so that x + zi \u2208 dom fi.\nthe main disadvantage of this approach to the phase i problem is that there is\nno good stopping criterion when the problem is infeasible; the residual simply fails\nto converge to zero.\n\n11.4.3 examples\n\nwe consider a family of linear feasibility problems,\n\nax (cid:22) b(\u03b3)\n\nwhere a \u2208 r50\u00d720 and b(\u03b3) = b + \u03b3\u2206b. the problem data are chosen so that the\ninequalities are strictly feasible for \u03b3 > 0 and infeasible for \u03b3 < 0. for \u03b3 = 0 the\nproblem is feasible but not strictly feasible.\n\n "}, {"Page_number": 597, "text": "11.4 feasibility and phase i methods\n\n583\n\nfigure 11.10 shows the total number of newton steps required to find a strictly\nfeasible point, or a certificate of infeasibility, for 40 values of \u03b3 in [\u22121, 1]. we use\nthe basic phase i method of \u00a711.4.1, i.e., for each value of \u03b3, we form the lp\n\ns\n\nminimize\nsubject to ax (cid:22) b(\u03b3) + s1.\n\nthe barrier method is used with \u00b5 = 10, and starting point x = 0, s = \u2212 mini bi(\u03b3)+\n1. the method terminates when a point (x, s) with s < 0 is found, or a feasible\nsolution z of the dual problem\n\nmaximize \u2212b(\u03b3)t z\nsubject to at z = 0\n1t z = 1\nz (cid:23) 0\n\nis found with \u2212b(\u03b3)t z > 0.\nthe plot shows that when the inequalities are feasible, with some margin, it\ntakes around 25 newton steps to produce a strictly feasible point. conversely,\nwhen the inequalities are infeasible, again with some margin, it takes around 35\nsteps to produce a certificate proving infeasibility. the phase i effort increases as\nthe set of inequalities approaches the boundary between feasible and infeasible,\ni.e., \u03b3 near zero. when \u03b3 is very near zero, so the inequalities are very near the\nboundary between feasible and infeasible, the number of steps grows substantially.\nfigure 11.11 shows the total number of newton steps required for values of \u03b3\nnear zero. the plots show an approximately logarithmic increase in the number\nof steps required to detect feasibility, or prove infeasibility, for problems very near\nthe boundary between feasible and infeasible.\n\nthis example is typical: the cost of solving a set of convex inequalities and\nlinear equalities using the barrier method is modest, and approximately constant,\nas long as the problem is not very close to the boundary between feasibility and\ninfeasibility. when the problem is very close to the boundary, the number of\nnewton steps required to find a strictly feasible point or produce a certificate\nof infeasibility grows. when the problem is exactly on the boundary between\nstrictly feasible and infeasible, for example, feasible but not strictly feasible, the\ncost becomes infinite.\n\nfeasibility using infeasible start newton method\n\nwe also solve the same set of feasibility problems using the infeasible start newton\nmethod, applied to the problem\n\nminimize \u2212pm\n\nsubject to ax + s = b(\u03b3).\n\ni=1 log si\n\nwe use backtracking parameters \u03b1 = 0.01, \u03b2 = 0.9, and initialize with x(0) = 0,\ns(0) = 1, \u03bd(0) = 0. we consider only feasible problems (i.e., \u03b3 > 0) and terminate\nonce a feasible point is found. (we do not consider infeasible problems, since in\nthat case the residual simply converges to a positive number.) figure 11.12 shows\nthe number of newton steps required to find a feasible point, as a function of \u03b3.\n\n "}, {"Page_number": 598, "text": "584\n\n11\n\ninterior-point methods\n\ninfeasible\n\nfeasible\n\n100\n\n80\n\n60\n\n40\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n0\n\u22121\n\n\u22120.5\n\n0\n\u03b3\n\n0.5\n\n1\n\nfigure 11.10 number of newton iterations required to detect feasibility or\ninfeasibility of a set of linear inequalities ax (cid:22) b + \u03b3\u2206b parametrized by\n\u03b3 \u2208 r. the inequalities are strictly feasible for \u03b3 > 0, and infeasible for\n\u03b3 < 0. for \u03b3 larger than around 0.2, about 30 steps are required to compute\na strictly feasible point; for \u03b3 less than \u22120.5 or so, it takes around 35 steps\nto produce a certificate proving infeasibility. for values of \u03b3 in between, and\nespecially near zero, more newton steps are required to determine feasibility.\n\n100\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n80\n\n60\n\n40\n\n20\n\n100\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n80\n\n60\n\n40\n\n20\n\n0\n\u2212100\n\n\u221210\u22122\n\n\u221210\u22124\n\n\u03b3\n\n\u221210\u22126\n\n0\n10\u22126\n\n10\u22124\n\n\u03b3\n\n10\u22122\n\n100\n\nfigure 11.11 left. number of newton iterations required to find a proof of\ninfeasibility versus \u03b3, for \u03b3 small and negative. right. number of newton\niterations required to find a strictly feasible point versus \u03b3, for \u03b3 small and\npositive.\n\n "}, {"Page_number": 599, "text": "11.5 complexity analysis via self-concordance\n\n585\n\n104\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n103\n\n102\n\n101\n\n100\n10\u22122\n\n10\u22121\n\n\u03b3\n\n100\n\n101\n\nfigure 11.12 number of iterations required to find a feasible point for a set\nof linear inequalities ax (cid:22) b + \u03b3\u2206b parametrized by \u03b3 \u2208 r. the infeasible\nstart newton method is used, and terminated when a feasible point is found.\nfor \u03b3 = 10, the starting point x(0) = 0 happened to be feasible (0 iterations).\n\nthe plot shows that for \u03b3 larger than 0.3 or so, it takes fewer than 20 newton\nsteps to find a feasible point. in these cases the method is more efficient than a\nphase i method, which takes a total of around 30 newton steps. for smaller values\nof \u03b3, the number of newton steps required grows dramatically, approximately as\n1/\u03b3. for \u03b3 = 0.01, the infeasible start newton method requires several thousand\niterations to produce a feasible point. in this region the phase i approach is far\nmore efficient, requiring only 40 iterations or so.\n\nthese results are quite typical. the infeasible start newton method works\nvery well provided the inequalities are feasible, and not very close to the boundary\nbetween feasible and infeasible. but when the feasible set is just barely nonempty\n(as is the case in this example with small \u03b3), a phase i method is far better. another\nadvantage of the phase i method is that it gracefully handles the infeasible case;\nthe infeasible start newton method, in contrast, simply fails to converge.\n\n11.5 complexity analysis via self-concordance\n\nusing the complexity analysis of newton\u2019s method for self-concordant functions\n(\u00a79.6.4, page 503, and \u00a710.2.4, page 531), we can give a complexity analysis of\nthe barrier method. the analysis applies to many common problems, and leads\nto several interesting conclusions: it gives a rigorous bound on the total number\nof newton steps required to solve a problem using the barrier method, and it\njustifies our observation that the centering problems do not become more difficult\nas t increases.\n\n "}, {"Page_number": 600, "text": "586\n\n11\n\ninterior-point methods\n\n11.5.1 self-concordance assumption\n\nwe make two assumptions.\n\n\u2022 the function tf0 + \u03c6 is closed and self-concordant for all t \u2265 t(0).\n\u2022 the sublevel sets of (11.1) are bounded.\n\nthe second assumption implies that the centering problem has bounded sublevel\nsets (see exercise 11.3), and, therefore, the centering problem is solvable. the\nbounded sublevel set assumption also implies that the hessian of tf0 + \u03c6 is positive\ndefinite everywhere (see exercise 11.14). while the self-concordance assumption\nrestricts the complexity analysis to a particular class of problems, it is important\nto emphasize that the barrier method works well in general, whether or not the\nself-concordance assumption holds.\n\nthe self-concordance assumption holds for a variety of problems, including all\n\nlinear and quadratic problems. if the functions fi are linear or quadratic, then\n\ntf0 \u2212\n\nmxi=1\n\nlog(\u2212fi)\n\nis self-concordant for all values of t \u2265 0 (see \u00a79.6). the complexity analysis given\nbelow therefore applies to lps, qps, and qcqps.\nin other cases, it is possible to reformulate the problem so the assumption of\nself-concordance holds. as an example, consider the linear inequality constrained\nentropy maximization problem\n\nminimize pn\n\nsubject to f x (cid:22) g\nax = b.\n\ni=1 xi log xi\n\nthe function\n\ntf0(x) + \u03c6(x) = t\n\nnxi=1\n\nxi log xi \u2212\n\nmxi=1\n\nlog(gi \u2212 f t\n\ni x),\n\n1 , . . . , f t\n\nwhere f t\nm are the rows of f , is not closed (unless f x (cid:22) g implies x (cid:23) 0), or\nself-concordant. we can, however, add the redundant inequality constraints x (cid:23) 0\nto obtain the equivalent problem\n\ni=1 xi log xi\n\nminimize pn\n\nsubject to f x (cid:22) g\nax = b\nx (cid:23) 0.\n\n(11.23)\n\nfor this problem we have\n\ntf0(x) + \u03c6(x) = t\n\nnxi=1\n\nxi log xi \u2212\n\nnxi=1\n\nlog xi \u2212\n\nmxi=1\n\nlog(gi \u2212 f t\n\ni x),\n\n "}, {"Page_number": 601, "text": "11.5 complexity analysis via self-concordance\n\n587\n\nwhich is self-concordant and closed, for any t \u2265 0. (the function ty log y \u2212 log y\nis self-concordant on r++, for all t \u2265 0; see exercise 11.13.) the complexity\nanalysis therefore applies to the reformulated linear inequality constrained entropy\nmaximization problem (11.23).\n\nas a more exotic example, consider the gp\n\nminimize\n\nsubject to\n\nf0(x) = log(cid:16)pk0\nlog(cid:16)pki\n\nk=1 exp(at\n\nk=1 exp(at\n\n0kx + b0k)(cid:17)\nikx + bik)(cid:17) \u2264 0,\n\ni = 1, . . . , m.\n\nit is not clear whether or not the function\n\ntf0(x) + \u03c6(x) = t log  k0xk=1\n\nexp(at\n\n0kx + b0k)! \u2212\n\nlog \u2212 log\n\nmxi=1\n\nkixk=1\n\nexp(at\n\nikx + bik)!\n\nis self-concordant, so although the barrier method works, the complexity analysis\nof this section need not hold.\n\nwe can, however, reformulate the gp in a form that definitely satisfies the self-\nikx + bik) we introduce\n\nconcordance assumption. for each (monomial) term exp(at\na new variable yik that serves as an upper bound,\n\nusing these new variables we can express the gp in the form\n\nexp(at\n\nikx + bik) \u2264 yik.\n\nminimize pk0\nsubject to pki\n\nk=1 y0k\nk=1 yik \u2264 1,\nat\nikx + bik \u2212 log yik \u2264 0,\nyik \u2265 0,\ni = 0, . . . , m,\n\ni = 1, . . . , m\n\ni = 0, . . . , m,\nk = 1, . . . , ki.\n\nk = 1, . . . , ki\n\nthe associated logarithmic barrier is\n\nmxi=0\n\nkixk=1(cid:0)\u2212 log yik \u2212 log(log yik \u2212 at\n\nikx \u2212 bik)(cid:1) \u2212\n\nmxi=1\n\nlog 1 \u2212\n\nyik! ,\n\nkixk=1\n\nwhich is closed and self-concordant (example 9.8, page 500). since the objective is\nlinear, it follows that tf0 + \u03c6 is closed and self-concordant for any t.\n\n11.5.2 newton iterations per centering step\n\nthe complexity theory of newton\u2019s method for self-concordant functions, developed\nin \u00a79.6.4 (page 503) and \u00a710.2.4 (page 531), shows that the number of newton\niterations required to minimize a closed strictly convex self-concordant function f\nis bounded above by\n\nf (x) \u2212 p\u22c6\n\n\u03b3\n\n+ c.\n\n(11.24)\n\n "}, {"Page_number": 602, "text": "588\n\n11\n\ninterior-point methods\n\nhere x is the starting point for newton\u2019s method, and p\u22c6 = inf x f (x) is the optimal\nvalue. the constant \u03b3 depends only on the backtracking parameters \u03b1 and \u03b2, and\nis given by\n\n1\n\u03b3\n\n=\n\n20 \u2212 8\u03b1\n\u03b1\u03b2(1 \u2212 2\u03b1)2 .\n\nthe constant c depends only on the tolerance \u01ebnt,\n\nc = log2 log2(1/\u01ebnt),\n\nand can reasonably be approximated as c = 6. the expression (11.24) is a quite\nconservative bound on the number of newton steps required, but our interest in this\nsection is only to establish a complexity bound, concentrating on how it increases\nwith problem size and algorithm parameters.\n\nin this section we use this result to derive a bound on the number of newton\nsteps required for one outer iteration of the barrier method, i.e., for computing\nx\u22c6(\u00b5t), starting from x\u22c6(t). to lighten the notation we use x to denote x\u22c6(t), the\ncurrent iterate, and we use x+ to denote x\u22c6(\u00b5t), the next iterate. we use \u03bb and \u03bd\nto denote \u03bb\u22c6(t) and \u03bd\u22c6(t), respectively.\n\nthe self-concordance assumption implies that\n\n\u00b5tf0(x) + \u03c6(x) \u2212 \u00b5tf0(x+) \u2212 \u03c6(x+)\n\n\u03b3\n\n+ c\n\n(11.25)\n\nis an upper bound on the number of newton steps required to compute x+ = x\u22c6(\u00b5t),\nstarting at x = x\u22c6(t). unfortunately we do not know x+, and hence the upper\nbound (11.25), until we actually compute x+, i.e., carry out the newton algorithm\n(whereupon we know the exact number of newton steps required to compute x\u22c6(\u00b5t),\nwhich defeats the purpose). we can, however, derive an upper bound on (11.25),\nas follows:\n\n= \u00b5tf0(x) \u2212 \u00b5tf0(x+) +\n\n\u00b5tf0(x) + \u03c6(x) \u2212 \u00b5tf0(x+) \u2212 \u03c6(x+)\nmxi=1\nlog(\u2212\u00b5t\u03bbifi(x+)) \u2212 m log \u00b5\nmxi=1\n\u03bbifi(x+) \u2212 m \u2212 m log \u00b5\n\u2264 \u00b5tf0(x) \u2212 \u00b5tf0(x+) \u2212 \u00b5t\n\u03bbifi(x+) + \u03bdt (ax+ \u2212 b)! \u2212 m \u2212 m log \u00b5\n= \u00b5tf0(x) \u2212 \u00b5t f0(x+) +\nmxi=1\n\n\u2264 \u00b5tf0(x) \u2212 \u00b5tg(\u03bb, \u03bd) \u2212 m \u2212 m log \u00b5\n= m(\u00b5 \u2212 1 \u2212 log \u00b5).\n\nthis chain of equalities and inequalities needs some explanation. to obtain the\nsecond line from the first, we use \u03bbi = \u22121/(tfi(x)). in the first inequality we use\nthe fact that log a \u2264 a \u2212 1 for a > 0. to obtain the fourth line from the third, we\nuse ax+ = b, so the extra term \u03bdt (ax+ \u2212 b) is zero. the second inequality follows\n\n "}, {"Page_number": 603, "text": "11.5 complexity analysis via self-concordance\n\n589\n\n1\n\n0.8\n\n\u00b5\ng\no\nl\n\n0.6\n\n\u2212\n1\n\u2212\n\u00b5\n\n0.4\n\n0.2\n\n0\n1\n\n1.5\n\n2\n\u00b5\n\n2.5\n\n3\n\nfigure 11.13 the function \u00b5 \u2212 1 \u2212 log \u00b5, versus \u00b5. the number of newton\nsteps required for one outer iteration of the barrier method is bounded by\n(m/\u03b3)(\u00b5 \u2212 1 \u2212 log \u00b5) + c.\n\nfrom the definition of the dual function:\n\ng(\u03bb, \u03bd) = inf\n\nz  f0(z) +\nmxi=1\n\u2264 f0(x+) +\n\n\u03bbifi(z) + \u03bdt (az \u2212 b)!\nmxi=1\n\u03bbifi(x+) + \u03bdt (ax+ \u2212 b).\n\nthe last line follows from g(\u03bb, \u03bd) = f0(x) \u2212 m/t.\nm(\u00b5 \u2212 1 \u2212 log \u00b5)\n\nthe conclusion is that\n\n+ c\n\n\u03b3\n\n(11.26)\n\nis an upper bound on (11.25), and therefore an upper bound on the number of\nnewton steps required for one outer iteration of the barrier method. the function\n\u00b5 \u2212 1 \u2212 log \u00b5 is shown in figure 11.13. for small \u00b5 it is approximately quadratic;\nfor large \u00b5 it grows approximately linearly. this fits with our intuition that for \u00b5\nnear one, the number of newton steps required to center is small, whereas for large\n\u00b5, it could well grow.\n\nthe bound (11.26) shows that the number of newton steps required in each\ncentering step is bounded by a quantity that depends mostly on \u00b5, the factor by\nwhich t is updated in each outer step of the barrier method, and m, the number of\ninequality constraints in the problem. it also depends, weakly, on the parameters\n\u03b1 and \u03b2 used in the line search for the inner iterations, and in a very weak way\non the tolerance used to terminate the inner iterations. it is interesting to note\nthat the bound does not depend on n, the dimension of the variable, or p, the\nnumber of equality constraints, or the particular values of the problem data, i.e.,\nthe objective and constraint functions (provided the self-concordance assumption\nin \u00a711.5.1 holds). finally, we note that it does not depend on t; in particular, as\nt \u2192 \u221e, a uniform bound on the number of newton steps per outer iteration holds.\n\n "}, {"Page_number": 604, "text": "590\n\n11\n\ninterior-point methods\n\n11.5.3 total number of newton iterations\n\nwe can now give an upper bound on the total number of newton steps in the barrier\nmethod, not counting the initial centering step (which we will analyze later, as part\nof phase i). we multiply (11.26), which bounds the number of newton steps per\nouter iteration, by (11.13), the number of outer steps required, to obtain\n\nn =(cid:24) log(m/(t(0)\u01eb))\n\nlog \u00b5\n\n(cid:25)(cid:18) m(\u00b5 \u2212 1 \u2212 log \u00b5)\n\n\u03b3\n\n+ c(cid:19) ,\n\n(11.27)\n\nan upper bound on the total number of newton steps required. this formula\nshows that when the self-concordance assumption holds, we can bound the number\nof newton steps required by the barrier method, for any value of \u00b5 > 1.\n\nif we fix \u00b5 and m, the bound n is proportional to log(m/(t(0)\u01eb)), which is the\nlog of the ratio of the initial duality gap m/t(0) to the final duality gap \u01eb, i.e., the\nlog of the required duality gap reduction. we can therefore say that the barrier\nmethod converges at least linearly, since the number of steps required to reach a\ngiven precision grows logarithmically with the inverse of the precision.\n\nif \u00b5, and the required duality gap reduction factor, are fixed, the bound n grows\nlinearly with m, the number of inequalities. the bound n is independent of the\nother problem dimensions n and p, and the particular problem data or functions.\nwe will see below that by a particular choice of \u00b5, that depends on m, we can\nobtain a bound on the number of newton steps that grows only as \u221am, instead of\nas m.\n\nfinally, we analyze the bound n as a function of the algorithm parameter\n\u00b5. as \u00b5 approaches one, the first term in n grows large, and therefore so does\nn . this is consistent with our intuition and observation that for \u00b5 near one, the\nnumber of outer iterations is very large. as \u00b5 becomes large, the bound n grows\napproximately as \u00b5/ log \u00b5, this time because the bound on the number of newton\niterations required per outer iteration grows. this, too, is consistent with our\nobservations. as a result, the bound n has a minimum value as a function of \u00b5.\n\nthe variation of the bound with the parameter \u00b5 is illustrated in figure 11.14,\n\nwhich shows the bound (11.27) versus \u00b5 for the values\n\nc = 6,\n\n\u03b3 = 1/375,\n\nm/(t(0)\u01eb) = 105,\n\nm = 100.\n\nthe bound is qualitatively consistent with intuition, and our observations: it grows\nvery large as \u00b5 approaches one, and increases, more slowly, as \u00b5 becomes large. the\nbound n has a minimum at \u00b5 \u2248 1.02, which gives a bound on the total number\nof newton iterations around 8000. the complexity analysis of newton\u2019s method is\nconservative, but the basic trade-off in the choice of \u00b5 is reflected in the plot. (in\npractice, far larger values of \u00b5, from around 2 to 100, work very well, and require\na total number of newton iterations on the order of a few tens.)\n\nchoosing \u00b5 as a function of m\n\nwhen \u00b5 (and the required duality gap reduction) is fixed, the bound (11.27) grows\nlinearly with m, the number of inequalities. it turns out we can obtain a better\n\n "}, {"Page_number": 605, "text": "11.5 complexity analysis via self-concordance\n\n591\n\n5 104\n\n4 104\n\n3 104\n\n2 104\n\n1 104\n\nn\n\n0\n1\n\n1.1\n\u00b5\n\n1.2\n\nfigure 11.14 the upper bound n on the total number of newton iterations,\ngiven by equation (11.27), for c = 6, \u03b3 = 1/375, m = 100, and a duality gap\nreduction factor m/(t(0)\u01eb) = 105, versus the barrier algorithm parameter \u00b5.\n\nexponent for m by making \u00b5 a function of m. suppose we choose\n\n\u00b5 = 1 + 1/\u221am.\n\n(11.28)\n\nthen we can bound the second term in (11.27) as\n\n\u00b5 \u2212 1 \u2212 log \u00b5 = 1/\u221am \u2212 log(1 + 1/\u221am)\n\u2264 1/\u221am \u2212 1/\u221am + 1/(2m)\n\n= 1/(2m)\n\n(using \u2212 log(1 + a) \u2264 \u2212a + a2/2 for a \u2265 0). using concavity of the logarithm, we\nalso have\n\nusing these inequalities we can bound the total number of newton steps by\n\nn \u2264 (cid:24) log(m/(t(0)\u01eb))\n\nlog \u00b5 = log(1 + 1/\u221am) \u2265 (log 2)/\u221am.\n(cid:25)(cid:18) m(\u00b5 \u2212 1 \u2212 log \u00b5)\n(cid:25)(cid:18) 1\n\u2264 (cid:24)\u221am\n= l\u221am log2(m/(t(0)\u01eb))m(cid:18) 1\n\u2264 c1 + c2\u221am,\n\n+ c(cid:19)\n+ c(cid:19)\n\nlog \u00b5\nlog(m/(t(0)\u01eb))\n\nlog 2\n\n2\u03b3\n\n2\u03b3\n\n\u03b3\n\n+ c(cid:19)\n\n(11.29)\n\nwhere\n\nc1 =\n\n1\n2\u03b3\n\n+ c,\n\nc2 = log2(m/(t(0)\u01eb))(cid:18) 1\n\n2\u03b3\n\n+ c(cid:19) .\n\n "}, {"Page_number": 606, "text": "592\n\n11\n\ninterior-point methods\n\nhere c1 depends (and only weakly) on algorithm parameters for the centering\nnewton steps, and c2 depends on these and the required duality gap reduction.\nnote that the term log2(m/(t(0)\u01eb)) is exactly the number of bits of required duality\ngap reduction.\nfor fixed duality gap reduction, the bound (11.29) grows as \u221am, whereas the\nbound n in (11.27) grows like m, if the parameter \u00b5 is held constant. for this\nreason the barrier method, with parameter value (11.28), is said to be an order\n\u221am method.\nin practice, we would not use the value \u00b5 = 1 + 1/\u221am, which is far too small,\nor even decrease \u00b5 as a function of m. our only interest in this value of \u00b5 is that\nit (approximately) minimizes our (very conservative) upper bound on the number\nof newton steps, and yields an overall estimate that grows as \u221am, instead of m.\n\n11.5.4 feasibility problems\n\nin this section we analyze the complexity of a (minor) variation on the basic phase i\nmethod described in \u00a711.4.1, used to solve a set of convex inequalities,\n\nf1(x) \u2264 0,\n\n. . . ,\n\nfm(x) \u2264 0,\n\n(11.30)\n\nwhere f1, . . . , fm are convex, with continuous second derivatives. (we will consider\nequality constraints later.) we assume that the phase i problem\n\nminimize\nsubject to\n\ns\nfi(x) \u2264 s,\n\ni = 1, . . . , m\n\n(11.31)\n\nsatisfies the conditions in \u00a711.5.1. in particular we assume that the feasible set of\nthe inequalities (11.30) (which of course can be empty) is contained in a euclidean\nball of radius r:\n\n{x | fi(x) \u2264 0, i = 1, . . . , m} \u2286 {x | kxk2 \u2264 r}.\n\nwe can interpret r as a prior bound on the norm of any point in the feasible set of\nthe inequalities. this assumption implies that the sublevel sets of the phase i prob-\nlem are bounded. without loss of generality, we will start the phase i method at the\npoint x = 0. we define f = maxi fi(0), which is the maximum constraint violation,\nassumed to be positive (since otherwise x = 0 satisfies the inequalities (11.30)).\n\nwe define \u00afp\u22c6 as the optimal value of the phase i optimization problem (11.31).\nthe sign of \u00afp\u22c6 determines whether or not the set of inequalities (11.30) is feasible.\nthe magnitude of \u00afp\u22c6 also has a meaning. if \u00afp\u22c6 is positive and large (say, near f ,\nthe largest value it can have) it means that the set of inequalities is quite infeasible,\nin the sense that for each x, at least one of the inequalities is substantially violated\n(by at least \u00afp\u22c6). on the other hand, if \u00afp\u22c6 is negative and large, it means that\nthe set of inequalities is quite feasible, in the sense that there is not only an x for\nwhich fi(x) are all nonpositive, but in fact there is an x for which fi(x) are all quite\nnegative (no more than \u00afp\u22c6). thus, the magnitude |\u00afp\u22c6| is a measure of how clearly\nthe set of inequalities is feasible or infeasible, and therefore related to the difficulty\n\n "}, {"Page_number": 607, "text": "11.5 complexity analysis via self-concordance\n\n593\n\nof determining feasibility of the inequalities (11.30). in particular, if |\u00afp\u22c6| is small,\nit means the problem is near the boundary between feasibility and infeasibility.\nto determine feasibility of the inequalities, we use a variation on the basic\nphase i problem (11.31). we add a redundant linear inequality at x \u2264 1, to obtain\n\nminimize\nsubject to\n\ns\nfi(x) \u2264 s,\nat x \u2264 1.\n\ni = 1, . . . , m\n\n(11.32)\n\nwe will specify a later. our choice will satisfy kak2 \u2264 1/r, so kxk2 \u2264 r implies\nat x \u2264 1, i.e., the extra constraint is redundant.\nwe will choose a and s0 so that x = 0, s = s0 is on the central path of the\nproblem (11.32), with a parameter value t(0), i.e., they minimize\n\nt(0)s \u2212\n\nmxi=1\n\nlog(s \u2212 fi(x)) \u2212 log(1 \u2212 at x).\n\nsetting to zero the derivative with respect to s, we get\n\ns0 \u2212 fi(0)\nsetting to zero the gradient with respect to x yields\n\nt(0) =\n\nmxi=1\n\n1\n\n.\n\na = \u2212\n\nmxi=1\n\n1\n\ns0 \u2212 fi(0)\u2207fi(0).\n\n(11.33)\n\n(11.34)\n\nso it remains only to pick the parameter s0; once we have chosen s0, the vector a\nis given by (11.34), and the parameter t(0) is given by (11.33). since x = 0 and\ns = s0 must be strictly feasible for the phase i problem (11.32), we must choose\ns0 > f .\n\nwe must also pick s0 to make sure that kak2 \u2264 1/r. from (11.34), we have\n\nkak2 \u2264\n\nmxi=1\n\n1\n\ns0 \u2212 fi(0)k\u2207fi(0)k \u2264\n\nmg\ns0 \u2212 f\n\n,\n\nwhere g = maxi k\u2207fi(0)k2. therefore we can take s0 = mgr + f , which ensures\nkak2 \u2264 1/r, so the extra linear inequality is redundant.\n\nusing (11.33), we have\n\nt(0) =\n\nmxi=1\n\n1\n\nmgr + f \u2212 fi(0) \u2265\n\n1\n\nmgr\n\n,\n\nsince f = maxi fi(0). thus x = 0, s = s0 are on the central path for the phase i\nproblem (11.32), with initial duality gap\n\nm + 1\nt(0) \u2264 (m + 1)mgr.\n\n "}, {"Page_number": 608, "text": "594\n\n11\n\ninterior-point methods\n\nto solve the original inequalities (11.30) we need to determine the sign of \u00afp\u22c6.\nwe can stop when either the primal objective value of (11.32) is negative, or the\ndual objective value is positive. one of these two cases must occur when the duality\ngap for (11.32) is less than |\u00afp\u22c6|.\nwe use the barrier method to solve (11.32), starting from a central point with\nduality gap no more than (m + 1)mgr, and terminating when (or before) the\nduality gap is less than |\u00afp\u22c6|. using the results of the previous section, this requires\nno more than\n\n(cid:24)\u221am + 1 log2\n\nm(m + 1)gr\n\n(cid:25)(cid:18) 1\n\n+ c(cid:19)\n\n2\u03b3\n\n|\u00afp\u22c6|\n\n(11.35)\nnewton steps. (here we take \u00b5 = 1 + 1/\u221am + 1, which gives a better complexity\nexponent for m than a fixed value of \u00b5.)\nthe bound (11.35) grows only slightly faster than \u221am, and depends weakly on\nthe algorithm parameters used in the centering steps. it is approximately propor-\ntional to log2((gr)/|\u00afp\u22c6|), which can be interpreted as a measure of how difficult\nthe particular feasibility problem is, or how close it is to the boundary between\nfeasibility and infeasibility.\n\nfeasibility problems with equality constraints\n\nwe can apply the same analysis to feasibility problems that include equality con-\nstraints, by eliminating the equality constraints. this does not affect the self-\nconcordance of the problem, but it does mean that g and r refer to the reduced,\nor eliminated, problem.\n\n11.5.5 combined phase i/phase ii complexity\n\nin this section we give an end-to-end complexity analysis for solving the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b\n\ni = 1, . . . , m\n\nusing (a variation on) the barrier method. first we solve the phase i problem\n\nminimize\nsubject to\n\ns\nfi(x) \u2264 s,\nf0(x) \u2264 m\nax = b\nat x \u2264 1,\n\ni = 1, . . . , m\n\nwhich we assume satisfies the self-concordance and bounded sublevel set assump-\ntions of \u00a711.5.1. here we have added two redundant inequalities to the basic phase i\nproblem. the constraint f0(x) \u2264 m is added to guarantee that the phase i cen-\ntral path intersects the central path for phase ii, as described in section \u00a711.4.1\n(see (11.21)). the number m is a prior bound on the optimal value of the problem.\nthe second added constraint is the linear inequality at x \u2264 1, where a is chosen\n\n "}, {"Page_number": 609, "text": "11.5 complexity analysis via self-concordance\n\n595\n\nas described in \u00a711.5.4. we use the barrier method to solve this problem, with\n\u00b5 = 1 + 1/\u221am + 2, and the starting points x = 0, s = s0 given in \u00a711.5.4.\nto either find a strictly feasible point, or determine the problem is infeasible,\n\nrequires no more than\n\nni =(cid:24)\u221am + 2 log2\n\n(m + 1)(m + 2)gr\n\n|\u00afp\u22c6|\n\n(cid:25)(cid:18) 1\n\n2\u03b3\n\n+ c(cid:19)\n\n(11.36)\n\nnewton steps, where g and r are as given in 11.5.4. if the problem is infeasible\nwe are done; if it is feasible, then we find a point in phase i, associated with s = 0,\nthat lies on the central path of the phase ii problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b\nat x \u2264 1.\n\ni = 1, . . . , m\n\nthe associated initial duality gap of this initial point is no more than (m + 1)(m \u2212\np\u2217) (see (11.22)). we assume the phase ii problem also satisfies the the self-\nconcordance and bounded sublevel set assumptions in \u00a711.5.1.\nwe now proceed to phase ii, again using the barrier method. we must reduce\nthe duality gap from its initial value, which is no more than (m + 1)(m \u2212 p\u2217), to\nsome tolerance \u01eb > 0. this takes at most\n\nnii =(cid:24)\u221am + 1 log2\n\n(m + 1)(m \u2212 p\u22c6)\n\n\u01eb\n\n(cid:25)(cid:18) 1\n\n2\u03b3\n\n+ c(cid:19)\n\n(11.37)\n\nnewton steps.\nthe total number of newton steps is therefore no more than ni + nii. this\nbound grows with the number of inequalities m approximately as \u221am, and includes\ntwo terms that depend on the particular problem instance,\n\nlog2\n\n,\n\ngr\n|\u00afp\u22c6|\n\nlog2\n\nm \u2212 p\u22c6\n\n\u01eb\n\n.\n\n11.5.6 summary\n\nthe complexity analysis given in this section is mostly of theoretical interest. in\nparticular, we remind the reader that the choice \u00b5 = 1 + 1/\u221am, discussed in this\nsection, would be a very poor one to use in practice; its only advantage is that it\nresults in a bound that grows like \u221am instead of m. likewise, we do not recommend\nadding the redundant inequality at x \u2264 1 in practice.\nthe actual bounds obtained from the analysis given here are far higher than the\nnumbers of iterations actually observed. even the order in the bound appears to\nbe conservative. the best bounds on the number of newton steps grow like \u221am,\nwhereas practical experience suggests that the number of newton steps hardly\ngrows at all with m (or any other parameter, in fact).\n\nstill, it is comforting to know that when the self-concordance condition holds,\nwe can give a uniform bound on the number of newton steps required in each\n\n "}, {"Page_number": 610, "text": "596\n\n11\n\ninterior-point methods\n\ncentering step of the barrier method. an obvious potential pitfall of the barrier\nmethod is the possibility that as t grows, the associated centering problems might\nbecome more difficult, requiring more newton steps. while practical experience\nsuggests that this is not the case, the uniform bound bolsters our confidence that\nit cannot happen.\n\nfinally, we mention that it is not yet clear whether or not there is a practical\nadvantage to formulating a problem so that the self-concordance condition holds.\nall we can say is that when the self-concordance condition holds, the barrier method\nwill work well in practice, and we can give a worst case complexity bound.\n\n11.6 problems with generalized inequalities\n\nin this section we show how the barrier method can be extended to problems with\ngeneralized inequalities. we consider the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) (cid:22)ki 0,\nax = b,\n\ni = 1, . . . , m\n\n(11.38)\n\nwhere f0 : rn \u2192 r is convex, fi : rn \u2192 rki, i = 1, . . . , k, are ki-convex, and\nki \u2286 rki are proper cones. as in \u00a711.1, we assume that the functions fi are twice\ncontinuously differentiable, that a \u2208 rp\u00d7n with rank a = p, and that the problem\nis solvable.\n\nthe kkt conditions for problem (11.38) are\n\nax\u22c6\n=\nfi(x\u22c6) (cid:22)ki\n\u03bb\u22c6\ni (cid:23)k \u2217\ni + at \u03bd\u22c6\ni=1 dfi(x\u22c6)t \u03bb\u22c6\n=\nt fi(x\u22c6)\n\u03bb\u22c6\n=\ni\n\ni\n\n\u2207f0(x\u22c6) +pm\n\nb\n0,\n0,\n0\n0,\n\ni = 1, . . . , m\ni = 1, . . . , m\n\ni = 1, . . . , m,\n\n(11.39)\n\nwhere dfi(x\u22c6) \u2208 rki\u00d7n is the derivative of fi at x\u22c6. we will assume that prob-\nlem (11.38) is strictly feasible, so the kkt conditions are necessary and sufficient\nconditions for optimality of x\u22c6.\n\nthe development of the method is parallel to the case with scalar constraints.\nonce we develop a generalization of the logarithm function that applies to general\nproper cones, we can define a logarithmic barrier function for the problem (11.38).\nfrom that point on, the development is essentially the same as in the scalar case.\nin particular, the central path, barrier method, and complexity analysis are very\nsimilar.\n\n "}, {"Page_number": 611, "text": "11.6 problems with generalized inequalities\n\n597\n\n11.6.1 logarithmic barrier and central path\n\ngeneralized logarithm for a proper cone\nwe first define the analog of the logarithm, log x, for a proper cone k \u2286 rq. we\nsay that \u03c8 : rq \u2192 r is a generalized logarithm for k if\n\n\u2022 \u03c8 is concave, closed, twice continuously differentiable, dom \u03c8 = int k, and\n\n\u22072\u03c8(y) \u227a 0 for y \u2208 int k.\n\n\u2022 there is a constant \u03b8 > 0 such that for all y \u227bk 0, and all s > 0,\n\n\u03c8(sy) = \u03c8(y) + \u03b8 log s.\n\nin other words, \u03c8 behaves like a logarithm along any ray in the cone k.\n\nwe call the constant \u03b8 the degree of \u03c8 (since exp \u03c8 is a homogeneous function of\ndegree \u03b8). note that a generalized logarithm is only defined up to an additive\nconstant; if \u03c8 is a generalized logarithm for k, then so is \u03c8 + a, where a \u2208 r. the\nordinary logarithm is, of course, a generalized logarithm for r+.\nwe will use the following two properties, which are satisfied by any generalized\n\nlogarithm: if y \u227bk 0, then\n\n\u2207\u03c8(y) \u227bk \u2217 0,\nwhich implies \u03c8 is k-increasing (see \u00a73.6.1), and\nyt\u2207\u03c8(y) = \u03b8.\n\n(11.40)\n\nthe first property is proved in exercise 11.15. the second property follows imme-\ndiately from differentiating \u03c8(sy) = \u03c8(y) + \u03b8 log s with respect to s.\n\nexample 11.5 nonnegative orthant. the function \u03c8(x) =pn\n\n+, with degree n. for x \u227b 0,\n\nlogarithm for k = rn\n\ni=1 log xi is a generalized\n\n\u2207\u03c8(x) = (1/x1, . . . , 1/xn),\n\nso \u2207\u03c8(x) \u227b 0, and xt\u2207\u03c8(x) = n.\n\nexample 11.6 second-order cone. the function\n\nis a generalized logarithm for the second-order cone\n\n\u03c8(x) = log x2\nx \u2208 rn+1 (cid:12)(cid:12)(cid:12)(cid:12)(cid:12)(cid:12)\nk =\uf8f1\uf8f2\uf8f3\n\n  nxi=1\n\nn+1 \u2212\n\nx2\n\nnxi=1\n\ni!1/2\n\nx2\n\ni!\n\u2264 xn+1\uf8fc\uf8fd\uf8fe\n\n,\n\n "}, {"Page_number": 612, "text": "598\n\n11\n\ninterior-point methods\n\nwith degree 2. the gradient of \u03c8 at a point x \u2208 int k is given by\nj = 1, . . . , n\n\n\u2202\u03c8(x)\n\n\u22122xj\n\n=\n\n\u2202xj\n\n\u2202\u03c8(x)\n\u2202xn+1\n\n=\n\n2xn+1\n\n(cid:0)x2\nn+1 \u2212pn\n(cid:0)x2\nn+1 \u2212pn\n\ni=1 x2\n\ni=1 x2\n\ni(cid:1) ,\ni(cid:1) .\n\nthe identities \u2207\u03c8(x) \u2208 int k \u2217 = int k and xt\u2207\u03c8(x) = 2 are easily verified.\n\nexample 11.7 positive semidefinite cone. the function \u03c8(x) = log det x is a gen-\neralized logarithm for the cone sp\n\n+. the degree is p, since\n\nlog det(sx) = log det x + p log s\n\nfor s > 0. the gradient of \u03c8 at a point x \u2208 sp\n\n++ is equal to\n\n\u2207\u03c8(x) = x \u22121.\n\nthus, we have \u2207\u03c8(x) = x \u22121 \u227b 0, and the inner product of x and \u2207\u03c8(x) is equal\nto tr(xx \u22121) = p.\n\nlogarithmic barrier functions for generalized inequalities\n\nreturning to problem (11.38), let \u03c81, . . . , \u03c8m be generalized logarithms for the\ncones k1, . . . , km, respectively, with degrees \u03b81, . . . , \u03b8m. we define the logarithmic\nbarrier function for problem (11.38) as\n\n\u03c6(x) = \u2212\n\nmxi=1\n\n\u03c8i(\u2212fi(x)),\n\ndom \u03c6 = {x | fi(x) \u227a 0, i = 1, . . . , m}.\n\nconvexity of \u03c6 follows from the fact that the functions \u03c8i are ki-increasing, and\nthe functions fi are ki-convex (see the composition rule of \u00a73.6.2).\nthe central path\n\nthe next step is to define the central path for problem (11.38). we define the\ncentral point x\u22c6(t), for t \u2265 0, as the minimizer of tf0 + \u03c6, subject to ax = b, i.e.,\nas the solution of\n\nminimize\nsubject to ax = b\n\ntf0(x) \u2212pm\n\ni=1 \u03c8i(\u2212fi(x))\n\n(assuming the minimizer exists, and is unique). central points are characterized\nby the optimality condition\n\nt\u2207f0(x) + \u2207\u03c6(x) + at \u03bd\nmxi=1\n\n= t\u2207f0(x) +\n\ndfi(x)t\u2207\u03c8i(\u2212fi(x)) + at \u03bd = 0,\n\n(11.41)\n\nfor some \u03bd \u2208 rp, where dfi(x) is the derivative of fi at x.\n\n "}, {"Page_number": 613, "text": "11.6 problems with generalized inequalities\n\n599\n\ndual points on central path\n\nas in the scalar case, points on the central path give dual feasible points for the\nproblem (11.38). for i = 1, . . . , m, define\n\n\u03bb\u22c6\ni (t) =\n\n1\nt \u2207\u03c8i(\u2212fi(x\u22c6(t))),\n\n(11.42)\n\nand let \u03bd\u22c6(t) = \u03bd/t, where \u03bd is the optimal dual variable in (11.41). we will\nshow that \u03bb\u22c6\nm(t), together with \u03bd\u22c6(t), are dual feasible for the original\nproblem (11.38).\n\n1(t), . . . , \u03bb\u22c6\n\nfirst, \u03bb\u22c6\n\ni (t) \u227bk \u2217\n\ni\n\nrithms. second, it follows from (11.41) that the lagrangian\n\n0, by the monotonicity property (11.40) of generalized loga-\n\nl(x, \u03bb\u22c6(t), \u03bd\u22c6(t)) = f0(x) +\n\nmxi=1\n\ni (t)t fi(x) + \u03bd\u22c6(t)t (ax \u2212 b)\n\u03bb\u22c6\n\nis minimized over x by x = x\u22c6(t). the dual function g evaluated at (\u03bb\u22c6(t), \u03bd\u22c6(t))\nis therefore equal to\n\ng(\u03bb\u22c6(t), \u03bd\u22c6(t)) = f0(x\u22c6(t)) +\n\nmxi=1\n\n= f0(x\u22c6(t)) + (1/t)\n\n= f0(x\u22c6(t)) \u2212 (1/t)\n\n\u2207\u03c8i(\u2212fi(x\u22c6(t)))t fi(x\u22c6(t))\n\ni (t)t fi(x\u22c6(t)) + \u03bd\u22c6(t)t (ax\u22c6(t) \u2212 b)\n\u03bb\u22c6\nmxi=1\nmxi=1\n\n\u03b8i,\n\nwhere \u03b8i is the degree of \u03c8i. in the last line, we use the fact that yt\u2207\u03c8i(y) = \u03b8i\nfor y \u227bki 0, and therefore\n\ni = 1, . . . , m.\n\n(11.43)\n\nthus, if we define\n\ni (t)t fi(x\u22c6(t)) = \u2212\u03b8i/t,\n\u03bb\u22c6\nmxi=1\n\n\u03b8 =\n\n\u03b8i,\n\nthen the primal feasible point x\u22c6(t) and the dual feasible point (\u03bb\u22c6(t), \u03bd\u22c6(t)) have\nduality gap \u03b8/t. this is just like the scalar case, except that \u03b8, the sum of the\ndegrees of the generalized logarithms for the cones, appears in place of m, the\nnumber of inequalities.\n\nexample 11.8 second-order cone programming. we consider an socp with variable\nx \u2208 rn:\n\nminimize\nsubject to\n\nf t x\nkaix + bik2 \u2264 ct\n\ni = 1, . . . , m,\nwhere ai \u2208 rni\u00d7n. as we have seen in example 11.6, the function\n\ni x + di,\n\n(11.44)\n\n\u03c8(y) = log y2\n\np+1 \u2212\n\ni!\n\ny2\n\npxi=1\n\n "}, {"Page_number": 614, "text": "600\n\n11\n\ninterior-point methods\n\nis a generalized logarithm for the second-order cone in rp+1, with degree 2. the\ncorresponding logarithmic barrier function for (11.44) is\n\n\u03c6(x) = \u2212\n\nlog((ct\n\ni x + di)2 \u2212 kaix + bik2\n2),\n\n(11.45)\n\nmxi=1\n\nwith dom \u03c6 = {x | kaix + bik2 < ct\non the central path is tf + \u2207\u03c6(x\u22c6(t)) = 0, where\n\ni x + di, i = 1, . . . , m}. the optimality condition\n\n\u2207\u03c6(x) = \u22122\n\nmxi=1\n\nit follows that the point\n\n1\n\ni x + di)2 \u2212 kaix + bik2\n(ct\n\n2(cid:0)(ct\n\ni x + di)ci \u2212 at\n\ni (aix + bi)(cid:1) .\n\nz\u22c6\ni (t) = \u2212\nwhere \u03b1i = (ct\n\n(ct\n\ni x\u22c6(t) + di),\n\ni = 1, . . . , m,\n\n2, is strictly feasible in the dual problem\n\n2\nt\u03b1i\n\nw\u22c6\n\ni (t) =\n\n(aix\u22c6(t) + bi),\n\n2\nt\u03b1i\ni x\u22c6(t) + di)2 \u2212 kaix\u22c6(t) + bik2\ni=1(bt\ni=1(at\nkzik2 \u2264 wi,\n\nmaximize \u2212pm\nsubject to pm\nmxi=1(cid:0)(aix\u22c6(t) + bi)t z\u22c6\n\ni (t) + (ct\n\ni zi + diwi)\n\ni zi + ciwi) = f\n\ni = 1, . . . , m.\n\ni x\u22c6(t) + di)w\u22c6\n\n2m\n\nt\n\n,\n\ni (t)(cid:1) =\n\nthe duality gap associated with x\u22c6(t) and (z\u22c6(t), w\u22c6(t)) is\n\nwhich agrees with the general formula \u03b8/t, since \u03b8i = 2.\n\nexample 11.9 semidefinite programming in inequality form. we consider the sdp\nwith variable x \u2208 rn,\n\nct x\n\nminimize\nsubject to f (x) = x1f1 + \u00b7\u00b7\u00b7 + xnfn + g (cid:22) 0,\n\nwhere g, f1, . . . , fn \u2208 sp. the dual problem is\n\nmaximize\nsubject to\n\ntr(gz)\ntr(fiz) + ci = 0,\nz (cid:23) 0.\n\ni = 1, . . . , n\n\nusing the generalized logarithm log det x for the positive semidefinite cone sp\nhave the barrier function (for the primal problem)\n\n+, we\n\n\u03c6(x) = log det(\u2212f (x)\u22121)\n\nwith dom \u03c6 = {x | f (x) \u227a 0}. for strictly feasible x, the gradient of \u03c6 is equal to\n\n\u2202\u03c6(x)\n\n\u2202xi\n\n= tr(\u2212f (x)\u22121fi),\n\ni = 1, . . . , n,\n\nwhich gives us the optimality conditions that characterize central points:\n\ntci + tr(\u2212f (x\u22c6(t))\u22121fi) = 0,\n\ni = 1, . . . , n.\n\nhence the matrix\n\nz \u22c6(t) =\n\n1\nt\n\n(\u2212f (x\u22c6(t)))\u22121\n\nis strictly dual feasible, and the duality gap associated with x\u22c6(t) and z \u22c6(t) is p/t.\n\n "}, {"Page_number": 615, "text": "11.6 problems with generalized inequalities\n\n601\n\n11.6.2 barrier method\n\nwe have seen that the key properties of the central path generalize to problems\nwith generalized inequalities.\n\n\u2022 computing a point on the central path involves minimizing a twice differ-\nentiable convex function subject to equality constraints (which can be done\nusing newton\u2019s method).\n\n\u2022 with the central point x\u22c6(t) we can associate a dual feasible point (\u03bb\u22c6(t), \u03bd\u22c6(t))\nin particular, x\u22c6(t) is no more than \u03b8/t-\n\nwith associated duality gap \u03b8/t.\nsuboptimal.\n\nthis means we can apply the barrier method, exactly as described in \u00a711.3, to the\nproblem (11.38). the number of outer iterations, or centering steps, required to\ncompute a central point with duality gap \u01eb starting at x\u22c6(t(0)) is equal to\n\n(cid:24) log(\u03b8/(t(0)\u01eb))\n\nlog \u00b5\n\n(cid:25) ,\n\nplus one initial centering step. the only difference between this result and the\nassociated one for the scalar case is that \u03b8 takes the place of m.\n\nphase i and feasibility problems\nthe phase i methods described in \u00a711.4 are readily extended to problems with\ngeneralized inequalities. let ei \u227bki 0 be some given, ki-positive vectors, for\ni = 1, . . . , m. to determine feasibility of the equalities and generalized inequalities\n\nf1(x) (cid:22)k1 0,\n\n. . . ,\n\nfl(x) (cid:22)km 0,\n\nax = b,\n\nwe solve the problem\n\nminimize\nsubject to\n\ns\nfi(x) (cid:22)ki sei,\nax = b,\n\ni = 1, . . . , m\n\nwith variables x and s \u2208 r. the optimal value \u00afp\u22c6 determines the feasibility\nof the equalities and generalized inequalities, exactly as in the case of ordinary\ninequalities. when \u00afp\u22c6 is positive, any dual feasible point with positive objective\ngives an alternative that proves the set of equalities and generalized inequalities is\ninfeasible (see page 270).\n\n11.6.3 examples\n\na small socp\n\nwe solve an socp\n\nminimize\nsubject to\n\nf t x\nkaix + bik2 \u2264 ct\n\ni x + di,\n\ni = 1, . . . , m,\n\n "}, {"Page_number": 616, "text": "602\n\n11\n\ninterior-point methods\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n102\n\n100\n\n10\u22122\n\n10\u22124\n\n10\u22126\n\n\u00b5 = 50 \u00b5 = 200\n\n\u00b5 = 2\n\n0\n\n20\n\n40\n\n60\nnewton iterations\n\n80\n\nfigure 11.15 progress of barrier method for an socp, showing duality gap\nversus cumulative number of newton steps.\n\nwith x \u2208 r50, m = 50, and ai \u2208 r5\u00d750. the problem instance was randomly\ngenerated, in such a way that the problem is strictly primal and dual feasible, and\nhas optimal value p\u22c6 = 1. we start with a point x(0) on the central path, with a\nduality gap of 100.\n\nthe barrier method is used to solve the problem, using the barrier function\n\n\u03c6(x) = \u2212\n\nmxi=1\n\nlog(cid:0)(ct\n\n2(cid:1) .\ni x + di)2 \u2212 kaix + bik2\n\nthe centering problems are solved using newton\u2019s method, with the same algorithm\nparameters as in the examples of \u00a711.3.2: backtracking parameters \u03b1 = 0.01, \u03b2 =\n0.5, and a stopping criterion \u03bb(x)2/2 \u2264 10\u22125.\nfigure 11.15 shows the duality gap versus cumulative number of newton steps.\nthe plot is very similar to those for linear and geometric programming, shown\nin figures 11.4 and 11.6, respectively. we see an approximately constant number\nof newton steps required per centering step, and therefore approximately linear\nconvergence of the duality gap. for this example, too, the choice of \u00b5 has little\neffect on the total number of newton steps, provided \u00b5 is at least 10 or so. as in\nthe examples for linear and geometric programming, a reasonable choice of \u00b5 is in\nthe range 10 \u2013 100, which results in a total number of newton steps around 30 (see\nfigure 11.16).\n\na small sdp\n\nour next example is an sdp\n\nct x\n\nminimize\n\nsubject to pn\n\ni=1 xifi + g (cid:22) 0\n\n(11.46)\n\n "}, {"Page_number": 617, "text": "11.6 problems with generalized inequalities\n\n603\n\n140\n\n120\n\n100\n\n80\n\n60\n\n40\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n0\n0\n\n40\n\n80\n\n\u00b5\n\n120\n\n160\n\n200\n\nfigure 11.16 trade-off in the choice of the parameter \u00b5, for a small socp.\nthe vertical axis shows the total number of newton steps required to reduce\nthe duality gap from 100 to 10\u22123, and the horizontal axis shows \u00b5.\n\nwith variable x \u2208 r100, and fi \u2208 s100, g \u2208 s100. the problem instance was\ngenerated randomly, in such a way that the problem is strictly primal and dual\nfeasible, with p\u22c6 = 1. the initial point is on the central path, with a duality gap\nof 100.\n\nwe apply the barrier method with logarithmic barrier function\n\n\u03c6(x) = \u2212 log det \u2212\n\nxifi \u2212 g! .\n\nnxi=1\n\nthe progress of the barrier method for three values of \u00b5 is shown in figure 11.17.\nnote the similarity with the plots for linear, geometric, and second-order cone\nprogramming, shown in figures 11.4, 11.6, and 11.15. as in the other examples,\nthe parameter \u00b5 has only a small effect on the efficiency, provided it is not too\nsmall. the number of newton steps required to reduce the duality gap by a factor\n105, versus \u00b5, is shown in figure 11.18.\n\na family of sdps\n\nin this section we examine the performance of the barrier method as a function of\nthe problem dimensions. we consider a family of sdps of the form\n\n1t x\n\nminimize\nsubject to a + diag(x) (cid:23) 0,\n\n(11.47)\n\nwith variable x \u2208 rn, and parameter a \u2208 sn. the matrices a are generated as\nfollows. for i \u2265 j, the coefficients aij are generated from independent n (0, 1)\ndistributions. for i < j, we set aij = aji, so a \u2208 sn. we then scale a so that its\n(spectral) norm is one.\n\n "}, {"Page_number": 618, "text": "604\n\n11\n\ninterior-point methods\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n102\n\n100\n\n10\u22122\n\n10\u22124\n\n10\u22126\n\n\u00b5 = 150\n\n\u00b5 = 50\n\n\u00b5 = 2\n\n0\n\n20\n\n40\n\n60\n\nnewton iterations\n\n80\n\n100\n\nfigure 11.17 progress of barrier method for a small sdp, showing duality\ngap versus cumulative number of newton steps. three plots are shown,\ncorresponding to three values of the parameter \u00b5: 2, 50, and 150.\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n140\n\n120\n\n100\n\n80\n\n60\n\n40\n\n20\n\n0\n0\n\n20\n\n40\n\n60\n\u00b5\n\n80\n\n100\n\n120\n\nfigure 11.18 trade-off in the choice of the parameter \u00b5, for a small sdp.\nthe vertical axis shows the total number of newton steps required to reduce\nthe duality gap from 100 to 10\u22123, and the horizontal axis shows \u00b5.\n\n "}, {"Page_number": 619, "text": "11.6 problems with generalized inequalities\n\n605\n\n105\n\np\na\ng\n\ny\nt\ni\nl\na\nu\nd\n\n100\n\n10\u22125\n0\n\n10\n\n20\n\n30\n\n40\n\n50\n\nnewton iterations\n\nn = 50 n = 500\n\nn = 1000\n\nfigure 11.19 progress of barrier method for three randomly generated sdps\nof the form (11.47), with different dimensions. the plot shows duality gap\nversus cumulative number of newton steps. the number of variables in each\nproblem is n.\n\nthe algorithm parameters are \u00b5 = 20, and the same parameters for the center-\ning steps as in the examples above: backtracking parameters \u03b1 = 0.01, \u03b2 = 0.5,\nand stopping criterion \u03bb(x)2/2 \u2264 10\u22125. the initial point is on the central path\nwith t(0) = 1 (i.e., gap n). the algorithm is terminated when the initial duality\ngap is reduced by a factor 8000, i.e., after completing three outer iterations.\n\nfigure 11.19 shows the duality gap versus iteration number for three problem\ninstances, with dimensions n = 50, n = 500, and n = 1000. the plots look very\nmuch like the others, and very much like the ones for lps.\n\nto examine the effect of problem size on the number of newton steps required,\nwe generate 100 problem instances for each of 20 values of n, ranging from n = 10\nto n = 1000. we solve each of these 2000 problems using the barrier method, noting\nthe number of newton steps required. the results are summarized in figure 11.20,\nwhich shows the mean and standard deviation in the number of newton steps, for\neach value of n. the plot looks very much like the one for lps, shown in figure 11.8.\nin particular, the number of newton steps required grows very slowly, from around\n20 to 26 iterations, as the problem dimensions increase by a factor of 100.\n\n11.6.4 complexity analysis via self-concordance\n\nin this section we extend the complexity analysis of the barrier method for problems\nwith ordinary inequalities (given in \u00a711.5), to problems with generalized inequali-\nties. we have already seen that the number of outer iterations is given by\n\n(cid:24) log(\u03b8/t(0)\u01eb)\n\nlog \u00b5\n\n(cid:25) ,\n\n "}, {"Page_number": 620, "text": "606\n\n11\n\ninterior-point methods\n\n35\n\n30\n\n25\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\nn\no\nt\nw\ne\nn\n\n15\n\n101\n\n102\nn\n\n103\n\nfigure 11.20 average number of newton steps required to solve 100 ran-\ndomly generated sdps (11.47) for each of 20 values of n, the problem size.\nerror bars show standard deviation, around the average value, for each value\nof n. the growth in the average number of newton steps required, as the\nproblem dimensions range over a 100 : 1 ratio, is very small.\n\nplus one initial centering step. it remains to bound the number of newton steps\nrequired in each centering step, which we will do using the complexity theory of\nnewton\u2019s method for self-concordant functions. for simplicity, we will exclude the\ncost of the initial centering.\n\nwe make the same assumptions as in \u00a711.5: the function tf0 + \u03c6 is closed and\n\nself-concordant for all t \u2265 t(0), and the sublevel sets of (11.38) are bounded.\n\nexample 11.10 second-order cone programming. the function\n\n\u2212\u03c8(x) = \u2212 log x2\n\np+1 \u2212\n\ni! ,\n\nx2\n\npxi=1\n\nis self-concordant (see example 9.8), so the logarithmic barrier function (11.45) sat-\nisfies the closedness and self-concordance assumption for the socp (11.44).\n\nexample 11.11 semidefinite programming. the self-concordance assumption holds\nfor general semidefinite programs, using log det x as generalized logarithm for the\npositive semidefinite cone. for example, for the standard form sdp\n\nminimize\nsubject to\n\ntr(cx)\ntr(aix) = bi,\nx (cid:23) 0,\n\ni = 1, . . . , p\n\nwith variable x \u2208 sn, the function t(0) tr(cx) \u2212 log det x is self-concordant (and\nclosed), for any t(0) \u2265 0.\n\n "}, {"Page_number": 621, "text": "11.6 problems with generalized inequalities\n\n607\n\nwe will see that, exactly as in the scalar case, we have\n\n\u00b5tf0(x\u22c6(t)) + \u03c6(x\u22c6(t)) \u2212 \u00b5tf0(x\u22c6(\u00b5t)) \u2212 \u03c6(x\u22c6(\u00b5t)) \u2264 \u03b8(\u00b5 \u2212 1 \u2212 log \u00b5).\n\n(11.48)\n\ntherefore when the self-concordance and bounded sublevel set conditions hold, the\nnumber of newton steps per centering step is no more than\n\n\u03b8(\u00b5 \u2212 1 \u2212 log \u00b5)\n\n\u03b3\n\n+ c,\n\nexactly as in the barrier method for problems with ordinary inequalities. once\nwe establish the basic bound (11.48), the complexity analysis for problems with\ngeneralized inequalities is identical to the analysis for problems with ordinary in-\nequalities, with one exception: \u03b8 is the sum of the degrees of the cones, instead of\nthe number of inequalities.\n\ngeneralized logarithm for dual cone\n\nwe will use conjugates to prove the bound (11.48). let \u03c8 be a generalized logarithm\nfor the proper cone k, with degree \u03b8. the conjugate of the (convex) function \u2212\u03c8\nis\n\n(\u2212\u03c8)\u2217(v) = sup\n\nu (cid:0)vt u + \u03c8(u)(cid:1) .\n\nthis function is convex, and has domain \u2212k \u2217 = {v | v \u227ak \u2217 0}. define \u03c8 by\n\n\u03c8(v) = \u2212(\u2212\u03c8)\u2217(\u2212v) = inf\n\nu (cid:0)vt u \u2212 \u03c8(u)(cid:1) ,\n\ndom \u03c8 = int k \u2217.\n\n(11.49)\n\nthe function \u03c8 is concave, and in fact is a generalized logarithm for the dual cone\nk \u2217, with the same parameter \u03b8 (see exercise 11.17). we call \u03c8 the dual logarithm\nassociated with the generalized logarithm \u03c8.\n\nfrom (11.49) we obtain the inequality\n\n\u03c8(v) + \u03c8(u) \u2264 ut v,\n\n(11.50)\n\nwhich holds for any u \u227bk 0, v \u227bk \u2217 0, with equality holding if and only \u2207\u03c8(u) = v\n(or equivalently, \u2207\u03c8(v) = u).\n(this inequality is just a variation on young\u2019s\ninequality, for concave functions.)\n\np+1 \u2212pp\n\nexample 11.12 second-order cone. the second-order cone has generalized logarithm\n\u03c8(x) = log(x2\ni=1 x2\ni )1/2}. the\nassociated dual logarithm is\n\ni=1 x2\n\ni ), with dom \u03c8 = {x \u2208 rp+1 | xp+1 > (pp\n\u03c8(y) = log y2\n\ni! + 2 \u2212 log 4,\n\ny2\n\npxi=1\nwith dom \u03c8 = {y \u2208 rp+1 | yp+1 > (pp\n\np+1 \u2212\n\ni )1/2} (see exercise 3.36). except for\na constant, it is the same as the original generalized logarithm for the second-order\ncone.\n\ni=1 y2\n\n "}, {"Page_number": 622, "text": "608\n\n11\n\ninterior-point methods\n\nexample 11.13 positive semidefinite cone. the dual logarithm associated with\n\u03c8(x) = log det x, with dom \u03c8 = sp\n\n++, is\n\n\u03c8(y ) = log det y + p,\n\nwith domain dom \u03c8\u2217 = sp\nlogarithm, except for a constant.\n\n++ (see example 3.23). again, it is the same generalized\n\nderivation of the basic bound\n\nto simplify notation, we denote x\u22c6(t) as x, x\u22c6(\u00b5t) as x+, \u03bb\u22c6\n\u03bd. from t\u03bbi = \u2207\u03c8i(\u2212fi(x)) (in (11.42)) and property (11.43), we conclude that\n\ni (t) as \u03bbi, and \u03bd\u22c6(t) as\n\n\u03c8i(\u2212fi(x)) + \u03c8i(t\u03bbi) = \u2212t\u03bbt\n\ni fi(x) = \u03b8i,\n\n(11.51)\n\ni.e., the inequality (11.50) holds with equality for the pair u = \u2212fi(x) and v = t\u03bbi.\nthe same inequality for the pair u = \u2212fi(x+), v = \u00b5t\u03bbi gives\ni fi(x+),\n\n\u03c8i(\u2212fi(x+)) + \u03c8i(\u00b5t\u03bbi) \u2264 \u2212\u00b5t\u03bbt\nwhich becomes, using logarithmic homogeneity of \u03c8i,\n\n\u03c8i(\u2212fi(x+)) + \u03c8i(t\u03bbi) + \u03b8i log \u00b5 \u2264 \u2212\u00b5t\u03bbt\n\ni fi(x+).\n\nsubtracting the equality (11.51) from this inequality, we get\n\n\u2212\u03c8i(\u2212fi(x)) + \u03c8i(\u2212fi(x+)) + \u03b8i log \u00b5 \u2264 \u2212\u03b8i \u2212 \u00b5t\u03bbt\n\ni fi(x+),\n\nand summing over i yields\n\n\u03c6(x) \u2212 \u03c6(x+) + \u03b8 log \u00b5 \u2264 \u2212\u03b8 \u2212 \u00b5t\n\nmxi=1\n\n\u03bbt\ni fi(x+).\n\n(11.52)\n\nwe also have, from the definition of the dual function,\n\nf0(x) \u2212 \u03b8/t = g(\u03bb, \u03bd)\n\n\u2264 f0(x+) +\n\n= f0(x+) +\n\n\u03bbt\ni fi(x+) + \u03bdt (ax+ \u2212 b)\n\n\u03bbt\ni fi(x+).\n\nmxi=1\nmxi=1\n\nmultiplying this inequality by \u00b5t and adding to the inequality (11.52), we get\n\n\u03c6(x) \u2212 \u03c6(x+) + \u03b8 log \u00b5 + \u00b5tf0(x) \u2212 \u00b5\u03b8 \u2264 \u00b5tf0(x+) \u2212 \u03b8,\n\nwhich when re-arranged gives\n\n\u00b5tf0(x) + \u03c6(x) \u2212 \u00b5tf0(x+) \u2212 \u03c6(x+) \u2264 \u03b8(\u00b5 \u2212 1 \u2212 log \u00b5),\n\nthe desired inequality (11.48).\n\n "}, {"Page_number": 623, "text": "11.7 primal-dual interior-point methods\n\n609\n\n11.7 primal-dual interior-point methods\n\nin this section we describe a basic primal-dual interior-point method. primal-\ndual interior-point methods are very similar to the barrier method, with some\ndifferences.\n\n\u2022 there is only one loop or iteration, i.e., there is no distinction between inner\nand outer iterations as in the barrier method. at each iteration, both the\nprimal and dual variables are updated.\n\n\u2022 the search directions in a primal-dual interior-point method are obtained\nfrom newton\u2019s method, applied to modified kkt equations (i.e., the opti-\nmality conditions for the logarithmic barrier centering problem). the primal-\ndual search directions are similar to, but not quite the same as, the search\ndirections that arise in the barrier method.\n\n\u2022 in a primal-dual interior-point method, the primal and dual iterates are not\n\nnecessarily feasible.\n\nprimal-dual interior-point methods are often more efficient than the barrier\nmethod, especially when high accuracy is required, since they can exhibit better\nthan linear convergence. for several basic problem classes, such as linear, quadratic,\nsecond-order cone, geometric, and semidefinite programming, customized primal-\ndual methods outperform the barrier method. for general nonlinear convex op-\ntimization problems, primal-dual interior-point methods are still a topic of active\nresearch, but show great promise. another advantage of primal-dual algorithms\nover the barrier method is that they can work when the problem is feasible, but\nnot strictly feasible (although we will not pursue this).\n\nin this section we present a basic primal-dual method for (11.1), without conver-\ngence analysis. we refer the reader to the references for a more thorough treatment\nof primal-dual methods and their convergence analysis.\n\n11.7.1 primal-dual search direction\n\nas in the barrier method, we start with the modified kkt conditions (11.15),\nexpressed as rt(x, \u03bb, \u03bd) = 0, where we define\n\nand t > 0. here f : rn \u2192 rm and its derivative matrix df are given by\n\n\u2207f0(x) + df (x)t \u03bb + at \u03bd\n\u2212 diag(\u03bb)f (x) \u2212 (1/t)1\n\nax \u2212 b\n\n(11.53)\n\nrt(x, \u03bb, \u03bd) =\uf8ee\uf8f0\nf (x) =\uf8ee\uf8ef\uf8f0\n\nfm(x)\n\nf1(x)\n\n...\n\n\uf8f9\uf8fa\uf8fb ,\n\n\uf8f9\uf8fb ,\n\uf8f9\uf8fa\uf8fb .\n\ndf (x) =\uf8ee\uf8ef\uf8f0\n\n\u2207f1(x)t\n\n...\n\n\u2207fm(x)t\n\nif x, \u03bb, \u03bd satisfy rt(x, \u03bb, \u03bd) = 0 (and fi(x) < 0), then x = x\u22c6(t), \u03bb = \u03bb\u22c6(t), and\n\u03bd = \u03bd\u22c6(t).\nin particular, x is primal feasible, and \u03bb, \u03bd are dual feasible, with\n\n "}, {"Page_number": 624, "text": "610\n\n11\n\ninterior-point methods\n\nduality gap m/t. the first block component of rt,\n\nrdual = \u2207f0(x) + df (x)t \u03bb + at \u03bd,\n\nis called the dual residual, and the last block component, rpri = ax \u2212 b, is called\nthe primal residual. the middle block,\n\nrcent = \u2212 diag(\u03bb)f (x) \u2212 (1/t)1,\n\nis the centrality residual, i.e., the residual for the modified complementarity condi-\ntion.\n\nnow consider the newton step for solving the nonlinear equations rt(x, \u03bb, \u03bd) =\n0, for fixed t (without first eliminating \u03bb, as in \u00a711.3.4), at a point (x, \u03bb, \u03bd) that\nsatisifes f (x) \u227a 0, \u03bb \u227b 0. we will denote the current point and newton step as\n\ny = (x, \u03bb, \u03bd),\n\n\u2206y = (\u2206x, \u2206\u03bb, \u2206\u03bd),\n\nrespectively. the newton step is characterized by the linear equations\n\nrt(y + \u2206y) \u2248 rt(y) + drt(y)\u2206y = 0,\ni.e., \u2206y = \u2212drt(y)\u22121rt(y). in terms of x, \u03bb, and \u03bd, we have\n\u2206x\n\u2206\u03bb\n\ndf (x)t\n\n\u22072f0(x) +pm\n\n\u2212 diag(\u03bb)df (x)\n\ni=1 \u03bbi\u22072fi(x)\na\n\n\u2212 diag(f (x))\n\nat\n0\n\n0\n\n\uf8ee\uf8f0\n\n0 \uf8f9\uf8fb\uf8ee\uf8f0\n\n\u2206\u03bd \uf8f9\uf8fb = \u2212\uf8ee\uf8f0\n\nrdual\nrcent\nrpri\n\n\uf8f9\uf8fb .\n\n(11.54)\nthe primal-dual search direction \u2206ypd = (\u2206xpd, \u2206\u03bbpd, \u2206\u03bdpd) is defined as the\nsolution of (11.54).\n\nthe primal and dual search directions are coupled, both through the coefficient\nmatrix and the residuals. for example, the primal search direction \u2206xpd depends\non the current value of the dual variables \u03bb and \u03bd, as well as x. we note also that\nif x satisfies ax = b, i.e., the primal feasibility residual rpri is zero, then we have\na\u2206xpd = 0, so \u2206xpd defines a (primal) feasible direction: for any s, x + s\u2206xpd\nwill satisfy a(x + s\u2206xpd) = b.\n\ncomparison with barrier method search directions\n\nthe primal-dual search directions are closely related to the search directions used\nin the barrier method, but not quite the same. we start with the linear equa-\ntions (11.54) that define the primal-dual search directions. we eliminate the vari-\nable \u2206\u03bbpd, using\n\n\u2206\u03bbpd = \u2212 diag(f (x))\u22121 diag(\u03bb)df (x)\u2206xpd + diag(f (x))\u22121rcent,\n\nwhich comes from the second block of equations. substituting this into the first\nblock of equations gives\n\na\n\n0 (cid:21)(cid:20) \u2206xpd\n\u2206\u03bdpd (cid:21)\n\n(cid:20) hpd at\n= \u2212(cid:20) rdual + df (x)t diag(f (x))\u22121rcent\n= \u2212(cid:20) \u2207f0(x) + (1/t)pm\n\nrpri\n\nrpri\n\ni=1\n\n1\n\n(cid:21)\n\n\u2212fi(x)\u2207fi(x) + at \u03bd\n\n(cid:21) ,\n\n(11.55)\n\n "}, {"Page_number": 625, "text": "11.7 primal-dual interior-point methods\n\n611\n\nwhere\n\nhpd = \u22072f0(x) +\n\nmxi=1\n\n\u03bbi\u22072fi(x) +\n\nmxi=1\n\n\u03bbi\n\n\u2212fi(x)\u2207fi(x)\u2207fi(x)t .\n\n(11.56)\n\nwe can compare (11.55) to the equation (11.14), which defines the newton step\nfor the centering problem in the barrier method with parameter t. this equation\ncan be written as\n\n(cid:21)\n\na\n\nrpri\n\n0 (cid:21)(cid:20) \u2206xbar\n\u03bdbar (cid:21)\n(cid:20) hbar at\n= \u2212(cid:20) t\u2207f0(x) + \u2207\u03c6(x)\n= \u2212(cid:20) t\u2207f0(x) +pm\nmxi=1\n\n\u2212fi(x)\u22072fi(x) +\n\ni=1\nrpri\n\n1\n\nmxi=1\n\nwhere\n\nhbar = t\u22072f0(x) +\n\n1\n\n\u2212fi(x)\u2207fi(x)\n\n(cid:21) ,\n\n(11.57)\n\n1\n\nfi(x)2\u2207fi(x)\u2207fi(x)t .\n\n(11.58)\n\n(here we give the general expression for the infeasible newton step; if the current x\nis feasible, i.e., rpri = 0, then \u2206xbar coincides with the feasible newton step \u2206xnt\ndefined in (11.14).)\n\nour first observation is that the two systems of equations (11.55) and (11.57)\nare very similar. the coefficient matrices in (11.55) and (11.57) have the same\nstructure; indeed, the matrices hpd and hbar are both positive linear combinations\nof the matrices\n\u2207f1(x)\u2207f1(x)t , . . . ,\u2207fm(x)\u2207fm(x)t .\n\u22072f0(x),\nthis means that the same method can be used to compute the primal-dual search\ndirections and the barrier method newton step.\n\n\u22072f1(x), . . . ,\u22072fm(x),\n\nwe can say more about the relation between the primal-dual equations (11.55)\nand the barrier method equations (11.57). suppose we divide the first block of\nequation (11.57) by t, and define the variable \u2206\u03bdbar = (1/t)\u03bdbar \u2212 \u03bd (where \u03bd is\narbitrary). then we obtain\n\n(cid:20) (1/t)hbar at\n\n0 (cid:21)(cid:20) \u2206xbar\n\n\u2206\u03bdbar (cid:21) = \u2212(cid:20) \u2207f0(x) + (1/t)pm\n\na\n\ni=1\n\nrpri\n\n1\n\n\u2212fi(x)\u2207fi(x) + at \u03bd\n\n(cid:21) .\n\nin this form, the righthand side is identical to the righthand side of the primal-dual\nequations (evaluated at the same x, \u03bb, and \u03bd). the coefficient matrices differ only\nin the 1, 1 block:\n\nhpd = \u22072f0(x) +\n\n(1/t)hbar = \u22072f0(x) +\n\nmxi=1\nmxi=1\n\n\u03bbi\u22072fi(x) +\n\nmxi=1\n\u2212tfi(x)\u22072fi(x) +\n\n1\n\n\u03bbi\n\n\u2212fi(x)\u2207fi(x)\u2207fi(x)t ,\nmxi=1\n\ntfi(x)2\u2207fi(x)\u2207fi(x)t .\n\n1\n\nwhen x and \u03bb satisfy \u2212fi(x)\u03bbi = 1/t, the coefficient matrices, and therefore also\nthe search directions, coincide.\n\n "}, {"Page_number": 626, "text": "612\n\n11\n\ninterior-point methods\n\n11.7.2 the surrogate duality gap\n\nin the primal-dual interior-point method the iterates x(k), \u03bb(k), and \u03bd(k) are not\nnecessarily feasible, except in the limit as the algorithm converges. this means\nthat we cannot easily evaluate a duality gap \u03b7(k) associated with step k of the\nalgorithm, as we do in (the outer steps of) the barrier method. instead we define\nthe surrogate duality gap, for any x that satisfies f (x) \u227a 0 and \u03bb (cid:23) 0, as\n\n\u02c6\u03b7(x, \u03bb) = \u2212f (x)t \u03bb.\n\n(11.59)\n\nthe surrogate gap \u02c6\u03b7 would be the duality gap, if x were primal feasible and \u03bb, \u03bd\nwere dual feasible, i.e., if rpri = 0 and rdual = 0. note that the value of the\nparameter t that corresponds to the surrogate duality gap \u02c6\u03b7 is m/\u02c6\u03b7.\n\n11.7.3 primal-dual interior-point method\n\nwe can now describe the basic primal-dual interior-point algorithm.\n\nalgorithm 11.2 primal-dual interior-point method.\n\ngiven x that satisfies f1(x) < 0, . . . , fm(x) < 0, \u03bb \u227b 0, \u00b5 > 1, \u01ebfeas > 0, \u01eb > 0.\nrepeat\n\n1. determine t. set t := \u00b5m/\u02c6\u03b7.\n2. compute primal-dual search direction \u2206ypd.\n3. line search and update.\n\ndetermine step length s > 0 and set y := y + s\u2206ypd.\n\nuntil krprik2 \u2264 \u01ebfeas, krdualk2 \u2264 \u01ebfeas, and \u02c6\u03b7 \u2264 \u01eb.\n\nin step 1, the parameter t is set to a factor \u00b5 times m/\u02c6\u03b7, which is the value of t\nassociated with the current surrogate duality gap \u02c6\u03b7. if x, \u03bb, and \u03bd were central,\nwith parameter t (and therefore with duality gap m/t), then in step 1 we would\nincrease t by the factor \u00b5, which is exactly the update used in the barrier method.\nvalues of the parameter \u00b5 on the order of 10 appear to work well.\n\nthe primal-dual interior-point algorithm terminates when x is primal feasible\nand \u03bb, \u03bd are dual feasible (within the tolerance \u01ebfeas) and the surrogate gap is\nsmaller than the tolerance \u01eb. since the primal-dual interior-point method often has\nfaster than linear convergence, it is common to choose \u01ebfeas and \u01eb small.\n\nline search\n\nthe line search in the primal-dual interior point method is a standard backtracking\nline search, based on the norm of the residual, and modified to ensure that \u03bb \u227b 0\nand f (x) \u227a 0. we denote the current iterate as x, \u03bb, and \u03bd, and the next iterate\nas x+, \u03bb+, and \u03bd+, i.e.,\n\nx+ = x + s\u2206xpd,\n\n\u03bb+ = \u03bb + s\u2206\u03bbpd,\n\n\u03bd+ = \u03bd + s\u2206\u03bdpd.\n\n "}, {"Page_number": 627, "text": "11.7 primal-dual interior-point methods\n\n613\n\nthe residual, evaluated at y+, will be denoted r+.\n\nwe first compute the largest positive step length, not exceeding one, that gives\n\n\u03bb+ (cid:23) 0, i.e.,\n\nsmax = sup{s \u2208 [0, 1] | \u03bb + s\u2206\u03bb (cid:23) 0}\n\n= min{1, min{\u2212\u03bbi/\u2206\u03bbi | \u2206\u03bbi < 0}} .\n\nwe start the backtracking with s = 0.99smax, and multiply s by \u03b2 \u2208 (0, 1) until we\nhave f (x+) \u227a 0. we continue multiplying s by \u03b2 until we have\nkrt(x+, \u03bb+, \u03bd+)k2 \u2264 (1 \u2212 \u03b1s)krt(x, \u03bb, \u03bd)k2.\n\ncommon choices for the backtracking parameters \u03b1 and \u03b2 are the same as those for\nnewton\u2019s method: \u03b1 is typically chosen in the range 0.01 to 0.1, and \u03b2 is typically\nchosen in the range 0.3 to 0.8.\n\none iteration of the primal-dual interior-point algorithm is the same as one step\nof the infeasible newton method, applied to solving rt(x, \u03bb, \u03bd) = 0, but modified to\nensure \u03bb \u227b 0 and f (x) \u227a 0 (or, equivalently, with dom rt restricted to \u03bb \u227b 0 and\nf (x) \u227a 0). the same arguments used in the proof of convergence of the infeasible\nstart newton method show that the line search for the primal-dual method always\nterminates in a finite number of steps.\n\n11.7.4 examples\n\nwe illustrate the performance of the primal-dual interior-point method for the\nsame problems considered in \u00a711.3.2. the only difference is that instead of starting\nwith a point on the central path, as in \u00a711.3.2, we start the primal-dual interior-\npoint method at a randomly generated x(0), that satisfies f (x) \u227a 0, and take\n\u03bb(0)\ni = \u22121/fi(x(0)), so the initial value of the surrogate gap is \u02c6\u03b7 = 100. the\nparameter values we use for the primal-dual interior-point method are\n\n\u00b5 = 10,\n\n\u03b2 = 0.5,\n\n\u01eb = 10\u22128,\n\n\u03b1 = 0.01.\n\nsmall lp and gp\nwe first consider the small lp used in \u00a711.3.2, with m = 100 inequalities and\nn = 50 variables. figure 11.21 shows the progress of the primal-dual interior-point\nmethod. two plots are shown: the surrogate gap \u02c6\u03b7, and the norm of the primal\nand dual residuals,\n\nrfeas =(cid:0)krprik2\n\n2(cid:1)1/2\n2 + krdualk2\n\n,\n\nversus iteration number. (the initial point is primal feasible, so the plot shows the\nnorm of the dual feasibility residual.) the plots show that the residual converges\nto zero rapidly, and becomes zero to numerical precision in 24 iterations. the\nsurrogate gap also converges rapidly. compared to the barrier method, the primal-\ndual interior-point method is faster, especially when high accuracy is required.\n\nfigure 11.22 shows the progress of the primal-dual interior-point method on the\n\ngp considered in \u00a711.3.2. the convergence is similar to the lp example.\n\n "}, {"Page_number": 628, "text": "psfrag\n\n614\n\n11\n\ninterior-point methods\n\n102\n\n100\n\n10\u22122\n\n\u02c6\u03b7\n\n10\u22124\n\n10\u22126\n\n10\u22128\n\n10\u221210\n0\n\n5\n\n105\n\n100\n\n10\u22125\n\ns\na\ne\nf\nr\n\n10\u221210\n\n10\u221215\n0\n\n5\n\n25\n\n30\n\n10\n\n15\n\n20\n\n25\n\n30\n\niteration number\n\n10\n\n15\n\n20\n\niteration number\n\nfigure 11.21 progress of the primal-dual interior-point method for an lp,\nshowing surrogate duality gap \u02c6\u03b7 and the norm of the primal and dual resid-\nuals, versus iteration number. the residual converges rapidly to zero within\n24 iterations; the surrogate gap also converges to a very small number in\nabout 28 iterations. the primal-dual interior-point method converges faster\nthan the barrier method, especially if high accuracy is required.\n\n102\n\n100\n\n10\u22122\n\n\u02c6\u03b7\n\n10\u22124\n\n10\u22126\n\n10\u22128\n\n10\u221210\n0\n\n5\n\n105\n\n100\n\n10\u22125\n\ns\na\ne\nf\nr\n\n10\u221210\n\n20\n\n25\n\n10\u221215\n0\n\n5\n\n10\n\n15\n\niteration number\n\n10\n\n15\n\niteration number\n\n20\n\n25\n\nfigure 11.22 progress of primal-dual interior-point method for a gp, show-\ning surrogate duality gap \u02c6\u03b7 and the norm of the primal and dual residuals\nversus iteration number.\n\n "}, {"Page_number": 629, "text": "11.8\n\nimplementation\n\n615\n\n50\n\n40\n\n30\n\n20\n\ns\nn\no\ni\nt\na\nr\ne\nt\ni\n\n10\n\n101\n\n102\nm\n\n103\n\nfigure 11.23 number of iterations required to solve randomly generated\nstandard lps of different dimensions, with n = 2m. error bars show stan-\ndard deviation, around the average value, for 100 instances of each dimen-\nsion. the growth in the number of iterations required, as the problem di-\nmensions range over a 100 : 1 ratio, is approximately logarithmic.\n\na family of lps\n\nhere we examine the performance of the primal-dual method as a function of\nthe problem dimensions, for the same family of standard form lps considered\nin \u00a711.3.2. we use the primal-dual interior-point method to solve the same 2000\ninstances, which consist of 100 instances for each value of m. the primal-dual\nalgorithm is started at x(0) = 1, \u03bb(0) = 1, \u03bd(0) = 0, and terminated using tolerance\n\u01eb = 10\u22128. figure 11.23 shows the average, and standard deviation, of the number\nof iterations required versus m. the number of iterations ranges from 15 to 35,\nand grows approximately as the logarithm of m. comparing with the results for\nthe barrier method shown in figure 11.8, we see that the number of iterations in\nthe primal-dual method is only slightly higher, despite the fact that we start at\ninfeasible starting points, and solve the problem to a much higher accuracy.\n\n11.8 implementation\n\nthe main effort in the barrier method is computing the newton step for the cen-\ntering problem, which consists of solving sets of linear equations of the form\n\nwhere\n\na\n\n(cid:20) h at\nmxi=1\n\n1\n\n0 (cid:21)(cid:20) \u2206xnt\n\n\u03bdnt (cid:21) = \u2212(cid:20) g\n0 (cid:21) ,\nmxi=1\n\nh = t\u22072f0(x) +\n\nfi(x)2\u2207fi(x)\u2207fi(x)t +\n\n(11.60)\n\n1\n\n\u2212fi(x)\u22072fi(x)\n\n "}, {"Page_number": 630, "text": "616\n\n11\n\ninterior-point methods\n\ng = t\u2207f0(x) +\n\nmxi=1\n\n1\n\n\u2212fi(x)\u2207fi(x).\n\nthe newton equations for the primal-dual method have exactly the same structure,\nso our observations in this section apply to the primal-dual method as well.\n\nthe coefficient matrix of (11.60) has kkt structure, so all of the discussion\nin \u00a79.7 and \u00a710.4 applies here. in particular, the equations can be solved by elimi-\nnation, and structure such as sparsity or diagonal plus low rank can be exploited.\nlet us give some generic examples in which the special structure of the kkt equa-\ntions can be exploited to compute the newton step more efficiently.\n\nsparse problems\n\nif the original problem is sparse, which means that the objective and every con-\nstraint function each depend on only a modest number of variables, then the gradi-\nents and hessian matrices of the objective and constraint functions are all sparse,\nas is the coefficient matrix a. provided m is not too big, the matrix h is then\nlikely to be sparse, so a sparse matrix method can be used to compute the newton\nstep. the method will likely work well if there are a few relatively dense rows and\ncolumns in the kkt matrix, which would occur, for example, if there were a few\nequality constraints involving a large number of variables.\n\nseparable objective and a few linear inequality constraints\n\nsuppose the objective function is separable, and there are only a relatively small\nnumber of linear equality and inequality constraints. then \u22072f0(x) is diagonal,\nand the terms \u22072fi(x) vanish, so the matrix h is diagonal plus low rank. since h\nis easily inverted, we can solve the kkt equations efficiently. the same method\ncan be applied whenever \u22072f0(x) is easily inverted, e.g., banded, sparse, or block\ndiagonal.\n\n11.8.1 standard form linear programming\n\nwe first discuss the implementation of the barrier method for the standard form\nlp\n\nminimize\nsubject to ax = b,\n\nct x\n\nx (cid:23) 0,\n\nwith a \u2208 rm\u00d7n. the newton equations for the centering problem\n\nminimize\nsubject to ax = b\n\ntct x \u2212pn\n\ni=1 log xi\n\nare given by\n\n(cid:20) diag(x)\u22122 at\n\n0 (cid:21)(cid:20) \u2206xnt\n\n\u03bdnt (cid:21) =(cid:20) \u2212tc + diag(x)\u221211\n\na\n\n0\n\n(cid:21) .\n\n "}, {"Page_number": 631, "text": "11.8\n\nimplementation\n\n617\n\nthese equations are usually solved by block elimination of \u2206xnt. from the first\nequation,\n\n\u2206xnt = diag(x)2(\u2212tc + diag(x)\u221211 \u2212 at \u03bdnt)\n\n= \u2212t diag(x)2c + x \u2212 diag(x)2at \u03bdnt.\n\nsubstituting in the second equation yields\n\na diag(x)2at \u03bdnt = \u2212ta diag(x)2c + b.\n\nthe coefficient matrix is positive definite since by assumption rank a = m. more-\nover if a is sparse, then usually a diag(x)2at is sparse, so a sparse cholesky\nfactorization can be used.\n\n11.8.2 \u21131-norm approximation\n\nconsider the \u21131-norm approximation problem\n\nminimize\n\nkax \u2212 bk1\n\nwith a \u2208 rm\u00d7n. we will discuss the implementation assuming m and n are large,\nand a is structured, e.g., sparse, and compare it with the cost of the corresponding\nleast-squares problem\n\nminimize\n\nkax \u2212 bk2\n2 .\n\nwe start by expressing the \u21131-norm approximation problem as an lp by intro-\n\nducing auxiliary variables y \u2208 rm:\n1t y\n\nminimize\n\nsubject to (cid:20) a \u2212i\n\n\u2212a \u2212i (cid:21)(cid:20) x\n\ny (cid:21) (cid:22)(cid:20) b\n\n\u2212b (cid:21) .\n\nthe newton equation for the centering problem is\n\n0\n\n0 d2 (cid:21)(cid:20) a \u2212i\n\n\u2212i \u2212i (cid:21)(cid:20) d1\n(cid:20) at \u2212at\nd1 = diag(b \u2212 ax + y)\u22122,\n\n\u2212a \u2212i (cid:21)(cid:20) \u2206xnt\n\n\u2206ynt (cid:21) = \u2212(cid:20) at g1\nd2 = diag(\u2212b + ax + y)\u22122\n\ng2\n\n(cid:21)\n\nwhere\n\nand\n\ng1 = diag(b \u2212 ax + y)\u221211 \u2212 diag(\u2212b + ax + y)\u221211\ng2 = t1 \u2212 diag(b \u2212 ax + y)\u221211 \u2212 diag(\u2212b + ax + y)\u221211.\n\nif we multiply out the lefthand side, this can be simplified as\n\n(cid:20) at (d1 + d2)a \u2212at (d1 \u2212 d2)\n\n\u2212(d1 \u2212 d2)a\n\nd1 + d2\n\n(cid:21)(cid:20) \u2206xnt\n\u2206ynt (cid:21) = \u2212(cid:20) at g1\n\ng2\n\n(cid:21) .\n\n "}, {"Page_number": 632, "text": "618\n\n11\n\ninterior-point methods\n\napplying block elimination to \u2206ynt, we can reduce this to\n\nat da\u2206xnt = \u2212at g\n\n(11.61)\n\nwhere\n\nand\n\nd = 4d1d2(d1 + d2)\u22121 = 2(diag(y)2 + diag(b \u2212 ax)2)\u22121\n\nafter solving for \u2206xnt, we obtain \u2206ynt from\n\ng = g1 + (d1 \u2212 d2)(d1 + d2)\u22121g2.\n\n\u2206ynt = (d1 + d2)\u22121(\u2212g2 + (d1 \u2212 d2)a\u2206xnt).\n\nit is interesting to note that (11.61) are the normal equations of a weighted least-\nsquares problem\n\nminimize\n\nkd1/2(a\u2206x + d\u22121g)k2.\n\nin other words, the cost of solving the \u21131-norm approximation problem is the cost\nof solving a relatively small number of weighted least-squares problems with the\nsame matrix a, and weights that change at each iteration.\nif a has structure\nthat allows us to solve the least-squares problem fast (for example, by exploiting\nsparsity), then we can solve (11.61) fast.\n\n11.8.3 semidefinite programming in inequality form\n\nwe consider the sdp\n\nct x\n\nminimize\n\nsubject to pn\n\ni=1 xifi + g (cid:22) 0,\n\nwith variable x \u2208 rn, and parameters f1, . . . , fn, g \u2208 sp. the associated centering\nproblem, using the log-determinant barrier function, is\n\nminimize\n\ntct x \u2212 log det(\u2212pn\n\ni=1 xifi \u2212 g).\n\nthe newton step \u2206xnt is found from h\u2206xnt = \u2212g, where the hessian and gradient\nare given by\n\nhij = tr(s\u22121fis\u22121fj),\ngi = tci + tr(s\u22121fi),\n\ni, j = 1, . . . , n\ni = 1, . . . , n,\n\nwhere s = \u2212pn\n\nthen solve the newton equation via cholesky factorization.\n\ni=1 xifi \u2212 g. one standard approach is to form h (and g), and\nwe first consider the unstructured case, i.e., we assume all matrices are dense.\nwe will also just keep track of the order in the flop count, with respect to the\nproblem dimensions n and p. we first form s, which costs order np2 flops. we\nthen compute the matrices s\u22121fi, for each i, via cholesky factorization of s, and\nthen back substitution with the columns of fi (or forming s\u22121 and multiplying\nby fi). this cost is order p3 for each i, so the total cost is order np3. finally,\n\n "}, {"Page_number": 633, "text": "11.8\n\nimplementation\n\n619\n\nwe form hij as the inner product of the matrices s\u22121fi and s\u22121fj, which costs\norder p2 flops. since we do this for n(n + 1)/2 such pairs, the cost is order n2p2.\nsolving for the newton direction costs order n3. the dominating order is thus\nmax{np3, n2p2, n3}.\nit is not possible, in general, to exploit sparsity in the matrices fi and g, since\nh is often dense, even when fi and g are sparse. one exception is when fi and g\nhave a common block diagonal structure, in which case all the operations described\nabove can be carried out block by block.\n\nit is often possible to exploit (common) sparsity in fi and g to form the (dense)\nhessian h more efficiently.\nif we can find an ordering that results in s having\na reasonably sparse cholesky factor, then we can compute the matrices s\u22121fi\nefficiently, and form hij far more efficiently.\n\none interesting example that arises frequently is an sdp with matrix inequality\n\nthis corresponds to fi = eii, where eii is the matrix with i, i entry one and all\nothers zero. in this case, the matrix h can be found very efficiently:\n\ndiag(x) (cid:22) b.\n\nhij = (s\u22121)2\nij,\n\nwhere s = b \u2212 diag(x). the cost of forming h is thus the cost of forming s\u22121,\nwhich is at most (i.e., when no other structure is exploited) order n3.\n\n11.8.4 network rate optimization\n\nwe consider a variation on the optimal network flow problem described in \u00a710.4.3\n(page 550), which is sometimes called the network rate optimization problem. the\nnetwork is described as a directed graph with l arcs or links. goods, or packets\nof information, travel on the network, passing through the links. the network\nsupports n flows, with (nonnegative) rates x1, . . . , xn, which are the optimization\nvariables. each flow moves along a fixed, or pre-determined, path (or route) in the\nnetwork, from a source node to a destination node. each link can support multiple\nflows passing through it. the total traffic on a link is the sum of the flow rates of\nthe flows that travel over the link. each link has a positive capacity, which is the\nmaximum total traffic it can handle.\n\nwe can describe these link capacity limits using the flow-link incidence matrix\n\na \u2208 rl\u00d7n, defined as\n\naij =(cid:26) 1 flow j passes through link i\n\n0 otherwise.\n\nthe total traffic on link i is then given by (ax)i, so the link capacity constraints\ncan be expressed as ax (cid:22) c, where ci is the capacity of link i. usually each path\npasses through only a small fraction of the total number of links, so the matrix a\nis sparse.\n\nin the network rate problem the paths are fixed (and encoded in the matrix a,\nwhich is a problem parameter); the variables are the flow rates xi. the objective\n\n "}, {"Page_number": 634, "text": "620\n\n11\n\ninterior-point methods\n\nis to choose the flow rates to maximize a separable utility function u , given by\n\nu (x) = u1(x1) + \u00b7\u00b7\u00b7 + un(xn).\n\nwe assume that each ui (and hence, u ) is concave and nondecreasing. we can\nthink of ui(xi) as the income derived from supporting the ith flow at rate xi; u (x)\nis then the total income associated with the flows. the network rate optimization\nproblem is then\n\nwhich is a convex optimization problem.\n\nmaximize u (x)\nsubject to ax (cid:22) c,\n\nx (cid:23) 0,\n\n(11.62)\n\nlet us apply the barrier method to solve this problem. at each step we must\n\nminimize a function of the form\n\n\u2212tu (x) \u2212\n\nlog(c \u2212 ax)i \u2212\n\nlog xj,\n\nlxi=1\n\nnxj=1\n\nusing newton\u2019s method. the newton step \u2206xnt is found by solving the linear\nequations\n\nwhere\n\n(d0 + at d1a + d2)\u2206xnt = \u2212g,\n\n1 (x), . . . , u \u2032\u2032\n\nn (x))\n\nd0 = \u2212t diag(u \u2032\u2032\nd1 = diag(1/(c \u2212 ax)2\nd2 = diag(1/x2\n\n1, . . . , 1/x2\nn)\n\n1, . . . , 1/(c \u2212 ax)2\nl)\n\nare diagonal matrices, and g \u2208 rn. we can describe the sparsity structure of this\nn \u00d7 n coefficient matrix precisely:\n\n(d0 + at d1a + d2)ij 6= 0\n\nif and only if flow i and flow j share a link. if the paths are relatively short, and\neach link has relatively few paths passing through it, then this matrix is sparse, so\na sparse cholesky factorization can be used. we can also solve the newton system\nefficiently when some, but not too many, of the rows and columns are relatively\ndense. this occurs when a few of the flows intersect with a large number of the\nother flows, which might occur if a few flows are relatively long.\n\nwe can also use the matrix inversion lemma to compute the newton step by\n\nsolving a system with l \u00d7 l coefficient matrix, with form\n\n(d\u22121\n\n1 + a(d0 + d2)\u22121at )y = \u2212a(d0 + d2)\u22121g,\n\nand then computing\n\n\u2206xnt = \u2212(d0 + d2)\u22121(g + at y).\nhere too we can precisely describe the sparsity pattern:\n1 + a(d0 + d2)\u22121at )ij 6= 0\n\n(d\u22121\n\nif and only if there is a path that passes through link i and link j. if most paths\nare short, this matrix is sparse. this matrix will be sparse, with a few dense rows\nand columns, if there are a few bottlenecks, i.e., a few links over which many flows\ntravel.\n\n "}, {"Page_number": 635, "text": "bibliography\n\nbibliography\n\n621\n\nthe early history of the barrier method is described in detail by fiacco and mccormick\n[fm90, \u00a71.2]. the method was a popular algorithm for convex optimization in the 1960s,\nalong with closely related techniques such as the method of centers (li\u02c6e\u02dcu and huard\n[lh66]; see also exercise 11.11), and penalty (or exterior-point) methods [fm90, \u00a74].\ninterest declined in the 1970s amid concerns about the ill-conditioning of the newton\nequations of the centering problem (11.6) for high values of t.\n\nthe barrier method regained popularity in the 1980s, after gill, murray, saunders, tom-\nlin, and wright [gms+86] pointed out the close connections with karmarkar\u2019s polynomial-\ntime projective algorithm for linear programming [kar84]. the focus of research through-\nout the 1980s remained on linear (and to a lesser extent, quadratic) programming, result-\ning in different variations of the basic interior-point methods, and improved worst-case\ncomplexity results (see gonzaga [gon92]). primal-dual methods emerged as the algo-\nrithms of choice for practical implementations (see mehrotra [meh92], lustig, marsten,\nand shanno [lms94], wright [wri97]).\n\nin their 1994 book, nesterov and nemirovski extended the complexity theory of linear\nprogramming interior-point methods to nonlinear convex optimization problems, using\nthe convergence theory of newton\u2019s method for self-concordant functions. they also\ndeveloped interior-point methods for problems with generalized inequalities, and discussed\nways of reformulating problems to satisfy the self-concordance assumption. the geometric\nprogramming reformulation on page 587, for example, is from [nn94, \u00a76.3.1].\nas mentioned on page 585, the complexity analysis shows that, contrary to what one might\nexpect, the centering problems in the barrier method do not become more difficult as t\nincreases, at least not in exact arithmetic. practical experience, supported by theoretical\nresults (forsgren, gill, and wright [fgw02, \u00a74.3.2], nocedal and wright [nw99, page\n525]), also indicates that the effects of ill-conditioning on the computed solution of the\nnewton system are more benign than thought earlier.\n\nrecent research on interior-point methods has concentrated on extending the primal-dual\nmethods for linear programming, which converge faster and reach higher accuracies than\n(primal) barrier methods, to nonlinear convex problems. one popular approach, along\nthe lines of the simple primal-dual method of \u00a711.7, is based on linearizing modified kkt\nequations for a convex optimization problem in standard form, i.e., problem (11.1). more\nsophisticated algorithms of this type differ from algorithm 11.2 in the strategy used to\nselect t (which is crucial to achieve superlinear asymptotic convergence), and the line\nsearch. we refer to wright [wri97, chapter 8], ralph and wright [rw97], den hertog\n[dh93], terlaky [ter96], and the survey by forsgren, gill, and wright [fgw02, \u00a75] for\ndetails and references.\n\nother authors adopt the cone programming framework as starting point for extending\nprimal-dual interior-point methods for linear programming to convex optimization (see\nfor example, nesterov and todd [nt98]). this approach has resulted in efficient and\naccurate primal-dual methods for semidefinite and second-order programming (see the\nsurveys by todd [tod01] and alizadeh and goldfarb [ag03]).\n\nas for linear programming, primal-dual methods for semidefinite programming are usually\ndescribed as variations of newton\u2019s method applied to modified kkt equations. unlike\nin linear programming, however, the linearization can be carried out in many different\nways, which lead to different search directions and algorithms; see helmberg, rendl,\nvanderbei, and wolkowicz [hrvw96], kojima, shindo, and harah [ksh97], monteiro\n[mon97], nesterov and todd [nt98], zhang [zha98], alizadeh, haeberly, and overton\n[aho98], and todd, toh, and t\u00a8ut\u00a8unc\u00a8u [ttt98].\n\ngreat progress has also been made in the area of initialization and infeasibility detection.\nhomogeneous self-dual formulations provide an elegant and efficient alternative to the\nclassical two-phase approach of \u00a711.4; see ye, todd, and mizuno [ytm94], xu, hung,\n\n "}, {"Page_number": 636, "text": "622\n\n11\n\ninterior-point methods\n\nand ye [xhy96], andersen and ye [ay98] and luo, sturm, and zhang [lsz00] for details.\n\nthe primal-dual interior-point methods for semidefinite and second-order cone program-\nming have been implemented in a number of software packages, including sedumi [stu99],\nsdpt3 [ttt02], sdpa [fkn98], csdp [bor02], and dsdp [by02], a user-friendly in-\nterface to several of these codes is provided by yalmip [l\u00a8of04].\n\nthe following books document the recent developments in this rapidly advancing field\nin greater detail: vanderbei [van96], wright [wri97], roos, terlaky, and vial [rtv97]\nye [ye97], wolkowicz, saigal, and vandenberghe [wsv00], ben-tal and nemirovski,\n[btn01], renegar [ren01], and peng, roos, and terlaky [prt02].\n\n "}, {"Page_number": 637, "text": "exercises\n\nexercises\n\nthe barrier method\n\n623\n\n11.1 barrier method example. consider the simple problem\n\nminimize\nsubject to\n\nx2 + 1\n2 \u2264 x \u2264 4,\n\nwhich has feasible set [2, 4], and optimal point x\u22c6 = 2. plot f0, and tf0 + \u03c6, for several\nvalues of t > 0, versus x. label x\u22c6(t).\n\n11.2 what happens if the barrier method is applied to the lp\n\nx2\n\nminimize\nsubject to x1 \u2264 x2,\n\n0 \u2264 x2,\n\nwith variable x \u2208 r2?\n\n11.3 boundedness of centering problem. suppose the sublevel sets of (11.1),\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b,\n\ni = 1, . . . , m\n\nare bounded. show that the sublevel sets of the associated centering problem,\n\nminimize\nsubject to ax = b,\n\ntf0(x) + \u03c6(x)\n\nare bounded.\n\n11.4 adding a norm bound to ensure strong convexity of the centering problem. suppose we\n\nadd the constraint xt x \u2264 r2 to the problem (11.1):\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\nax = b\nxt x \u2264 r2.\n\ni = 1, . . . , m\n\nlet \u02dc\u03c6 denote the logarithmic barrier function for this modified problem. find a > 0 for\nwhich \u22072(tf0(x) + \u02dc\u03c6(x)) (cid:23) ai holds, for all feasible x.\nconstraints, for simplicity)\n\n11.5 barrier method for second-order cone programming. consider the socp (without equality\n\nminimize\nsubject to\n\nf t x\nkaix + bik2 \u2264 ct\n\ni x + di,\n\ni = 1, . . . , m.\n\n(11.63)\n\nthe constraint functions in this problem are not differentiable (since the euclidean norm\nkuk2 is not differentiable at u = 0) so the (standard) barrier method cannot be applied.\nin \u00a711.6, we saw that this socp can be solved by an extension of the barrier method\nthat handles generalized inequalities. (see example 11.8, page 599, and page 601.) in this\nexercise, we show how the standard barrier method (with scalar constraint functions) can\nbe used to solve the socp.\nwe first reformulate the socp as\n\nminimize\nsubject to\n\nf t x\nkaix + bik2\nct\ni x + di \u2265 0,\n\n2/(ct\n\ni x + di) \u2264 ct\ni = 1, . . . , m.\n\ni x + di,\n\ni = 1, . . . , m\n\n(11.64)\n\n "}, {"Page_number": 638, "text": "624\n\n11\n\ninterior-point methods\n\nthe constraint function\n\nfi(x) = kaix + bik2\n\ni x + di \u2212 ct\nct\n\n2\n\ni x \u2212 di\n\nis the composition of a quadratic-over-linear function with an affine function, and is twice\ndifferentiable (and convex), provided we define its domain as dom fi = {x | ct\ni x+di > 0}.\nnote that the two problems (11.63) and (11.64) are not exactly equivalent. if ct\ni x\u22c6+di = 0\nfor some i, where x\u22c6 is the optimal solution of the socp (11.63), then the reformulated\nproblem (11.64) is not solvable; x\u22c6 is not in its domain. nevertheless we will see that\nthe barrier method, applied to (11.64), produces arbitrarily accurate suboptimal solutions\nof (11.64), and hence also for (11.63).\n\n(a) form the log barrier \u03c6 for the problem (11.64). compare it to the log barrier that\narises when the socp (11.63) is solved using the barrier method for generalized\ninequalities (in \u00a711.6).\n\n(b) show that if tf t x + \u03c6(x) is minimized, the minimizer x\u22c6(t) is 2m/t-suboptimal for\nthe problem (11.63). it follows that the standard barrier method, applied to the\nreformulated problem (11.64), solves the socp (11.63), in the sense of producing\narbitrarily accurate suboptimal solutions. this is the case even though the optimal\npoint x\u22c6 need not be in the domain of the reformulated problem (11.64).\n\nindicator function bi\u2212(u) (see \u00a711.2.1, page 563). we can also construct barriers from\n\n11.6 general barriers. the log barrier is based on the approximation \u2212(1/t) log(\u2212u) of the\nother approximations, which in turn yield generalizations of the central path and barrier\nmethod. let h : r \u2192 r be a twice differentiable, closed, increasing convex function,\nwith dom h = \u2212r++.\n(this implies h(u) \u2192 \u221e as u \u2192 0.) one such function is\nh(u) = \u2212 log(\u2212u); another example is h(u) = \u22121/u (for u < 0).\nnow consider the optimization problem (without equality constraints, for simplicity)\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nwhere fi are twice differentiable. we define the h-barrier for this problem as\n\n\u03c6h(x) =\n\nmxi=1\n\nh(fi(x)),\n\nwith domain {x | fi(x) < 0, i = 1, . . . , m}. when h(u) = \u2212 log(\u2212u), this is the usual\nlogarithmic barrier; when h(u) = \u22121/u, \u03c6h is called the inverse barrier. we define the\nh-central path as\n\nx\u22c6(t) = argmin tf0(x) + \u03c6h(x),\n\nwhere t > 0 is a parameter. (we assume that for each t, the minimizer exists and is\nunique.)\n\n(a) explain why tf0(x) + \u03c6h(x) is convex in x, for each t > 0.\n(b) show how to construct a dual feasible \u03bb from x\u22c6(t). find the associated duality gap.\n\n(c) for what functions h does the duality gap found in part (b) depend only on t and\n\nm (and no other problem data)?\n\n11.7 tangent to central path. this problem concerns dx\u22c6(t)/dt, which gives the tangent to the\ncentral path at the point x\u22c6(t). for simplicity, we consider a problem without equality\nconstraints; the results readily generalize to problems with equality constraints.\n\n(a) find an explicit expression for dx\u22c6(t)/dt. hint. differentiate the centrality equa-\n\ntions (11.7) with respect to t.\n\n "}, {"Page_number": 639, "text": "exercises\n\n625\n\n(b) show that f0(x\u22c6(t)) decreases as t increases. thus, the objective value in the barrier\nmethod decreases, as the parameter t is increased. (we already know that the duality\ngap, which is m/t, decreases as t increases.)\n\n11.8 predictor-corrector method for centering problems. in the standard barrier method, x\u22c6(\u00b5t)\nis computed using newton\u2019s method, starting from the initial point x\u22c6(t). one alternative\n\nthat has been proposed is to make an approximation or predictionbx of x\u22c6(\u00b5t), and then\nstart the newton method for computing x\u22c6(\u00b5t) from bx. the idea is that this should\nreduce the number of newton steps, since bx is (presumably) a better initial point than\n\nx\u22c6(t). this method of centering is called a predictor-corrector method, since it first makes\na prediction of what x\u22c6(\u00b5t) is, then corrects the prediction using newton\u2019s method.\nthe most widely used predictor is the first-order predictor, based on the tangent to the\ncentral path, explored in exercise 11.7. this predictor is given by\n\ndx\u22c6(t)\n\ndt\n\n(\u00b5t \u2212 t).\n\nbx = x\u22c6(t) +\n\nderive an expression for the first-order predictor bx. compare it to the newton update\n\nobtained, i.e., x\u22c6(t) + \u2206xnt, where \u2206xnt is the newton step for \u00b5tf0(x) + \u03c6(x), at x\u22c6(t).\nwhat can you say when the objective f0 is linear? (for simplicity, you can consider a\nproblem without equality constraints.)\n\n11.9 dual feasible points near the central path. consider the problem\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m,\n\nwith variable x \u2208 rn. we assume the functions fi are convex and twice differentiable. (we\nassume for simplicity there are no equality constraints.) recall (from \u00a711.2.2, page 565)\nthat \u03bbi = \u22121/(tfi(x\u22c6(t))), i = 1, . . . , m, is dual feasible, and in fact, x\u22c6(t) minimizes\nl(x, \u03bb). this allows us to evaluate the dual function for \u03bb, which turns out to be g(\u03bb) =\nf0(x\u22c6(t)) \u2212 m/t. in particular, we conclude that x\u22c6(t) is m/t-suboptimal.\nin this problem we consider what happens when a point x is close to x\u22c6(t), but not quite\ncentered. (this would occur if the centering steps were terminated early, or not carried\nout to full accuracy.) in this case, of course, we cannot claim that \u03bbi = \u22121/(tfi(x)),\ni = 1, . . . , m, is dual feasible, or that x is m/t-suboptimal. however, it turns out that\na slightly more complicated formula does yield a dual feasible point, provided x is close\nenough to centered.\nlet \u2206xnt be the newton step at x of the centering problem\n\na formula that often gives a dual feasible point when \u2206xnt is small (i.e., for x nearly\ncentered) is\n\ni=1 log(\u2212fi(x)).\n\nminimize\n\ntf0(x) \u2212pm\n\u2212tfi(x)(cid:18)1 + \u2207fi(x)t \u2206xnt\n\u2212fi(x) (cid:19) ,\n\n1\n\n\u03bbi =\n\ni = 1, . . . , m.\n\nin this case, the vector x does not minimize l(x, \u03bb), so there is no general formula for the\ndual function value g(\u03bb) associated with \u03bb. (if we have an analytical expression for the\ndual objective, however, we can simply evaluate g(\u03bb).)\nverify that for a qcqp\n\nminimize\nsubject to\n\n(1/2)xt p0x + qt\n(1/2)xt pix + qt\n\n0 x + r0\ni x + ri \u2264 0,\n\ni = 1, . . . , m,\n\nthe formula for \u03bb yields a dual feasible point (i.e., \u03bb (cid:23) 0 and l(x, \u03bb) is bounded below)\nwhen \u2206xnt is sufficiently small.\n\n "}, {"Page_number": 640, "text": "626\n\n11\n\ninterior-point methods\n\nhint. define\n\nshow that\n\nx0 = x + \u2206xnt,\n\nxi = x \u2212\n\n1\n\nt\u03bbifi(x)\n\n\u2206xnt,\n\ni = 1, . . . , m.\n\n\u2207f0(x0) +\n\n\u03bbi\u2207fi(xi) = 0.\n\nmxi=1\n\nnow use fi(z) \u2265 fi(xi) + \u2207fi(xi)t (z \u2212 xi), i = 0, . . . , m, to derive a lower bound on\nl(z, \u03bb).\n11.10 another parametrization of the central path. we consider the problem (11.1), with central\n\npath x\u22c6(t) for t > 0, defined as the solution of\n\nminimize\nsubject to ax = b.\n\ntf0(x) \u2212pm\n\ni=1 log(\u2212fi(x))\n\nin this problem we explore another parametrization of the central path.\nfor u > p\u22c6, let z\u22c6(u) denote the solution of\n\nminimize \u2212 log(u \u2212 f0(x)) \u2212pm\n\nsubject to ax = b.\n\ni=1 log(\u2212fi(x))\n\nshow that the curve defined by z\u22c6(u), for u > p\u22c6, is the central path. (in other words,\nfor each u > p\u22c6, there is a t > 0 for which x\u22c6(t) = z\u22c6(u), and conversely, for each t > 0,\nthere is an u > p\u22c6 for which z\u22c6(u) = x\u22c6(t)).\n\n11.11 method of analytic centers. in this problem we consider a variation on the barrier method,\nbased on the parametrization of the central path described in exercise 11.10. for simplic-\nity, we consider a problem with no equality constraints,\n\nminimize\nsubject to\n\nf0(x)\nfi(x) \u2264 0,\n\ni = 1, . . . , m.\n\nthe method of analytic centers starts with any strictly feasible initial point x(0), and any\nu(0) > f0(x(0)). we then set\n\nu(1) = \u03b8u(0) + (1 \u2212 \u03b8)f0(x(0)),\n\nwhere \u03b8 \u2208 (0, 1) is an algorithm parameter (usually chosen small), and then compute the\nnext iterate as\n\nx(1) = z\u22c6(u(1))\n\n(using newton\u2019s method, starting from x(0)). here z\u22c6(s) denotes the minimizer of\n\n\u2212 log(s \u2212 f0(x)) \u2212\n\nlog(\u2212fi(x)),\n\nmxi=1\n\nwhich we assume exists and is unique. this process is then repeated.\nthe point z\u22c6(s) is the analytic center of the inequalities\n\nf0(x) \u2264 s,\n\nf1(x) \u2264 0, . . . , fm(x) \u2264 0,\n\nhence the algorithm name.\nshow that the method of centers works, i.e., x(k) converges to an optimal point. find a\nstopping criterion that guarantees that x is \u01eb-suboptimal, where \u01eb > 0.\nhint. the points x(k) are on the central path; see exercise 11.10. use this to show that\n\nwhere u and u+ are the values of u on consecutive iterations.\n\nu+ \u2212 p\u22c6 \u2264\n\nm + \u03b8\nm + 1\n\n(u \u2212 p\u22c6),\n\n "}, {"Page_number": 641, "text": "exercises\n\n627\n\n11.12 barrier method for convex-concave games. we consider a convex-concave game with\n\ninequality constraints,\n\nminimizew maximizez\nsubject to\n\nf0(w, z)\nfi(w) \u2264 0,\n\u02dcfi(z) \u2264 0,\n\ni = 1, . . . , m\ni = 1, . . . , \u02dcm.\n\nhere w \u2208 rn is the variable associated with minimizing the objective, and z \u2208 r\u02dcn is\nthe variable associated with maximizing the objective. the constraint functions fi and \u02dcfi\nare convex and differentiable, and the objective function f0 is differentiable and convex-\nconcave, i.e., convex in w, for each z, and concave in z, for each w. we assume for\nsimplicity that dom f0 = rn \u00d7 r\u02dcn.\na solution or saddle-point for the game is a pair w\u22c6, z\u22c6, for which\n\nf0(w\u22c6, z) \u2264 f0(w\u22c6, z\u22c6) \u2264 f0(w, z\u22c6)\n\nholds for every feasible w and z. (for background on convex-concave games and functions,\nsee \u00a75.4.3, \u00a710.3.4 and exercises 3.14, 5.24, 5.25, 10.10, and 10.13.) in this exercise we\nshow how to solve this game using an extension of the barrier method, and the infeasible\nstart newton method (see \u00a710.3).\n(a) let t > 0. explain why the function\n\ntf0(w, z) \u2212\n\nmxi=1\n\nlog(\u2212fi(w)) +\n\n\u02dcmxi=1\n\nlog(\u2212 \u02dcfi(z))\n\nis convex-concave in (w, z). we will assume that it has a unique saddle-point,\n(w\u22c6(t), z\u22c6(t)), which can be found using the infeasible start newton method.\n\n(b) as in the barrier method for solving a convex optimization problem, we can derive\na simple bound on the suboptimality of (w\u22c6(t), z\u22c6(t)), which depends only on the\nproblem dimensions, and decreases to zero as t increases. let w and z denote the\nfeasible sets for w and z,\n\nw = {w | fi(w) \u2264 0, i = 1, . . . , m},\n\nz = {z | \u02dcfi(z) \u2264 0, i = 1, . . . , \u02dcm}.\n\nshow that\n\nf0(w\u22c6(t), z\u22c6(t)) \u2264 inf\nf0(w\u22c6(t), z\u22c6(t)) \u2265 sup\n\nw\u2208w\n\nz\u2208z\n\nf0(w, z\u22c6(t)) +\n\nf0(w\u22c6(t), z) \u2212\n\n,\n\nm\nt\n\u02dcm\nt\n\n,\n\nand therefore\n\nsup\nz\u2208z\n\nf0(w\u22c6(t), z) \u2212 inf\n\nw\u2208w\n\nf0(w, z\u22c6(t)) \u2264\n\nm + \u02dcm\n\nt\n\n.\n\nself-concordance and complexity analysis\n\n11.13 self-concordance and negative entropy.\n\n(a) show that the negative entropy function x log x (on r++) is not self-concordant.\n(b) show that for any t > 0, tx log x \u2212 log x is self-concordant (on r++).\n\n11.14 self-concordance and the centering problem. let \u03c6 be the logarithmic barrier function of\nproblem (11.1). suppose that the sublevel sets of (11.1) are bounded, and that tf0 + \u03c6 is\nclosed and self-concordant. show that t\u22072f0(x) + \u22072\u03c6(x) \u227b 0, for all x \u2208 dom \u03c6. hint.\nsee exercises 9.17 and 11.3.\n\n "}, {"Page_number": 642, "text": "628\n\n11\n\ninterior-point methods\n\nbarrier method for generalized inequalities\n\n11.15 generalized logarithm is k-increasing. let \u03c8 be a generalized logarithm for the proper\n\ncone k. suppose y \u227bk 0.\n(a) show that \u2207\u03c8(y) (cid:23)k \u2217 0, i.e., that \u03c8 is k-nondecreasing. hint. if \u2207\u03c8(y) 6(cid:23)k \u2217 0,\nthen there is some w \u227bk 0 for which wt\u2207\u03c8(y) \u2264 0. use the inequality \u03c8(sw) \u2264\n\u03c8(y) + \u2207\u03c8(y)t (sw \u2212 y), with s > 0.\n(b) now show that \u2207\u03c8(y) \u227bk \u2217 0, i.e., that \u03c8 is k-increasing. hint. show that\n\u22072\u03c8(y) \u227a 0, \u2207\u03c8(y) (cid:23)k \u2217 0 imply \u2207\u03c8(y) \u227bk \u2217 0.\n\n11.16 [nn94, page 41] properties of a generalized logarithm. let \u03c8 be a generalized logarithm\nfor the proper cone k, with degree \u03b8. prove that the following properties hold at any\ny \u227bk 0.\n(a) \u2207\u03c8(sy) = \u2207\u03c8(y)/s for all s > 0.\n(b) \u2207\u03c8(y) = \u2212\u22072\u03c8(y)y.\n(c) yt\u2207\u03c82(y)y = \u2212\u03b8.\n(d) \u2207\u03c8(y)t\u22072\u03c8(y)\u22121\u2207\u03c8(y) = \u2212\u03b8.\n\n11.17 dual generalized logarithm. let \u03c8 be a generalized logarithm for the proper cone k, with\n\ndegree \u03b8. show that the dual generalized logarithm \u03c8, defined in (11.49), satisfies\n\n\u03c8(sv) = \u03c8(v) + \u03b8 log s,\n\nfor v \u227bk \u2217 0, s > 0.\n\n11.18 is the function\n\nwith dom \u03c8 = {y \u2208 rn+1 | yn+1 > pn\n\norder cone in rn+1?\n\nimplementation\n\n\u03c8(y) = log(cid:18)yn+1 \u2212pn\n\ni=1 y2\n\nyn+1 (cid:19) ,\n\ni\n\ni=1 y2\n\ni }, a generalized logarithm for the second-\n\n11.19 yet another method for computing the newton step. show that the newton step for the\nbarrier method, which is given by the solution of the linear equations (11.14), can be\nfound by solving a larger set of linear equations with coefficient matrix\n\nt\u22072f0(x) +pi\n\ndf (x)\n\na\n\n1\n\n\u2212fi(x)\u22072fi(x)\n\ndf (x)t\n\n\u2212 diag(f (x))2\n\n0\n\n\uf8ee\uf8f0\n\nat\n0\n\n0 \uf8f9\uf8fb\n\nwhere f (x) = (f1(x), . . . , fm(x)).\nfor what types of problem structure might solving this larger system be interesting?\n\n11.20 network rate optimization via the dual problem. in this problem we examine a dual method\nfor solving the network rate optimization problem of \u00a711.8.4. to simplify the presentation\nwe assume that the utility functions ui are strictly concave, with dom ui = r++, and\nthat they satisfy u \u2032\n\ni (xi) \u2192 \u221e as xi \u2192 0 and u \u2032\n\ni (xi) \u2192 0 as xi \u2192 \u221e.\n\n(a) express the dual problem of (11.62) in terms of the conjugate utility functions\n\nvi = (\u2212ui)\u2217, defined as\n\nvi(\u03bb) = sup\nx>0\n\n(\u03bbx + ui(x)).\n\nshow that dom vi = \u2212r++, and that for each \u03bb < 0 there is a unique x with\nu \u2032\ni (x) = \u2212\u03bb.\n(b) describe a barrier method for the dual problem. compare the complexity per iter-\nation with the complexity of the method in \u00a711.8.4. distinguish the same two cases\nas in \u00a711.8.4 (at a is sparse and aat is sparse).\n\n "}, {"Page_number": 643, "text": "exercises\n\nnumerical experiments\n\n629\n\n11.21 log-chebyshev approximation with bounds. we consider an approximation problem: find\nx \u2208 rn, that satisfies the variable bounds l (cid:22) x (cid:22) u, and yields ax \u2248 b, where b \u2208 rm.\nyou can assume that l \u227a u, and b \u227b 0 (for reasons we explain below). we let at\ni denote\nthe ith row of the matrix a.\nwe judge the approximation ax \u2248 b by the maximum fractional deviation, which is\n\nmax\n\ni=1,...,n\n\nmax{(at\n\ni x)/bi, bi/(at\n\ni x)} = max\n\ni=1,...,n\n\nmax{at\nmin{at\n\ni x, bi}\ni x, bi}\n\n,\n\nwhen ax \u227b 0; we define the maximum fractional deviation as \u221e if ax 6\u227b 0.\nthe problem of minimizing the maximum fractional deviation is called the fractional\nchebyshev approximation problem, or the logarithmic chebyshev approximation problem,\nsince it is equivalent to minimizing the objective\n\ni=1,...,n| log at\nmax\n\ni x \u2212 log bi|.\n\n(see also exercise 6.3, part (c).)\n\n(a) formulate the fractional chebyshev approximation problem (with variable bounds)\nas a convex optimization problem with twice differentiable objective and constraint\nfunctions.\n\n(b) implement a barrier method that solves the fractional chebyshev approximation\nproblem. you can assume an initial point x(0), satisfying l \u227a x(0) \u227a u, ax(0) \u227b 0, is\nknown.\n\n11.22 maximum volume rectangle inside a polyhedron. consider the problem described in exer-\ncise 8.16, i.e., finding the maximum volume rectangle r = {x | l (cid:22) x (cid:22) u} that lies in\na polyhedron described by a set of linear inequalities, p = {x | ax (cid:22) b}. implement a\nbarrier method for solving this problem. you can assume that b \u227b 0, which means that\nfor small l \u227a 0 and u \u227b 0, the rectangle r lies inside p.\ntest your implementation on several simple examples. find the maximum volume rect-\nangle that lies in the polyhedron defined by\n\na =\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\n0 \u22121\n2 \u22124\n1\n2\n\u22124\n4\n\u22124\n0\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\n,\n\nb = 1.\n\nplot this polyhedron, and the maximum volume rectangle that lies inside it.\n\n11.23 sdp bounds and heuristics for the two-way partitioning problem.\n\nin this exercise we\nconsider the two-way partitioning problem (5.7), described on page 219, and also in ex-\nercise 5.39:\n\nminimize\nsubject to x2\n\nxt w x\ni = 1,\n\ni = 1, . . . , n,\n\n(11.65)\n\nwith variable x \u2208 rn. we assume, without loss of generality, that w \u2208 sn satisfies\nwii = 0. we denote the optimal value of the partitioning problem as p\u22c6, and x\u22c6 will\ndenote an optimal partition. (note that \u2212x\u22c6 is also an optimal partition.)\nthe lagrange dual of the two-way partitioning problem (11.65) is given by the sdp\n\nmaximize \u22121t \u03bd\nsubject to w + diag(\u03bd) (cid:23) 0,\n\n(11.66)\n\n "}, {"Page_number": 644, "text": "630\n\n11\n\ninterior-point methods\n\nwith variable \u03bd \u2208 rn. the dual of this sdp is\ntr(w x)\n\nminimize\nsubject to x (cid:23) 0\nxii = 1,\n\ni = 1, . . . , n,\n\n(11.67)\n\nwith variable x \u2208 sn.\n(this sdp can be interpreted as a relaxation of the two-way\npartitioning problem (11.65); see exercise 5.39.) the optimal values of these two sdps\nare equal, and give a lower bound, which we denote d\u22c6, on the optimal value p\u22c6. let \u03bd\u22c6\nand x \u22c6 denote optimal points for the two sdps.\n\n(a) implement a barrier method that solves the sdp (11.66) and its dual (11.67), given\nthe weight matrix w . explain how you obtain nearly optimal \u03bd and x, give for-\nmulas for any hessians and gradients that your method requires, and explain how\nyou compute the newton step. test your implementation on some small problem\ninstances, comparing the bound you find with the optimal value (which can be found\nby checking the objective value of all 2n partitions). try your implementation on a\nrandomly chosen problem instance large enough that you cannot find the optimal\npartition by exhaustive search (e.g., n = 100).\n\n(b) a heuristic for partitioning. in exercise 5.39, you found that if x \u22c6 has rank one,\nthen it must have the form x \u22c6 = x\u22c6(x\u22c6)t , where x\u22c6 is optimal for the two-way\npartitioning problem. this suggests the following simple heuristic for finding a good\npartition (if not the best): solve the sdps above, to find x \u22c6 (and the bound d\u22c6).\nlet v denote an eigenvector of x \u22c6 associated with its largest eigenvalue, and let\n\u02c6x = sign(v). the vector \u02c6x is our guess for a good partition.\ntry this heuristic on some small problem instances, and the large problem instance\nyou used in part (a). compare the objective value of your heuristic partition, \u02c6xt w \u02c6x,\nwith the lower bound d\u22c6.\n\n(c) a randomized method. another heuristic technique for finding a good partition,\ngiven the solution x \u22c6 of the sdp (11.67), is based on randomization. the method\nis simple: we generate independent samples x(1), . . . , x(k) from a normal distribution\non rn, with zero mean and covariance x \u22c6. for each sample we consider the heuristic\napproximate solution \u02c6x(k) = sign(x(k)). we then take the best among these, i.e.,\nthe one with lowest cost. try out this procedure on some small problem instances,\nand the large problem instance you considered in part (a).\n\n(d) a greedy heuristic refinement. suppose you are given a partition x, i.e., xi \u2208 {\u22121, 1},\ni = 1, . . . , n. how does the objective value change if we move element i from one\nset to the other, i.e., change xi to \u2212xi? now consider the following simple greedy\nalgorithm: given a starting partition x, move the element that gives the largest\nreduction in the objective. repeat this procedure until no reduction in objective\ncan be obtained by moving an element from one set to the other.\ntry this heuristic on some problem instances, including the large one, starting from\nvarious initial partitions, including x = 1, the heuristic approximate solution found\nin part (b), and the randomly generated approximate solutions found in part (c).\nhow much does this greedy refinement improve your approximate solutions from\nparts (b) and (c)?\n\n11.24 barrier and primal-dual interior-point methods for quadratic programming. implement\na barrier method, and a primal-dual method, for solving the qp (without equality con-\nstraints, for simplicity)\n\n(1/2)xt p x + qt x\n\nminimize\nsubject to ax (cid:22) b,\n\nwith a \u2208 rm\u00d7n. you can assume a strictly feasible initial point is given. test your codes\non several examples. for the barrier method, plot the duality gap versus newton steps.\nfor the primal-dual interior-point method, plot the surrogate duality gap and the norm\nof the dual residual versus iteration number.\n\n "}, {"Page_number": 645, "text": "appendices\n\n "}, {"Page_number": 646, "text": " "}, {"Page_number": 647, "text": "appendix a\n\nmathematical background\n\nin this appendix we give a brief review of some basic concepts from analysis and\nlinear algebra. the treatment is by no means complete, and is meant mostly to set\nout our notation.\n\na.1 norms\n\na.1.1 inner product, euclidean norm, and angle\n\nthe standard inner product on rn, the set of real n-vectors, is given by\n\nhx, yi = xt y =\n\nxiyi,\n\nnxi=1\n\nfor x, y \u2208 rn.\neuclidean norm, or \u21132-norm, of a vector x \u2208 rn is defined as\nn)1/2.\n\nin this book we use the notation xt y, instead of hx, yi. the\n\nkxk2 = (xt x)1/2 = (x2\n\n(a.1)\nthe cauchy-schwartz inequality states that |xt y| \u2264 kxk2kyk2 for any x, y \u2208 rn.\nthe (unsigned) angle between nonzero vectors x, y \u2208 rn is defined as\n\n1 + \u00b7\u00b7\u00b7 + x2\n\nwhere we take cos\u22121(u) \u2208 [0, \u03c0]. we say x and y are orthogonal if xt y = 0.\nby\n\nthe standard inner product on rm\u00d7n, the set of m \u00d7 n real matrices, is given\n\n6 (x, y) = cos\u22121(cid:18) xt y\n\nkxk2kyk2(cid:19) ,\n\nhx, y i = tr(x t y ) =\n\nmxi=1\n\nnxj=1\n\nxijyij,\n\nfor x, y \u2208 rm\u00d7n. (here tr denotes trace of a matrix, i.e., the sum of its diagonal\nelements.) we use the notation tr(x t y ) instead of hx, y i. note that the inner\n\n "}, {"Page_number": 648, "text": "634\n\na mathematical background\n\nproduct of two matrices is the inner product of the associated vectors, in rmn,\nobtained by listing the coefficients of the matrices in some order, such as row\nmajor.\n\nthe frobenius norm of a matrix x \u2208 rm\u00d7n is given by\n\nkxkf =(cid:0)tr(x t x)(cid:1)1/2\n\n1/2\n\n=\uf8eb\uf8ed\nmxi=1\n\nnxj=1\n\nx 2\n\nij\uf8f6\uf8f8\n\n.\n\n(a.2)\n\nthe frobenius norm is the euclidean norm of the vector obtained by listing the\ncoefficients of the matrix. (the \u21132-norm of a matrix is a different norm; see \u00a7a.1.5.)\nthe standard inner product on sn, the set of symmetric n\u00d7 n matrices, is given\nby\n\nhx, y i = tr(xy ) =\n\nxijyij =\n\nnxi=1\n\nnxj=1\n\nnxi=1\n\nxiiyii + 2xi<j\n\nxijyij.\n\na.1.2 norms, distance, and unit ball\n\na function f : rn \u2192 r with dom f = rn is called a norm if\n\n\u2022 f is nonnegative: f (x) \u2265 0 for all x \u2208 rn\n\u2022 f is definite: f (x) = 0 only if x = 0\n\u2022 f is homogeneous: f (tx) = |t|f (x), for all x \u2208 rn and t \u2208 r\n\u2022 f satisfies the triangle inequality: f (x + y) \u2264 f (x) + f (y), for all x, y \u2208 rn\nwe use the notation f (x) = kxk, which is meant to suggest that a norm is a\ngeneralization of the absolute value on r. when we specify a particular norm,\nwe use the notation kxksymb, where the subscript is a mnemonic to indicate which\nnorm is meant.\na norm is a measure of the length of a vector x; we can measure the distance\n\nbetween two vectors x and y as the length of their difference, i.e.,\n\ndist(x, y) = kx \u2212 yk.\n\nwe refer to dist(x, y) as the distance between x and y, in the norm k \u00b7 k.\n\nthe set of all vectors with norm less than or equal to one,\n\nb = {x \u2208 rn | kxk \u2264 1},\n\nis called the unit ball of the norm k \u00b7 k. the unit ball satisfies the following prop-\nerties:\n\n\u2022 b is symmetric about the origin, i.e., x \u2208 b if and only if \u2212x \u2208 b\n\u2022 b is convex\n\u2022 b is closed, bounded, and has nonempty interior\n\n "}, {"Page_number": 649, "text": "a.1 norms\n\n635\n\nconversely, if c \u2286 rn is any set satisfying these three conditions, then it is the\nunit ball of a norm, which is given by\n\nkxk = (sup{t \u2265 0 | tx \u2208 c})\u22121 .\n\na.1.3 examples\n\nthe simplest example of a norm is the absolute value on r. another simple\nexample is the euclidean or \u21132-norm on rn, defined above in (a.1). two other\nfrequently used norms on rn are the sum-absolute-value, or \u21131-norm, given by\n\nand the chebyshev or \u2113\u221e-norm, given by\n\nkxk1 = |x1| + \u00b7\u00b7\u00b7 + |xn|,\n\nkxk\u221e = max{|x1|, . . . ,|xn|}.\n\nthese three norms are part of a family parametrized by a constant traditionally\ndenoted p, with p \u2265 1: the \u2113p-norm is defined by\n\nkxkp = (|x1|p + \u00b7\u00b7\u00b7 + |xn|p)1/p.\n\nthis yields the \u21131-norm when p = 1 and the euclidean norm when p = 2. it is easy\nto show that for any x \u2208 rn,\np\u2192\u221ekxkp = max{|x1|, . . . ,|xn|},\nlim\n\nso the \u2113\u221e-norm also fits in this family, as a limit.\n\nanother important family of norms are the quadratic norms. for p \u2208 sn\n\n++, we\n\ndefine the p -quadratic norm as\n\nkxkp = (xt p x)1/2 = kp 1/2xk2.\n\nthe unit ball of a quadratic norm is an ellipsoid (and conversely, if the unit ball of\na norm is an ellipsoid, the norm is a quadratic norm).\n\nsome common norms on rm\u00d7n are the frobenius norm, defined above in (a.2),\n\nthe sum-absolute-value norm,\n\nkxksav =\n\nmxi=1\n\nnxj=1\n\n|xij|,\n\nand the maximum-absolute-value norm,\n\nkxkmav = max{|xij| | i = 1, . . . , m, j = 1, . . . , n}.\n\nwe will encounter several other important norms of matrices in \u00a7a.1.5.\n\n "}, {"Page_number": 650, "text": "636\n\na mathematical background\n\na.1.4 equivalence of norms\n\nsuppose that k \u00b7 ka and k \u00b7 kb are norms on rn. a basic result of analysis is that\nthere exist positive constants \u03b1 and \u03b2 such that, for all x \u2208 rn,\n\n\u03b1kxka \u2264 kxkb \u2264 \u03b2kxka.\n\nthis means that the norms are equivalent, i.e., they define the same set of open\nsubsets, the same set of convergent sequences, and so on (see \u00a7a.2).\n(we con-\nclude that any norms on any finite-dimensional vector space are equivalent, but on\ninfinite-dimensional vector spaces, the result need not hold.) using convex analy-\nsis, we can give a more specific result: if k \u00b7 k is any norm on rn, then there exists\na quadratic norm k \u00b7 kp for which\n\nkxkp \u2264 kxk \u2264 \u221ankxkp\n\nholds for all x. in other words, any norm on rn can be uniformly approximated,\n\nwithin a factor of \u221an, by a quadratic norm. (see \u00a78.4.1.)\n\na.1.5 operator norms\n\nsuppose k \u00b7 ka and k \u00b7 kb are norms on rm and rn, respectively. we define the\noperator norm of x \u2208 rm\u00d7n, induced by the norms k \u00b7 ka and k \u00b7 kb, as\n\nkxka,b = sup{kxuka | kukb \u2264 1} .\n\n(it can be shown that this defines a norm on rm\u00d7n.)\n\nwhen k \u00b7 ka and k \u00b7 kb are both euclidean norms, the operator norm of x is its\n\nmaximum singular value, and is denoted kxk2:\n\nkxk2 = \u03c3max(x) = (\u03bbmax(x t x))1/2.\n\n(this agrees with the euclidean norm on rm, when x \u2208 rm\u00d71, so there is no\nclash of notation.) this norm is also called the spectral norm or \u21132-norm of x.\nas another example, the norm induced by the \u2113\u221e-norm on rm and rn, denoted\n\nkxk\u221e, is the max-row-sum norm,\n\nkxk\u221e = sup{kxuk\u221e | kuk\u221e \u2264 1} = max\n\ni=1,...,m\n\nnxj=1\n\n|xij|.\n\nthe norm induced by the \u21131-norm on rm and rn, denoted kxk1, is the max-\ncolumn-sum norm,\n\nkxk1 = max\n\nj=1,...,n\n\nmxi=1\n\n|xij|.\n\n "}, {"Page_number": 651, "text": "a.2 analysis\n\na.1.6 dual norm\n\n637\n\nlet k \u00b7 k be a norm on rn. the associated dual norm, denoted k \u00b7 k\u2217, is defined as\n\nkzk\u2217 = sup{zt x | kxk \u2264 1}.\n\n(this can be shown to be a norm.) the dual norm can be interpreted as the\noperator norm of zt , interpreted as a 1\u00d7 n matrix, with the norm k\u00b7k on rn, and\nthe absolute value on r:\n\nfrom the definition of dual norm we have the inequality\n\nkzk\u2217 = sup{|zt x| | kxk \u2264 1}.\n\nzt x \u2264 kxkkzk\u2217,\n\nwhich holds for all x and z. this inequality is tight, in the following sense: for any\nx there is a z for which the inequality holds with equality. (similarly, for any z\nthere is an x that gives equality.) the dual of the dual norm is the original norm:\nwe have kxk\u2217\u2217 = kxk for all x. (this need not hold in infinite-dimensional vector\nspaces.)\n\nthe dual of the euclidean norm is the euclidean norm, since\n\nsup{zt x | kxk2 \u2264 1} = kzk2.\n\n(this follows from the cauchy-schwarz inequality; for nonzero z, the value of x\nthat maximizes zt x over kxk2 \u2264 1 is z/kzk2.)\nthe dual of the \u2113\u221e-norm is the \u21131-norm:\n\nsup{zt x | kxk\u221e \u2264 1} =\n\n|zi| = kzk1,\n\nnxi=1\n\nand the dual of the \u21131-norm is the \u2113\u221e-norm. more generally, the dual of the \u2113p-norm\nis the \u2113q-norm, where q satisfies 1/p + 1/q = 1, i.e., q = p/(p \u2212 1).\ndual norm is\n\nas another example, consider the \u21132- or spectral norm on rm\u00d7n. the associated\n\nwhich turns out to be the sum of the singular values,\n\nkzk2\u2217 = sup{tr(z t x) | kxk2 \u2264 1},\n\nkzk2\u2217 = \u03c31(z) + \u00b7\u00b7\u00b7 + \u03c3r(z) = tr(z t z)1/2,\n\nwhere r = rank z. this norm is sometimes called the nuclear norm.\n\na.2 analysis\n\na.2.1 open and closed sets\n\nan element x \u2208 c \u2286 rn is called an interior point of c if there exists an \u01eb > 0 for\nwhich\n\n{y | ky \u2212 xk2 \u2264 \u01eb} \u2286 c,\n\n "}, {"Page_number": 652, "text": "638\n\na mathematical background\n\ni.e., there exists a ball centered at x that lies entirely in c. the set of all points\ninterior to c is called the interior of c and is denoted int c. (since all norms\non rn are equivalent to the euclidean norm, all norms generate the same set of\ninterior points.) a set c is open if int c = c, i.e., every point in c is an interior\npoint. a set c \u2286 rn is closed if its complement rn \\ c = {x \u2208 rn | x 6\u2208 c} is\nopen.\n\nthe closure of a set c is defined as\n\ncl c = rn \\ int(rn \\ c),\n\ni.e., the complement of the interior of the complement of c. a point x is in the\nclosure of c if for every \u01eb > 0, there is a y \u2208 c with kx \u2212 yk2 \u2264 \u01eb.\nwe can also describe closed sets and the closure in terms of convergent sequences\nand limit points. a set c is closed if and only if it contains the limit point of every\nconvergent sequence in it. in other words, if x1, x2, . . . converges to x, and xi \u2208 c,\nthen x \u2208 c. the closure of c is the set of all limit points of convergent sequences\nin c.\n\nthe boundary of the set c is defined as\n\nbd c = cl c \\ int c.\n\na boundary point x (i.e., a point x \u2208 bd c) satisfies the following property: for\nall \u01eb > 0, there exists y \u2208 c and z 6\u2208 c with\n\nky \u2212 xk2 \u2264 \u01eb,\n\nkz \u2212 xk2 \u2264 \u01eb,\n\ni.e., there exist arbitrarily close points in c, and also arbitrarily close points not in\nc. we can characterize closed and open sets in terms of the boundary operation:\nc is closed if it contains its boundary, i.e., bd c \u2286 c. it is open if it contains no\nboundary points, i.e., c \u2229 bd c = \u2205.\n\na.2.2 supremum and infimum\n\nsuppose c \u2286 r. a number a is an upper bound on c if for each x \u2208 c, x \u2264 a.\nthe set of upper bounds on a set c is either empty (in which case we say c is\nunbounded above), all of r (only when c = \u2205), or a closed infinite interval [b,\u221e).\nthe number b is called the least upper bound or supremum of the set c, and is\ndenoted sup c. we take sup\u2205 = \u2212\u221e, and sup c = \u221e if c is unbounded above.\nwhen sup c \u2208 c, we say the supremum of c is attained or achieved.\nwhen the set c is finite, sup c is the maximum of its elements. some authors\nuse the notation max c to denote supremum, when it is attained, but we follow\nstandard mathematical convention, using max c only when the set c is finite.\n\nwe define lower bound, and infimum, in a similar way. a number a is a lower\nbound on c \u2286 r if for each x \u2208 c, a \u2264 x. the infimum (or greatest lower bound )\nof a set c \u2286 r is defined as inf c = \u2212 sup(\u2212c). when c is finite, the infimum\nis the minimum of its elements. we take inf \u2205 = \u221e, and inf c = \u2212\u221e if c is\nunbounded below, i.e., has no lower bound.\n\n "}, {"Page_number": 653, "text": "a.3 functions\n\n639\n\na.3 functions\n\na.3.1 function notation\n\nour notation for functions is mostly standard, with one exception. when we write\n\nf : a \u2192 b\n\nwe mean that f is a function on the set dom f \u2286 a into the set b; in particular\nwe can have dom f a proper subset of the set a. thus the notation f : rn \u2192 rm\nmeans that f maps (some) n-vectors into m-vectors; it does not mean that f (x)\nis defined for every x \u2208 rn. this convention is similar to function declarations in\ncomputer languages. specifying the data types of the input and output arguments\nof a function gives the syntax of that function; it does not guarantee that any input\nargument with the specified data type is valid.\n\nas an example consider the function f : sn \u2192 r, given by\n\nf (x) = log det x,\n\n(a.3)\n++. the notation f : sn \u2192 r specifies the syntax of f : it takes\nwith dom f = sn\nas argument a symmetric n \u00d7 n matrix, and returns a real number. the notation\ndom f = sn\n++ specifies which symmetric n\u00d7 n matrices are valid input arguments\nfor f (i.e., only positive definite ones). the formula (a.3) specifies what f (x) is,\nfor x \u2208 dom f .\n\na.3.2 continuity\n\na function f : rn \u2192 rm is continuous at x \u2208 dom f if for all \u01eb > 0 there exists a\n\u03b4 such that\n\ny \u2208 dom f,\n\nky \u2212 xk2 \u2264 \u03b4 =\u21d2 kf (y) \u2212 f (x)k2 \u2264 \u01eb.\n\ncontinuity can be described in terms of limits: whenever the sequence x1, x2, . . .\nin dom f converges to a point x \u2208 dom f , the sequence f (x1), f (x2), . . . converges\nto f (x), i.e.,\n\nlim\ni\u2192\u221e\n\nf (xi) = f ( lim\ni\u2192\u221e\n\nxi).\n\na function f is continuous if it is continuous at every point in its domain.\n\na.3.3 closed functions\n\na function f : rn \u2192 r is said to be closed if, for each \u03b1 \u2208 r, the sublevel set\n\n{x \u2208 dom f | f (x) \u2264 \u03b1}\n\nis closed. this is equivalent to the condition that the epigraph of f ,\n\nepi f = {(x, t) \u2208 rn+1 | x \u2208 dom f, f (x) \u2264 t},\n\n "}, {"Page_number": 654, "text": "640\n\na mathematical background\n\nis closed. (this definition is general, but is usually only applied to convex func-\ntions.)\n\nif f : rn \u2192 r is continuous, and dom f is closed, then f is closed. if f : rn \u2192\nr is continuous, with dom f open, then f is closed if and only if f converges to \u221e\nalong every sequence converging to a boundary point of dom f . in other words, if\nlimi\u2192\u221e xi = x \u2208 bd dom f , with xi \u2208 dom f , we have limi\u2192\u221e f (xi) = \u221e.\n\nexample a.1 examples on r.\n\n\u2022 the function f : r \u2192 r, with f (x) = x log x, dom f = r++, is not closed.\n\u2022 the function f : r \u2192 r, with\n\nf (x) =(cid:26) x log x x > 0\n\nx = 0,\n\n0\n\ndom f = r+,\n\nis closed.\n\n\u2022 the function f (x) = \u2212 log x, dom f = r++, is closed.\n\na.4 derivatives\n\na.4.1 derivative and gradient\n\nsuppose f : rn \u2192 rm and x \u2208 int dom f . the function f is differentiable at x if\nthere exists a matrix df (x) \u2208 rm\u00d7n that satisfies\n\nlim\n\nz\u2208dom f, z6=x, z\u2192x\n\nkf (z) \u2212 f (x) \u2212 df (x)(z \u2212 x)k2\n\nkz \u2212 xk2\n\n= 0,\n\n(a.4)\n\nin which case we refer to df (x) as the derivative (or jacobian) of f at x. (there\ncan be at most one matrix that satisfies (a.4).) the function f is differentiable if\ndom f is open, and it is differentiable at every point in its domain.\n\nthe affine function of z given by\n\nf (x) + df (x)(z \u2212 x)\n\nis called the first-order approximation of f at (or near) x. evidently this function\nagrees with f at z = x; when z is close to x, this affine function is very close to f .\nthe derivative can be found by deriving the first-order approximation of the\nfunction f at x (i.e., the matrix df (x) that satisfies (a.4)), or from partial deriva-\ntives:\n\ndf (x)ij =\n\n\u2202fi(x)\n\n\u2202xj\n\n,\n\ni = 1, . . . , m,\n\nj = 1, . . . , n.\n\n "}, {"Page_number": 655, "text": "a.4 derivatives\n\n641\n\ngradient\nwhen f is real-valued (i.e., f : rn \u2192 r) the derivative df (x) is a 1 \u00d7 n matrix,\ni.e., it is a row vector. its transpose is called the gradient of the function:\n\nwhich is a (column) vector, i.e., in rn. its components are the partial derivatives\nof f :\n\n\u2207f (x) = df (x)t ,\n\n\u2207f (x)i =\n\n\u2202f (x)\n\u2202xi\n\n,\n\ni = 1, . . . , n.\n\nthe first-order approximation of f at a point x \u2208 int dom f can be expressed as\n(the affine function of z)\n\nf (x) + \u2207f (x)t (z \u2212 x).\n\nexamples\nas a simple example consider the quadratic function f : rn \u2192 r,\n\nf (x) = (1/2)xt p x + qt x + r,\n\nwhere p \u2208 sn, q \u2208 rn, and r \u2208 r. its derivative at x is the row vector df (x) =\nxt p + qt , and its gradient is\n\n\u2207f (x) = p x + q.\n\nas a more interesting example, we consider the function f : sn \u2192 r, given by\n\nf (x) = log det x,\n\ndom f = sn\n\n++.\n\none (tedious) way to find the gradient of f is to introduce a basis for sn, find\nthe gradient of the associated function, and finally translate the result back to sn.\ninstead, we will directly find the first-order approximation of f at x \u2208 sn\n++. let\nz \u2208 sn\n++ be close to x, and let \u2206x = z \u2212 x (which is assumed to be small). we\nhave\n\nlog det z = log det(x + \u2206x)\n\n= log det(cid:16)x 1/2(i + x \u22121/2\u2206xx \u22121/2)x 1/2(cid:17)\n\n= log det x + log det(i + x \u22121/2\u2206xx \u22121/2)\n\n= log det x +\n\nlog(1 + \u03bbi),\n\nnxi=1\n\nwhere \u03bbi is the ith eigenvalue of x \u22121/2\u2206xx \u22121/2. now we use the fact that \u2206x is\nsmall, which implies \u03bbi are small, so to first order we have log(1 + \u03bbi) \u2248 \u03bbi. using\nthis first-order approximation in the expression above, we get\n\nlog det z \u2248 log det x +\n\n\u03bbi\n\nnxi=1\n\n= log det x + tr(x \u22121/2\u2206xx \u22121/2)\n= log det x + tr(x \u22121\u2206x)\n\n= log det x + tr(cid:0)x \u22121(z \u2212 x)(cid:1) ,\n\n "}, {"Page_number": 656, "text": "642\n\na mathematical background\n\nwhere we have used the fact that the sum of the eigenvalues is the trace, and the\nproperty tr(ab) = tr(ba).\n\nthus, the first-order approximation of f at x is the affine function of z given\n\nby\n\nf (z) \u2248 f (x) + tr(cid:0)x \u22121(z \u2212 x)(cid:1) .\n\nnoting that the second term on the righthand side is the standard inner product\nof x \u22121 and z \u2212 x, we can identify x \u22121 as the gradient of f at x. thus, we can\nwrite the simple formula\n\nthis result should not be surprising, since the derivative of log x, on r++, is 1/x.\n\n\u2207f (x) = x \u22121.\n\na.4.2 chain rule\n\nsuppose f : rn \u2192 rm is differentiable at x \u2208 int dom f and g : rm \u2192 rp\nis differentiable at f (x) \u2208 int dom g. define the composition h : rn \u2192 rp by\nh(z) = g(f (z)). then h is differentiable at x, with derivative\n\ndh(x) = dg(f (x))df (x).\n\n(a.5)\n\nas an example, suppose f : rn \u2192 r, g : r \u2192 r, and h(x) = g(f (x)). taking\n\nthe transpose of dh(x) = dg(f (x))df (x) yields\n\n\u2207h(x) = g\u2032(f (x))\u2207f (x).\n\n(a.6)\n\ncomposition with affine function\nsuppose f : rn \u2192 rm is differentiable, a \u2208 rn\u00d7p, and b \u2208 rn. define g : rp \u2192\nrm as g(x) = f (ax + b), with dom g = {x | ax + b \u2208 dom f}. the derivative of\ng is, by the chain rule (a.5), dg(x) = df (ax + b)a.\nwhen f is real-valued (i.e., m = 1), we obtain the formula for the gradient of\n\na composition of a function with an affine function,\n\n\u2207g(x) = at\u2207f (ax + b).\n\nfor example, suppose that f : rn \u2192 r, x, v \u2208 rn, and we define the function\n\u02dcf : r \u2192 r by \u02dcf (t) = f (x + tv). (roughly speaking, \u02dcf is f , restricted to the line\n{x + tv | t \u2208 r}.) then we have\n\nd \u02dcf (t) = \u02dcf \u2032(t) = \u2207f (x + tv)t v.\n\n(the scalar \u02dcf \u2032(0) is the directional derivative of f , at x, in the direction v.)\n\nexample a.2 consider the function f : rn \u2192 r, with dom f = rn and\n\nf (x) = log\n\nmxi=1\n\nexp(at\n\ni x + bi),\n\n "}, {"Page_number": 657, "text": "a.4 derivatives\n\n643\n\nwhere a1, . . . , am \u2208 rn, and b1, . . . , bm \u2208 r. we can find a simple expression for\nits gradient by noting that it is the composition of the affine function ax + b, where\nm, and the function g : rm \u2192 r given by g(y) =\na \u2208 rm\u00d7n with rows at\n\ni=1 exp yi). simple differentiation (or the formula (a.6)) shows that\n\n1 , . . . , at\n\nlog(pm\n\n\u2207g(y) =\n\n1\n\ni=1 exp yi\uf8ee\uf8ef\uf8f0\npm\n\nexp y1\n\n...\n\nexp ym\n\n\uf8f9\uf8fa\uf8fb ,\n\n(a.7)\n\nso by the composition formula we have\n\n\u2207f (x) =\n\n1\n\n1t z\n\nat z\n\nwhere zi = exp(at\n\ni x + bi), i = 1, . . . , m.\n\nexample a.3 we derive an expression for \u2207f (x), where\n\nf (x) = log det(f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn),\n\nwhere f0, . . . , fn \u2208 sp, and\n\ndom f = {x \u2208 rn | f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn \u227b 0}.\n\nthe function f is the composition of the affine mapping from x \u2208 rn to f0 + x1f1 +\n\u00b7\u00b7\u00b7 + xnfn \u2208 sp, with the function log det x. we use the chain rule to evaluate\n\n\u2202f (x)\n\n\u2202xi\n\n= tr(fi\u2207 log det(f )) = tr(f \u22121fi),\n\nwhere f = f0 + x1f1 + \u00b7\u00b7\u00b7 + xnfn. thus we have\ntr(f \u22121f1)\n\n\u2207f (x) =\uf8ee\uf8ef\uf8f0\n\n...\n\ntr(f \u22121fn)\n\n\uf8f9\uf8fa\uf8fb .\n\na.4.3 second derivative\n\nin this section we review the second derivative of a real-valued function f : rn \u2192\nr. the second derivative or hessian matrix of f at x \u2208 int dom f , denoted\n\u22072f (x), is given by\n\n\u22072f (x)ij =\n\n\u22022f (x)\n\u2202xi\u2202xj\n\n,\n\ni = 1, . . . n,\n\nj = 1, . . . , n,\n\nprovided f is twice differentiable at x, where the partial derivatives are evaluated\nat x. the second-order approximation of f , at or near x, is the quadratic function\nof z defined by\n\nbf (z) = f (x) + \u2207f (x)t (z \u2212 x) + (1/2)(z \u2212 x)t\u22072f (x)(z \u2212 x).\n\n "}, {"Page_number": 658, "text": "644\n\na mathematical background\n\nthis second-order approximation satisfies\n\nlim\n\nz\u2208dom f, z6=x, z\u2192x\n\n|f (z) \u2212 bf (z)|\nkz \u2212 xk2\n\n2\n\n= 0.\n\nnot surprisingly, the second derivative can be interpreted as the derivative of\nthe first derivative.\nif f is differentiable, the gradient mapping is the function\n\u2207f : rn \u2192 rn, with dom\u2207f = dom f , with value \u2207f (x) at x. the derivative\nof this mapping is\n\nd\u2207f (x) = \u22072f (x).\n\nexamples\nas a simple example consider the quadratic function f : rn \u2192 r,\n\nf (x) = (1/2)xt p x + qt x + r,\n\nwhere p \u2208 sn, q \u2208 rn, and r \u2208 r. its gradient is \u2207f (x) = p x + q, so its hessian\nis given by \u22072f (x) = p . the second-order approximation of a quadratic function\nis itself.\nas a more complicated example, we consider again the function f : sn \u2192 r,\ngiven by f (x) = log det x, with dom f = sn\n++. to find the second-order approxi-\nmation (and therefore, the hessian), we will derive a first-order approximation of\nthe gradient, \u2207f (x) = x \u22121. for z \u2208 sn\n++, and \u2206x = z \u2212 x, we\nhave\n\n++ near x \u2208 sn\n\nz \u22121 = (x + \u2206x)\u22121\n\n= (cid:16)x 1/2(i + x \u22121/2\u2206xx \u22121/2)x 1/2(cid:17)\u22121\n= x \u22121/2(i + x \u22121/2\u2206xx \u22121/2)\u22121x \u22121/2\n\u2248 x \u22121/2(i \u2212 x \u22121/2\u2206xx \u22121/2)x \u22121/2\n= x \u22121 \u2212 x \u22121\u2206xx \u22121,\n\nusing the first-order approximation (i + a)\u22121 \u2248 i \u2212 a, valid for a small.\nthis approximation is enough for us to identify the hessian of f at x. the\nhessian is a quadratic form on sn. such a quadratic form is cumbersome to de-\nscribe in the general case, since it requires four indices. but from the first-order\napproximation of the gradient above, the quadratic form can be expressed as\n\n\u2212 tr(x \u22121u x \u22121v ),\n\nwhere u, v \u2208 sn are the arguments of the quadratic form. (this generalizes the\nexpression for the scalar case: (log x)\u2032\u2032 = \u22121/x2.)\n\nnow we have the second-order approximation of f near x:\n\nf (z) = f (x + \u2206x)\n\n\u2248 f (x) + tr(x \u22121\u2206x) \u2212 (1/2) tr(x \u22121\u2206xx \u22121\u2206x)\n\u2248 f (x) + tr(cid:0)x \u22121(z \u2212 x)(cid:1) \u2212 (1/2) tr(cid:0)x \u22121(z \u2212 x)x \u22121(z \u2212 x)(cid:1) .\n\n "}, {"Page_number": 659, "text": "a.5 linear algebra\n\n645\n\na.4.4 chain rule for second derivative\n\na general chain rule for the second derivative is cumbersome in most cases, so we\nwill state it only for some special cases that we will need.\n\ncomposition with scalar function\nsuppose f : rn \u2192 r, g : r \u2192 r, and h(x) = g(f (x)). simply working out the\npartial derivatives yields\n\n\u22072h(x) = g\u2032(f (x))\u22072f (x) + g\u2032\u2032(f (x))\u2207f (x)\u2207f (x)t .\n\n(a.8)\n\ncomposition with affine function\nsuppose f : rn \u2192 r, a \u2208 rn\u00d7m, and b \u2208 rn. define g : rm \u2192 r by g(x) =\nf (ax + b). then we have\n\n\u22072g(x) = at\u22072f (ax + b)a.\n\nas an example, consider the restriction of a real-valued function f to a line, i.e.,\nthe function \u02dcf (t) = f (x + tv), where x and v are fixed. then we have\n\n\u22072 \u02dcf (t) = \u02dcf \u2032\u2032(t) = vt\u22072f (x + tv)v.\n\nexample a.4 we consider the function f : rn \u2192 r from example a.2,\n\nf (x) = log\n\nexp(at\n\ni x + bi),\n\nmxi=1\n\nwhere a1, . . . , am \u2208 rn, and b1, . . . , bm \u2208 r. by noting that f (x) = g(ax + b), where\ni=1 exp yi), we can obtain a simple formula for the hessian of f . taking\npartial derivatives, or using the formula (a.8), noting that g is the composition of\n\ng(y) = log(pm\nlog withpm\n\ni=1 exp yi, yields\n\n\u22072g(y) = diag(\u2207g(y)) \u2212 \u2207g(y)\u2207g(y)t ,\n\nwhere \u2207g(y) is given in (a.7). by the composition formula we have\n\n\u22072f (x) = at(cid:18) 1\n\n1t z\n\ndiag(z) \u2212\n\n1\n\n(1t z)2 zzt(cid:19) a,\n\nwhere zi = exp(at\n\ni x + bi), i = 1, . . . , m.\n\na.5 linear algebra\n\na.5.1 range and nullspace\n\nlet a \u2208 rm\u00d7n (i.e., a is a real matrix with m rows and n columns). the range\nof a, denoted r(a), is the set of all vectors in rm that can be written as linear\n\n "}, {"Page_number": 660, "text": "646\n\na mathematical background\n\ncombinations of the columns of a, i.e.,\n\nr(a) = {ax | x \u2208 rn}.\n\nthe range r(a) is a subspace of rm, i.e., it is itself a vector space. its dimension\nis the rank of a, denoted rank a. the rank of a can never be greater than the\nminimum of m and n. we say a has full rank if rank a = min{m, n}.\ninto zero by a:\n\nthe nullspace (or kernel ) of a, denoted n (a), is the set of all vectors x mapped\n\nthe nullspace is a subspace of rn.\n\nn (a) = {x | ax = 0}.\n\northogonal decomposition induced by a\nif v is a subspace of rn, its orthogonal complement, denoted v \u22a5, is defined as\n\nv \u22a5 = {x | zt x = 0 for all z \u2208 v}.\n(as one would expect of a complement, we have v \u22a5\u22a5 = v.)\n\na basic result of linear algebra is that, for any a \u2208 rm\u00d7n, we have\n\nn (a) = r(at )\u22a5.\n\n(applying the result to at we also have r(a) = n (at )\u22a5.) this result is often\nstated as\n\nn (a)\n\n\u22a5\n\n\u2295 r(at ) = rn.\n\n(a.9)\n\n\u22a5\n\n\u2295 refers to orthogonal direct sum, i.e., the sum of two subspaces\nhere the symbol\nthat are orthogonal. the decomposition (a.9) of rn is called the orthogonal de-\ncomposition induced by a.\n\na.5.2 symmetric eigenvalue decomposition\n\nsuppose a \u2208 sn, i.e., a is a real symmetric n \u00d7 n matrix. then a can be factored\nas\n(a.10)\nwhere q \u2208 rn\u00d7n is orthogonal, i.e., satisfies qt q = i, and \u03bb = diag(\u03bb1, . . . , \u03bbn).\nthe (real) numbers \u03bbi are the eigenvalues of a, and are the roots of the charac-\nteristic polynomial det(si \u2212 a). the columns of q form an orthonormal set of\neigenvectors of a. the factorization (a.10) is called the spectral decomposition or\n(symmetric) eigenvalue decomposition of a.\n\na = q\u03bbqt ,\n\nwe order the eigenvalues as \u03bb1 \u2265 \u03bb2 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn. we use the notation \u03bbi(a)\nto refer to the ith largest eigenvalue of a \u2208 s. we usually write the largest or\nmaximum eigenvalue as \u03bb1(a) = \u03bbmax(a), and the least or minimum eigenvalue as\n\u03bbn(a) = \u03bbmin(a).\n\n "}, {"Page_number": 661, "text": "a.5 linear algebra\n\n647\n\nthe determinant and trace can be expressed in terms of the eigenvalues,\n\ndet a =\n\nnyi=1\n\n\u03bbi,\n\ntr a =\n\nas can the spectral and frobenius norms,\n\nkak2 = max\n\ni=1,...,n|\u03bbi| = max{\u03bb1,\u2212\u03bbn},\n\ndefiniteness and matrix inequalities\n\nthe largest and smallest eigenvalues satisfy\n\n\u03bbi,\n\nnxi=1\nkakf =  nxi=1\n\ni!1/2\n\n\u03bb2\n\n.\n\n\u03bbmax(a) = sup\nx6=0\n\nxt ax\nxt x\n\n,\n\n\u03bbmin(a) = inf\nx6=0\n\nxt ax\nxt x\n\n.\n\nin particular, for any x, we have\n\n\u03bbmin(a)xt x \u2264 xt ax \u2264 \u03bbmax(a)xt x,\n\nwith both inequalities tight for (different) choices of x.\n\na matrix a \u2208 sn is called positive definite if for all x 6= 0, xt ax > 0. we\ndenote this as a \u227b 0. by the inequality above, we see that a \u227b 0 if and only all\nits eigenvalues are positive, i.e., \u03bbmin(a) > 0. if \u2212a is positive definite, we say a\nis negative definite, which we write as a \u227a 0. we use sn\n++ to denote the set of\npositive definite matrices in sn.\n\nif a satisfies xt ax \u2265 0 for all x, we say that a is positive semidefinite or\nnonnegative definite. if \u2212a is in nonnegative definite, i.e., if xt ax \u2264 0 for all x,\nwe say that a is negative semidefinite or nonpositive definite. we use sn\n+ to denote\nthe set of nonnegative definite matrices in sn.\n\nfor a, b \u2208 sn, we use a \u227a b to mean b \u2212 a \u227b 0, and so on. these inequal-\nities are called matrix inequalities, or generalized inequalities associated with the\npositive semidefinite cone.\n\nsymmetric squareroot\nlet a \u2208 sn\nthe (symmetric) squareroot of a as\n\n+, with eigenvalue decomposition a = q diag(\u03bb1, . . . , \u03bbn)qt . we define\n\na1/2 = q diag(\u03bb1/2\n\n1\n\n, . . . , \u03bb1/2\n\nn )qt .\n\nthe squareroot a1/2 is the unique symmetric positive semidefinite solution of the\nequation x 2 = a.\n\na.5.3 generalized eigenvalue decomposition\n\nthe generalized eigenvalues of a pair of symmetric matrices (a, b) \u2208 sn \u00d7 sn are\ndefined as the roots of the polynomial det(sb \u2212 a).\n\n "}, {"Page_number": 662, "text": "648\n\na mathematical background\n\nwe are usually interested in matrix pairs with b \u2208 sn\n\nin this case the\ngeneralized eigenvalues are also the eigenvalues of b\u22121/2ab\u22121/2 (which are real).\nas with the standard eigenvalue decomposition, we order the generalized eigen-\nvalues in nonincreasing order, as \u03bb1 \u2265 \u03bb2 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03bbn, and denote the maximum\ngeneralized eigenvalue by \u03bbmax(a, b).\n\n++.\n\nwhen b \u2208 sn\n\n++, the pair of matrices can be factored as\n\na = v \u03bbv t ,\n\nb = v v t ,\n\n(a.11)\n\nwhere v \u2208 rn\u00d7n is nonsingular, and \u03bb = diag(\u03bb1, . . . , \u03bbn), where \u03bbi are the\ngeneralized eigenvalues of the pair (a, b). the decomposition (a.11) is called the\ngeneralized eigenvalue decomposition.\n\nthe generalized eigenvalue decomposition is related to the standard eigenvalue\ndecomposition of the matrix b\u22121/2ab\u22121/2. if q\u03bbqt is the eigenvalue decompo-\nsition of b\u22121/2ab\u22121/2, then (a.11) holds with v = b1/2q.\n\na.5.4 singular value decomposition\n\nsuppose a \u2208 rm\u00d7n with rank a = r. then a can be factored as\n\na = u \u03c3v t ,\n\n(a.12)\n\nwhere u \u2208 rm\u00d7r satisfies u t u = i, v \u2208 rn\u00d7r satisfies v t v = i, and \u03c3 =\ndiag(\u03c31, . . . , \u03c3r), with\n\n\u03c31 \u2265 \u03c32 \u2265 \u00b7\u00b7\u00b7 \u2265 \u03c3r > 0.\n\nthe factorization (a.12) is called the singular value decomposition (svd) of a.\nthe columns of u are called left singular vectors of a, the columns of v are right\nsingular vectors, and the numbers \u03c3i are the singular values. the singular value\ndecomposition can be written\n\na =\n\nrxi=1\n\n\u03c3iuivt\ni ,\n\nwhere ui \u2208 rm are the left singular vectors, and vi \u2208 rn are the right singular\nvectors.\nthe singular value decomposition of a matrix a is closely related to the eigen-\nvalue decomposition of the (symmetric, nonnegative definite) matrix at a. us-\ning (a.12) we can write\n\nat a = v \u03c32v t =(cid:2) v\n\n\u02dcv (cid:3)(cid:20) \u03c32\n\n0\n\n0\n\n0 (cid:21)(cid:2) v\n\n,\n\n\u02dcv (cid:3)t\n\nwhere \u02dcv is any matrix for which [v \u02dcv ] is orthogonal. the righthand expression is\nthe eigenvalue decomposition of at a, so we conclude that its nonzero eigenvalues\nare the singular values of a squared, and the associated eigenvectors of at a are\nthe right singular vectors of a. a similar analysis of aat shows that its nonzero\n\n "}, {"Page_number": 663, "text": "a.5 linear algebra\n\n649\n\neigenvalues are also the squares of the singular values of a, and the associated\neigenvectors are the left singular vectors of a.\n\nthe first or largest singular value is also written as \u03c3max(a). it can be expressed\n\nas\n\n\u03c3max(a) = sup\nx,y6=0\n\nxt ay\nkxk2kyk2\n\n= sup\ny6=0\n\nkayk2\nkyk2\n\n.\n\nthe righthand expression shows that the maximum singular value is the \u21132 operator\nnorm of a. the minimum singular value of a \u2208 rm\u00d7n is given by\n\n\u03c3min(a) =(cid:26) \u03c3r(a)\n\n0\n\nr = min{m, n}\nr < min{m, n},\n\nwhich is positive if and only if a is full rank.\n\nthe singular values of a symmetric matrix are the absolute values of its nonzero\neigenvalues, sorted into descending order. the singular values of a symmetric\npositive semidefinite matrix are the same as its nonzero eigenvalues.\n\nthe condition number of a nonsingular a \u2208 rn\u00d7n, denoted cond(a) or \u03ba(a),\n\nis defined as\n\ncond(a) = kak2ka\u22121k2 = \u03c3max(a)/\u03c3min(a).\n\npseudo-inverse\nlet a = u \u03c3v t be the singular value decomposition of a \u2208 rm\u00d7n, with rank a =\nr. we define the pseudo-inverse or moore-penrose inverse of a as\n\nalternative expressions are\n\na\u2020 = v \u03c3\u22121u t \u2208 rn\u00d7m.\n\na\u2020 = lim\n\u01eb\u21920\n\n(at a + \u01ebi)\u22121at = lim\n\u01eb\u21920\n\nat (aat + \u01ebi)\u22121,\n\nwhere the limits are taken with \u01eb > 0, which ensures that the inverses in the\nexpressions exist. if rank a = n, then a\u2020 = (at a)\u22121at . if rank a = m, then\na\u2020 = at (aat )\u22121. if a is square and nonsingular, then a\u2020 = a\u22121.\n\nthe pseudo-inverse comes up in problems involving least-squares, minimum\nnorm, quadratic minimization, and (euclidean) projection. for example, a\u2020b is a\nsolution of the least-squares problem\n\nminimize\n\nkax \u2212 bk2\n\n2\n\nin general. when the solution is not unique, a\u2020b gives the solution with minimum\n(euclidean) norm. as another example, the matrix aa\u2020 = u u t gives (euclidean)\nprojection on r(a). the matrix a\u2020a = v v t gives (euclidean) projection on\nr(at ).\nthe optimal value p\u22c6 of the (general, nonconvex) quadratic optimization prob-\nlem\n\nminimize\nwhere p \u2208 sn, can be expressed as\n\n(1/2)xt p x + qt x + r,\n\np\u22c6 =(cid:26) \u2212(1/2)qt p \u2020q + r p (cid:23) 0,\n\n\u2212\u221e\n\notherwise.\n\nq \u2208 r(p )\n\n(this generalizes the expression p\u22c6 = \u2212(1/2)qt p \u22121q + r, valid for p \u227b 0.)\n\n "}, {"Page_number": 664, "text": "650\n\na mathematical background\n\na.5.5 schur complement\n\nconsider a matrix x \u2208 sn partitioned as\n\nbt c (cid:21) ,\nx =(cid:20) a b\n\nwhere a \u2208 sk. if det a 6= 0, the matrix\n\ns = c \u2212 bt a\u22121b\n\nis called the schur complement of a in x. schur complements arise in several\ncontexts, and appear in many important formulas and theorems. for example, we\nhave\n\ndet x = det a det s.\n\ninverse of block matrix\n\nthe schur complement comes up in solving linear equations, by eliminating one\nblock of variables. we start with\n\nbt c (cid:21)(cid:20) x\n(cid:20) a b\n\ny (cid:21) =(cid:20) u\nv (cid:21) ,\n\nand assume that det a 6= 0. if we eliminate x from the top block equation and\nsubstitute it into the bottom block equation, we obtain v = bt a\u22121u + sy, so\n\nsubstituting this into the first equation yields\n\ny = s\u22121(v \u2212 bt a\u22121u).\n\nwe can express these two equations as a formula for the inverse of a block matrix:\n\nx =(cid:0)a\u22121 + a\u22121bs\u22121bt a\u22121(cid:1) u \u2212 a\u22121bs\u22121v.\n=(cid:20) a\u22121 + a\u22121bs\u22121bt a\u22121 \u2212a\u22121bs\u22121\n\n\u2212s\u22121bt a\u22121\n\ns\u22121\n\nbt c (cid:21)\u22121\n(cid:20) a b\n\n(cid:21) .\n\nin particular, we see that the schur complement is the inverse of the 2, 2 block\nentry of the inverse of x.\n\nminimization and definiteness\n\nthe schur complement arises when you minimize a quadratic form over some of\nthe variables. suppose a \u227b 0, and consider the minimization problem\n\nminimize ut au + 2vt bt u + vt cv\n\n(a.13)\n\nwith variable u. the solution is u = \u2212a\u22121bv, and the optimal value is\n\ninf\n\nu (cid:20) u\n\nv (cid:21)t(cid:20) a b\n\nbt c (cid:21)(cid:20) u\n\nv (cid:21) = vt sv.\n\n(a.14)\n\nfrom this we can derive the following characterizations of positive definiteness or\nsemidefiniteness of the block matrix x:\n\n "}, {"Page_number": 665, "text": "a.5 linear algebra\n\n651\n\n\u2022 x \u227b 0 if and only if a \u227b 0 and s \u227b 0.\n\u2022 if a \u227b 0, then x (cid:23) 0 if and only if s (cid:23) 0.\n\nschur complement with singular a\n\nsome schur complement results have generalizations to the case when a is singular,\nalthough the details are more complicated. as an example, if a (cid:23) 0 and bv \u2208\nr(a), then the quadratic minimization problem (a.13) (with variable u) is solvable,\nand has optimal value\n\nvt (c \u2212 bt a\u2020b)v,\n\nwhere a\u2020 is the pseudo-inverse of a. the problem is unbounded if bv 6\u2208 r(a) or\nif a 6(cid:23) 0.\nthe range condition bv \u2208 r(a) can also be expressed as (i \u2212 aa\u2020)bv = 0,\nso we have the following characterization of positive semidefiniteness of the block\nmatrix x:\n\nx (cid:23) 0 \u21d0\u21d2 a (cid:23) 0,\n\n(i \u2212 aa\u2020)b = 0, c \u2212 bt a\u2020b (cid:23) 0.\n\nhere the matrix c \u2212 bt a\u2020b serves as a generalization of the schur complement,\nwhen a is singular.\n\n "}, {"Page_number": 666, "text": "652\n\na mathematical background\n\nbibliography\n\nsome basic references for the material in this appendix are rudin [rud76] for analysis, and\nstrang [str80] and meyer [mey00] for linear algebra. more advanced linear algebra texts\ninclude horn and johnson [hj85, hj91], parlett [par98], golub and van loan [gl89],\ntrefethen and bau [tb97], and demmel [dem97].\nthe concept of closed function (\u00a7a.3.3) appears frequently in convex optimization, al-\nthough the terminology varies. the term is used by rockafellar [roc70, page 51], hiriart-\nurruty and lemar\u00b4echal [hul93, volume 1, page 149], borwein and lewis [bl00, page\n76], and bertsekas, nedi\u00b4c, and ozdaglar [ber03, page 28].\n\n "}, {"Page_number": 667, "text": "appendix b\n\nproblems involving two\nquadratic functions\n\nin this appendix we consider some optimization problems that involve two quadratic,\nbut not necessarily convex, functions. several strong results hold for these prob-\nlems, even when they are not convex.\n\nb.1 single constraint quadratic optimization\n\nwe consider the problem with one constraint\n\nxt a0x + 2bt\nminimize\nsubject to xt a1x + 2bt\n\n0 x + c0\n1 x + c1 \u2264 0,\n\n(b.1)\n\nwith variable x \u2208 rn, and problem parameters ai \u2208 sn, bi \u2208 rn, ci \u2208 r. we do\nnot assume that ai (cid:23) 0, so problem (b.1) is not a convex optimization problem.\n\nthe lagrangian of (b.1) is\n\nl(x, \u03bb) = xt (a0 + \u03bba1)x + 2(b0 + \u03bbb1)t x + c0 + \u03bbc1,\n\nand the dual function is\n\ng(\u03bb) = inf\nx\n\n= \uf8f1\uf8f2\uf8f3\n\nl(x, \u03bb)\nc0 + \u03bbc1 \u2212 (b0 + \u03bbb1)t (a0 + \u03bba1)\u2020(b0 + \u03bbb1) a0 + \u03bba1 (cid:23) 0,\n\u2212\u221e\n\notherwise\n\nb0 + \u03bbb1 \u2208 r(a0 + \u03bba1)\n\n(see \u00a7a.5.4). using a schur complement, we can express the dual problem as\n\n\u03b3\n\nmaximize\nsubject to \u03bb \u2265 0\n\n(cid:20) a0 + \u03bba1\n\n(b0 + \u03bbb1)t\n\nb0 + \u03bbb1\n\nc0 + \u03bbc1 \u2212 \u03b3 (cid:21) (cid:23) 0,\n\n(b.2)\n\n "}, {"Page_number": 668, "text": "654\n\nb problems involving two quadratic functions\n\nan sdp with two variables \u03b3, \u03bb \u2208 r.\nthe first result is that strong duality holds for problem (b.1) and its lagrange\ndual (b.2), provided slater\u2019s constraint qualification is satisfied, i.e., there exists\nan x with xt a1x + 2bt\n1 x + c1 < 0. in other words, if (b.1) is strictly feasible, the\noptimal values of (b.1) and (b.2) are equal. (a proof is given in \u00a7b.4.)\nrelaxation interpretation\n\nthe dual of the sdp (b.2) is\n\nminimize\nsubject to\n\n0 x + c0\n1 x + c1 \u2264 0\n\ntr(a0x) + 2bt\ntr(a1x) + 2bt\n\n(cid:20) x x\n\n1 (cid:21) (cid:23) 0,\n\nxt\n\n(b.3)\n\nan sdp with variables x \u2208 sn, x \u2208 rn. this dual sdp has an interesting\ninterpretation in terms of the original problem (b.1).\n\nwe first note that (b.1) is equivalent to\n\nminimize\nsubject to\n\ntr(a0x) + 2bt\ntr(a1x) + 2bt\nx = xxt .\n\n0 x + c0\n1 x + c1 \u2264 0\n\n(b.4)\n\nin this formulation we express the quadratic terms xt aix as tr(aixxt ), and then\nintroduce a new variable x = xxt . problem (b.4) has a linear objective function,\none linear inequality constraint, and a nonlinear equality constraint x = xxt . the\nnext step is to replace the equality constraint by an inequality x (cid:23) xxt :\n\nminimize\nsubject to\n\ntr(a0x) + bt\ntr(a1x) + bt\nx (cid:23) xxt .\n\n0 x + c0\n1 x + c1 \u2264 0\n\n(b.5)\n\nthis problem is called a relaxation of (b.4), since we have replaced one of the\nconstraints with a looser constraint. finally we note that the inequality in (b.5)\ncan be expressed as a linear matrix inequality by using a schur complement, which\ngives (b.3).\n\na number of interesting facts follow immediately from this interpretation of (b.3)\nas a relaxation of (b.1). first, it is obvious that the optimal value of (b.3) is less\nthan or equal to the optimal value of (b.1), since we minimize the same objec-\ntive function over a larger set. second, we can conclude that if x = xxt at the\noptimum of (b.3), then x must be optimal in (b.1).\n\ncombining the result above, that strong duality holds between (b.1) and (b.2)\n(if (b.1) is strictly feasible), with strong duality between the dual sdps (b.2)\nand (b.3), we conclude that strong duality holds between the original, nonconvex\nquadratic problem (b.1), and the sdp relaxation (b.3), provided (b.1) is strictly\nfeasible.\n\n "}, {"Page_number": 669, "text": "b.2 the s-procedure\n\n655\n\nb.2 the s-procedure\n\nthe next result is a theorem of alternatives for a pair of (nonconvex) quadratic\ninequalities. let a1, a2 \u2208 sn, b1, b2 \u2208 rn, c1, c2 \u2208 r, and suppose there exists an\n\u02c6x with\n\n\u02c6xt a2 \u02c6x + 2bt\n\n2 \u02c6x + c2 < 0.\n\nthen there exists an x \u2208 rn satisfying\n1 x + c1 < 0,\n\nxt a1x + 2bt\n\nif and only if there exists no \u03bb such that\n\nxt a2x + 2bt\n\n2 x + c2 \u2264 0,\n\n\u03bb \u2265 0,\n\n(cid:20) a1\n\nbt\n1\n\nb1\n\nc1 (cid:21) + \u03bb(cid:20) a2\n\nbt\n2\n\nb2\n\nc2 (cid:21) (cid:23) 0.\n\n(b.6)\n\n(b.7)\n\nin other words, (b.6) and (b.7) are strong alternatives.\n\nthis result is readily shown to be equivalent to the result from \u00a7b.1, and a proof\nis given in \u00a7b.4. here we point out that the two inequality systems are clearly weak\nalternatives, since (b.6) and (b.7) together lead to a contradiction:\n\n0 \u2264 (cid:20) x\n\n1 (cid:21)t(cid:18)(cid:20) a1\n\n= xt a1x + 2bt\n< 0.\n\nb1\n\nc1 (cid:21) + \u03bb(cid:20) a2\n\nbt\n1\n1 x + c1 + \u03bb(xt a2x + 2bt\n\nc2 (cid:21)(cid:19)(cid:20) x\n1 (cid:21)\n\n2 x + c2)\n\nbt\n2\n\nb2\n\nthis theorem of alternatives is sometimes called the s-procedure, and is usually\n\nstated in the following form: the implication\n\nwhere fi \u2208 sn, gi \u2208 rn, hi \u2208 r, holds if and only if there exists a \u03bb such that\n\nxt f1x + 2gt\n\n1 x + h1 \u2264 0 =\u21d2 xt f2x + 2gt\nh1 (cid:21) ,\n\nh2 (cid:21) (cid:22) \u03bb(cid:20) f1\n\n(cid:20) f2\n\ngt\n1\n\ngt\n2\n\ng2\n\ng1\n\n\u03bb \u2265 0,\n\n2 x + h2 \u2264 0,\n\nprovided there exists a point \u02c6x with \u02c6xt f1 \u02c6x + 2gt\nis clear.)\n\n1 \u02c6x + h1 < 0. (note that sufficiency\n\nexample b.1 ellipsoid containment. an ellipsoid e \u2286 rn with nonempty interior\ncan be represented as the sublevel set of a quadratic function,\n\ne = {x | xt f x + 2gt x + h \u2264 0},\n\nwhere f \u2208 s++ and h \u2212 gt f \u22121g < 0. suppose \u02dce is another ellipsoid with similar\nrepresentation,\n\nwith \u02dcf \u2208 s++, \u02dch \u2212 \u02dcgt \u02dcf \u22121\u02dcg < 0. by the s-procedure, we see that e \u2286 \u02dce if and only\nif there is a \u03bb > 0 such that\n\n\u02dce = {x | xt \u02dcf x + 2\u02dcgt x + \u02dch \u2264 0},\n\n(cid:20) \u02dcf\n\n\u02dcgt\n\n\u02dcg\n\n\u02dch (cid:21) (cid:22) \u03bb(cid:20) f\n\ngt\n\ng\n\nh (cid:21) .\n\n "}, {"Page_number": 670, "text": "656\n\nb problems involving two quadratic functions\n\nb.3 the field of values of two symmetric matrices\n\nthe following result is the basis for the proof of the strong duality result in \u00a7b.1\nand the s-procedure in \u00a7b.2. if a, b \u2208 sn, then for all x \u2208 sn\n+, there exists an\nx \u2208 rn such that\n\nxt ax = tr(ax),\n\nxt bx = tr(bx).\n\n(b.8)\n\nremark b.1 geometric interpretation. this result has an interesting interpretation\nin terms of the set\n\nwhich is a cone in r2. it is the cone generated by the set\n\nw (a, b) = {(xt ax, xt bx) | x \u2208 rn},\n\nf (a, b) = {(xt ax, xt bx) | kxk2 = 1},\n\nwhich is called the 2-dimensional field of values of the pair (a, b). geometrically,\nw (a, b) is the image of the set of rank-one positive semidefinite matrices under the\nlinear transformation f : sn \u2192 r2 defined by\n\nf (x) = (tr(ax), tr(bx)).\n\nthe result that for every x \u2208 sn\n\n+ there exists an x satisfying (b.8) means that\n\nw (a, b) = f (sn\n\n+).\n\nin other words, w (a, b) is a convex cone.\n\nthe proof is constructive and uses induction on the rank of x. suppose it is\ntrue for all x \u2208 sn\n+ with 1 \u2264 rank x \u2264 k, where k \u2265 2, that there exists an x such\nthat (b.8) holds. then the result also holds if rank x = k + 1, as can be seen as\nfollows. a matrix x \u2208 sn\n+ with rank x = k + 1 can be expressed as x = yyt + z\nwhere y 6= 0 and z \u2208 sn\n+ with rank z = k. by assumption, there exists a z such\nthat tr(az) = zt az, tr(az) = zt bz. therefore\n\ntr(ax) = tr(a(yyt + zzt )),\n\ntr(bx) = tr(b(yyt + zzt )).\n\nthe rank of yyt + zzt is one or two, so by assumption there exists an x such\nthat (b.8) holds.\n\nit is therefore sufficient to prove the result if rank x \u2264 2. if rank x = 0 and\nrank x = 1 there is nothing to prove. if rank x = 2, we can factor x as x = v v t\nwhere v \u2208 rn\u00d72, with linearly independent columns v1 and v2. without loss of\ngenerality we can assume that v t av is diagonal. (if v t av is not diagonal we\nreplace v with v p where v t av = p diag(\u03bb)p t is the eigenvalue decomposition\nof v t av .) we will write v t av and v t bv as\n\nand define\n\nv t av =(cid:20) \u03bb1\n\n0\n\n0\n\nv t bv =(cid:20) \u03c31\n\u03bb2 (cid:21) ,\ntr(bx) (cid:21) =(cid:20) \u03bb1 + \u03bb2\n\u03c31 + \u03c32 (cid:21) .\nw =(cid:20) tr(ax)\n\n\u03b3\n\n\u03b3\n\n\u03c32 (cid:21) ,\n\n "}, {"Page_number": 671, "text": "b.4 proofs of the strong duality results\n\n657\n\nwe need to show that w = (xt ax, xt bx) for some x.\n\nwe distinguish two cases. first, assume (0, \u03b3) is a linear combination of the\n\nvectors (\u03bb1, \u03c31) and (\u03bb2, \u03c32):\n\n0 = z1\u03bb1 + z2\u03bb2,\n\n\u03b3 = z1\u03c31 + z2\u03c32,\n\nfor some z1, z2. in this case we choose x = \u03b1v1 +\u03b2v2, where \u03b1 and \u03b2 are determined\nby solving two quadratic equations in two variables\n\n\u03b12 + 2\u03b1\u03b2z1 = 1,\n\n\u03b22 + 2\u03b1\u03b2z2 = 1.\n\n(b.9)\n\nthis will give the desired result, since\n\n(\u03b1v1 + \u03b2v2)t b(\u03b1v1 + \u03b2v2) (cid:21)\n(cid:20) (\u03b1v1 + \u03b2v2)t a(\u03b1v1 + \u03b2v2)\n= \u03b12(cid:20) \u03bb1\n\u03c31 (cid:21) + 2\u03b1\u03b2(cid:20) 0\n= (\u03b12 + 2\u03b1\u03b2z1)(cid:20) \u03bb1\n= (cid:20) \u03bb1 + \u03bb2\n\u03c31 + \u03c32 (cid:21) .\n\n\u03b3 (cid:21) + \u03b22(cid:20) \u03bb2\n\u03c32 (cid:21)\n\u03c31 (cid:21) + (\u03b22 + 2\u03b1\u03b2z2)(cid:20) \u03bb2\n\u03c32 (cid:21)\n\nit remains to show that the equations (b.9) are solvable. to see this, we first note\nthat \u03b1 and \u03b2 must be nonzero, so we can write the equations equivalently as\n\n\u03b12(1 + 2(\u03b2/\u03b1)z1) = 1,\n\n(\u03b2/\u03b1)2 + 2(\u03b2/\u03b1)(z2 \u2212 z1) = 1.\n\nthe equation t2 + 2t(z2 \u2212 z1) = 1 has a positive and a negative root. at least one\nof these roots (the root with the same sign as z1) satisfies 1 + 2tz1 > 0, so we can\nchoose\n\n\u03b1 = \u00b11/\u221a1 + 2tz1,\n\n\u03b2 = t\u03b1.\n\nthis yields two solutions (\u03b1, \u03b2) that satisfy (b.9). (if both roots of t2 +2t(z2\u2212z1) =\n1 satisfy 1 + 2tz1 > 0, we obtain four solutions.)\nnext, assume that (0, \u03b3) is not a linear combination of (\u03bb1, \u03c31) and (\u03bb2, \u03c32). in\nparticular, this means that (\u03bb1, \u03c31) and (\u03bb2, \u03c32) are linearly dependent. therefore\ntheir sum w = (\u03bb1 + \u03bb2, \u03c31 + \u03c32) is a nonnegative multiple of (\u03bb1, \u03c31), or (\u03bb2, \u03c32),\nor both. if w = \u03b12(\u03bb1, \u03c31) for some \u03b1, we can choose x = \u03b1v1. if w = \u03b22(\u03bb2, \u03c32)\nfor some \u03b2, we can choose x = \u03b2v2.\n\nb.4 proofs of the strong duality results\n\nwe first prove the s-procedure result given in \u00a7b.2. the assumption of strict\nfeasibility of \u02c6x implies that the matrix\n\n(cid:20) a2\n\nbt\n2\n\nb2\n\nc2 (cid:21)\n\n "}, {"Page_number": 672, "text": "658\n\nb problems involving two quadratic functions\n\nhas at least one negative eigenvalue. therefore\n\n\u03c4 \u2265 0,\n\n\u03c4(cid:20) a2\n\nbt\n2\n\nb2\n\nc2 (cid:21) (cid:23) 0 =\u21d2 \u03c4 = 0.\n\nwe can apply the theorem of alternatives for nonstrict linear matrix inequalities,\ngiven in example 5.14, which states that (b.7) is infeasible if and only if\n\nx (cid:23) 0,\n\ntr(cid:18)x(cid:20) a1\n\nbt\n1\n\nb1\n\nc1 (cid:21)(cid:19) < 0,\n\ntr(cid:18)x(cid:20) a2\n\nbt\n2\n\nb2\n\nc2 (cid:21)(cid:19) \u2264 0\n\nis feasible. from \u00a7b.3 this is equivalent to feasibility of\n\nb1\n\n(cid:20) v\nw (cid:21)t(cid:20) a1\n\nc1 (cid:21)(cid:20) v\nif w 6= 0, then x = v/w is feasible in (b.6).\nvt a2v \u2264 0, so x = \u02c6x + tv satisfies\n\nw (cid:21) < 0,\n\nbt\n1\n\n(cid:20) v\nw (cid:21)t(cid:20) a2\n\nbt\n2\n\nb2\n\nc2 (cid:21)(cid:20) v\n\nw (cid:21) \u2264 0.\n\nif w = 0, we have vt a1v < 0,\n\nxt a1x + 2bt\nxt a2x + 2bt\n\n1 x + c1 = \u02c6xt a1 \u02c6x + 2bt\n2 x + c2 = \u02c6xt a2 \u02c6x + 2bt\n\n1 \u02c6x + c1 + t2vt a1v + 2t(a1 \u02c6x + b1)t v\n2 \u02c6x + c2 + t2vt a2v + 2t(a2 \u02c6x + b2)t v\n\n< 2t(a2 \u02c6x + b2)t v,\n\ni.e., x becomes feasible as t \u2192 \u00b1\u221e, depending on the sign of (a2 \u02c6x + b2)t v.\nfinally, we prove the result in \u00a7b.1, i.e., that the optimal values of (b.1)\nand (b.2) are equal if (b.1) is strictly feasible. to do this we note that \u03b3 is a\nlower bound for the optimal value of (b.1) if\n\nxt a1x + bt\n\n1 x + c1 \u2264 0 =\u21d2 xt a0x + bt\n\n0 x + c0 \u2265 \u03b3.\n\nby the s-procedure this is true if and only if there exists a \u03bb \u2265 0 such that\n\n(cid:20) a0\n\nbt\n0\n\nb0\n\nc0 \u2212 \u03b3 (cid:21) + \u03bb(cid:20) a1\n\nbt\n1\n\nb1\n\nc1 (cid:21) (cid:23) 0,\n\ni.e., \u03b3, \u03bb are feasible in (b.2).\n\n "}, {"Page_number": 673, "text": "bibliography\n\nbibliography\n\n659\n\nthe results in this appendix are known under different names in different disciplines.\nthe term s-procedure is from control; see boyd, el ghaoui, feron, and balakrishnan\n[befb94, pages 23, 33] for a survey and references. variations of the s-procedure are\nknown in linear algebra in the context of joint diagonalization of a pair of symmetric\nmatrices; see, for example, calabi [cal64] and uhlig [uhl79]. special cases of the strong\nduality result are studied in the nonlinear programming literature on trust-region methods\n(stern and wolkowicz [sw95], nocedal and wright [nw99, page 78]).\nbrickman [bri61] proves that the field of values of a pair of matrices a, b \u2208 sn (i.e., the\nset f (a, b) defined in remark b.1) is a convex set if n > 2, and that the set w (a, b)\nis a convex cone (for any n). our proof in \u00a7b.3 is based on hestenes [hes68]. many\nrelated results and additional references can be found in horn and johnson [hj91, \u00a71.8]\nand ben-tal and nemirovski [btn01, \u00a74.10.5].\n\n "}, {"Page_number": 674, "text": " "}, {"Page_number": 675, "text": "appendix c\n\nnumerical linear algebra\nbackground\n\nin this appendix we give a brief overview of some basic numerical linear algebra,\nconcentrating on methods for solving one or more sets of linear equations. we focus\non direct (i.e., noniterative) methods, and how problem structure can be exploited\nto improve efficiency. there are many important issues and methods in numerical\nlinear algebra that we do not consider here, including numerical stability, details\nof matrix factorizations, methods for parallel or multiple processors, and iterative\nmethods. for these (and other) topics, we refer the reader to the references given\nat the end of this appendix.\n\nc.1 matrix structure and algorithm complexity\n\nwe concentrate on methods for solving the set of linear equations\n\nax = b\n\n(c.1)\n\nwhere a \u2208 rn\u00d7n and b \u2208 rn. we assume a is nonsingular, so the solution is\nunique for all values of b, and given by x = a\u22121b. this basic problem arises in\nmany optimization algorithms, and often accounts for most of the computation. in\nthe context of solving the linear equations (c.1), the matrix a is often called the\ncoefficient matrix, and the vector b is called the righthand side.\n\nthe standard generic methods for solving (c.1) require a computational effort\nthat grows approximately like n3. these methods assume nothing more about a\nthan nonsingularity, and so are generally applicable. for n several hundred or\nsmaller, these generic methods are probably the best methods to use, except in the\nmost demanding real-time applications. for n more than a thousand or so, the\ngeneric methods of solving ax = b become less practical.\n\n "}, {"Page_number": 676, "text": "662\n\nc numerical linear algebra background\n\ncoefficient matrix structure\n\nin many cases the coefficient matrix a has some special structure or form that can\nbe exploited to solve the equation ax = b more efficiently, using methods tailored\nfor the special structure. for example, in the newton system \u22072f (x)\u2206xnt =\n\u2212\u2207f (x), the coefficient matrix is symmetric and positive definite, which allows us\nto use a solution method that is around twice as fast as the generic method (and\nalso has better roundoff properties). there are many other types of structure that\ncan be exploited, with computational savings (or algorithm speedup) that is usually\nfar more than a factor of two. in many cases, the effort is reduced to something\nproportional to n2 or even n, as compared to n3 for the generic methods. since\nthese methods are usually applied when n is at least a hundred, and often far larger,\nthe savings can be dramatic.\n\na wide variety of coefficient matrix structures can be exploited. simple exam-\nples related to the sparsity pattern (i.e., the pattern of zero and nonzero entries\nin the matrix) include banded, block diagonal, or sparse matrices. a more subtle\nexploitable structure is diagonal plus low rank. many common forms of convex\noptimization problems lead to linear equations with coefficient matrices that have\nthese exploitable structures. (there are many other matrix structures that can be\nexploited, e.g., toeplitz, hankel, and circulant, that we will not consider in this\nappendix.)\n\nwe refer to a generic method that does not exploit any sparsity pattern in the\nmatrices as one for dense matrices. we refer to a method that does not exploit any\nstructure at all in the matrices as one for unstructured matrices.\n\nc.1.1 complexity analysis via flop count\n\nthe cost of a numerical linear algebra algorithm is often expressed by giving the\ntotal number of floating-point operations or flops required to carry it out, as a\nfunction of various problem dimensions. we define a flop as one addition, sub-\ntraction, multiplication, or division of two floating-point numbers. (some authors\ndefine a flop as one multiplication followed by one addition, so their flop counts\nare smaller by a factor up to two.) to evaluate the complexity of an algorithm, we\ncount the total number of flops, express it as a function (usually a polynomial) of\nthe dimensions of the matrices and vectors involved, and simplify the expression\nby ignoring all terms except the leading (i.e., highest order or dominant) terms.\n\nas an example, suppose that a particular algorithm requires a total of\n\nm3 + 3m2n + mn + 4mn2 + 5m + 22\n\nflops, where m and n are problem dimensions. we would normally simplify this\nflop count to\n\nm3 + 3m2n + 4mn2\n\nflops, since these are the leading terms in the problem dimensions m and n.\nif\nin addition we assumed that m \u226a n, we would further simplify the flop count to\n4mn2.\n\n "}, {"Page_number": 677, "text": "c.1 matrix structure and algorithm complexity\n\n663\n\nflop counts were originally popularized when floating-point operations were rel-\natively slow, so counting the number gave a good estimate of the total computation\ntime. this is no longer the case: issues such as cache boundaries and locality of\nreference can dramatically affect the computation time of a numerical algorithm.\nhowever, flop counts can still give us a good rough estimate of the computation\ntime of a numerical algorithm, and how the time grows with increasing problem\nsize. since a flop count no longer accurately predicts the computation time of an\nalgorithm, we usually pay most attention to its order or orders, i.e., its largest\nexponents, and ignore differences in flop counts smaller than a factor of two or so.\nfor example, an algorithm with flop count 5n2 is considered comparable to one\nwith a flop count 4n2, but faster than an algorithm with flop count (1/3)n3.\n\nc.1.2 cost of basic matrix-vector operations\n\nvector operations\nto compute the inner product xt y of two vectors x, y \u2208 rn we form the products\nxiyi, and then add them, which requires n multiplies and n\u2212 1 additions, or 2n\u2212 1\nflops. as mentioned above, we keep only the leading term, and say that the inner\nproduct requires 2n flops, or even more approximately, order n flops. a scalar-\nvector multiplication \u03b1x, where \u03b1 \u2208 r and x \u2208 rn costs n flops. the addition\nx + y of two vectors x, y \u2208 rn also costs n flops.\nif the vectors x and y are sparse, i.e., have only a few nonzero terms, these\nbasic operations can be carried out faster (assuming the vectors are stored using\nan appropriate data structure). for example, if x is a sparse vector with n nonzero\nentries, then the inner product xt y can be computed in 2n flops.\n\nmatrix-vector multiplication\na matrix-vector multiplication y = ax where a \u2208 rm\u00d7n costs 2mn flops: we have\nto calculate m components of y, each of which is the product of a row of a with\nx, i.e., an inner product of two vectors in rn.\n\nmatrix-vector products can often be accelerated by taking advantage of struc-\nture in a. for example, if a is diagonal, then ax can be computed in n flops,\ninstead of 2n2 flops for multiplication by a general n\u00d7 n matrix. more generally, if\na is sparse, with only n nonzero elements (out of mn), then 2n flops are needed\nto form ax, since we can skip multiplications and additions with zero.\n\nas a less obvious example, suppose the matrix a has rank p \u226a min{m, n}, and\nis represented (stored) in the factored form a = u v , where u \u2208 rm\u00d7p, v \u2208 rp\u00d7n.\nthen we can compute ax by first computing v x (which costs 2pn flops), and then\ncomputing u (v x) (which costs 2mp flops), so the total is 2p(m + n) flops. since\np \u226a min{m, n}, this is small compared to 2mn.\nmatrix-matrix multiplication\nthe matrix-matrix product c = ab, where a \u2208 rm\u00d7n and b \u2208 rn\u00d7p, costs 2mnp\nflops. we have mp elements in c to calculate, each of which is an inner product of\n\n "}, {"Page_number": 678, "text": "664\n\nc numerical linear algebra background\n\ntwo vectors of length n. again, we can often make substantial savings by taking\nadvantage of structure in a and b. for example, if a and b are sparse, we can\naccelerate the multiplication by skipping additions and multiplications with zero.\nif m = p and we know that c is symmetric, then we can calculate the matrix\nproduct in m2n flops, since we only have to compute the (1/2)m(m + 1) elements\nin the lower triangular part.\n\nto form the product of several matrices, we can carry out the matrix-matrix\nmultiplications in different ways, which have different flop counts in general. the\nsimplest example is computing the product d = abc, where a \u2208 rm\u00d7n, b \u2208\nrn\u00d7p, and c \u2208 rp\u00d7q. here we can compute d in two ways, using matrix-matrix\nmultiplies. one method is to first form the product ab (2mnp flops), and then form\nd = (ab)c (2mpq flops), so the total is 2mp(n+q) flops. alternatively, we can first\nform the product bc (2npq flops), and then form d = a(bc) (2mnq flops), with a\ntotal of 2nq(m+p) flops. the first method is better when 2mp(n+q) < 2nq(m+p),\ni.e., when\n\n1\nn\n\n+\n\n1\nq\n\n<\n\n1\nm\n\n+\n\n1\np\n\n.\n\nthis assumes that no structure of the matrices is exploited in carrying out matrix-\nmatrix products.\n\nfor products of more than three matrices, there are many ways to parse the\nproduct into matrix-matrix multiplications. although it is not hard to develop an\nalgorithm that determines the best parsing (i.e., the one with the fewest required\nflops) given the matrix dimensions, in most applications the best parsing is clear.\n\nc.2 solving linear equations with factored matrices\n\nc.2.1 linear equations that are easy to solve\n\nwe start by examining some cases for which ax = b is easily solved, i.e., x = a\u22121b\nis easily computed.\n\ndiagonal matrices\n\nsuppose a is diagonal and nonsingular (i.e., aii 6= 0 for all i). the set of linear\nequations ax = b can be written as aiixi = bi, i = 1, . . . , n. the solution is given\nby xi = bi/aii, and can be calculated in n flops.\n\nlower triangular matrices\na matrix a \u2208 rn\u00d7n is lower triangular if aij = 0 for j > i. a lower triangular\nmatrix is called unit lower triangular if the diagonal elements are equal to one. a\nlower triangular matrix is nonsingular if and only if aii 6= 0 for all i.\n\n "}, {"Page_number": 679, "text": "c.2 solving linear equations with factored matrices\n\n665\n\nsuppose a is lower triangular and nonsingular. the equations ax = b are\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\na11\n0\na21\na22\n...\n...\nan1 an2\n\n\u00b7\u00b7\u00b7\n0\n\u00b7\u00b7\u00b7\n0\n...\n. . .\n\u00b7\u00b7\u00b7 ann\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\n\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\nx1\nx2\n...\nxn\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\n=\uf8ee\uf8ef\uf8ef\uf8ef\uf8f0\n\nb1\nb2\n...\nbn\n\n.\n\n\uf8f9\uf8fa\uf8fa\uf8fa\uf8fb\n\nfrom the first row, we have a11x1 = b1, from which we conclude x1 = b1/a11.\nfrom the second row we have a21x1 + a22x2 = b2, so we can express x2 as x2 =\n(b2\u2212a21x1)/a22. (we have already computed x1, so every number on the righthand\nside is known.) continuing this way, we can express each component of x in terms\nof previous components, yielding the algorithm\n\nx1\nx2\nx3\n\nxn\n\n:= b1/a11\n:= (b2 \u2212 a21x1)/a22\n:= (b3 \u2212 a31x1 \u2212 a32x2)/a33\n...\n:= (bn \u2212 an1x1 \u2212 an2x2 \u2212 \u00b7\u00b7\u00b7 \u2212 an,n\u22121xn\u22121)/ann.\n\nthis procedure is called forward substitution, since we successively compute the\ncomponents of x by substituting the known values into the next equation.\n\nlet us give a flop count for forward substitution. we start by calculating x1 (1\nflop). we substitute x1 in the second equation to find x2 (3 flops), then substitute\nx1 and x2 in the third equation to find x3 (5 flops), etc. the total number of flops\nis\n\n1 + 3 + 5 + \u00b7\u00b7\u00b7 + (2n \u2212 1) = n2.\n\nthus, when a is lower triangular and nonsingular, we can compute x = a\u22121b in\nn2 flops.\n\nif the matrix a has additional structure, in addition to being lower triangular,\nthen forward substitution can be more efficient than n2 flops. for example, if a\nis sparse (or banded), with at most k nonzero entries per row, then each forward\nsubstitution step requires at most 2k + 1 flops, so the overall flop count is 2(k + 1)n,\nor 2kn after dropping the term 2n.\n\nupper triangular matrices\na matrix a \u2208 rn\u00d7n is upper triangular if at is lower triangular, i.e., if aij = 0 for\nj < i. we can solve linear equations with nonsingular upper triangular coefficient\nmatrix in a way similar to forward substitution, except that we start by calculating\nxn, then xn\u22121, and so on. the algorithm is\n\nxn\nxn\u22121\nxn\u22122\n\nx1\n\n:= bn/ann\n:= (bn\u22121 \u2212 an\u22121,nxn)/an\u22121,n\u22121\n:= (bn\u22122 \u2212 an\u22122,n\u22121xn\u22121 \u2212 an\u22122,nxn)/an\u22122,n\u22122\n...\n:= (b1 \u2212 a12x2 \u2212 a13x3 \u2212 \u00b7\u00b7\u00b7 \u2212 a1nxn)/a11.\n\n "}, {"Page_number": 680, "text": "666\n\nc numerical linear algebra background\n\nthis is called backward substitution or back substitution since we determine the\ncoefficients in backward order. the cost to compute x = a\u22121b via backward\nsubstitution is n2 flops. if a is upper triangular and sparse (or banded), with at\nmost k nonzero entries per row, then back substitution costs 2kn flops.\n\northogonal matrices\na matrix a \u2208 rn\u00d7n is orthogonal if at a = i, i.e., a\u22121 = at . in this case we can\ncompute x = a\u22121b by a simple matrix-vector product x = at b, which costs 2n2\nin general.\n\nif the matrix a has additional structure, we can compute x = a\u22121b even more\nefficiently than 2n2 flops. for example, if a has the form a = i \u2212 2uut , where\nkuk2 = 1, we can compute\n\nx = a\u22121b = (i \u2212 2uut )t b = b \u2212 2(ut b)u\n\nby first computing ut b, then forming b \u2212 2(ut b)u, which costs 4n flops.\npermutation matrices\n\nlet \u03c0 = (\u03c01, . . . , \u03c0n) be a permutation of (1, 2, . . . , n). the associated permutation\nmatrix a \u2208 rn\u00d7n is given by\n\naij =(cid:26) 1 j = \u03c0i\n\n0 otherwise.\n\nin each row (or column) of a permutation matrix there is exactly one entry with\nvalue one; all other entries are zero. multiplying a vector by a permutation matrix\nsimply permutes its coefficients:\n\nax = (x\u03c01, . . . , x\u03c0n ) .\n\nthe inverse of a permutation matrix is the permutation matrix associated with the\ninverse permutation \u03c0\u22121. this turns out to be at , which shows that permutation\nmatrices are orthogonal.\n\nif a is a permutation matrix, solving ax = b is very easy: x is obtained by\npermuting the entries of b by \u03c0\u22121. this requires no floating point operations,\naccording to our definition (but, depending on the implementation, might involve\ncopying floating point numbers). we can reach the same conclusion from the\nequation x = at b. the matrix at (like a) has only one nonzero entry per row, with\nvalue one. thus no additions are required, and the only multiplications required\nare by one.\n\nc.2.2 the factor-solve method\n\nthe basic approach to solving ax = b is based on expressing a as a product of\nnonsingular matrices,\n\na = a1a2 \u00b7\u00b7\u00b7 ak,\n\n "}, {"Page_number": 681, "text": "c.2 solving linear equations with factored matrices\n\n667\n\nso that\n\nwe can compute x using this formula, working from right to left:\n\nx = a\u22121b = a\u22121\n\nk a\u22121\n\nk\u22121 \u00b7\u00b7\u00b7 a\u22121\n1 b.\n\n2 a\u22121\n1 b\n\nz1\nz2\n\n:= a\u22121\n1 b\n2 z1 = a\u22121\n:= a\u22121\n...\n:= a\u22121\nx := a\u22121\n\nzk\u22121\n\nk\u22121zk\u22122 = a\u22121\nk zk\u22121 = a\u22121\n\nk\u22121 \u00b7\u00b7\u00b7 a\u22121\n1 b\nk \u00b7\u00b7\u00b7 a\u22121\n1 b.\nthe ith step of this process requires computing zi = a\u22121\ni zi\u22121, i.e., solving the\nlinear equations aizi = zi\u22121. if each of these equations is easy to solve (e.g., if ai\nis diagonal, lower or upper triangular, a permutation, etc.), this gives a method for\ncomputing x = a\u22121b.\n\nthe step of expressing a in factored form (i.e., computing the factors ai) is\ncalled the factorization step, and the process of computing x = a\u22121b recursively,\nby solving a sequence problems of the form aizi = zi\u22121, is often called the solve\nstep. the total flop count for solving ax = b using this factor-solve method is f +s,\nwhere f is the flop count for computing the factorization, and s is the total flop\ncount for the solve step. in many cases, the cost of the factorization, f , dominates\nthe total solve cost s.\nin this case, the cost of solving ax = b, i.e., computing\nx = a\u22121b, is just f .\n\nsolving equations with multiple righthand sides\n\nsuppose we need to solve the equations\n\nax1 = b1,\n\nax2 = b2,\n\n. . . ,\n\naxm = bm,\n\nwhere a \u2208 rn\u00d7n is nonsingular.\nin other words, we need to solve m sets of\nlinear equations, with the same coefficient matrix, but different righthand sides.\nalternatively, we can think of this as computing the matrix\n\nwhere\n\nx = a\u22121b\n\nx =(cid:2) x1 x2\n\n\u00b7\u00b7\u00b7 xm (cid:3) \u2208 rn\u00d7m,\n\nb =(cid:2) b1\n\nb2\n\n\u00b7\u00b7\u00b7\n\nbm (cid:3) \u2208 rn\u00d7m.\n\nto do this, we first factor a, which costs f . then for i = 1, . . . , m we compute\na\u22121bi using the solve step. since we only factor a once, the total effort is\n\nf + ms.\n\nin other words, we amortize the factorization cost over the set of m solves. had we\n(needlessly) repeated the factorization step for each i, the cost would be m(f + s).\nwhen the factorization cost f dominates the solve cost s, the factor-solve\nmethod allows us to solve a small number of linear systems, with the same co-\nefficient matrix, at essentially the same cost as solving one. this is because the\nmost expensive step, the factorization, is done only once.\n\n "}, {"Page_number": 682, "text": "668\n\nc numerical linear algebra background\n\nwe can use the factor-solve method to compute the inverse a\u22121 by solving\nax = ei for i = 1, . . . , n, i.e., by computing a\u22121i. this requires one factorization\nand n solves, so the cost is f + ns.\n\nc.3 lu, cholesky, and ldlt factorization\n\nc.3.1 lu factorization\n\nevery nonsingular matrix a \u2208 rn\u00d7n can be factored as\n\na = p lu\n\nwhere p \u2208 rn\u00d7n is a permutation matrix, l \u2208 rn\u00d7n is unit lower triangular, and\nu \u2208 rn\u00d7n is upper triangular and nonsingular. this is called the lu factorization\nof a. we can also write the factorization as p t a = lu , where the matrix p t a is\nobtained from a by re-ordering the rows. the standard algorithm for computing an\nlu factorization is called gaussian elimination with partial pivoting or gaussian\nelimination with row pivoting. the cost is (2/3)n3 flops if no structure in a is\nexploited, which is the case we consider first.\n\nsolving sets of linear equations using the lu factorization\n\nthe lu factorization, combined with the factor-solve approach, is the standard\nmethod for solving a general set of linear equations ax = b.\n\nalgorithm c.1 solving linear equations by lu factorization.\n\ngiven a set of linear equations ax = b, with a nonsingular.\n\n1. lu factorization. factor a as a = p lu ((2/3)n3 flops).\n2. permutation. solve p z1 = b (0 flops).\n3. forward substitution. solve lz2 = z1 (n2 flops).\n4. backward substitution. solve u x = z2 (n2 flops).\n\nthe total cost is (2/3)n3 + 2n2, or (2/3)n3 flops if we keep only the leading term.\nif we need to solve multiple sets of linear equations with different righthand\n\nsides, i.e., axi = bi, i = 1, . . . , m, the cost is\n\n(2/3)n3 + 2mn2,\n\nsince we factor a once, and carry out m pairs of forward and backward substi-\ntutions. for example, we can solve two sets of linear equations, with the same\ncoefficient matrix but different righthand sides, at essentially the same cost as\nsolving one. we can compute the inverse a\u22121 by solving the equations axi = ei,\nwhere xi is the ith column of a\u22121, and ei is the ith unit vector. this costs (8/3)n3,\ni.e., about 3n3 flops.\n\nif the matrix a has certain structure, for example banded or sparse, the lu fac-\ntorization can be computed in less than (2/3)n3 flops, and the associated forward\nand backward substitutions can also be carried out more efficiently.\n\n "}, {"Page_number": 683, "text": "c.3 lu, cholesky, and ldlt factorization\n\n669\n\nlu factorization of banded matrices\nsuppose the matrix a \u2208 rn\u00d7n is banded, i.e., aij = 0 if |i \u2212 j| > k, where\nk < n\u2212 1 is called the bandwidth of a. we are interested in the case where k \u226a n,\ni.e., the bandwidth is much smaller than the size of the matrix. in this case an\nlu factorization of a can be computed in roughly 4nk2 flops. the resulting upper\ntriangular matrix u has bandwidth at most 2k, and the lower triangular matrix l\nhas at most k + 1 nonzeros per column, so the forward and back substitutions can\nbe carried out in order 6nk flops. therefore if a is banded, the linear equations\nax = b can be solved in about 4nk2 flops.\n\nlu factorization of sparse matrices\n\nwhen the matrix a is sparse, the lu factorization usually includes both row and\ncolumn permutations, i.e., a is factored as\n\na = p1lu p2,\n\nwhere p1 and p2 are permutation matrices, l is lower triangular, and u is upper\ntriangular. if the factors l and u are sparse, the forward and backward substi-\ntutions can be carried out efficiently, and we have an efficient method for solving\nax = b. the sparsity of the factors l and u depends on the permutations p1 and\np2, which are chosen in part to yield relatively sparse factors.\n\nthe cost of computing the sparse lu factorization depends in a complicated\nway on the size of a, the number of nonzero elements, its sparsity pattern, and\nthe particular algorithm used, but is often dramatically smaller than the cost of a\ndense lu factorization. in many cases the cost grows approximately linearly with\nn, when n is large. this means that when a is sparse, we can solve ax = b very\nefficiently, often with an order approximately n.\n\nc.3.2 cholesky factorization\n\nif a \u2208 rn\u00d7n is symmetric and positive definite, then it can be factored as\n\na = llt\n\nwhere l is lower triangular and nonsingular with positive diagonal elements. this\nis called the cholesky factorization of a, and can be interpreted as a symmetric\nlu factorization (with l = u t ). the matrix l, which is uniquely determined\nby a, is called the cholesky factor of a. the cost of computing the cholesky\nfactorization of a dense matrix, i.e., without exploiting any structure, is (1/3)n3\nflops, half the cost of an lu factorization.\n\nsolving positive definite sets of equations using cholesky factorization\n\nthe cholesky factorization can be used to solve ax = b when a is symmetric\npositive definite.\n\n "}, {"Page_number": 684, "text": "670\n\nc numerical linear algebra background\n\nalgorithm c.2 solving linear equations by cholesky factorization.\n\ngiven a set of linear equations ax = b, with a \u2208 sn\n1. cholesky factorization. factor a as a = llt ((1/3)n3 flops).\n2. forward substitution. solve lz1 = b (n2 flops).\n3. backward substitution. solve lt x = z1 (n2 flops).\n\n++.\n\nthe total cost is (1/3)n3 + 2n2, or roughly (1/3)n3 flops.\n\nthere are specialized algorithms, with a complexity much lower than (1/3)n3,\n\nfor cholesky factorization of banded and sparse matrices.\n\ncholesky factorization of banded matrices\n\nif a is symmetric positive definite and banded with bandwidth k, then its cholesky\nfactor l is banded with bandwidth k, and can be calculated in nk2 flops. the cost\nof the associated solve step is 4nk flops.\n\ncholesky factorization of sparse matrices\n\nwhen a is symmetric positive definite and sparse, it is usually factored as\n\na = p llt p t ,\n\nwhere p is a permutation matrix and l is lower triangular with positive diagonal\nelements. we can also express this as p t ap = llt , i.e., llt is the cholesky\nfactorization of p t ap . we can interpret this as first re-ordering the variables and\nequations, and then forming the (standard) cholesky factorization of the resulting\npermuted matrix. since p t ap is positive definite for any permutation matrix p ,\nwe are free to choose any permutation matrix; for each choice there is a unique\nassociated cholesky factor l. the choice of p , however, can greatly affect the\nsparsity of the factor l, which in turn can greatly affect the efficiency of solving\nax = b. various heuristic methods are used to select a permutation p that leads\nto a sparse factor l.\n\nexample c.1 cholesky factorization with an arrow sparsity pattern. consider a\nsparse matrix of the form\n\na =(cid:20) 1 ut\nu d (cid:21)\n\nwhere d \u2208 rn\u00d7n is positive diagonal, and u \u2208 rn. it can be shown that a is positive\ndefinite if ut d\u22121u < 1. the cholesky factorization of a is\n\n(cid:20) 1 ut\nu d (cid:21) =(cid:20) 1\n\n0 lt (cid:21)\nu l (cid:21)(cid:20) 1 ut\n\n0\n\n(c.2)\n\nwhere l is lower triangular with llt = d\u2212 uut . for general u, the matrix d\u2212 uut\nis dense, so we can expect l to be dense. although the matrix a is very sparse\n(most of its rows have just two nonzero elements), its cholesky factors are almost\ncompletely dense.\n\n "}, {"Page_number": 685, "text": "c.3 lu, cholesky, and ldlt factorization\n\n671\n\non the other hand, suppose we permute the first row and column of a to the end.\nafter this re-ordering, we obtain the cholesky factorization\n\n(cid:20) d u\n\n1 (cid:21) =(cid:20) d1/2\n\nut d\u22121/2 \u221a1 \u2212 ut d\u22121u (cid:21)(cid:20) d1/2\n\nut\n\n0\n\n0\n\nd\u22121/2u\n\n\u221a1 \u2212 ut d\u22121u (cid:21) .\n\nnow the cholesky factor has a diagonal 1,1 block, so it is very sparse.\n\nthis example illustrates that the re-ordering greatly affects the sparsity of the cholesky\nfactors. here it was quite obvious what the best permutation is, and all good re-\nordering heuristics would select this re-ordering and permute the dense row and\ncolumn to the end. for more complicated sparsity patterns, it can be very difficult\nto find the \u2018best\u2019 re-ordering (i.e., resulting in the greatest number of zero elements\nin l), but various heuristics provide good suboptimal permutations.\n\nfor the sparse cholesky factorization, the re-ordering permutation p is often\ndetermined using only sparsity pattern of the matrix a, and not the particular\nnumerical values of the nonzero elements of a. once p is chosen, we can also\ndetermine the sparsity pattern of l without knowing the numerical values of the\nnonzero entries of a. these two steps combined are called the symbolic factorization\nof a, and form the first step in a sparse cholesky factorization. in contrast, the\npermutation matrices in a sparse lu factorization do depend on the numerical\nvalues in a, in addition to its sparsity pattern.\n\nthe symbolic factorization is then followed by the numerical factorization, i.e.,\nthe calculation of the nonzero elements of l. software packages for sparse cholesky\nfactorization often include separate routines for the symbolic and the numerical\nfactorization. this is useful in many applications, because the cost of the symbolic\nfactorization is significant, and often comparable to the numerical factorization.\nsuppose, for example, that we need to solve m sets of linear equations\n\na1x = b1,\n\na2x = b2,\n\n. . . ,\n\namx = bm\n\nwhere the matrices ai are symmetric positive definite, with different numerical\nvalues, but the same sparsity pattern. suppose the cost of a symbolic factorization\nis fsymb, the cost of a numerical factorization is fnum, and the cost of the solve step\nis s. then we can solve the m sets of linear equations in\n\nfsymb + m(fnum + s)\n\nflops, since we only need to carry out the symbolic factorization once, for all m sets\nof equations. if instead we carry out a separate symbolic factorization for each set\nof linear equations, the flop count is m(fsymb + fnum + s).\n\nc.3.3 ldlt factorization\n\nevery nonsingular symmetric matrix a can be factored as\n\na = p ldlt p t\n\n "}, {"Page_number": 686, "text": "672\n\nc numerical linear algebra background\n\nwhere p is a permutation matrix, l is lower triangular with positive diagonal\nelements, and d is block diagonal, with nonsingular 1 \u00d7 1 and 2 \u00d7 2 diagonal\nblocks. this is called an ldlt factorization of a. (the cholesky factorization\ncan be considered a special case of ldlt factorization, with p = i and d = i.)\nan ldlt factorization can be computed in (1/3)n3 flops, if no structure of a is\nexploited.\n\nalgorithm c.3 solving linear equations by ldlt factorization.\n\ngiven a set of linear equations ax = b, with a \u2208 sn nonsingular.\n\n1. ldlt factorization. factor a as a = p ldlt p ((1/3)n3 flops).\n2. permutation. solve p z1 = b (0 flops).\n3. forward substitution. solve lz2 = z1 (n2 flops).\n4. (block) diagonal solve. solve dz3 = z2 (order n flops).\n5. backward substitution. solve lt z4 = z3 (n2 flops).\n6. permutation. solve p t x = z4 (0 flops).\n\nthe total cost is, keeping only the dominant term, (1/3)n3 flops.\n\nldlt factorization of banded and sparse matrices\n\nas with the lu and cholesky factorizations, there are specialized methods for\ncalculating the ldlt factorization of a sparse or banded matrix. these are similar\nto the analogous methods for cholesky factorization, with the additional factor d.\nin a sparse ldlt factorization, the permutation matrix p cannot be chosen only\non the basis of the sparsity pattern of a (as in a sparse cholesky factorization); it\nalso depends on the particular nonzero values in the matrix a.\n\nc.4 block elimination and schur complements\n\nc.4.1 eliminating a block of variables\n\nin this section we describe a general method that can be used to solve ax = b\nby first eliminating a subset of the variables, and then solving a smaller system\nof linear equations for the remaining variables. for a dense unstructured matrix,\nthis approach gives no advantage. but when the submatrix of a associated with\nthe eliminated variables is easily factored (for example, if it is block diagonal or\nbanded) the method can be substantially more efficient than a general method.\n\nsuppose we partition the variable x \u2208 rn into two blocks or subvectors,\n\nwhere x1 \u2208 rn1 , x2 \u2208 rn2 . we conformally partition the linear equations ax = b\nas\n\n(c.3)\n\nx =(cid:20) x1\nx2 (cid:21) ,\n(cid:20) a11 a12\na21 a22 (cid:21)(cid:20) x1\nx2 (cid:21) =(cid:20) b1\nb2 (cid:21)\n\n "}, {"Page_number": 687, "text": "c.4 block elimination and schur complements\n\n673\n\nwhere a11 \u2208 rn1\u00d7n1, a22 \u2208 rn2\u00d7n2. assuming that the submatrix a11 is invert-\nible, we can eliminate x1 from the equations, as follows. using the first equation,\nwe can express x1 in terms of x2:\n\nsubstituting this expression into the second equation yields\n\nx1 = a\u22121\n\n11 (b1 \u2212 a12x2).\n\n(a22 \u2212 a21a\u22121\n\n11 a12)x2 = b2 \u2212 a21a\u22121\n\n11 b1.\n\n(c.4)\n\n(c.5)\n\nwe refer to this as the reduced equation obtained by eliminating x1 from the orig-\ninal equation. the reduced equation (c.5) and the equation (c.4) together are\nequivalent to the original equations (c.3). the matrix appearing in the reduced\nequation is called the schur complement of the first block a11 in a:\n\ns = a22 \u2212 a21a\u22121\n\n11 a12\n\n(see also \u00a7a.5.5). the schur complement s is nonsingular if and only if a is\nnonsingular.\nthe two equations (c.5) and (c.4) give us an alternative approach to solving\nthe original system of equations (c.3). we first form the schur complement s, then\nfind x2 by solving (c.5), and then calculate x1 from (c.4). we can summarize this\nmethod as follows.\n\nalgorithm c.4 solving linear equations by block elimination.\n\ngiven a nonsingular set of linear equations (c.3), with a11 nonsingular.\n\n1. form a\u22121\n11 a12 and a\u22121\n11 b1.\n11 a12 and \u02dcb = b2 \u2212 a21a\u22121\n2. form s = a22 \u2212 a21a\u22121\n3. determine x2 by solving sx2 = \u02dcb.\n4. determine x1 by solving a11x1 = b1 \u2212 a12x2.\n\n11 b1.\n\nremark c.1 interpretation as block factor-solve. block elimination can be interpreted\nin terms of the factor-solve approach described in \u00a7c.2.2, based on the factorization\n\n(cid:20) a11 a12\na21 a22 (cid:21) =(cid:20) a11\n\na21 s (cid:21)(cid:20) i a\u22121\n\n0\n\n0\n\ni\n\n11 a12\n\n(cid:21) ,\n\nwhich can be considered a block lu factorization. this block lu factorization sug-\ngests the following method for solving (c.3). we first do a \u2018block forward substitution\u2019\nto solve\n\nand then solve\n\n0\n\na21 s (cid:21)(cid:20) z1\n(cid:20) a11\nz2 (cid:21) =(cid:20) b1\nb2 (cid:21) ,\n(cid:20) i a\u22121\n(cid:21)(cid:20) x1\nx2 (cid:21) =(cid:20) z1\nz2 (cid:21)\n\n11 a12\n\n0\n\ni\n\n "}, {"Page_number": 688, "text": "674\n\nc numerical linear algebra background\n\nby \u2018block backward substitution\u2019. this yields the same expressions as the block\nelimination method:\n\n11 b1\n\nz1 = a\u22121\nz2 = s\u22121(b2 \u2212 a21z1)\nx2 = z2\nx1 = z1 \u2212 a\u22121\n\n11 a12z2.\n\nin fact, the modern approach to the factor-solve method is based on block factor\nand solve steps like these, with the block sizes optimally chosen for the processor (or\nprocessors), cache sizes, etc.\n\ncomplexity analysis of block elimination method\n\nto analyze the (possible) advantage of solving the set of linear equations using\nblock elimination, we carry out a flop count. we let f and s denote the cost of\nfactoring a11 and carrying out the associated solve step, respectively. to keep the\nanalysis simple we assume (for now) that a12, a22, and a21 are treated as dense,\nunstructured matrices. the flop counts for each of the four steps in solving ax = b\nusing block elimination are:\n\n1. computing a\u22121\n\n11 a12 and a\u22121\n\n11 b1 requires factoring a11 and n2 + 1 solves, so\n\nit costs f + (n2 + 1)s, or just f + n2s, dropping the dominated term s.\n\n2. forming the schur complement s requires the matrix multiply a21(a\u22121\n2n1, and an n2 \u00d7 n2 matrix subtraction, which costs n2\n\n11 a12),\nwhich costs 2n2\n2 (and\ncan be dropped). the cost of forming \u02dcb = b2\u2212 a21a\u22121\n11 b1 is dominated by the\ncost of forming s, and so can be ignored. the total cost of step 2, ignoring\ndominated terms, is then 2n2\n\n2n1.\n\n3. to compute x2 = s\u22121\u02dcb, we factor s and solve, which costs (2/3)n3\n2.\n4. forming b1\u2212a12x2 costs 2n1n2 +n1 flops. to compute x1 = a\u22121\n\n11 (b1\u2212a12x2),\nwe can use the factorization of a11 already computed in step 1, so only the\nsolve is necessary, which costs s. both of these costs are dominated by other\nterms, and can be ignored.\n\nthe total cost is then\n\nflops.\n\nf + n2s + 2n2\n\n2n1 + (2/3)n3\n2\n\n(c.6)\n\neliminating an unstructured matrix\n\nwe first consider the case when no structure in a11 is exploited. we factor a11\nusing a standard lu factorization, so f = (2/3)n3\n1, and then solve using a forward\nand a backward substitution, so s = 2n2\n1. the flop count for solving the equations\nvia block elimination is then\n\n(2/3)n3\n\n1 + n2(2n2\n\n1) + 2n2\n\n2n1 + (2/3)n3\n\n2 = (2/3)(n1 + n2)3,\n\n "}, {"Page_number": 689, "text": "c.4 block elimination and schur complements\n\n675\n\nwhich is the same as just solving the larger set of equations using a standard lu\nfactorization. in other words, solving a set of equations by block elimination gives\nno advantage when no structure of a11 is exploited.\n\non the other hand, when the structure of a11 allows us to factor and solve\nmore efficiently than the standard method, block elimination can be more efficient\nthan applying the standard method.\n\neliminating a diagonal matrix\n\nif a11 is diagonal, no factorization is needed, and we can carry out a solve in n1\nflops, so we have f = 0 and s = n1. substituting these values into (c.6) and\nkeeping only the leading terms yields\n\n2n2\n\n2n1 + (2/3)n3\n2,\n\nflops, which is far smaller than (2/3)(n1 +n2)3, the cost using the standard method.\nin particular, the flop count of the standard method grows cubicly in n1, whereas\nfor block elimination the flop count grows only linearly in n1.\n\neliminating a banded matrix\n\nif a11 is banded with bandwidth k, we can carry out the factorization in about\nf = 4k2n1 flops, and the solve can be done in about s = 6kn1 flops. the overall\ncomplexity of solving ax = b using block elimination is\n\n4k2n1 + 6n2kn1 + 2n2\n\n2n1 + (2/3)n3\n2\n\n2n1+(2/3)n3\nflops. assuming k is small compared to n1 and n2, this simplifies to 2n2\n2,\nthe same as when a11 is diagonal. in particular, the complexity grows linearly in\nn1, as opposed to cubicly in n1 for the standard method.\n\na matrix for which a11 is banded is sometimes called an arrow matrix since the\nsparsity pattern, when n1 \u226b n2, looks like an arrow pointing down and right. block\nelimination can solve linear equations with arrow structure far more efficiently than\nthe standard method.\n\neliminating a block diagonal matrix\n\nsuppose that a11 is block diagonal, with (square) block sizes m1, . . . , mk, where\nn1 = m1 + \u00b7\u00b7\u00b7 + mk.\nin this case we can factor a11 by factoring each block\nseparately, and similarly we can carry out the solve step on each block separately.\nusing standard methods for these we find\n1 + \u00b7\u00b7\u00b7 + (2/3)m3\nk,\n\n1 + \u00b7\u00b7\u00b7 + 2m2\nk,\n\nf = (2/3)m3\n\ns = 2m2\n\nso the overall complexity of block elimination is\n\n(2/3)\n\nkxi=1\n\nm3\n\ni + 2n2\n\nkxi=1\n\nm2\n\ni + 2n2\n2\n\nkxi=1\n\nmi + (2/3)n3\n2.\n\nif the block sizes are small compared to n1 and n1 \u226b n2, the savings obtained by\nblock elimination is dramatic.\n\n "}, {"Page_number": 690, "text": "676\n\nc numerical linear algebra background\n\nthe linear equations ax = b, where a11 is block diagonal, are called partially\nseparable for the following reason.\nif the subvector x2 is fixed, the remaining\nequations decouple into k sets of independent linear equations (which can be solved\nseparately). the subvector x2 is sometimes called the complicating variable since\nthe equations are much simpler when x2 is fixed. using block elimination, we\ncan solve partially separable linear equations far more efficiently than by using a\nstandard method.\n\neliminating a sparse matrix\n\nif a11 is sparse, we can eliminate a11 using a sparse factorization and sparse solve\nsteps, so the values of f and s in (c.6) are much less than for unstructured a11.\nwhen a11 in (c.3) is sparse and the other blocks are dense, and n2 \u226a n1, we\nsay that a is a sparse matrix with a few dense rows and columns. eliminating\nthe sparse block a11 provides an efficient method for solving equations which are\nsparse except for a few dense rows and columns.\n\nan alternative is to simply apply a sparse factorization algorithm to the entire\nmatrix a. most sparse solvers will handle dense rows and columns, and select a\npermutation that results in sparse factors, and hence fast factorization and solve\ntimes. this is more straightforward than using block elimination, but often slower,\nespecially in applications where we can exploit structure in the other blocks (see,\ne.g., example c.4).\n\nremark c.2 as already suggested in remark c.1, these two methods for solving sys-\ntems with a few dense rows and columns are closely related. applying the elimination\nmethod by factoring a11 and s as\n\na11 = p1l1u1p2,\n\ns = p3l2u2,\n\ncan be interpreted as factoring a as\n\n(cid:20) a11 a12\na21 a22 (cid:21) =\n(cid:20) p1\np3 (cid:21)(cid:20)\n\n0\n\n0\n\nl1\n3 a21p t\n\np t\n\n2 u \u22121\n\n1\n\n0\n\nl2 (cid:21)(cid:20) u1 l\u22121\n\n0\n\n1 p t\nu2\n\n1 a12\n\n(cid:21)(cid:20) p2\n\n0\n\n0\n\ni (cid:21) ,\n\nfollowed by forward and backward substitutions.\n\nc.4.2 block elimination and structure\n\nsymmetry and positive definiteness\n\nthere are variants of the block elimination method that can be used when a is\nsymmetric, or symmetric and positive definite. when a is symmetric, so are a11\nand the schur complement s, so a symmetric factorization can be used for a11\nand s. symmetry can also be exploited in the other operations, such as the matrix\nmultiplies. overall the savings over the nonsymmetric case is around a factor of\ntwo.\n\n "}, {"Page_number": 691, "text": "c.4 block elimination and schur complements\n\n677\n\npositive definiteness can also be exploited in block elimination. when a is sym-\nmetric and positive definite, so are a11 and the schur complement s, so cholesky\nfactorizations can be used.\n\nexploiting structure in other blocks\n\nour complexity analysis above assumes that we exploit no structure in the matrices\na12, a21, a22, and the schur complement s, i.e., they are treated as dense. but in\nmany cases there is structure in these blocks that can be exploited in forming the\nschur complement, factoring it, and carrying out the solve steps. in such cases the\ncomputational savings of the block elimination method over a standard method\ncan be even higher.\n\nexample c.2 block triangular equations. suppose that a12 = 0, i.e., the linear\nequations ax = b have block lower triangular structure:\n\n(cid:20) a11\na21 a22 (cid:21)(cid:20) x1\n\nx2 (cid:21) =(cid:20) b1\nb2 (cid:21) .\n\n0\n\nin this case the schur complement is just s = a22, and the block elimination method\nreduces to block forward substitution:\n\nx1\n\nx2\n\n:= a\u22121\n:= a\u22121\n\n11 b1\n22 (b2 \u2212 a21x1).\n\nexample c.3 block diagonal and banded systems. suppose that a11 is block diagonal,\nwith maximum block size l \u00d7 l, and that a12, a21, and a22 are banded, say with\nbandwidth k. in this case, a\u22121\n11 is also block diagonal, with the same block sizes as\na11. therefore the product a\u22121\n11 a12 is also banded, with bandwidth k + l, and the\nschur complement, s = a22 \u2212 a21a\u22121\n11 a12 is banded with bandwidth 2k + l. this\nmeans that forming the schur complement s can be done more efficiently, and that\nthe factorization and solve steps with s can be done efficiently. in particular, for\nfixed maximum block size l and bandwidth k, we can solve ax = b with a number of\nflops that grows linearly with n.\n\nexample c.4 kkt structure. suppose that the matrix a has kkt structure, i.e.,\n\na =(cid:20) a11 a12\n0 (cid:21) ,\n\nat\n12\n\nwhere a11 \u2208 sp\nuse a cholesky factorization. the schur complement s = \u2212at\ndefinite, so we can factor \u2212s using a cholesky factorization.\n\n++, and a12 \u2208 rp\u00d7m with rank a12 = m. since a11 \u227b 0, we can\n11 a12 is negative\n\n12a\u22121\n\n "}, {"Page_number": 692, "text": "678\n\nc numerical linear algebra background\n\nc.4.3 the matrix inversion lemma\n\nthe idea of block elimination is to remove variables, and then solve a smaller set of\nequations that involve the schur complement of the original matrix with respect to\nthe eliminated variables. the same idea can be turned around: when we recognize\na matrix as a schur complement, we can introduce new variables, and create a\nlarger set of equations to solve. in most cases there is no advantage to doing this,\nsince we end up with a larger set of equations. but when the larger set of equations\nhas some special structure that can be exploited to solve it, introducing variables\ncan lead to an efficient method. the most common case is when another block of\nvariables can be eliminated from the larger matrix.\n\nwe start with the linear equations\n\n(c.7)\nwhere a \u2208 rn\u00d7n is nonsingular, and b \u2208 rn\u00d7p, c \u2208 rp\u00d7n. we introduce a new\nvariable y = cx, and rewrite the equations as\n\n(a + bc)x = b,\n\nax + by = b,\n\ny = cx,\n\nor, in matrix form,\n\n(cid:20) a b\nc \u2212i (cid:21)(cid:20) x\n\ny (cid:21) =(cid:20) b\n0 (cid:21) .\n\n(c.8)\n\nnote that our original coefficient matrix, a + bc, is the schur complement of \u2212i\nin the larger matrix that appears in (c.8). if we were to eliminate the variable y\nfrom (c.8), we would get back the original equation (c.7).\n\nin some cases, it can be more efficient to solve the larger set of equations (c.8)\nthan the original, smaller set of equations (c.7). this would be the case, for\nexample, if a, b, and c were relatively sparse, but the matrix a + bc were far\nless sparse.\n\nafter introducing the new variable y, we can eliminate the original variable x\nfrom the larger set of equations (c.8), using x = a\u22121(b \u2212 by). substituting this\ninto the second equation y = cx, we obtain\n\nso that\n\n(i + ca\u22121b)y = ca\u22121b,\n\ny = (i + ca\u22121b)\u22121ca\u22121b.\n\nusing x = a\u22121(b \u2212 by), we get\n\nsince b is arbitrary, we conclude that\n\nx =(cid:0)a\u22121 \u2212 a\u22121b(i + ca\u22121b)\u22121ca\u22121(cid:1) b.\n(a + bc)\u22121 = a\u22121 \u2212 a\u22121b(cid:0)i + ca\u22121b(cid:1)\u22121\n\nca\u22121.\n\nthis is known as the matrix inversion lemma, or the sherman-woodbury-morrison\nformula.\n\nthe matrix inversion lemma has many applications. for example if p is small\n(or even just not very large), it gives us a method for solving (a + bc)x = b,\nprovided we have an efficient method for solving au = v.\n\n(c.9)\n\n "}, {"Page_number": 693, "text": "c.4 block elimination and schur complements\n\n679\n\ndiagonal or sparse plus low rank\n\nsuppose that a is diagonal with nonzero diagonal elements, and we want to solve\nan equation of the form (c.7). the straightforward solution would consist in first\nforming the matrix d = a + bc, and then solving dx = b. if the product bc\nis dense, then the complexity of this method is 2pn2 flops to form a + bc, plus\n(2/3)n3 flops for the lu factorization of d, so the total cost is\n\n2pn2 + (2/3)n3\n\nflops. the matrix inversion lemma suggests a more efficient method. we can\ncalculate x by evaluating the expression (c.9) from right to left, as follows. we\nfirst evaluate z = a\u22121b (n flops, since a is diagonal). then we form the matrix\ne = i + ca\u22121b (2p2n flops). next we solve ew = cz, which is a set of p linear\nequations in p variables. the cost is (2/3)p3 flops, plus 2pn to form cz. finally,\nwe evaluate x = z \u2212 a\u22121bw (2pn flops for the matrix-vector product bw, plus\nlower order terms). the total cost is\n\n2p2n + (2/3)p3\n\nflops, dropping dominated terms. comparing with the first method, we see that\nthe second method is more efficient when p < n. in particular if p is small and\nfixed, the complexity grows linearly with n.\n\nanother important application of the matrix inversion lemma occurs when a is\nsparse and nonsingular, and the matrices b and c are dense. again we can compare\ntwo methods. the first method is to form the (dense) matrix a + bc, and to\nsolve (c.7) using a dense lu factorization. the cost of this method is 2pn2+(2/3)n3\nflops. the second method is based on evaluating the expression (c.9), using a\nsparse lu factorization of a. specifically, suppose that f is the cost of factoring\na as a = p1lu p2, and s is the cost of solving the factored system p1lu p2x = d.\nwe can evaluate (c.9) from right to left as follows. we first factor a, and solve\np + 1 linear systems\n\naz = b,\n\nad = b,\n\nto find z \u2208 rn, and d \u2208 rn\u00d7p. the cost is f + (p + 1)s flops. next, we form the\nmatrix e = i + cd, and solve\n\new = cz,\n\nwhich is a set of p linear equations in p variables w. the cost of this step is\n2p2n + (2/3)p3 plus lower order terms. finally, we evaluate x = z \u2212 dw, at a cost\nof 2pn flops. this gives us a total cost of\n\nf + ps + 2p2n + (2/3)p3\n\nflops. if f \u226a (2/3)n3 and s \u226a 2n2, this is much lower than the complexity of the\nfirst method.\n\nremark c.3 the augmented system approach. a different approach to exploiting\nsparse plus low rank structure is to solve (c.8) directly using a sparse lu-solver. the\nsystem (c.8) is a set of p + n linear equations in p + n variables, and is sometimes\n\n "}, {"Page_number": 694, "text": "680\n\nc numerical linear algebra background\n\ncalled the augmented system associated with (c.7). if a is very sparse and p is small,\nthen solving the augmented system using a sparse solver can be much faster than\nsolving the system (c.7) using a dense solver.\n\nthe augmented system approach is closely related to the method that we described\nabove. suppose\n\nis a sparse lu factorization of a, and\n\na = p1lu p2\n\ni + ca\u22121b = p3 \u02dcl \u02dcu\n\nis a dense lu factorization of i + ca\u22121b. then\n\n(cid:20) a b\nc \u2212i (cid:21)\n=(cid:20) p1\n\n0\n\n0\n\np3 (cid:21)(cid:20)\n\nl\n3 cp t\n\np t\n\n2 u \u22121 \u2212 \u02dcl (cid:21)(cid:20) u l\u22121p t\n\n\u02dcu\n\n0\n\n0\n\n1 b\n\n(c.10)\n\n(cid:21)(cid:20) p2\n\n0\n\n0\n\ni (cid:21) ,\n\nand this factorization can be used to solve the augmented system. it can be verified\nthat this is equivalent to the method based on the matrix inversion lemma that we\ndescribed above.\n\nof course, if we solve the augmented system using a sparse lu solver, we have no\ncontrol over the permutations that are selected. the solver might choose a factor-\nization different from (c.10), and more expensive to compute. in spite of this, the\naugmented system approach remains an attractive option. it is easier to implement\nthan the method based on the matrix inversion lemma, and it is numerically more\nstable.\n\nlow rank updates\nsuppose a \u2208 rn\u00d7n is nonsingular, u, v \u2208 rn with 1 + vt a\u22121u 6= 0, and we want\nto solve two sets of linear equations\n\nax = b,\n\n(a + uvt )\u02dcx = b.\n\nthe solution \u02dcx of the second system is called a rank-one update of x. the matrix\ninversion lemma allows us to calculate the rank-one update \u02dcx very cheaply, once\nwe have computed x. we have\n\n\u02dcx = (a + uvt )\u22121b\n1\n\n= (a\u22121 \u2212\n\n1 + vt a\u22121u\nvt x\n\na\u22121u.\n\n= x \u2212\n\n1 + vt a\u22121u\n\na\u22121uvt a\u22121)b\n\nwe can therefore solve both systems by factoring a, computing x = a\u22121b and\nw = a\u22121u, and then evaluating\n\n\u02dcx = x \u2212\n\nvt x\n\n1 + vt w\n\nw.\n\nthe overall cost is f + 2s, as opposed to 2(f + s) if we were to solve for \u02dcx from\nscratch.\n\n "}, {"Page_number": 695, "text": "c.5 solving underdetermined linear equations\n\n681\n\nc.5 solving underdetermined linear equations\n\nto conclude this appendix, we mention a few important facts about underdeter-\nmined linear equations\n\n(c.11)\nwhere a \u2208 rp\u00d7n with p < n. we assume that rank a = p, so there is at least one\nsolution for all b.\nin many applications it is sufficient to find just one particular solution \u02c6x. in\n\nax = b,\n\nother situations we might need a complete parametrization of all solutions as\n\n{x | ax = b} = {f z + \u02c6x | z \u2208 rn\u2212p}\n\n(c.12)\n\nwhere f is a matrix whose columns form a basis for the nullspace of a.\n\ninverting a nonsingular submatrix of a\nthe solution of the underdetermined system is straightforward if a p\u00d7p nonsingular\nsubmatrix of a is known. we start by assuming that the first p columns of a are\nindependent. then we can write the equation ax = b as\n\nax =(cid:2) a1 a2 (cid:3)(cid:20) x1\n\nx2 (cid:21) = a1x1 + a2x2 = b,\n\nwhere a1 \u2208 rp\u00d7p is nonsingular. we can express x1 as\n1 b \u2212 a\u22121\n\n1 (b \u2212 a2x2) = a\u22121\n\nx1 = a\u22121\n\n1 a2x2.\n\nthis expression allows us to easily calculate a solution: we simply take \u02c6x2 = 0,\n\u02c6x1 = a\u22121\n1 b. the cost is equal to the cost of solving one square set of p linear\nequations a1 \u02c6x1 = b.\n\nwe can also parametrize all solutions of ax = b, using x2 \u2208 rn\u2212p as a free\n\nparameter. the general solution of ax = b can be expressed as\n\nx =(cid:20) x1\n\nx2 (cid:21) =(cid:20) \u2212a\u22121\n\n1 a2\ni\n\n(cid:21) x2 +(cid:20) a\u22121\n\n1 b\n0\n\n(cid:21) .\n\nthis gives a parametrization of the form (c.12) with\n\nf =(cid:20) \u2212a\u22121\n\n1 a2\ni\n\n(cid:21) ,\n\n\u02c6x =(cid:20) a\u22121\n\n1 b\n0\n\n(cid:21) .\n\nto summarize, assume that the cost of factoring a1 is f and the cost of solving one\nsystem of the form a1x = d is s. then the cost of finding one solution of (c.11)\nis f + s. the cost of parametrizing all solutions (i.e., calculating f and \u02c6x) is\nf + s(n \u2212 p + 1).\nnow we consider the general case, when the first p columns of a need not be\nindependent. since rank a = p, we can select a set of p columns of a that is\nindependent, permute them to the front, and then apply the method described\n\n "}, {"Page_number": 696, "text": "682\n\nc numerical linear algebra background\n\nabove.\ncolumns of \u02dca = ap are independent, i.e.,\n\nin other words, we find a permutation matrix p such that the first p\n\nwhere a1 is invertible. the general solution of \u02dca\u02dcx = b, where \u02dcx = p t x, is then\ngiven by\n\n\u02dca = ap =(cid:2) a1 a2 (cid:3) ,\n(cid:21) \u02dcx2 +(cid:20) a\u22121\n(cid:21) .\n(cid:21) z + p(cid:20) a\u22121\n\n\u02dcx =(cid:20) \u2212a\u22121\nx = p \u02dcx = p(cid:20) \u2212a\u22121\n\n1 a2\ni\n\n1 a2\ni\n\n1 b\n0\n\n1 b\n0\n\n(cid:21) ,\n\nthe general solution of ax = b is then given by\n\nwhere z \u2208 rn\u2212p is a free parameter. this idea is useful when it is easy to identify\na nonsingular or easily inverted submatrix of a, for example, a diagonal matrix\nwith nonzero diagonal elements.\n\nthe qr factorization\nif c \u2208 rn\u00d7p with p \u2264 n and rank c = p, then it can be factored as\n\nc =(cid:2) q1 q2 (cid:3)(cid:20) r\n0 (cid:21) ,\n\nwhere q1 \u2208 rn\u00d7p and q2 \u2208 rn\u00d7(n\u2212p) satisfy\n2 q2 = i,\n\n1 q1 = i,\n\nqt\n\nqt\n\nqt\n\n1 q2 = 0,\n\nand r \u2208 rp\u00d7p is upper triangular with nonzero diagonal elements. this is called\nthe qr factorization of c. the qr factorization can be calculated in 2p2(n\u2212 p/3)\nflops. (the matrix q is stored in a factored form that makes it possible to efficiently\ncompute matrix-vector products qx and qt x.)\n\nthe qr factorization can be used to solve the underdetermined set of linear\n\nequations (c.11). suppose\n\nat =(cid:2) q1 q2 (cid:3)(cid:20) r\n0 (cid:21)\n\nis the qr factorization of at . substituting in the equations it is clear that \u02c6x =\nq1r\u2212t b satisfies the equations:\n\na\u02c6x = rt qt\n\n1 q1r\u2212t b = b.\n\nmoreover, the columns of q2 form a basis for the nullspace of a, so the complete\nsolution set can be parametrized as\n\n{x = \u02c6x + q2z | z \u2208 rn\u2212p}.\n\nthe qr factorization method is the most common method for solving under-\ndetermined equations. one drawback is that it is difficult to exploit sparsity. the\nfactor q is usually dense, even when c is very sparse.\n\n "}, {"Page_number": 697, "text": "c.5 solving underdetermined linear equations\n\n683\n\nlu factorization of a rectangular matrix\nif c \u2208 rn\u00d7p with p \u2264 n and rank c = p, then it can be factored as\n\nc = p lu\n\nwhere p \u2208 rn\u00d7n is a permutation matrix, l \u2208 rn\u00d7p is unit lower triangular (i.e.,\nlij = 0 for i < j and lii = 1), and u \u2208 rp\u00d7p is nonsingular and upper triangular.\nthe cost is (2/3)p3 + p2(n \u2212 p) flops if no structure in c is exploited.\nif the matrix c is sparse, the lu factorization usually includes row and column\npermutations, i.e., we factor c as\n\nc = p1lu p2\n\nwhere p1, p2 \u2208 rp\u00d7p are permutation matrices. the lu factorization of a sparse\nrectangular matrix can be calculated very efficiently, at a cost that is much lower\nthan for dense matrices.\n\nthe lu factorization can be used to solve underdetermined sets of linear equa-\ntions. suppose at = p lu is the lu factorization of the matrix at in (c.11), and\nwe partition l as\n\nl =(cid:20) l1\nl2 (cid:21) ,\n\nwhere l1 \u2208 rp\u00d7p and l2 \u2208 r(n\u2212p)\u00d7p. it is easily verified that the solution set can\nbe parametrized as (c.12) with\n\n\u02c6x = p(cid:20) l\u2212t\n\n0\n\n1 u \u2212t b\n\n(cid:21) ,\n\nf = p(cid:20) \u2212l\u2212t\n\n1 lt\n2\ni\n\n(cid:21) .\n\n "}, {"Page_number": 698, "text": "684\n\nc numerical linear algebra background\n\nbibliography\n\nstandard references for dense numerical linear algebra are golub and van loan [gl89],\ndemmel [dem97], trefethen and bau [tb97], and higham [hig96]. the sparse cholesky\nfactorization is covered in george and liu [gl81]. duff, erisman, and reid [der86] and\nduff [duf93] discuss the sparse lu and ldlt factorizations. the books by gill, murray,\nand wright [gmw81, \u00a72.2], wright [wri97, chapter 11], and nocedal and wright [nw99,\n\u00a7a.2] include introductions to numerical linear algebra that focus on problems arising in\nnumerical optimization.\n\nhigh-quality implementations of common dense linear algebra algorithms are included\nin the lapack package [abb+99]. lapack is built upon the basic linear algebra\nsubprograms (blas), a library of routines for basic vector and matrix operations that can\nbe easily customized to take advantage of specific computer architectures. several codes\nfor solving sparse linear equations are also available, including spooles [apww99],\nsuperlu [dgl03], umfpack [dav03], and wsmp [gup00], to mention only a few.\n\n "}, {"Page_number": 699, "text": "references\n\n[abb+99] e. anderson, z. bai, c. bischof, s. blackford, j. demmel, j. dongarra, j. du\ncroz, a. greenbaum, s. hammarling, a. mckenney, and d. sorensen. la-\npack users\u2019 guide. society for industrial and applied mathematics, third\nedition, 1999. available from www.netlib.org/lapack.\n\n[ae61]\n\n[ag03]\n\n[aho98]\n\n[ali91]\n\n[and70]\n\nk. j. arrow and a. c. enthoven. quasi-concave programming. econometrica,\n29(4):779\u2013800, 1961.\n\nf. alizadeh and d. goldfarb. second-order cone programming. mathematical\nprogramming series b, 95:3\u201351, 2003.\n\nf. alizadeh, j.-p. a. haeberly, and m. l. overton. primal-dual interior-\npoint methods for semidefinite programming: convergence rates, stability\nand numerical results. siam journal on optimization, 8(3):746\u2013768, 1998.\n\nf. alizadeh. combinatorial optimization with interior-point methods and\nsemi-definite matrices. phd thesis, university of minnesota, 1991.\n\nt. w. anderson. estimation of covariance matrices which are linear com-\nbinations or whose inverses are linear combinations of given matrices.\nin\nr. c. bose et al., editor, essays in probability and statistics, pages 1\u201324.\nuniversity of north carolina press, 1970.\n\n[apww99] c. ashcraft, d. pierce, d. k. wah, and j. wu. the reference man-\nual\nfor spooles version 2.2: an object oriented software library\nfor solving sparse linear systems of equations, 1999. available from\nwww.netlib.org/linalg/spooles/spooles.2.2.html.\n\n[ay98]\n\n[bar02]\n\n[bb65]\n\n[bb91]\n\n[bbi71]\n\ne. d. andersen and y. ye. a computational study of the homogeneous\nalgorithm for large-scale convex optimization. computational optimization\nand applications, 10:243\u2013269, 1998.\n\na. barvinok. a course in convexity, volume 54 of graduate studies in\nmathematics. american mathematical society, 2002.\n\ne. f. beckenbach and r. bellman. inequalities. springer, second edition,\n1965.\n\ns. boyd and c. barratt. linear controller design: limits of performance.\nprentice-hall, 1991.\n\na. berman and a. ben-israel. more on linear inequalities with applications to\nmatrix theory. journal of mathematical analysis and applications, 33:482\u2013\n496, 1971.\n\n[bd77]\n\np. j. bickel and k. a. doksum. mathematical statistics. holden-day, 1977.\n\n[bdx04]\n\n[be93]\n\ns. boyd, p. diaconis, and l. xiao. fastest mixing markov chain on a graph.\nsiam review, 46(4):667\u2013689, 2004.\n\ns. boyd and l. el ghaoui. method of centers for minimizing generalized\neigenvalues. linear algebra and its applications, 188:63\u2013111, 1993.\n\n "}, {"Page_number": 700, "text": "686\n\nreferences\n\n[befb94]\n\ns. boyd, l. el ghaoui, e. feron, and v. balakrishnan. linear matrix in-\nequalities in system and control theory. society for industrial and applied\nmathematics, 1994.\n\n[ber73]\n\n[ber90]\n\n[ber99]\n\n[ber03]\n\n[bf48]\n\n[bf63]\n\na. berman. cones, matrices and mathematical programming. springer, 1973.\n\nm. berger. convexity. the american mathematical monthly, 97(8):650\u2013678,\n1990.\n\nd. p. bertsekas. nonlinear programming. athena scientific, second edition,\n1999.\n\nd. p. bertsekas. convex analysis and optimization. athena scientific, 2003.\nwith a. nedi\u00b4c and a. e. ozdaglar.\n\nt. bonnesen and w. fenchel. theorie der konvexen k\u00a8orper. chelsea pub-\nlishing company, 1948. first published in 1934.\n\nr. bellman and k. fan. on systems of linear inequalities in hermitian matrix\nvariables. in v. l. klee, editor, convexity, volume vii of proceedings of the\nsymposia in pure mathematics, pages 1\u201311. american mathematical society,\n1963.\n\n[bgt81]\n\n[bi69]\n\nr. g. bland, d. goldfarb, and m. j. todd. the ellipsoid method: a survey.\noperations research, 29(6):1039\u20131091, 1981.\n\na. ben-israel. linear equations and inequalities on finite dimensional, real or\ncomplex vector spaces: a unified theory. journal of mathematical analysis\nand applications, 27:367\u2013389, 1969.\n\n[bj\u00a8o96]\n\na. bj\u00a8orck. numerical methods for least squares problems. society for in-\ndustrial and applied mathematics, 1996.\n\n[bkmr98] a. brooke, d. kendrick, a. meeraus, and r. raman. gams: a user\u2019s guide.\n\nthe scientific press, 1998.\n\n[bl00]\n\n[bn78]\n\n[bon94]\n\n[bor02]\n\n[bp94]\n\n[bri61]\n\n[bs00]\n\n[bss93]\n\n[bt97]\n\n[btn98]\n\nj. m. borwein and a. s. lewis. convex analysis and nonlinear optimization.\nspringer, 2000.\n\no. barndorff-nielsen.\ntheory. john wiley & sons, 1978.\n\ninformation and exponential families in statistical\n\nj. v. bondar. comments on and complements to inequalities: theory of ma-\njorization and its applications. linear algebra and its applications, 199:115\u2013\n129, 1994.\n\nb. borchers.\nwww.nmt.edu/~borchers/csdp.html.\n\ncsdp user\u2019s guide,\n\n2002.\n\navailable\n\nfrom\n\na. berman and r. j. plemmons. nonnegative matrices in the mathemati-\ncal sciences. society for industrial and applied mathematics, 1994. first\npublished in 1979 by academic press.\n\nl. brickman. on the field of values of a matrix. proceedings of the american\nmathematical society, 12:61\u201366, 1961.\n\nd. bertsimas and j. sethuraman. moment problems and semidefinite opti-\nmization. in h. wolkowicz, r. saigal, and l. vandenberghe, editors, hand-\nbook of semidefinite programming, chapter 16, pages 469\u2013510. kluwer aca-\ndemic publishers, 2000.\n\nm. s. bazaraa, h. d. sherali, and c. m. shetty. nonlinear programming.\ntheory and algorithms. john wiley & sons, second edition, 1993.\n\nd. bertsimas and j. n. tsitsiklis.\nathena scientific, 1997.\n\nintroduction to linear optimization.\n\na. ben-tal and a. nemirovski. robust convex optimization. mathematics\nof operations research, 23(4):769\u2013805, 1998.\n\n "}, {"Page_number": 701, "text": "references\n\n687\n\n[btn99]\n\n[btn01]\n\n[by02]\n\n[byt99]\n\n[cal64]\n\n[cds01]\n\na. ben-tal and a. nemirovski. robust solutions of uncertain linear programs.\noperations research letters, 25(1):1\u201313, 1999.\n\na. ben-tal and a. nemirovski. lectures on modern convex optimization.\nanalysis, algorithms, and engineering applications. society for industrial\nand applied mathematics, 2001.\n\ns. j. benson and y. ye. dsdp \u2014 a software package implementing the\ndual-scaling algorithm for semidefinite programming, 2002. available from\nwww-unix.mcs.anl.gov/~benson.\n\ne. bai, y. ye, and r. tempo. bounded error parameter estimation: a se-\nquential analytic center approach. ieee transactions on automatic control,\n44(6):1107\u20131117, 1999.\n\ne. calabi. linear systems of real quadratic forms. proceedings of the amer-\nican mathematical society, 15(5):844\u2013846, 1964.\n\ns. s. chen, d. l. donoho, and m. a. saunders. atomic decomposition by\nbasis pursuit. siam review, 43(1):129\u2013159, 2001.\n\n[cggs98] s. chandrasekaran, g. h. golub, m. gu, and a. h. sayed. parameter es-\ntimation in the presence of bounded data uncertainties. siam journal of\nmatrix analysis and applications, 19(1):235\u2013252, 1998.\n\n[ch53]\n\n[ck77]\n\n[ct91]\n\n[dan63]\n\n[dav63]\n\nr. courant and d. hilbert. method of mathematical physics. volume 1.\ninterscience publishers, 1953. tranlated and revised from the 1937 german\noriginal.\n\nb. d. craven and j. j. koliha. generalizations of farkas\u2019 theorem. siam\njournal on numerical analysis, 8(6), 1977.\n\nt. m. cover and j. a. thomas. elements of information theory. john wiley\n& sons, 1991.\n\ng. b. dantzig. linear programming and extensions. princeton university\npress, 1963.\n\nc. davis. notions generalizing convexity for functions defined on spaces of\nmatrices.\nin v. l. klee, editor, convexity, volume vii of proceedings of\nthe symposia in pure mathematics, pages 187\u2013201. american mathematical\nsociety, 1963.\n\n[dav03]\n\nt. a. davis.\numfpack user guide,\nwww.cise.ufl.edu/research/sparse/umfpack.\n\n2003.\n\navailable\n\nfrom\n\n[ddb95] m. a. dahleh and i. j. diaz-bobillo. control of uncertain systems: a linear\n\nprogramming approach. prentice-hall, 1995.\n\n[deb59]\n\n[dem97]\n\n[der86]\n\n[dgl03]\n\n[dh93]\n\n[dhs99]\n\n[dik67]\n\ng. debreu. theory of value: an axiomatic analysis of economic equilib-\nrium. yale university press, 1959.\n\nj. w. demmel. applied numerical linear algebra. society for industrial and\napplied mathematics, 1997.\n\ni. s. duff, a. m. erismann, and j. k. reid. direct methods for sparse\nmatrices. clarendon press, 1986.\n\nj. w. demmel, j. r. gilbert, and x. s. li. superlu users\u2019 guide, 2003.\navailable from crd.lbl.gov/~xiaoye/superlu.\n\nd. den hertog. interior point approach to linear, quadratic and convex\nprogramming. kluwer, 1993.\n\nr. o. duda, p. e. hart, and d. g. stork. pattern classification. john wiley\n& sons, second edition, 1999.\n\ni. dikin. iterative solution of problems of linear and quadratic programming.\nsoviet mathematics doklady, 8(3):674\u2013675, 1967.\n\n "}, {"Page_number": 702, "text": "688\n\nreferences\n\n[dlw00]\n\n[dp00]\n\n[dpz67]\n\n[ds96]\n\n[duf93]\n\nt. n. davidson, z.-q. luo, and k. m. wong. design of orthogonal pulse\nshapes for communications via semidefinite programming. ieee transactions\non signal processing, 48(5):1433\u20131445, 2000.\n\ng. e. dullerud and f. paganini. a course in robust control theory: a\nconvex approach. springer, 2000.\n\nr. j. duffin, e. l. peterson, and c. zener. geometric programming. theory\nand applications. john wiley & sons, 1967.\n\nj. e. dennis and r. s. schnabel. numerical methods for unconstrained opti-\nmization and nonlinear equations. society for industrial and applied math-\nematics, 1996. first published in 1983 by prentice-hall.\n\ni. s. duff. the solution of augmented systems. in d. f. griffiths and g. a.\nwatson, editors, numerical analysis 1993. proceedings of the 15th dundee\nconference, pages 40\u201355. longman scientific & technical, 1993.\n\n[eck80]\n\nj. g. ecker. geometric programming: methods, computations and applica-\ntions. siam review, 22(3):338\u2013362, 1980.\n\n[egg58]\n\nh. g. eggleston. convexity. cambridge university press, 1958.\n\n[el97]\n\n[em75]\n\n[en00]\n\n[eol98]\n\n[et99]\n\n[far02]\n\n[fd85]\n\nl. el ghaoui and h. lebret. robust solutions to least-squares problems\nwith uncertain data. siam journal of matrix analysis and applications,\n18(4):1035\u20131064, 1997.\n\nj. elzinga and t. g. moore. a central cutting plane algorithm for the convex\nprogramming problem. mathematical programming studies, 8:134\u2013145, 1975.\n\nl. el ghaoui and s. niculescu, editors. advances in linear matrix inequality\nmethods in control. society for industrial and applied mathematics, 2000.\n\nl. el ghaoui, f. oustry, and h. lebret. robust solutions to uncertain\nsemidefinite programs. siam journal on optimization, 9(1):33\u201352, 1998.\n\ni. ekeland and r. t\u00b4emam. convex analysis and variational inequalities.\nclassics in applied mathematics. society for industrial and applied mathe-\nmatics, 1999. originally published in 1976.\n\nj. farkas. theorie der einfachen ungleichungen. journal f\u00a8ur die reine und\nangewandte mathematik, 124:1\u201327, 1902.\n\nj. p. fishburn and a. e. dunlop. tilos: a posynomial programming ap-\nproach to transistor sizing. in ieee international conference on computer-\naided design: iccad-85. digest of technical papers, pages 326\u2013328. ieee\ncomputer society press, 1985.\n\n[fen83]\n\nw. fenchel. convexity through the ages. in p. m. gruber and j. m. wills,\neditors, convexity and its applications, pages 120\u2013130. birkh\u00a8auser verlag,\n1983.\n\n[fgk99]\n\nr. fourer, d. m. gay, and b. w. kernighan. ampl: a modeling language\nfor mathematical programming. duxbury press, 1999.\n\n[fgw02] a. forsgren, p. e. gill, and m. h. wright. interior methods for nonlinear\n\noptimization. siam review, 44(4):525\u2013597, 2002.\n\n[fkn98]\n\nk. fujisawa, m. kojima, and k. nakata. sdpa user\u2019s manual, 1998. avail-\nable from grid.r.dendai.ac.jp/sdpa.\n\n[fl01]\n\n[fm90]\n\nm. florenzano and c. le van. finite dimensional convexity and optimiza-\ntion. number 13 in studies in economic theory. springer, 2001.\n\na. v. fiacco and g. p. mccormick. nonlinear programming. sequential\nunconstrained minimization techniques. society for industrial and applied\nmathematics, 1990. first published in 1968 by research analysis corpora-\ntion.\n\n "}, {"Page_number": 703, "text": "references\n\n689\n\n[fre56]\n\n[fw56]\n\n[gau95]\n\n[gi03a]\n\n[gi03b]\n\n[gkt51]\n\n[gl81]\n\n[gl89]\n\n[gls88]\n\n[gly96]\n\nr. j. freund. the introduction of risk into a programming model. econo-\nmetrica, 24(3):253\u2013263, 1956.\n\nm. frank and p. wolfe. an algorithm for quadratic programming. naval\nresearch logistics quarterly, 3:95\u2013110, 1956.\n\nc. f. gauss. theory of the combination of observations least subject to\nerrors. society for industrial and applied mathematics, 1995. translated\nfrom original 1820 manuscript by g. w. stewart.\n\nd. goldfarb and g. iyengar. robust convex quadratically constrained pro-\ngrams. mathematical programming series b, 97:495\u2013515, 2003.\n\nd. goldfarb and g. iyengar. robust portfolio selection problems. mathemat-\nics of operations research, 28(1):1\u201338, 2003.\n\nd. gale, h. w. kuhn, and a. w. tucker. linear programming and the\ntheory of games. in t. c. koopmans, editor, activity analysis of production\nand allocation, volume 13 of cowles commission for research in economics\nmonographs, pages 317\u2013335. john wiley & sons, 1951.\n\na. george and j. w.-h. liu. computer solution of large sparse positive\ndefinite systems. prentice-hall, 1981.\n\ng. golub and c. f. van loan. matrix computations. johns hopkins uni-\nversity press, second edition, 1989.\n\nm. gr\u00a8otschel, l. lovasz, and a. schrijver. geometric algorithms and com-\nbinatorial optimization. springer, 1988.\n\nj.-l. goffin, z.-q. luo, and y. ye. complexity analysis of an interior cutting\nplane method for convex feasibility problems. siam journal on optimization,\n6:638\u2013652, 1996.\n\n[gms+86] p. e. gill, w. murray, m. a. saunders, j. a. tomlin, and m. h. wright. on\nprojected newton barrier methods for linear programming and an equivalence\nto karmarkar\u2019s projective method. mathematical programming, 36:183\u2013209,\n1986.\n\n[gmw81] p. e. gill, w. murray, and m. h. wright. practical optimization. academic\n\npress, 1981.\n\n[gon92]\n\n[gow85]\n\n[gup00]\n\n[gw95]\n\n[han98]\n\nc. c. gonzaga. path-following methods for linear programming. siam re-\nview, 34(2):167\u2013224, 1992.\n\nj. c. gower. properties of euclidean and non-euclidean distance matrices.\nlinear algebra and its applications, 67:81\u201397, 1985.\n\na. gupta. wsmp: watson sparse matrix package. part i \u2014 direct solution\nof symmetric sparse systems. part ii \u2014 direct solution of general sparse\nsystems, 2000. available from www.cs.umn.edu/~agupta/wsmp.\n\nm. x. goemans and d. p. williamson. improved approximation algorithms\nfor maximum cut and satisfiability problems using semidefinite programming.\njournal of the association for computing machinery, 42(6):1115\u20131145, 1995.\n\np. c. hansen. rank-deficient and discrete ill-posed problems. numerical\naspects of linear inversion. society for industrial and applied mathematics,\n1998.\n\n[hbl01] m. del mar hershenson, s. p. boyd, and t. h. lee. optimal design of a cmos\nop-amp via geometric programming. ieee transactions on computer-aided\ndesign of integrated circuits and systems, 20(1):1\u201321, 2001.\n\n[hes68]\n\n[hig96]\n\nm. r. hestenes. pairs of quadratic forms. linear algebra and its applications,\n1:397\u2013407, 1968.\n\nn. j. higham. accuracy and stability of numerical algorithms. society for\nindustrial and applied mathematics, 1996.\n\n "}, {"Page_number": 704, "text": "690\n\nreferences\n\n[hil57]\n\n[hj85]\n\n[hj91]\n\nc. hildreth. a quadratic programming procedure. naval research logistics\nquarterly, 4:79\u201385, 1957.\n\nr. a. horn and c. a. johnson. matrix analysis. cambridge university press,\n1985.\n\nr. a. horn and c. a. johnson. topics in matrix analysis. cambridge\nuniversity press, 1991.\n\n[hlp52]\n\ng. h. hardy, j. e. littlewood, and g. p\u00b4olya. inequalities. cambridge uni-\nversity press, second edition, 1952.\n\n[hp94]\n\nr. horst and p. pardalos. handbook of global optimization. kluwer, 1994.\n\n[hrvw96] c. helmberg, f. rendl, r. vanderbei, and h. wolkowicz. an interior-\npoint method for semidefinite programming. siam journal on optimization,\n6:342\u2013361, 1996.\n\n[htf01]\n\n[hub64]\n\nt. hastie, r. tibshirani, and j. friedman. the elements of statistical learn-\ning. data mining, inference, and prediction. springer, 2001.\n\np. j. huber. robust estimation of a location parameter. the annals of\nmathematical statistics, 35(1):73\u2013101, 1964.\n\n[hub81]\n\np. j. huber. robust statistics. john wiley & sons, 1981.\n\n[hul93]\n\n[hul01]\n\n[isi64]\n\n[jar94]\n\n[jen06]\n\n[joh85]\n\n[kan52]\n\n[kan60]\n\n[kar84]\n\n[kel60]\n\n[kle63]\n\n[kle71]\n\n[kn77]\n\nj.-b. hiriart-urruty and c. lemar\u00b4echal. convex analysis and minimization\nalgorithms. springer, 1993. two volumes.\n\nj.-b. hiriart-urruty and c. lemar\u00b4echal. fundamentals of convex analy-\nsis. springer, 2001. abridged version of convex analysis and minimization\nalgorithms volumes 1 and 2.\n\nk. isii. inequalities of the types of chebyshev and cram\u00b4er-rao and math-\nematical programming. annals of the institute of statistical mathematics,\n16:277\u2013293, 1964.\n\nf. jarre. optimal ellipsoidal approximations around the analytic center.\napplied mathematics and optimization, 30:15\u201319, 1994.\n\nj. l. w. v. jensen. sur les fonctions convexes et les in\u00b4egalit\u00b4es entre les\nvaleurs moyennes. acta mathematica, 30:175\u2013193, 1906.\n\nf. john. extremum problems with inequalities as subsidiary conditions. in\nj. moser, editor, fritz john, collected papers, pages 543\u2013560. birkh\u00a8auser\nverlag, 1985. first published in 1948.\n\nl. v. kantorovich. functional analysis and applied mathematics. national\nbureau of standards, 1952. translated from russian by c. d. benster. first\npublished in 1948.\n\nl. v. kantorovich. mathematical methods of organizing and planning pro-\nduction. management science, 6(4):366\u2013422, 1960. translated from russian.\nfirst published in 1939.\n\nn. karmarkar. a new polynomial-time algorithm for linear programming.\ncombinatorica, 4(4):373\u2013395, 1984.\n\nj. e. kelley. the cutting-plane method for solving convex programs. journal\nof the society for industrial and applied mathematics, 8(4):703\u2013712, 1960.\n\nv. l. klee, editor. convexity, volume 7 of proceedings of symposia in pure\nmathematics. american mathematical society, 1963.\n\nv. klee. what is a convex set? the american mathematical monthly,\n78(6):616\u2013631, 1971.\n\nm. g. krein and a. a. nudelman. the markov moment problem and ex-\ntremal problems. american mathematical society, 1977. translated from\nrussian. first published in 1973.\n\n "}, {"Page_number": 705, "text": "references\n\n691\n\n[koo51]\n\nt. c. koopmans, editor. activity analysis of production and allocation,\nvolume 13 of cowles commission for research in economics monographs.\njohn wiley & sons, 1951.\n\n[ks66]\n\ns. karlin and w. j. studden. tchebycheff systems: with applications in\nanalysis and statistics. john wiley & sons, 1966.\n\n[ksh97] m. kojima, s. shindoh, and s. hara. interior-point methods for the monotone\nsemidefinite linear complementarity problem in symmetric matrices. siam\njournal on optimization, 7(1):86\u2013125, 1997.\n\n[ksh00]\n\n[ksja91]\n\n[kt51]\n\n[kuh76]\n\n[las95]\n\n[las02]\n\n[lay82]\n\n[lh66]\n\n[lh95]\n\n[lms94]\n\n[lo96]\n\n[l\u00a8of04]\n\n[l\u00a8ow34]\n\n[lsz00]\n\n[lue68]\n\n[lue69]\n\n[lue84]\n\nt. kailath, a. h. sayed, and b. hassibi. linear estimation. prentice-hall,\n2000.\n\nj. m. kleinhaus, g. sigl, f. m. johannes, and k. j. antreich. gordian:\nvlsi placement by quadratic programming and slicing optimization. ieee\ntransactions on computer-aided design of integrated circuits and systems,\n10(3):356\u2013200, 1991.\n\nh. w. kuhn and a. w. tucker. nonlinear programming. in j. neyman, ed-\nitor, proceedings of the second berkeley symposium on mathematical statis-\ntics and probability, pages 481\u2013492. university of california press, 1951.\n\nh. w. kuhn. nonlinear programming. a historical view. in r. w. cottle\nand c. e. lemke, editors, nonlinear programming, volume 9 of siam-ams\nproceedings, pages 1\u201326. american mathematical society, 1976.\n\nj. b. lasserre. a new farkas lemma for positive semidefinite matrices. ieee\ntransactions on automatic control, 40(6):1131\u20131133, 1995.\n\nj. b. lasserre. bounds on measures satisfying moment conditions. the\nannals of applied probability, 12(3):1114\u20131137, 2002.\n\ns. r. lay. convex sets and their applications. john wiley & sons, 1982.\n\nb. li\u02c6e\u02dcu and p. huard. la m\u00b4ethode des centres dans un espace topologique.\nnumerische mathematik, 8:56\u201367, 1966.\n\nc. l. lawson and r. j. hanson. solving least squares problems. society\nfor industrial and applied mathematics, 1995. first published in 1974 by\nprentice-hall.\n\ni. j. lustig, r. e. marsten, and d. f. shanno. interior point methods for\nlinear programming: computational state of the art. orsa journal on\ncomputing, 6(1):1\u201314, 1994.\n\na. s. lewis and m. l. overton. eigenvalue optimization. acta numerica,\n5:149\u2013190, 1996.\n\nj. l\u00a8ofberg. yalmip : a toolbox for modeling and optimization in mat-\nlab.\nin proceedings of the ieee international symposium on com-\nputer aided control systems design, pages 284\u2013289, 2004. available from\ncontrol.ee.ethz.ch/~joloef/yalmip.php.\nk. l\u00a8owner. \u00a8uber monotone matrixfunktionen. mathematische zeitschrift,\n38:177\u2013216, 1934.\n\nz.-q. luo, j. f. sturm, and s. zhang. conic convex programming and self-\ndual embedding. optimization methods and software, 14:169\u2013218, 2000.\n\nd. g. luenberger. quasi-convex programming. siam journal on applied\nmathematics, 16(5), 1968.\n\nd. g. luenberger. optimization by vector space methods. john wiley &\nsons, 1969.\n\nd. g. luenberger. linear and nonlinear programming. addison-wesley,\nsecond edition, 1984.\n\n "}, {"Page_number": 706, "text": "692\n\nreferences\n\n[lue95]\n\n[lue98]\n\n[luo03]\n\nd. g. luenberger. microeconomic theory. mcgraw-hill, 1995.\n\nd. g. luenberger. investment science. oxford university press, 1998.\n\nz.-q. luo. applications of convex optimization in signal processing and\ndigital communication. mathematical programming series b, 97:177\u2013207,\n2003.\n\n[lvbl98] m. s. lobo, l. vandenberghe, s. boyd, and h. lebret. applications of second-\norder cone programming. linear algebra and its applications, 284:193\u2013228,\n1998.\n\n[man65]\n\n[man94]\n\n[mar52]\n\n[mar56]\n\no. mangasarian. linear and nonlinear separation of patterns by linear pro-\ngramming. operations research, 13(3):444\u2013452, 1965.\n\no. mangasarian. nonlinear programming. society for industrial and applied\nmathematics, 1994. first published in 1969 by mcgraw-hill.\n\nh. markowitz. portfolio selection. the journal of finance, 7(1):77\u201391, 1952.\n\nh. markowitz. the optimization of a quadratic function subject to linear\nconstraints. naval research logistics quarterly, 3:111\u2013133, 1956.\n\n[mdw+02] w.-k. ma, t. n. davidson, k. m. wong, z.-q. luo, and p.-c. ching. quasi-\nmaximum-likelihood multiuser detection using semi-definite relaxation with\napplication to synchronous cdma. ieee transactions on signal processing,\n50:912\u2013922, 2002.\n\n[meh92]\n\n[mey00]\n\n[ml57]\n\n[mo60]\n\n[mo79]\n\n[mon97]\n\ns. mehrotra. on the implementation of a primal-dual interior point method.\nsiam journal on optimization, 2(4):575\u2013601, 1992.\n\nc. d. meyer. matrix analysis and applied linear algebra. society for in-\ndustrial and applied mathematics, 2000.\n\nm. marcus and l. lopes. inequalities for symmetric functions and hermitian\nmatrices. canadian journal of mathematics, 9:305\u2013312, 1957.\n\na. w. marshall and i. olkin. multivariate chebyshev inequalities. annals\nof mathematical statistics, 32(4):1001\u20131014, 1960.\n\na. w. marshall and i. olkin. inequalities: theory of majorization and its\napplications. academic press, 1979.\n\nr. d. c. monteiro. primal-dual path-following algorithms for semidefinite\nprogramming. siam journal on optimization, 7(3):663\u2013678, 1997.\n\n[mos02] mosek aps. the mosek optimization tools. user\u2019s manual and refer-\n\nence, 2002. available from www.mosek.com.\n\n[mot33]\n\n[mp68]\n\n[mr95]\n\n[mz89]\n\n[nes98]\n\n[nes00]\n\nt. motzkin. beitr\u00a8age zur theorie der linearen ungleichungen. phd thesis,\nuniversity of basel, 1933.\n\nr. f. meyer and j. w. pratt. the consistent assessment and fairing of pref-\nerence functions. ieee transactions on systems science and cybernetics,\n4(3):270\u2013278, 1968.\n\nr. motwani and p. raghavan. randomized algorithms. cambridge university\npress, 1995.\n\nm. morari and e. zafiriou. robust process control. prentice-hall, 1989.\n\ny. nesterov. semidefinite relaxations and nonconvex quadratic optimization.\noptimization methods and software, 9(1-3):141\u2013160, 1998.\n\ny. nesterov. squared functional systems and optimization problems.\nin\nj. frenk, c. roos, t. terlaky, and s. zhang, editors, high performance\noptimization techniques, pages 405\u2013440. kluwer, 2000.\n\n[nik54]\n\nh. nikaid\u02c6o. on von neumann\u2019s minimax theorem. pacific journal of math-\nematics, 1954.\n\n "}, {"Page_number": 707, "text": "references\n\n693\n\n[nn94]\n\n[nt98]\n\ny. nesterov and a. nemirovskii. interior-point polynomial methods in con-\nvex programming. society for industrial and applied mathematics, 1994.\n\ny. e. nesterov and m. j. todd. primal-dual interior-point methods for self-\nscaled cones. siam journal on optimization, 8(2):324\u2013364, 1998.\n\n[nw99]\n\nj. nocedal and s. j. wright. numerical optimization. springer, 1999.\n\n[nwy00] y. nesterov, h. wolkowicz, and y. ye. semidefinite programming relaxations\nof nonconvex quadratic optimization. in h. wolkowicz, r. saigal, and l. van-\ndenberghe, editors, handbook of semidefinite programming, chapter 13, pages\n361\u2013419. kluwer academic publishers, 2000.\n\n[ny83]\n\n[or00]\n\n[par71]\n\n[par98]\n\n[par00]\n\n[par03]\n\n[pet76]\n\n[pin95]\n\n[pol87]\n\n[pon67]\n\n[pr\u00b4e71]\n\n[pr\u00b4e73]\n\n[pr\u00b4e80]\n\na. nemirovskii and d. yudin. problem complexity and method efficiency in\noptimization. john wiley & sons, 1983.\n\nj. m. ortega and w. c. rheinboldt. iterative solution of nonlinear equations\nin several variables. society for industrial and applied mathematics, 2000.\nfirst published in 1970 by academic press.\n\nv. pareto. manual of political economy. a. m. kelley publishers, 1971.\ntranslated from the french edition. first published in italian in 1906.\n\nb. n. parlett. the symmetric eigenvalue problem. society for industrial and\napplied mathematics, 1998. first published in 1980 by prentice-hall.\n\np. a. parrilo. structured semidefinite programs and semialgebraic geometry\nmethods in robustness and optimization. phd thesis, california institute of\ntechnology, 2000.\n\np. a. parrilo. semidefinite programming relaxations for semialgebraic prob-\nlems. mathematical programming series b, 96:293\u2013320, 2003.\n\ne. l. peterson. geometric programming. siam review, 18(1):1\u201351, 1976.\n\nj. pinter. global optimization in action, volume 6 of nonconvex optimiza-\ntion and its applications. kluwer, 1995.\n\nb. t. polyak. introduction to optimization. optimization software, 1987.\ntranslated from russian.\n\nj. ponstein. seven kinds of convexity. siam review, 9(1):115\u2013119, 1967.\n\na. pr\u00b4ekopa. logarithmic concave measures with application to stochastic\nprogramming. acta scientiarum mathematicarum, 32:301\u2013315, 1971.\n\na. pr\u00b4ekopa. on logarithmic concave measures and functions. acta scien-\ntiarum mathematicarum, 34:335\u2013343, 1973.\n\na. pr\u00b4ekopa. logarithmic concave measures and related topics. in m. a. h.\ndempster, editor, stochastic programming, pages 63\u201382. academic press,\n1980.\n\n[pro01]\n\nj. g. proakis. digital communications. mcgraw-hill, fourth edition, 2001.\n\n[prt02]\n\n[ps98]\n\n[psu88]\n\n[puk93]\n\n[ren01]\n\nj. peng, c. roos, and t. terlaky. self-regularity. a new paradigm for\nprimal-dual interior-point algorithms. princeton university press, 2002.\n\nc. h. papadimitriou and k. steiglitz. combinatorial optimization. algo-\nrithms and complexity. dover publications, 1998. first published in 1982 by\nprentice-hall.\n\na. l. peressini, f. e. sullivan, and j. j. uhl. the mathematics of nonlinear\nprogramming. undergraduate texts in mathematics. springer, 1988.\n\nf. pukelsheim. optimal design of experiments. wiley & sons, 1993.\n\nj. renegar. a mathematical view of interior-point methods in convex op-\ntimization. society for industrial and applied mathematics, 2001.\n\n[roc70]\n\nr. t. rockafellar. convex analysis. princeton university press, 1970.\n\n "}, {"Page_number": 708, "text": "694\n\nreferences\n\n[roc89]\n\n[roc93]\n\n[rof92]\n\n[ros65]\n\n[ros99]\n\n[rtv97]\n\nr. t. rockafellar. conjugate duality and optimization. society for industrial\nand applied mathematics, 1989. first published in 1974.\nr. t. rockafellar. lagrange multipliers and optimality. siam review,\n35:183\u2013283, 1993.\nl. rudin, s. j. osher, and e. fatemi. nonlinear total variation based noise\nremoval algorithms. physica d, 60:259\u2013268, 1992.\nj. b. rosen. pattern separation by convex programming. journal of mathe-\nmatical analysis and applications, 10:123\u2013134, 1965.\ns. m. ross. an introduction to mathematical finance: options and other\ntopics. cambridge university press, 1999.\nc. roos, t. terlaky, and j.-ph. vial. theory and algorithms for linear\noptimization. an interior point approach. john wiley & sons, 1997.\n\n[rud76] w. rudin. principles of mathematical analysis. mcgraw-hill, 1976.\n[rv73]\n[rw97]\n\na. w. roberts and d. e. varberg. convex functions. academic press, 1973.\nd. ralph and s. j. wright. superlinear convergence of an interior-point\nmethod for monotone variational inequalities. in m. c. ferris and j.-s. pang,\neditors, complementarity and variational problems: state of the art, pages\n345\u2013385. society for industrial and applied mathematics, 1997.\nc. v. rao, s. j. wright, and j. b. rawlings. application of interior-point\nmethods to model predictive control. journal of optimization theory and\napplications, 99(3):723\u2013757, 1998.\ni. j. schoenberg. remarks to maurice fr\u00b4echet\u2019s article \u201csur la d\u00b4efinition\naxiomatique d\u2019une classe d\u2019espaces distanci\u00b4es vectoriellement applicable sur\nl\u2019espace de hilbert\u201d. annals of mathematics, 38(3):724\u2013732, 1935.\ns. schaible. bibliography in fractional programming. zeitschrift f\u00a8ur opera-\ntions research, 26:211\u2013241, 1982.\ns. schaible. fractional programming. zeitschrift f\u00a8ur operations research,\n27:39\u201354, 1983.\na. schrijver. theory of linear and integer programming. john wiley &\nsons, 1986.\nl. l. scharf. statistical signal processing. detection, estimation, and time\nseries analysis. addison wesley, 1991. with c\u00b4edric demeure.\ng. sigl, k. doll, and f. m. johannes. analytical placement: a linear or\nquadratic objective function? in proceedings of the 28th acm/ieee design\nautomation conference, pages 427\u2013432, 1991.\nc. scherer, p. gahinet, and m. chilali. multiobjective output-feedback\ncontrol via lmi optimization.\nieee transactions on automatic control,\n42(7):896\u2013906, 1997.\nn. sherwani. algorithms for vlsi design automation. kluwer academic\npublishers, third edition, 1999.\nn. z. shor. minimization methods for non-differentiable functions. springer\nseries in computational mathematics. springer, 1985.\nn. z. shor. the development of numerical methods for nonsmooth optimiza-\ntion in the ussr. in j. k. lenstra, a. h. g. rinnooy kan, and a. schri-\njver, editors, history of mathematical programming. a collection of personal\nreminiscences, pages 135\u2013139. centrum voor wiskunde en informatica and\nnorth-holland, amsterdam, 1991.\ng. sonnevend. an \u2018analytical centre\u2019 for polyhedrons and new classes of\nglobal algorithms for linear (smooth, convex) programming. in lecture notes\nin control and information sciences, volume 84, pages 866\u2013878. springer,\n1986.\n\n[rwr98]\n\n[sch35]\n\n[sch82]\n\n[sch83]\n\n[sch86]\n\n[sch91]\n\n[sdj91]\n\n[sgc97]\n\n[she99]\n\n[sho85]\n\n[sho91]\n\n[son86]\n\n "}, {"Page_number": 709, "text": "695\n\nreferences\n\n[spv99]\n\na. seifi, k. ponnambalam, and j. vlach. a unified approach to statisti-\ncal design centering of integrated circuits with correlated parameters. ieee\ntransactions on circuits and systems \u2014 i. fundamental theory and appli-\ncations, 46(1):190\u2013196, 1999.\n\n[srvk93]\n\ns. s. sapatnekar, v. b. rao, p. m. vaidya, and s.-m. kang. an exact\nsolution to the transistor sizing problem for cmos circuits using convex\noptimization. ieee transactions on computer-aided design of integrated\ncircuits and systems, 12(11):1621\u20131634, 1993.\n\n[ss01]\n\n[str80]\n\n[stu99]\n\n[sw70]\n\n[sw95]\n\n[ta77]\n\n[tb97]\n\n[ter96]\n\n[tib96]\n\n[tik90]\n\n[tit75]\n\n[tke88]\n\n[tod01]\n\n[tod02]\n\nb. sch\u00a8olkopf and a. smola. learning with kernels: support vector machines,\nregularization, optimization, and beyond. mit press, 2001.\n\ng. strang. linear algebra and its applications. academic press, 1980.\n\nj. f. sturm. using sedumi 1.02, a matlab toolbox for optimization over\nsymmetric cones. optimization methods and software, 11-12:625\u2013653, 1999.\navailable from sedumi.mcmaster.ca.\n\nj. stoer and c. witzgall. convexity and optimization in finite dimensions i.\nspringer-verlag, 1970.\n\nr. j. stern and h. wolkowicz. indefinite trust region subproblems and non-\nsymmetric eigenvalue perturbations. siam journal on optimization, 15:286\u2013\n313, 1995.\n\na. n. tikhonov and v. y. arsenin.\nv. h. winston & sons, 1977. translated from russian.\n\nsolutions of ill-posed problems.\n\nl. n. trefethen and d. bau, iii. numerical linear algebra. society for\nindustrial and applied mathematics, 1997.\n\nt. terlaky, editor. interior point methods of mathematical programming,\nvolume 5 of applied optimization. kluwer academic publishers, 1996.\n\nr. tibshirani. regression shrinkage and selection via the lasso. journal of\nthe royal statistical society, series b, 58(1):267\u2013288, 1996.\n\nv. m. tikhomorov. convex analysis. in r. v. gamkrelidze, editor, analy-\nsis ii: convex analysis and approximation theory, volume 14, pages 1\u201392.\nspringer, 1990.\n\nd. m. titterington. optimal design: some geometrical aspects of d-\noptimality. biometrika, 62(2):313\u2013320, 1975.\ns. tarasov, l. khachiyan, and i. `erlikh. the method of inscribed ellipsoids.\nsoviet mathematics doklady, 37(1):226\u2013230, 1988.\n\nm. j. todd. semidefinite optimization. acta numerica, 10:515\u2013560, 2001.\n\nm. j. todd. the many facets of linear programming. mathematical program-\nming series b, 91:417\u2013436, 2002.\n\n[ttt98] m. j. todd, k. c. toh, and r. h. t\u00a8ut\u00a8unc\u00a8u. on the nesterov-todd direction\nin semidefinite programming. siam journal on optimization, 8(3):769\u2013796,\n1998.\n\n[ttt02]\n\n[tuy98]\n\n[uhl79]\n\nk. c. toh, r. h. t\u00a8ut\u00a8unc\u00a8u, and m. j. todd. sdpt3. a matlab soft-\nware for semidefinite-quadratic-linear programming, 2002. available from\nwww.math.nus.edu.sg/~mattohkc/sdpt3.html.\n\nh. tuy. convex analysis and global optimization, volume 22 of nonconvex\noptimization and its applications. kluwer, 1998.\n\nf. uhlig. a recurring theorem about pairs of quadratic forms and extensions.\na survey. linear algebra and its applications, 25:219\u2013237, 1979.\n\n[val64]\n\nf. a. valentine. convex sets. mcgraw-hill, 1964.\n\n "}, {"Page_number": 710, "text": "696\n\nreferences\n\n[van84]\n\n[van96]\n\n[van97]\n\n[vap00]\n\n[vav91]\n\n[vb95]\n\n[vn63]\n\n[vn46]\n\n[vnm53]\n\n[vt84]\n\n[web71]\n\ng. n. vanderplaats. numerical optimization techniques for engineering\ndesign. mcgraw-hill, 1984.\n\nr. j. vanderbei. linear programming: foundations and extensions. kluwer,\n1996.\n\nr. j. vanderbei.\nwww.orfe.princeton.edu/~rvdb.\n\nloqo user\u2019s manual, 1997.\n\navailable from\n\nv. n. vapnik. the nature of statistical learning theory. springer, second\nedition, 2000.\n\ns. a. vavasis. nonlinear optimization: complexity issues. oxford university\npress, 1991.\n\nl. vandenberghe and s. boyd. semidefinite programming. siam review,\npages 49\u201395, 1995.\n\nj. von neumann. discussion of a maximum problem. in a. h. taub, editor,\njohn von neumann. collected works, volume vi, pages 89\u201395. pergamon\npress, 1963. unpublished working paper from 1947.\n\nj. von neumann. a model of general economic equilibrium. review of eco-\nnomic studies, 13(1):1\u20139, 1945-46.\n\nj. von neumann and o. morgenstern. theory of games and economic be-\nhavior. princeton university press, third edition, 1953. first published in\n1944.\n\nj. van tiel. convex analysis. an introductory text. john wiley & sons,\n1984.\n\na. weber. theory of the location of industries. russell & russell, 1971.\ntranslated from german by c. j. friedrich. first published in 1929.\n\n[web94]\n\nr. webster. convexity. oxford university press, 1994.\n\n[whi71]\n\np. whittle. optimization under constraints. john wiley & sons, 1971.\n\n[wol81]\n\n[wri97]\n\n[wsv00]\n\n[xhy96]\n\n[ye97]\n\n[ye99]\n\nh. wolkowicz. some applications of optimization in matrix theory. linear\nalgebra and its applications, 40:101\u2013118, 1981.\n\ns. j. wright. primal-dual interior-point methods. society for industrial and\napplied mathematics, 1997.\n\nh. wolkowicz, r. saigal, and l. vandenberghe, editors. handbook of semidef-\ninite programming. kluwer academic publishers, 2000.\n\nx. xu, p. hung, and y. ye. a simplified homogeneous and self-dual lin-\near programming algorithm and its implementation. annals of operations\nresearch, 62:151\u2013172, 1996.\n\ny. ye. interior point algorithms. theory and analysis. john wiley & sons,\n1997.\n\ny. ye. approximating quadratic programming with bound and quadratic\nconstraints. mathematical programming, 84:219\u2013226, 1999.\n\n[ytm94] y. ye, m. j. todd, and s. mizuno. an o(\u221anl)-iteration homogeneous and\nself-dual linear programming algorithm. mathematics of operations research,\n19:53\u201367, 1994.\n\n[zen71]\n\n[zha98]\n\nc. zener. engineering design by geometric programming. john wiley &\nsons, 1971.\n\ny. zhang. on extending some primal-dual interior-point algorithms from\nlinear programming to semidefinite programming. siam journal on opti-\nmization, 8(2):365\u2013386, 1998.\n\n "}, {"Page_number": 711, "text": "notation\n\nsome specific sets\n\nr\nrn\nrm\u00d7n\nr+, r++\nc\ncn\ncm\u00d7n\nz\nz+\nsn\n+, sn\nsn\n\n++\n\nreal numbers.\nreal n-vectors (n \u00d7 1 matrices).\nreal m \u00d7 n matrices.\nnonnegative, positive real numbers.\ncomplex numbers.\ncomplex n-vectors.\ncomplex m \u00d7 n matrices.\nintegers.\nnonnegative integers.\nsymmetric n \u00d7 n matrices.\nsymmetric positive semidefinite, positive definite, n \u00d7 n\nmatrices.\n\nvectors and matrices\n\nvector with all components one.\nith standard basis vector.\nidentity matrix.\ntranspose of matrix x.\nhermitian (complex conjugate) transpose of matrix x.\ntrace of matrix x.\nith largest eigenvalue of symmetric matrix x.\n\n1\nei\ni\nx t\nx h\ntr x\n\u03bbi(x)\n\u03bbmax(x), \u03bbmin(x) maximum, minimum eigenvalue of symmetric matrix x.\n\u03c3i(x)\n\u03c3max(x), \u03c3min(x) maximum, minimum singular value of matrix x.\nx \u2020\nx \u22a5 y\nv \u22a5\ndiag(x)\ndiag(x, y, . . .)\nrank a\nr(a)\nn (a)\n\nmoore-penrose or pseudo-inverse of matrix x.\nvectors x and y are orthogonal: xt y = 0.\northogonal complement of subspace v .\ndiagonal matrix with diagonal entries x1, . . . , xn.\nblock diagonal matrix with diagonal blocks x, y, . . ..\nrank of matrix a.\nrange of matrix a.\nnullspace of matrix a.\n\nith largest singular value of matrix x.\n\n "}, {"Page_number": 712, "text": "698\n\nnotation\n\nnorms and distances\n\nk \u00b7 k\nk \u00b7 k\u2217\nkxk2\nkxk1\nkxk\u221e\nkxk2\nb(c, r)\ndist(a, b)\n\na norm.\ndual of norm k \u00b7 k.\neuclidean (or \u21132-) norm of vector x.\n\u21131-norm of vector x.\n\u2113\u221e-norm of vector x.\nspectral norm (maximum singular value) of matrix x.\nball with center c and radius r.\ndistance between sets (or points) a and b.\n\ngeneralized inequalities\n\nx (cid:22) y\nx \u227a y\nx (cid:22) y\nx \u227a y\nx (cid:22)k y\nx \u227ak y\nx (cid:22)k \u2217 y\nx \u227ak \u2217 y\n\ncomponentwise inequality between vectors x and y.\nstrict componentwise inequality between vectors x and y\nmatrix inequality between symmetric matrices x and y .\nstrict matrix inequality between symmetric matrices x\nand y .\ngeneralized inequality induced by proper cone k.\nstrict generalized inequality induced by proper cone k.\ndual generalized inequality.\ndual strict generalized inequality.\n\ntopology and convex analysis\n\ncard c\nint c\nrelint c\ncl c\nbd c\nconv c\naff c\nk \u2217\nic\nsc\nf \u2217\n\nprobability\n\ne x\nprob s\nvar x\nn (c, \u03c3)\n\u03c6\n\ncardinality of set c.\ninterior of set c.\nrelative interior of set c.\nclosure of set c.\nboundary of set c: bd c = cl c \\ int c.\nconvex hull of set c.\naffine hull of set c.\ndual cone associated with k.\nindicator function of set c.\nsupport function of set c.\nconjugate function of f .\n\nexpected value of random vector x.\nprobability of event s.\nvariance of scalar random variable x.\ngaussian distribution with mean c, covariance (matrix) \u03c3.\ncumulative distribution function of n (0, 1) random vari-\nable.\n\n "}, {"Page_number": 713, "text": "notation\n\n699\n\nfunctions and derivatives\nf : a \u2192 b\ndom f\nepi f\n\u2207f\n\u22072f\ndf\n\nf is a function on the set dom f \u2286 a into the set b.\ndomain of function f .\nepigraph of function f .\ngradient of function f .\nhessian of function f .\nderivative (jacobian) matrix of function f .\n\n "}, {"Page_number": 714, "text": " "}, {"Page_number": 715, "text": "index\n\na-optimal experiment design, 387\nabstract form convex problem, 137\nactive constraint, 128\nactivity planning, 149, 195\naff (affine hull), 23\naffine\n\ncombination, 22\ndimension, 23\nfunction, 36\n\ncomposition, 79, 95, 508, 642, 645\n\nhull, 23\nindependence, 32\ninvariance, 486\n\nanalytic center, 449\nnewton decrement, 487\nnewton step, 527\nnewton\u2019s method, 494, 496\nself-concordance, 498\n\nset, 21\n\nseparation from convex set, 49\n\nalgorithm, see method\nalignment constraint, 442\nallocation\n\nasset, 155, 186, 209\npower, 196, 210, 212, 245\nresource, 253, 523, 559\n\nalternatives, 258, 285\n\ngeneralized inequalities, 54, 269\nlinear discrimination, 423\nlinear inequalities, 50, 63\nlinear matrix inequality, 287\nnonconvex quadratic, 655\nstrong, 260\nweak, 258\n\namplitude distribution, 294, 304\nanalytic center, 141, 419, 449, 458, 519, 535,\n\n541, 546, 547\n\naffine invariance, 449\ndual, 276, 525\nefficient line search, 518\nellipsoid, 420, 450\nlinear matrix inequality, 422, 459, 508,\n\n553\n\nmethod, 626\nml interpretation, 450\nquadratic inequalities, 519\n\nangle, 633\n\napproximation, 448\nconstraint, 406\nproblem, 405, 408\n\nanisotropy, 461\napproximate newton method, 519\napproximation\n\nchebyshev, 6, 293\ncomplex, 197\nfitting angles, 448\n\u21131-norm, 193, 294\nleast-squares, 293\nlog-chebyshev, 344\nmatrix norm, 194\nminimax, 293\nmonomial, 199\npenalty function, 294, 353\nregularized, 305\nresidual, 291\nrobust, 318\nsparse, 333\ntotal variation, 312\nvariable bounds, 301\nwidth, 121\nwith constraints, 301\n\narbitrage-free price, 263\narithmetic mean, 75\narithmetic-geometric mean inequality, 78\narrow matrix, 670\nasymptotic cone, 66\n\nbacktracking line search, 464\nbackward substitution, 666\nball, 30, 634\n\neuclidean, 29\n\nbanded matrix, 510, 546, 553, 669, 675\nbandwidth allocation, 210\nbarrier\n\ncone, 66\nfunction, 563\nmethod, 568\n\ncomplexity, 585, 595\nconvergence analysis, 577\nconvex-concave game, 627\ngeneralized inequalities, 596, 601, 605\ninfeasible start, 571\n\n "}, {"Page_number": 716, "text": "702\n\nindex\n\nlinear program, 616\nsecond-order cone program, 601\nsemidefinite program, 602, 618\n\nsecond-order cone programming, 599\nsemidefinite programming, 600\ntangent, 624\n\nbasis, 405\n\ndictionary, 333\ndual, 407\nfunctions, 326\nlagrange, 326\nover-complete, 333\npursuit, 310, 333, 580\nwell conditioned, 407\n\nbayesian\n\nclassification, 428\ndetector, 367\nestimation, 357\n\nbd (boundary), 50, 638\nbest linear unbiased estimator, 176\nbinary hypothesis testing, 370\nbisection method, 249, 430\n\nquasiconvex optimization, 146\n\nblas, 684\nblock\n\nelimination, 546, 554, 672\nlu factorization, 673\nmatrix inverse, 650\nseparable, 552\ntridiagonal, 553\n\nboolean linear program\n\nlagrangian relaxation, 276\nlp relaxation, 194\n\nboundary, 638\nbounding box, 433\nbounds\n\nchebyshev, 150, 374\nchernoff, 379\nconvex function values, 338\ncorrelation coefficients, 408\nexpected values, 361\nfor global optimization, 11\nprobabilities, 361\n\nbox constraints, 129\n\ncertificate\n\ninfeasibility, 259, 582\nsuboptimality, 241, 568\n\nchain rule, 642\n\nsecond derivative, 645\n\nchange of variable, 130\nchebyshev\n\napproximation, 6, 293\n\nlower bounds via least-squares, 274\nrobust, 323\n\nbounds, 150, 374\ncenter, 148, 416\ninequalities, 150, 154\nnorm, 635\n\nchernoff bounds, 379\ncholesky factorization, 118, 406, 509, 546,\n\n617, 669\n\nbanded matrix, 670\nsparse matrix, 670\n\ncircuit design, 2, 17, 432, 446\ncl (closure), 638\nclassification, 422\n\nbayesian, 428\nlinear, 423\nlogistic, 427\nnonlinear, 429\npolynomial, 430\nquadratic, 429\nsupport vector, 425\n\nclosed\n\nfunction, 458, 529, 577, 639\nset, 637\nsublevel set assumption, 457, 529\n\nclosure, 638\ncombination\n\naffine, 22\nconic, 25\nconvex, 24\n\ncantilever beam, 163, 199\ncapacity of communication channel, 207\ncard (cardinality), 98\n\n\u21131-norm heuristic, 310\n\ncauchy-schwartz inequality, 633\nceiling, 96\ncenter\n\nanalytic, 419\nchebyshev, 148, 416\nmaximum volume ellipsoid, 418\n\ncentral path, 564\nduality, 565\ngeneralized inequalities, 598\nkkt conditions, 567\npredictor-corrector, 625\n\ncommunication channel\n\ncapacity, 207\n\ndual, 279\n\npower allocation, 245\n\ncomplementary slackness, 242\n\ngeneralized inequalities, 267\n\ncomplex\n\nnorm approximation, 197\nsemidefinite program, 202\n\ncomplexity\n\nbarrier method, 585\n\ngeneralized inequalities, 605\n\nlinear equations, 662\nsecond-order cone program, 606\nsemidefinite program, 608\n\n "}, {"Page_number": 717, "text": "index\n\n703\n\ncomponentwise inequality, 32, 43\ncomposition, 83\n\naffine function, 508, 642, 645\nquasiconvexity, 102\nself-concordance, 499\n\nconcave\n\nfunction, 67\nmaximization problem, 137\n\ncond (condition number), 649\ncondition number, 203, 407, 649\n\nellipsoid, 461\ngradient method, 473\nnewton\u2019s method, 495\nset, 461\n\nconditional probability, 42, 357, 428\ncone, 25\n\nbarrier, 66\ndual, 51\neuclidean, 449\nhyperbolic, 39\nin r2, 64\nlexicographic, 64\nlorentz, 31\nmoments, 66\nmonotone nonnegative, 64\nnormal, 66\npointed, 43\npositive semidefinite, 34, 64\nprogram, 168\n\ndual, 266\n\nproper, 43\nrecession, 66\nsecond-order, 31, 449\nseparation, 66\nsolid, 43\n\nconic\n\ncombination, 25\nform problem, 168, 201\nhull, 25\n\nconjugate\n\nand lagrange dual, 221\nfunction, 90\n\nself-concordance, 517\n\nlogarithm, 607\n\nconstraint\n\nactive, 128\nbox, 129\nexplicit, 134\nhyperbolic, 197\nimplicit, 134\nkinematic, 247\nqualifications, 226\nredundant, 128\nset, 127\n\nconsumer preference, 339\ncontinuous function, 639\n\ncontrol\n\nmodel predictive, 17\noptimal, 194, 303, 552\n\nconv (convex hull), 24\nconvergence\n\ninfeasible newton method, 536\nlinear, 467\nnewton method, 529\nquadratic, 489, 539\n\nconvex\n\ncombination, 24\ncone, 25\nequality constraints, 191\nfunction, 67\n\nbounded, 114\nbounding values, 338\nfirst-order conditions, 69\ninterpolation, 337\ninverse, 114\nlevel set, 113\nover concave function, 103\nproduct, 119\n\ngeometric program, 162\nhull, 24\n\nfunction, 119\nminimizing over, 207\noptimization, 2, 7, 136\n\nabstract form, 137\n\nset, 23\n\nimage under linear-fractional func-\n\ntion, 62\n\nseparating hyperplane, 403\nseparation from affine set, 49\n\nconvex-concave, 238\n\nfractional problem, 191\nfunction, 115\n\nsaddle-point property, 281\n\ngame, 540, 542, 560\n\nbarrier method, 627\nbounded inverse derivative condition,\n\n559\n\nnewton method, 540\nnewton step, 559\n\nconvexity\n\nfirst-order condition, 69\nmatrix, 110\nmidpoint, 60\nsecond-order conditions, 71\nstrong, 459, 558\n\ncoordinate projection, 38\ncopositive matrix, 65, 202\ncorrelation coefficient, 406\n\nbounding, 408\n\ncost, 127\n\nrandom, 154\nrisk-sensitive, 155\n\n "}, {"Page_number": 718, "text": "704\n\nindex\n\ncovariance\n\nestimation, 355\nestimation error, 384\nincomplete information, 171\n\ncovering ellipsoid, 275\ncumulant generating function, 106\ncumulative distribution, 107\n\nlog-concavity, 124\n\ncurve\n\nminimum length piecewise-linear, 547\noptimal trade-off, 182\npiecewise-arc, 453\n\nd-optimal experiment design, 387\ndamped newton step, 489\ndata fitting, 2, 291\nde-noising, 310\ndeadzone-linear penalty function, 295, 434\n\ndual, 345\ndecomposition\n\neigenvalue, 646\ngeneralized eigenvalue, 647\northogonal, 646\nsingular value, 648\n\ndeconvolution, 307\ndegenerate ellipsoid, 30\ndensity function\n\nlog-concave, 104, 124, 352\n\ndepth, 416\nderivative, 640\n\nchain rule, 642\ndirectional, 642\npricing, 264\nsecond, 643\n\ndescent\n\ndirection, 463\nfeasible, 527\n\nmethod, 463\n\ngradient, 466\nsteepest, 475\n\ndesign\n\ncircuit, 2, 17, 432, 446\ndetector, 364\nof experiments, 384\noptimal, 292, 303\n\ndetector\n\nbayes, 367\ndesign, 364\nmap, 369\nminimax, 367\nml, 369\nrandomized, 365\nrobust, 372\ndeterminant, 73\n\nderivative, 641\n\ndevice sizing, 2\ndiagonal plus low rank, 511, 678\n\ndiagonal scaling, 163\ndictionary, 333\ndiet problem, 148\ndifferentiable function, 640\ndirectional derivative, 642\ndirichlet density, 124\ndiscrete memoryless channel, 207\ndiscrimination, 422\ndist (distance), 46, 634\ndistance, 46, 634\n\nbetween polyhedra, 154, 403\nbetween sets, 402\nconstraint, 443\nmaximum probability, 118\nratio function, 97\nto farthest point in set, 81\nto set, 88, 397\n\ndistribution\n\namplitude, 294\ngaussian, 104\nlaplacian, 352\nmaximum entropy, 362\npoisson, 353\nwishart, 105\n\ndom (domain), 639\ndomain\n\nfunction, 639\nproblem, 127\n\ndual\n\nbasis, 407\ncone, 51\n\nlogarithm, 607\nproperties, 64\n\nfeasibility equations, 521\nfeasible, 216\nfunction, 216\n\ngeometric interpretation, 232\n\ngeneralized inequality, 53\n\ncharacterization of minimal points,\n\n54\n\nleast-squares, 218\nlogarithm, 607\nnewton method, 557\nnorm, 93, 637\nproblem, 223\nresidual, 532\nspectral norm, 637\nstopping criterion, 242\nvariable, 215\n\nduality, 215\n\ncentral path, 565\ngame interpretation, 239\ngap, 241\n\noptimal, 226\nsurrogate, 612\n\nmulticriterion interpretation, 236\n\n "}, {"Page_number": 719, "text": "index\n\n705\n\nprice interpretation, 240\nsaddle-point interpretation, 237\nstrong, 226\nweak, 225\n\ndynamic activity planning, 149\n\ne-optimal experiment design, 387\neccentricity, 461\nei (ith unit vector), 33\neigenvalue\n\ndecomposition, 646\ngeneralized, 647\ninterlacing theorem, 122\nmaximum, 82, 203\noptimization, 203\nspread, 203\nsum of k largest, 118\nelectronic device sizing, 2\nelementary symmetric functions, 122\nelimination\n\nbanded matrix, 675\nblock, 546\nconstraints, 132\nequality constraints, 523, 542\nvariables, 672\n\nellipsoid, 29, 39, 635\n\ncondition number, 461\ncovering, 275\ndegenerate, 30\nintersection, 262\nl\u00a8owner-john, 410\nmaximum volume, 414\nminimum volume, 410\nseparation, 197\nvia analytic center, 420\nvolume, 407\n\nembedded optimization, 3\nentropy, 72, 90, 117\n\nmaximization, 537, 558, 560, 562\n\ndual function, 222\nself-concordance, 497\n\nepigraph, 75\n\nproblem, 134\n\nequality\n\nconstrained minimization, 521\nconstraint, 127\nconvex, 191\nelimination, 132, 523, 542\n\nequations\n\nkkt, 243\nnormal, 458\n\nequivalent\n\nnorms, 636\nproblems, 130\n\nestimation, 292\n\nbayesian, 357\ncovariance, 355\n\nleast-squares, 177\nlinear measurements, 352\nmaximum a posteriori, 357\nnoise free, 303\nnonparametric distribution, 359\nstatistical, 351\n\neuclidean\n\nball, 29\ndistance\n\nmatrix, 65\nproblems, 405\n\nnorm, 633\nprojection via pseudo-inverse, 649\n\nexact line search, 464\nexchange rate, 184\nexpanded set, 61\nexperiment design, 384\n\na-optimal, 387\nd-optimal, 387\ndual, 276\ne-optimal, 387\n\nexplanatory variables, 353\nexplicit constraint, 134\nexponential, 71\n\ndistribution, 105\nmatrix, 110\n\nextended-value extension, 68\nextrapolation, 333\nextremal volume ellipsoids, 410\n\nfacility location problem, 432\nfactor-solve method, 666\nfactorization\n\nblock lu, 673\ncholesky, 118, 546, 669\nldlt, 671\nlu, 668\nqr, 682\nsymbolic, 511\nfarkas lemma, 263\nfastest mixing markov chain, 173\n\ndual, 286\n\nfeasibility\n\nmethods, 579\nproblem, 128\n\nfeasible, 127\n\ndescent direction, 527\ndual, 216\npoint, 127\nproblem, 127\nset, 127\n\nfenchel\u2019s inequality, 94\nfirst-order\n\napproximation, 640\ncondition\n\nconvexity, 69\nmonotonicity, 109\n\n "}, {"Page_number": 720, "text": "706\n\nindex\n\nquasiconvexity, 99, 121\n\nfitting\n\nminimum norm, 331\npolynomial, 331\nspline, 331\n\nfloor planning, 438\n\ngeometric program, 444\n\nflop count, 662\nflow\n\noptimal, 193, 550, 619\n\nforward substitution, 665\nfractional program\n\ngeneralized, 205\nfrobenius norm, 634\nscaling, 163, 478\nfuel use map, 194, 213\nfunction\n\naffine, 36\nbarrier, 563\nclosed, 458, 529, 577, 639\ncomposition, 83\nconcave, 67\nconjugate, 90, 221\ncontinuous, 639\nconvex, 67\nconvex hull, 119\nconvex-concave, 115\nderivative, 640\ndifferentiable, 640\ndomain, 639\ndual, 216\nelementary symmetric, 122\nextended-value extension, 68\nfirst-order approximation, 640\nfitting, 324\ngradient, 641\nhuber, 345\ninterpolation, 324, 329\nlagrange dual, 216\nlagrangian, 215\nlegendre transform, 95\nlikelihood, 351\nlinear-fractional, 41\nlog barrier, 563\nlog-concave, 104\nlog-convex, 104\nmatrix monotone, 108\nmonomial, 160\nmonotone, 115\nnotation, 14, 639\nobjective, 127\npenalty, 294\nperspective, 39, 89, 117\npiecewise-linear, 119, 326\npointwise maximum, 80\nposynomial, 160\n\nprojection, 397\nprojective, 41\nquasiconvex, 95\nquasilinear, 122\nself-concordant, 497\nseparable, 249\nsupport, 63\nunimodal, 95\nutility, 115, 211, 339\n\ngame, 238\n\nadvantage of going second, 240\nbarrier method, 627\nbounded inverse condition, 559\ncontinuous, 239\nconvex-concave, 540, 542, 560\n\nnewton step, 559\n\nduality, 231\nduality interpretation, 239\nmatrix, 230\n\ngamma function, 104\n\nlog-convexity, 123\n\ngauss-newton method, 520\ngaussian distribution\n\nlog-concavity, 104, 123\n\ngeneralized\n\neigenvalue\n\ndecomposition, 647\nminimization, 204\nquasiconvexity, 102\n\nfractional program, 205\ngeometric program, 200\ninequality, 43\n\nbarrier method, 596, 601\ncentral path, 598\ndual, 53, 264\nlog barrier, 598\nlogarithm, 597\noptimization problem, 167\ntheorem of alternatives, 269\nlinear-fractional program, 152\nlogarithm, 597\n\ndual, 607\npositive semidefinite cone, 598\nsecond-order cone, 597\n\nposynomial, 200\n\ngeometric\n\nmean, 73, 75\n\nconjugate, 120\nmaximizing, 198\nprogram, 160, 199\n\nbarrier method, 573\nconvex form, 162\ndual, 256\nfloor planning, 444\nsensitivity analysis, 284\nunconstrained, 254, 458\n\n "}, {"Page_number": 721, "text": "index\n\n707\n\nglobal optimization, 10\n\nbounds, 11\n\ngp, see geometric program\ngradient, 641\n\nconjugate, 121\nlog barrier, 564\nmethod, 466\n\nand condition number, 473\nprojected, 557\n\ngram matrix, 405\n\nhalfspace, 27\n\nvoronoi description, 60\n\nhankel matrix, 65, 66, 170, 204\nharmonic mean, 116, 198\n\nlog-concavity, 122\n\nhessian, 71, 643\n\nconjugate, 121\nlipschitz continuity, 488\nlog barrier, 564\nsparse, 511\n\nh\u00a8older\u2019s inequality, 78\nhuber penalty function, 190, 299, 345\nhull\n\naffine, 23\nconic, 25\nconvex, 24\n\nhybrid vehicle, 212\nhyperbolic\n\ncone, 39\nconstraint, 197\nset, 61\n\nhyperplane, 27\n\nseparating, 46, 195, 423\nsupporting, 50\n\nhypothesis testing, 364, 370\n\niid noise, 352\nimplementation\n\nequality constrained methods, 542\ninterior-point methods, 615\nline search, 508\nnewton\u2019s method, 509\nunconstrained methods, 508\n\nimplicit constraint, 134\nlagrange dual, 257\n\nindicator function, 68, 92\n\nlinear approximation, 218\nprojection and separation, 401\n\ninduced norm, 636\ninequality\n\narithmetic-geometric mean, 75, 78\ncauchy-schwartz, 633\nchebyshev, 150, 154\ncomponentwise, 32, 43\nconstraint, 127\nfenchel\u2019s, 94\n\nform linear program, 147\n\ndual, 225\n\ngeneralized, 43\nh\u00a8older\u2019s, 78\ninformation, 115\njensen\u2019s, 77\nmatrix, 43, 647\ntriangle, 634\nyoung\u2019s, 94, 120\n\ninexact line search, 464\ninfeasibility certificate, 259\ninfeasible\n\nbarrier method, 571\nnewton method, 531, 534, 558\n\nconvergence analysis, 536\nphase i, 582\n\nproblem, 127\n\nweak duality, 273\n\ninfimum, 638\ninformation inequality, 115\ninner product, 633\ninput design, 307\ninterior, 637\n\nrelative, 23\n\ninterior-point\n\nmethod, 561\n\nimplementation, 615\n\nprimal-dual method, 609\n\ninternal rate of return, 97\ninterpolation, 324, 329\n\nleast-norm, 333\nwith convex function, 337\n\nintersection\n\nellipsoids, 262\nsets, 36\n\nint (interior), 637\ninverse\n\nconvex function, 114\nlinear-fractional function, 62\n\ninvestment\n\nlog-optimal, 559\nreturn, 208\n\nirr (internal rate of return), 97\n\njacobian, 640\njensen\u2019s inequality, 77\n\nquasiconvex function, 98\n\nkarush-kuhn-tucker, see kkt\nkinematic constraints, 247\nkkt\n\nconditions, 243\n\ncentral path, 567\ngeneralized inequalities, 267\nmechanics interpretation, 246\nmodified, 577\n\n "}, {"Page_number": 722, "text": "708\n\nindex\n\nsupporting hyperplane interpretation,\n\n283\n\nmatrix, 522\n\nbounded inverse assumption, 530\nnonsingularity, 523, 547\n\nsystem, 677\n\nnonsingularity, 557\nsolving, 542\n\nkullback-leibler divergence, 90, 115, 362\n\n\u21131-norm\n\napproximation, 294, 353, 514\n\nbarrier method, 617\n\nregularization, 308\nsteepest descent method, 477\n\nlagrange\n\nbasis, 326\ndual function, 216\ndual problem, 223\nmultiplier, 215\n\ncontact force interpretation, 247\nprice interpretation, 253\n\nlagrangian, 215\n\nrelaxation, 276, 654\n\nlapack, 684\nlaplace transform, 106\nlaplacian distribution, 352\nldlt factorization, 671\nleast-norm\n\ninterpolation, 333\nproblem, 131, 302\n\nleast-penalty problem, 304\n\nstatistical interpretation, 359\n\nleast-squares, 4, 131, 153, 177, 293, 304, 458\n\nconvex function fit, 338\ncost as function of weights, 81\ndual function, 218\nregularized, 184, 205\nrobust, 190, 300, 323\nstrong duality, 227\nlegendre transform, 95\nlength, 96, 634\nlevel set\n\nconvex function, 113\n\nlexicographic cone, 64\nlikelihood function, 351\nlikelihood ratio test, 371\nline, 21\n\nsearch, 464, 514\n\nbacktracking, 464\nexact, 464\nimplementation, 508\npre-computation, 518\nprimal-dual interior-point method, 612\n\nconvergence, 467\ndiscrimination, 423\nequality constraint\neliminating, 132\n\nequations\n\nbanded, 669\nblock elimination, 672\neasy, 664\nfactor-solve method, 666\nkkt system, 677\nlapack, 684\nleast-squares, 304\nlow rank update, 680\nlower triangular, 664\nmultiple righthand sides, 667\nnewton system, 510\northogonal, 666\nschur complement, 672\nsoftware, 684\nsolution set, 22\nsolving, 661\nsparse solution, 304\nsymmetric positive definite, 669\nunderdetermined, 681\nupper triangular, 665\n\nestimation, 292\n\nbest unbiased, 176\nfacility location, 432\ninequalities\n\nalternative, 261\nanalytic center, 458\nlog-barrier, 499\nsolution set, 27, 31\ntheorem of alternatives, 50, 54\n\nmatrix inequality, 38, 76, 82\n\nalternative, 270\nanalytic center, 422, 459, 508, 553\nmultiple, 169\nstrong alternatives, 287\n\nprogram, 1, 6, 146\n\nbarrier method, 571, 574\nboolean, 194, 276\ncentral path, 565\ndual, 224, 274\ndual function, 219\ninequality form, 147\nprimal-dual interior-point method, 613\nrandom constraints, 157\nrandom cost, 154\nrelaxation of boolean, 194\nrobust, 157, 193, 278\nstandard form, 146\nstrong duality, 227, 280\n\nsegment, 21\n\nlinear\n\nclassification, 423\n\nseparation\n\nellipsoids, 197\n\nlinear-fractional\n\n "}, {"Page_number": 723, "text": "index\n\n709\n\nfunction, 41\n\ncomposition, 102\nimage of convex set, 62\ninverse, 62\nquasiconvexity, 97\n\nprogram, 151\n\ngeneralized, 152\n\nlinearized optimality condition, 485\nlmi, see linear matrix inequality\nlocally optimal, 9, 128, 138\nlocation, 432\nlog barrier, 563\n\ngeneralized inequalities, 597, 598\ngradient and hessian, 564\nlinear inequalities, 499\nlinear matrix inequality, 459\npenalty function, 295\n\nlog-chebyshev approximation, 344, 629\nlog-concave\n\ndensity, 104, 352\nfunction, 104\n\nlog-convex function, 104\nlog-convexity\n\nperron-frobenius eigenvalue, 200\nsecond-order conditions, 105\n\nlog-determinant, 499\n\nfunction, 73\ngradient, 641\nhessian, 644\n\nlog-likelihood function, 352\nlog-optimal investment, 209, 559\nlog-sum-exp\n\nfunction, 72, 93\ngradient, 642\n\nlogarithm, 71\ndual, 607\ngeneralized inequality, 597\nself-concordance, 497\n\nlogistic\n\nclassification, 427\nfunction, 122\nmodel, 210\nregression, 354\n\nlorentz cone, 31\nlow rank update, 680\nlower triangular matrix, 664\nl\u00a8owner-john ellipsoid, 410\nlp, see linear progam\n\u2113p-norm, 635\n\ndual, 637\n\nlu factorization, 668\n\nmanufacturing yield, 211\nmap, see maximum a posteriori probability\nmarkov chain\n\nequilibrium distribution, 285\nestimation, 394\n\nfastest mixing, 173\n\ndual, 286\n\nmarkowitz portfolio optimization, 155\nmatrix\n\narrow, 670\nbanded, 510, 546, 553, 669, 675\nblock inverse, 650\ncompletion problem, 204\ncondition number, 649\nconvexity, 110, 112\ncopositive, 65, 202\ndetection probabilities, 366\ndiagonal plus low rank, 511, 678\neuclidean distance, 65\nexponential, 110\nfactorization, 666\nfractional function, 76, 82, 89\nfractional minimization, 198\ngame, 230\ngram, 405\nhankel, 65, 66, 170, 204\nhessian, 643\ninequality, 43, 647\ninverse\n\nmatrix convexity, 124\n\ninversion lemma, 515, 678\nkkt, 522\n\nnonsingularity, 557\nlow rank update, 680\nminimal upper bound, 180\nmonotone function, 108\nmultiplication, 663\nnode incidence, 551\nnonnegative, 165\nnonnegative definite, 647\nnorm, 82\n\napproximation, 194\nminimization, 169\n\northogonal, 666\np0, 202\npermutation, 666\npositive definite, 647\npositive semidefinite, 647\npower, 110, 112\npseudo-inverse, 649\nquadratic function, 111\nsparse, 511\nsquare-root, 647\n\nmax function, 72\n\nconjugate, 120\n\nmax-min\n\ninequality, 238\nproperty, 115, 237\n\nmax-row-sum norm, 194, 636\nmaximal element, 45\nmaximization problem, 129\n\n "}, {"Page_number": 724, "text": "710\n\nindex\n\nconcave, 137\n\nmaximum\n\na posteriori probability estimation, 357\ndeterminant matrix completion, 204\neigenvalue, 82, 203\nelement, 45\nentropy, 254, 558\n\ndistribution, 362\ndual, 248\nstrong duality, 228\n\nlikelihood\n\ndetector, 369\nestimation, 351\n\nprobability distance, 118\nsingular value, 82, 649\n\ndual, 637\nminimization, 169\nnorm, 636\n\nvolume\n\nellipsoid, 414\nrectangle, 449, 629\n\nmean\n\nharmonic, 116\n\nmethod\n\nanalytic centers, 626\nbarrier, 568\nbisection, 146\ndescent, 463\nfactor-solve, 666\nfeasibility, 579\ngauss-newton, 520\ninfeasible start newton, 534\ninterior-point, 561\nlocal optimization, 9\nnewton\u2019s, 484\nphase i, 579\nprimal-dual, 609\nrandomized, 11\nsequential unconstrained minimization,\n\n569\n\nsteepest descent, 475\n\nmidpoint convexity, 60\nminimal\n\nelement, 45\n\nvia dual inequalities, 54\n\nsurface, 159\n\nminimax\n\nangle fitting, 448\napproximation, 293\ndetector, 367\n\nminimization\n\nequality constrained, 521\n\nminimizing\n\nsequence, 457\n\nminimum\n\nelement, 45\n\nvia dual inequalities, 54\n\nfuel optimal control, 194\nlength piecewise-linear curve, 547\nnorm\n\nfitting, 331\n\nsingular value, 649\nvariance linear unbiased estimator, 176\nvolume ellipsoid\ndual, 222, 228\n\nminkowski function, 119\nmixed strategy matrix game, 230\nml, see maximum likelihood\nmodel predictive control, 17\nmoment, 66\n\nbounds, 170\nfunction\n\nlog-concavity, 123\n\ngenerating function, 106\nmultidimensional, 204\n\nmonomial, 160\n\napproximation, 199\n\nmonotone\n\nmapping, 115\nnonnegative cone, 64\nvector function, 108\n\nmonotonicity\n\nfirst-order condition, 109\n\nmoore-penrose inverse, 649\nmotzkin\u2019s theorem, 447\nmulticriterion\n\ndetector design, 368\noptimization, 181\nproblem, 181\n\nscalarization, 183\n\nmultidimensional moments, 204\nmultiplier, 215\nmutual information, 207\n\nn (nullspace), 646\nnetwork\n\noptimal flow, 193, 550\nrate optimization, 619, 628\n\nnewton\n\ndecrement, 486, 515, 527\ninfeasible start method, 531\nmethod, 484\n\naffine invariance, 494, 496\napproximate, 519\nconvergence analysis, 529, 536\nconvex-concave game, 540\ndual, 557\nequality constraints, 525, 528\nimplementing, 509\ninfeasible, 558\nself-concordance, 531\ntrust region, 515\n\nstep\n\n "}, {"Page_number": 725, "text": "index\n\n711\n\naffine invariance, 527\nequality constraints, 526\nprimal-dual, 532\n\nsystem, 510\n\nneyman-pearson lemma, 371\nnode incidence matrix, 551\nnonconvex\n\noptimization, 9\nquadratic problem\n\nstrong duality, 229\n\nnonlinear\n\nclassification, 429\nfacility location problem, 434\noptimization, 9\nprogramming, 9\n\nnonnegative\n\ndefinite matrix, 647\nmatrix, 165\northant, 32, 43\n\nminimization, 142\n\npolynomial, 44, 65\n\nnonparametric distribution estimation, 359\nnorm, 72, 93, 634\n\napproximation, 291\nby quadratic, 636\ndual, 254\ndual function, 221\nweighted, 293\n\nball, 30\ncone, 31\n\ndual, 52\n\nconjugate, 93\ndual, 637\nequivalence, 636\neuclidean, 633\nfrobenius, 634\ninduced, 636\nmatrix, 82\nmax-row-sum, 636\nmaximum singular value, 636\noperator, 636\nquadratic, 635\n\napproximation, 413\n\nspectral, 636\nsum-absolute-value, 635\n\nnormal\n\ncone, 66\ndistribution\n\nlog-concavity, 104\nequations, 458, 510\nvector, 27\n\nnormalized entropy, 90\nnuclear norm, 637\nnullspace, 646\n\nobjective function, 127\nopen set, 637\n\noperator norm, 636\noptimal\n\nactivity levels, 195\nallocation, 523\nconsumption, 208\ncontrol, 194, 303, 552\nhybrid vehicle, 212\nminimum fuel, 194\n\ndesign, 292, 303\ndetector design, 364\nduality gap, 226\ninput design, 307\nlagrange multipliers, 223\nlocally, 9\nnetwork flow, 550\npareto, 57\npoint, 128\n\nlocal, 138\n\nresource allocation, 559\nset, 128\ntrade-off analysis, 182\nvalue, 127, 175\n\nbound via dual function, 216\n\noptimality\n\nconditions, 241\n\ngeneralized inequalities, 266\nkkt, 243\nlinearized, 485, 526\n\noptimization\n\nconvex, 7\nembedded, 3\nglobal, 10\nlocal, 9\nmulticriterion, 181\nnonlinear, 9\nover polynomials, 203\nproblem, 127\n\nepigraph form, 134\nequivalent, 130\nfeasibility, 128\nfeasible, 127\ngeneralized inequalities, 167\nmaximization, 129\noptimal value, 127\nperturbation analysis, 249, 250\nsensitivity analysis, 250\nstandard form, 127\nsymmetry, 189\nrecourse, 211, 519\nrobust, 208\ntwo-stage, 211, 519\nvariable, 127\nvector objective, 174\n\noptimizing\n\nover some variables, 133\n\noption pricing, 285\n\n "}, {"Page_number": 726, "text": "712\n\nindex\n\noracle problem description, 136\nordering\n\nlexicographic, 64\n\northogonal\n\ncomplement, 27\ndecomposition, 646\nmatrix, 666\n\noutliers, 298\noutward normal vector, 27\nover-complete basis, 333\n\nparameter problem description, 136\nparametric distribution estimation, 351\npareto optimal, 57, 177, 206\npartial\n\nordering via cone, 43\nsum, 62\n\npartitioning problem, 219, 629\n\ndual, 226\ndual function, 220\neigenvalue bound, 220\nsemidefinite program relaxation, 285\n\npattern recognition, 422\npenalty function\n\napproximation, 294\ndeadzone-linear, 295\nhuber, 299\nlog barrier, 295\nrobust, 299, 343\nstatistical interpretation, 353\n\npermutation matrix, 666\nperron-frobenius eigenvalue, 165\n\nlog-convexity, 200\nperspective, 39, 89, 117\n\nconjugate, 120\nfunction, 207\nimage of polyhedron, 62\n\nperturbed optimization problem, 250\nphase i method, 579\ncomplexity, 592\ninfeasible start, 582\nsum of infeasibilities, 580\n\npiecewise\n\narc, 453\npolynomial, 327\n\npiecewise-linear\n\ncurve\n\nminimum length, 547\n\nfunction, 80, 119, 326\n\nconjugate, 120\n\nminimization, 150, 562\n\ndual, 275\n\npin-hole camera, 39\nplacement, 432\n\nquadratic, 434\n\npoint\n\nminimal, 45\n\nminimum, 45\n\npointed cone, 43\npointwise maximum, 80\npoisson distribution, 353\npolyhedral uncertainty\n\nrobust linear program, 278\n\npolyhedron, 31, 38\n\nchebyshev center, 148, 417\nconvex hull description, 34\ndistance between, 154, 403\neuclidean projection on, 398\nimage under perspective, 62\nvolume, 108\nvoronoi description, 60\n\npolynomial\n\nclassification, 430\nfitting, 326, 331\ninterpolation, 326\nlog-concavity, 123\nnonnegative, 44, 65, 203\npiecewise, 327\npositive semidefinite, 203\nsum of squares, 203\ntrigonometric, 116, 326\n\npolytope, 31\nportfolio\n\nbounding risk, 171\ndiversification constraint, 279\nlog-optimal, 209\nloss risk constraints, 158\noptimization, 2, 155\nrisk-return trade-off, 185\n\npositive\n\ndefinite matrix, 647\nsemidefinite\n\ncone, 34, 36, 64\nmatrix, 647\nmatrix completion, 204\npolynomial, 203\n\nposynomial, 160\n\ngeneralized, 200\ntwo-term, 200\n\npower allocation, 196\n\nbroadcast channel, 210\ncommunication channel, 210\nhybrid vehicle, 212\n\npower function, 71\nconjugate, 120\nlog-concavity, 104\n\npre-computation for line search, 518\npredictor-corrector method, 625\npreference relation, 340\npresent value, 97\nprice, 57\n\narbitrage-free, 263\ninterpretation of duality, 240\n\n "}, {"Page_number": 727, "text": "index\n\noption, 285\nshadow, 241\n\nprimal residual, 532\nprimal-dual\n\nmethod, 609\n\ngeometric program, 613\nlinear program, 613\n\nnewton step, 532\nsearch direction, 609\n\nprobability\n\nconditional, 42\ndistribution\n\nconvex sets, 62\nmaximum distance, 118\n\nsimplex, 33\n\nproblem\n\nconic form, 168\ncontrol, 303\nconvex, 136\ndata, 136\ndual, 223\nequality constrained, 521\nestimation, 292\neuclidean distance and angle, 405\nfloor planning, 438\nlagrange dual, 223\nleast-norm, 302\nleast-penalty, 304\nlocation, 432\nmatrix completion, 204\nmaximization, 129\nmulticriterion, 181\nnorm approximation, 291\noptimal design, 292, 303\npartitioning, 629\nplacement, 432\nquasiconvex, 137\nregression, 291\nregressor selection, 310\nunbounded below, 128\nunconstrained, 457\nunconstrained quadratic, 458\n\nproduct\n\nconvex functions, 119\ninner, 633\n\nproduction frontier, 57\nprogram\n\ngeometric, 160\nlinear, 146\nquadratic, 152\nquadratically constrained quadratic, 152\nsemidefinite, 168, 201\n\nprojected gradient method, 557\nprojection\n\ncoordinate, 38\neuclidean, 649\n\n713\n\nfunction, 397\nindicator and support function, 401\non affine set, 304\non set, 397\non subspace, 292\nprojective function, 41\nproper cone, 43\npsd (positive semidefinite), 203\npseudo-inverse, 88, 141, 153, 177, 185, 305,\n\n649\n\nqcqp (quadratically constrained quadratic\n\nprogram), 152\n\nqp (quadratic program), 152\nqr factorization, 682\nquadratic\n\nconvergence, 489, 539\ndiscrimination, 429\nfunction\n\nconvexity, 71\ngradient, 641\nhessian, 644\nminimizing, 140, 514\n\ninequalities\n\nanalytic center, 519\n\ninequality\n\nsolution set, 61\n\nmatrix function, 111\nminimization, 458, 649\n\nequality constraints, 522\n\nnorm, 635\n\napproximation, 636\n\nnorm approximation, 413\noptimization, 152, 196\nplacement, 434\nproblem\n\nstrong duality, 229\n\nprogram, 152\n\nprimal-dual interior-point method, 630\nrobust, 198\n\nsmoothing, 312\n\nquadratic-over-linear function, 72, 76\n\nminimizing, 514\n\nquadratically constrained quadratic program,\n\n152, 196\n\nstrong duality, 227\n\nquartile, 62, 117\nquasi-newton methods, 496\nquasiconvex\n\nfunction, 95\n\nconvex representation, 103\nfirst-order conditions, 99, 121\njensen\u2019s inequality, 98\nsecond-order conditions, 101\n\noptimization, 137\n\nvia convex feasibility, 145\n\nquasilinear function, 122\n\n "}, {"Page_number": 728, "text": "714\n\nindex\n\nr (range), 645\nr (reals), 14\nr+ (nonnegative reals), 14\nr++ (positive reals), 14\nrn\nrandomized\n\n+ (nonnegative orthant), 32\n\nalgorithm, 11\ndetector, 365, 395\nstrategy, 230\n\nrange, 645\nrank, 645\n\nquasiconcavity, 98\n\nratio of distances, 97\nrecession cone, 66\nreconstruction, 310\nrecourse, 211, 519\nrectangle, 61\n\nmaximum volume, 449, 629\n\nredundant constraint, 128\nregression, 153, 291\n\nlogistic, 354\nrobust, 299\n\nregressor, 291\n\nselection, 310, 334\n\nregularization, 5\n\n\u21131, 308\nsmoothing, 307\ntikhonov, 306\n\nregularized\n\napproximation, 305\nleast-squares, 184, 205\n\nrelative\n\nentropy, 90\ninterior, 23\npositioning constraint, 439\n\nresidual, 291\n\namplitude distribution, 296\ndual, 532\nprimal, 532\n\nresource allocation, 559\nrestricted set, 61\nriccati recursion, 553\nriesz-fej\u00b4er theorem, 348\nrisk-return trade-off, 185\nrisk-sensitive cost, 155\nrobust\n\napproximation, 318\nchebyshev approximation, 323\ndetector, 372\nleast-squares, 190, 300, 323\nlinear discrimination, 424\nlinear program, 157, 193, 278\noptimization, 208\npenalty function, 299, 343\nquadratic program, 198\nregression, 299\n\nsn (symmetric n \u00d7 n matrices), 34\nstandard inner product, 633\nsn\n+ (positive semidefinite n \u00d7 n matrices),\nsaddle-point, 115\n\n34\n\nconvex-concave function, 281\nduality interpretation, 237\nvia newton\u2019s method, 627\nscalarization, 178, 206, 306, 368\nduality interpretation, 236\nmulticriterion problem, 183\n\nscaling, 38\nschur complement, 76, 88, 124, 133, 546,\n\n650, 672\n\nsdp, see semidefinite program\nsearch direction, 463\n\nnewton, 484, 525\nprimal-dual, 609\nsecond derivative, 643\n\nchain rule, 645\n\nsecond-order\n\nconditions\n\nconvexity, 71\nlog-convexity, 105\nquasiconvexity, 101\n\ncone, 31, 449\n\ngeneralized logarithm, 597\n\ncone program, 156\n\nbarrier method, 601\ncentral path, 599\ncomplexity, 606\ndual, 287\n\nsegment, 21\nself-concordance, 496, 516\n\nbarrier method complexity, 585\ncomposition, 499\nconjugate function, 517\nnewton method with equality constraints,\n\n531\n\nsemidefinite program, 168, 201\nbarrier method, 602, 618\ncentral path, 600\ncomplex, 202\ncomplexity, 608\ndual, 265\nrelaxation\n\npartitioning problem, 285\n\nsensitivity analysis, 250\n\ngeometric program, 284\n\nseparable\n\nblock, 552\nfunction, 249\n\nseparating\n\naffine and convex set, 49\ncones, 66\nconvex sets, 403, 422\n\n "}, {"Page_number": 729, "text": "index\n\n715\n\nhyperplane, 46, 195, 423\nconverse theorem, 50\nduality proof, 235\npolyhedra, 278\ntheorem proof, 46\n\npoint and convex set, 49, 399\npoint and polyhedron, 401\nsphere, 195\nstrictly, 49\n\nset\n\naffine, 21\nboundary, 638\nclosed, 637\nclosure, 638\ncondition number, 461\nconvex, 23\ndistance between, 402\ndistance to, 397\neccentricity, 461\nexpanded, 61\nhyperbolic, 61\nintersection, 36\nopen, 637\nprojection, 397\nrectangle, 61\nrestricted, 61\nslab, 61\nsublevel, 75\nsum, 38\nsuperlevel, 75\nwedge, 61\nwidth, 461\n\nshadow price, 241, 253\nsignomial, 200\nsimplex, 32\n\nprobability, 33\nunit, 33\nvolume, 407\nsingular value, 82\n\ndecomposition, 648\n\nslab, 61\nslack variable, 131\nslater\u2019s condition, 226\n\ngeneralized inequalities, 265\nproof of strong duality, 234\n\nsmoothing, 307, 310\nquadratic, 312\n\nsocp, see second-order cone program\nsolid cone, 43\nsolution set\n\nlinear equations, 22\nlinear inequality, 27\nlinear matrix inequality, 38\nquadratic inequality, 61\nstrict linear inequalities, 63\n\nsparse\n\napproximation, 333\ndescription, 334\nmatrix, 511\n\ncholesky factorization, 670\nlu factorization, 669\n\nsolution, 304\nvectors, 663\n\nspectral\n\ndecomposition, 646\nnorm, 636\n\ndual, 637\nminimization, 169\n\nsphere\n\nseparating, 195\n\nspline, 327\n\nfitting, 331\n\nspread of eigenvalues, 203\nsquare-root of matrix, 647\nstandard form\n\ncone program, 168\n\ndual, 266\n\nlinear program, 146\n\ndual, 224\n\nstandard inner product, 633\n\nsn, 633\n\nstatistical estimation, 351\nsteepest descent method, 475\n\n\u21131-norm, 477\n\nstep length, 463\nstopping criterion via duality, 242\nstrict\n\nlinear inequalities, 63\nseparation, 49\n\nstrong\n\nalternatives, 260\nconvexity, 459, 558\nduality, 226\n\nlinear program, 280\nmax-min property, 238\n\nconvex-concave function, 281\n\nsublevel set, 75\n\nclosedness assumption, 457\ncondition number, 461\n\nsuboptimality\n\ncertificate, 241\ncondition, 460\n\nsubstitution of variable, 130\nsum\n\nof k largest, 80\n\nconjugate, 120\nsolving via dual, 278\n\nof squares, 203\npartial, 62\nsets, 38\n\nsos (sum of squares), 203\n\nsum-absolute-value norm, 635\n\n "}, {"Page_number": 730, "text": "716\n\nindex\n\nsumt (sequential unconstrained minimiza-\n\ntion method), 569\n\nsuperlevel set, 75\nsupport function, 63, 81, 92, 120\n\nprojection and separation, 401\n\nsupport vector classifier, 425\nsupporting hyperplane, 50\nconverse theorem, 63\nkkt conditions, 283\ntheorem, 51\n\nsupremum, 638\nsurface\n\narea, 159\noptimal trade-off, 182\nsurrogate duality gap, 612\nsvd (singular value decomposition), 648\nsymbolic factorization, 511\nsymmetry, 189\n\nconstraint, 442\n\ntheorem\n\nalternatives, 50, 54, 258\n\ngeneralized inequalities, 269\n\neigenvalue interlacing, 122\ngauss-markov, 188\nmotzkin, 447\nperron-frobenius, 165\nriesz-fej\u00b4er, 348\nseparating hyperplane, 46\nslater, 226\nsupporting hyperplane, 51\n\ntikhonov regularization, 306\ntime-frequency analysis, 334\ntotal variation reconstruction, 312\ntrade-off analysis, 182\ntransaction fee, 155\ntranslation, 38\ntriangle inequality, 634\ntriangularization, 326\ntrigonometric polynomial, 116, 326\ntrust region, 302\n\nnewton method, 515\nproblem, 229\n\nupper triangular matrix, 665\nutility function, 115, 130, 211, 339\n\nvariable\n\nchange of, 130\ndual, 215\nelimination, 672\nexplanatory, 353\noptimization, 127\nslack, 131\n\nvector\n\nnormal, 27\noptimization, 174\n\nscalarization, 178\n\nverification, 10\nvolume\n\nellipsoid, 407\npolyhedron, 108\nsimplex, 407\n\nvon neuman growth problem, 152\nvoronoi region, 60\n\nwater-filling method, 245\nweak\n\nalternatives, 258\nduality, 225\n\ninfeasible problems, 273\n\nmax-min inequality, 281\n\nwedge, 61\nweight vector, 179\nweighted\n\nleast-squares, 5\nnorm approximation, 293\n\nwell conditioned basis, 407\nwidth, 461\nwireless communication system, 196\nwishart distribution, 105\nworst-case\n\nanalysis, 10\nrobust approximation, 319\n\nyield function, 107, 211\nyoung\u2019s inequality, 94, 120\n\ntwo-stage optimization, 519\ntwo-way partitioning problem, see partition-\n\nz (integers), 697\n\ning problem\n\nunbounded below, 128\nuncertainty ellipsoid, 322\nunconstrained minimization, 457\n\nmethod, 568\n\nunderdetermined linear equations, 681\nuniform distribution, 105\nunimodal function, 95\nunit\n\nball, 634\nsimplex, 33\n\n "}]}